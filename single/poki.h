#pragma once
#define PK_SINGLE_HEADER
#define SOKOL_NO_DEPRECATED

#ifdef POKI_IMPL
#define SOKOL_IMPL
#define SOKOL_SHDC_IMPL
#define CUTE_PNG_IMPLEMENTATION
#define QOI_IMPLEMENTATION
#define M3D_IMPLEMENTATION
#define CGLTF_IMPLEMENTATION
#endif // POKI_IMPL

//FILE_START:deps/sokol_gfx.h
#if defined(SOKOL_IMPL) && !defined(SOKOL_GFX_IMPL)
#define SOKOL_GFX_IMPL
#endif
#ifndef SOKOL_GFX_INCLUDED
/*
    sokol_gfx.h -- simple 3D API wrapper

    Project URL: https://github.com/floooh/sokol

    Example code: https://github.com/floooh/sokol-samples

    Do this:
        #define SOKOL_IMPL or
        #define SOKOL_GFX_IMPL
    before you include this file in *one* C or C++ file to create the
    implementation.

    In the same place define one of the following to select the rendering
    backend:
        #define SOKOL_GLCORE
        #define SOKOL_GLES3
        #define SOKOL_D3D11
        #define SOKOL_METAL
        #define SOKOL_WGPU
        #define SOKOL_DUMMY_BACKEND

    I.e. for the desktop GL it should look like this:

    #include ...
    #include ...
    #define SOKOL_IMPL
    #define SOKOL_GLCORE
    #include "sokol_gfx.h"

    The dummy backend replaces the platform-specific backend code with empty
    stub functions. This is useful for writing tests that need to run on the
    command line.

    Optionally provide the following defines with your own implementations:

    SOKOL_ASSERT(c)             - your own assert macro (default: assert(c))
    SOKOL_UNREACHABLE()         - a guard macro for unreachable code (default: assert(false))
    SOKOL_GFX_API_DECL          - public function declaration prefix (default: extern)
    SOKOL_API_DECL              - same as SOKOL_GFX_API_DECL
    SOKOL_API_IMPL              - public function implementation prefix (default: -)
    SOKOL_TRACE_HOOKS           - enable trace hook callbacks (search below for TRACE HOOKS)
    SOKOL_EXTERNAL_GL_LOADER    - indicates that you're using your own GL loader, in this case
                                  sokol_gfx.h will not include any platform GL headers and disable
                                  the integrated Win32 GL loader

    If sokol_gfx.h is compiled as a DLL, define the following before
    including the declaration or implementation:

    SOKOL_DLL

    On Windows, SOKOL_DLL will define SOKOL_GFX_API_DECL as __declspec(dllexport)
    or __declspec(dllimport) as needed.

    If you want to compile without deprecated structs and functions,
    define:

    SOKOL_NO_DEPRECATED

    Optionally define the following to force debug checks and validations
    even in release mode:

    SOKOL_DEBUG - by default this is defined if _DEBUG is defined

    sokol_gfx DOES NOT:
    ===================
    - create a window, swapchain or the 3D-API context/device, you must do this
      before sokol_gfx is initialized, and pass any required information
      (like 3D device pointers) to the sokol_gfx initialization call

    - present the rendered frame, how this is done exactly usually depends
      on how the window and 3D-API context/device was created

    - provide a unified shader language, instead 3D-API-specific shader
      source-code or shader-bytecode must be provided (for the "official"
      offline shader cross-compiler / code-generator, see here:
      https://github.com/floooh/sokol-tools/blob/master/docs/sokol-shdc.md)


    STEP BY STEP
    ============
    --- to initialize sokol_gfx, after creating a window and a 3D-API
        context/device, call:

            sg_setup(const sg_desc*)

        Depending on the selected 3D backend, sokol-gfx requires some
        information about its runtime environment, like a GPU device pointer,
        default swapchain pixel formats and so on. If you are using sokol_app.h
        for the window system glue, you can use a helper function provided in
        the sokol_glue.h header:

            #include "sokol_gfx.h"
            #include "sokol_app.h"
            #include "sokol_glue.h"
            //...
            sg_setup(&(sg_desc){
                .environment = sglue_environment(),
            });

        To get any logging output for errors and from the validation layer, you
        need to provide a logging callback. Easiest way is through sokol_log.h:

            #include "sokol_log.h"
            //...
            sg_setup(&(sg_desc){
                //...
                .logger.func = slog_func,
            });

    --- create resource objects (at least buffers, shaders and pipelines,
        and optionally images, samplers and render/compute-pass-attachments):

            sg_buffer sg_make_buffer(const sg_buffer_desc*)
            sg_image sg_make_image(const sg_image_desc*)
            sg_sampler sg_make_sampler(const sg_sampler_desc*)
            sg_shader sg_make_shader(const sg_shader_desc*)
            sg_pipeline sg_make_pipeline(const sg_pipeline_desc*)
            sg_attachments sg_make_attachments(const sg_attachments_desc*)

    --- start a render- or compute-pass:

            sg_begin_pass(const sg_pass* pass);

        Typically, render passes render into an externally provided swapchain which
        presents the rendering result on the display. Such a 'swapchain pass'
        is started like this:

            sg_begin_pass(&(sg_pass){ .action = { ... }, .swapchain = sglue_swapchain() })

        ...where .action is an sg_pass_action struct containing actions to be performed
        at the start and end of a render pass (such as clearing the render surfaces to
        a specific color), and .swapchain is an sg_swapchain struct with all the required
        information to render into the swapchain's surfaces.

        To start an 'offscreen render pass' into sokol-gfx image objects, an sg_attachment
        object handle is required instead of an sg_swapchain struct. An offscreen
        pass is started like this (assuming attachments is an sg_attachments handle):

            sg_begin_pass(&(sg_pass){ .action = { ... }, .attachments = attachments });

        To start a compute-pass, just set the .compute item to true:

            sg_begin_pass(&(sg_pass){ .compute = true });

        If the compute pass writes into storage images, provide those as
        'storage attachments' via an sg_attachments object:

            sg_begin_pass(&(sg_pass){ .compute = true, .attachments = attattachments });

    --- set the pipeline state for the next draw call with:

            sg_apply_pipeline(sg_pipeline pip)

    --- fill an sg_bindings struct with the resource bindings for the next
        draw- or dispatch-call (0..N vertex buffers, 0 or 1 index buffer, 0..N images,
        samplers and storage-buffers), and call

            sg_apply_bindings(const sg_bindings* bindings)

        ...to update the resource bindings. Note that in a compute pass, no vertex-
        or index-buffer bindings are allowed and will be rejected by the validation
        layer.

    --- optionally update shader uniform data with:

            sg_apply_uniforms(int ub_slot, const sg_range* data)

        Read the section 'UNIFORM DATA LAYOUT' to learn about the expected memory layout
        of the uniform data passed into sg_apply_uniforms().

    --- kick off a draw call with:

            sg_draw(int base_element, int num_elements, int num_instances)

        The sg_draw() function unifies all the different ways to render primitives
        in a single call (indexed vs non-indexed rendering, and instanced vs non-instanced
        rendering). In case of indexed rendering, base_element and num_element specify
        indices in the currently bound index buffer. In case of non-indexed rendering
        base_element and num_elements specify vertices in the currently bound
        vertex-buffer(s). To perform instanced rendering, the rendering pipeline
        must be setup for instancing (see sg_pipeline_desc below), a separate vertex buffer
        containing per-instance data must be bound, and the num_instances parameter
        must be > 1.

    --- ...or kick of a dispatch call to invoke a compute shader workload:

            sg_dispatch(int num_groups_x, int num_groups_y, int num_groups_z)

        The dispatch args define the number of 'compute workgroups' processed
        by the currently applied compute shader.

    --- finish the current pass with:

            sg_end_pass()

    --- when done with the current frame, call

            sg_commit()

    --- at the end of your program, shutdown sokol_gfx with:

            sg_shutdown()

    --- if you need to destroy resources before sg_shutdown(), call:

            sg_destroy_buffer(sg_buffer buf)
            sg_destroy_image(sg_image img)
            sg_destroy_sampler(sg_sampler smp)
            sg_destroy_shader(sg_shader shd)
            sg_destroy_pipeline(sg_pipeline pip)
            sg_destroy_attachments(sg_attachments atts)

    --- to set a new viewport rectangle, call:

            sg_apply_viewport(int x, int y, int width, int height, bool origin_top_left)

        ...or if you want to specify the viewport rectangle with float values:

            sg_apply_viewportf(float x, float y, float width, float height, bool origin_top_left)

    --- to set a new scissor rect, call:

            sg_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left)

        ...or with float values:

            sg_apply_scissor_rectf(float x, float y, float width, float height, bool origin_top_left)

        Both sg_apply_viewport() and sg_apply_scissor_rect() must be called
        inside a rendering pass (e.g. not in a compute pass, or outside a pass)

        Note that sg_begin_default_pass() and sg_begin_pass() will reset both the
        viewport and scissor rectangles to cover the entire framebuffer.

    --- to update (overwrite) the content of buffer and image resources, call:

            sg_update_buffer(sg_buffer buf, const sg_range* data)
            sg_update_image(sg_image img, const sg_image_data* data)

        Buffers and images to be updated must have been created with
        sg_buffer_desc.usage.dynamic_update or .stream_update.

        Only one update per frame is allowed for buffer and image resources when
        using the sg_update_*() functions. The rationale is to have a simple
        protection from the CPU scribbling over data the GPU is currently
        using, or the CPU having to wait for the GPU

        buffer_t and image updates can be partial, as long as a rendering
        operation only references the valid (updated) data in the
        buffer or image.

    --- to append a chunk of data to a buffer resource, call:

            int sg_append_buffer(sg_buffer buf, const sg_range* data)

        The difference to sg_update_buffer() is that sg_append_buffer()
        can be called multiple times per frame to append new data to the
        buffer piece by piece, optionally interleaved with draw calls referencing
        the previously written data.

        sg_append_buffer() returns a byte offset to the start of the
        written data, this offset can be assigned to
        sg_bindings.vertex_buffer_offsets[n] or
        sg_bindings.index_buffer_offset

        Code example:

        for (...) {
            const void* data = ...;
            const int num_bytes = ...;
            int offset = sg_append_buffer(buf, &(sg_range) { .ptr=data, .size=num_bytes });
            bindings.vertex_buffer_offsets[0] = offset;
            sg_apply_pipeline(pip);
            sg_apply_bindings(&bindings);
            sg_apply_uniforms(...);
            sg_draw(...);
        }

        A buffer to be used with sg_append_buffer() must have been created
        with sg_buffer_desc.usage.dynamic_update or .stream_update.

        If the application appends more data to the buffer then fits into
        the buffer, the buffer will go into the "overflow" state for the
        rest of the frame.

        Any draw calls attempting to render an overflown buffer will be
        silently dropped (in debug mode this will also result in a
        validation error).

        You can also check manually if a buffer is in overflow-state by calling

            bool sg_query_buffer_overflow(sg_buffer buf)

        You can manually check to see if an overflow would occur before adding
        any data to a buffer by calling

            bool sg_query_buffer_will_overflow(sg_buffer buf, size_t size)

        NOTE: Due to restrictions in underlying 3D-APIs, appended chunks of
        data will be 4-byte aligned in the destination buffer. This means
        that there will be gaps in index buffers containing 16-bit indices
        when the number of indices in a call to sg_append_buffer() is
        odd. This isn't a problem when each call to sg_append_buffer()
        is associated with one draw call, but will be problematic when
        a single indexed draw call spans several appended chunks of indices.

    --- to check at runtime for optional features, limits and pixelformat support,
        call:

            sg_features sg_query_features()
            sg_limits sg_query_limits()
            sg_pixelformat_info sg_query_pixelformat(sg_pixel_format fmt)

    --- if you need to call into the underlying 3D-API directly, you must call:

            sg_reset_state_cache()

        ...before calling sokol_gfx functions again

    --- you can inspect the original sg_desc structure handed to sg_setup()
        by calling sg_query_desc(). This will return an sg_desc struct with
        the default values patched in instead of any zero-initialized values

    --- you can get a desc struct matching the creation attributes of a
        specific resource object via:

            sg_buffer_desc sg_query_buffer_desc(sg_buffer buf)
            sg_image_desc sg_query_image_desc(sg_image img)
            sg_sampler_desc sg_query_sampler_desc(sg_sampler smp)
            sg_shader_desc sq_query_shader_desc(sg_shader shd)
            sg_pipeline_desc sg_query_pipeline_desc(sg_pipeline pip)
            sg_attachments_desc sg_query_attachments_desc(sg_attachments atts)

        ...but NOTE that the returned desc structs may be incomplete, only
        creation attributes that are kept around internally after resource
        creation will be filled in, and in some cases (like shaders) that's
        very little. Any missing attributes will be set to zero. The returned
        desc structs might still be useful as partial blueprint for creating
        similar resources if filled up with the missing attributes.

        Calling the query-desc functions on an invalid resource will return
        completely zeroed structs (it makes sense to check  the resource state
        with sg_query_*_state() first)

    --- you can query the default resource creation parameters through the functions

            sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc* desc)
            sg_image_desc sg_query_image_defaults(const sg_image_desc* desc)
            sg_sampler_desc sg_query_sampler_defaults(const sg_sampler_desc* desc)
            sg_shader_desc sg_query_shader_defaults(const sg_shader_desc* desc)
            sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc* desc)
            sg_attachments_desc sg_query_attachments_defaults(const sg_attachments_desc* desc)

        These functions take a pointer to a desc structure which may contain
        zero-initialized items for default values. These zero-init values
        will be replaced with their concrete values in the returned desc
        struct.

    --- you can inspect various internal resource runtime values via:

            sg_buffer_info sg_query_buffer_info(sg_buffer buf)
            sg_image_info sg_query_image_info(sg_image img)
            sg_sampler_info sg_query_sampler_info(sg_sampler smp)
            sg_shader_info sg_query_shader_info(sg_shader shd)
            sg_pipeline_info sg_query_pipeline_info(sg_pipeline pip)
            sg_attachments_info sg_query_attachments_info(sg_attachments atts)

        ...please note that the returned info-structs are tied quite closely
        to sokol_gfx.h internals, and may change more often than other
        public API functions and structs.

    --- you can query frame stats and control stats collection via:

            sg_query_frame_stats()
            sg_enable_frame_stats()
            sg_disable_frame_stats()
            sg_frame_stats_enabled()

    --- you can ask at runtime what backend sokol_gfx.h has been compiled for:

            sg_backend sg_query_backend(void)

    --- call the following helper functions to compute the number of
        bytes in a texture row or surface for a specific pixel format.
        These functions might be helpful when preparing image data for consumption
        by sg_make_image() or sg_update_image():

            int sg_query_row_pitch(sg_pixel_format fmt, int width, int int row_align_bytes);
            int sg_query_surface_pitch(sg_pixel_format fmt, int width, int height, int row_align_bytes);

        Width and height are generally in number pixels, but note that 'row' has different meaning
        for uncompressed vs compressed pixel formats: for uncompressed formats, a row is identical
        with a single line if pixels, while in compressed formats, one row is a line of *compression blocks*.

        This is why calling sg_query_surface_pitch() for a compressed pixel format and height
        N, N+1, N+2, ... may return the same result.

        The row_align_bytes parameter is for added flexibility. For image data that goes into
        the sg_make_image() or sg_update_image() this should generally be 1, because these
        functions take tightly packed image data as input no matter what alignment restrictions
        exist in the backend 3D APIs.

    ON INITIALIZATION:
    ==================
    When calling sg_setup(), a pointer to an sg_desc struct must be provided
    which contains initialization options. These options provide two types
    of information to sokol-gfx:

        (1) upper bounds and limits needed to allocate various internal
            data structures:
                - the max number of resources of each type that can
                  be alive at the same time, this is used for allocating
                  internal pools
                - the max overall size of uniform data that can be
                  updated per frame, including a worst-case alignment
                  per uniform update (this worst-case alignment is 256 bytes)
                - the max size of all dynamic resource updates (sg_update_buffer,
                  sg_append_buffer and sg_update_image) per frame
                - the max number of compute-dispatch calls in a compute pass
            Not all of those limit values are used by all backends, but it is
            good practice to provide them none-the-less.

        (2) 3D backend "environment information" in a nested sg_environment struct:
            - pointers to backend-specific context- or device-objects (for instance
              the D3D11, WebGPU or Metal device objects)
            - defaults for external swapchain pixel formats and sample counts,
              these will be used as default values in image and pipeline objects,
              and the sg_swapchain struct passed into sg_begin_pass()
            Usually you provide a complete sg_environment struct through
            a helper function, as an example look at the sglue_environment()
            function in the sokol_glue.h header.

    See the documentation block of the sg_desc struct below for more information.


    ON RENDER PASSES
    ================
    Relevant samples:
        - https://floooh.github.io/sokol-html5/offscreen-sapp.html
        - https://floooh.github.io/sokol-html5/offscreen-msaa-sapp.html
        - https://floooh.github.io/sokol-html5/mrt-sapp.html
        - https://floooh.github.io/sokol-html5/mrt-pixelformats-sapp.html

    A render pass groups rendering commands into a set of render target images
    (called 'pass attachments'). Render target images can be used in subsequent
    passes as textures (it is invalid to use the same image both as render target
    and as texture in the same pass).

    The following sokol-gfx functions must only be called inside a render-pass:

        sg_apply_viewport[f]
        sg_apply_scissor_rect[f]
        sg_draw

    The following function may be called inside a render- or compute-pass, but
    not outside a pass:

        sg_apply_pipeline
        sg_apply_bindings
        sg_apply_uniforms

    A frame must have at least one 'swapchain render pass' which renders into an
    externally provided swapchain provided as an sg_swapchain struct to the
    sg_begin_pass() function. If you use sokol_gfx.h together with sokol_app.h,
    just call the sglue_swapchain() helper function in sokol_glue.h to
    provide the swapchain information. Otherwise the following information
    must be provided:

        - the color pixel-format of the swapchain's render surface
        - an optional depth/stencil pixel format if the swapchain
          has a depth/stencil buffer
        - an optional sample-count for MSAA rendering
        - NOTE: the above three values can be zero-initialized, in that
          case the defaults from the sg_environment struct will be used that
          had been passed to the sg_setup() function.
        - a number of backend specific objects:
            - GL/GLES3: just a GL framebuffer handle
            - D3D11:
                - an ID3D11RenderTargetView for the rendering surface
                - if MSAA is used, an ID3D11RenderTargetView as
                  MSAA resolve-target
                - an optional ID3D11DepthStencilView for the
                  depth/stencil buffer
            - WebGPU
                - a WGPUTextureView object for the rendering surface
                - if MSAA is used, a WGPUTextureView object as MSAA resolve target
                - an optional WGPUTextureView for the
            - Metal (NOTE that the roles of provided surfaces is slightly
              different in Metal than in D3D11 or WebGPU, notably, the
              CAMetalDrawable is either rendered to directly, or serves
              as MSAA resolve target):
                - a CAMetalDrawable object which is either rendered
                  into directly, or in case of MSAA rendering, serves
                  as MSAA-resolve-target
                - if MSAA is used, an multisampled MTLTexture where
                  rendering goes into
                - an optional MTLTexture for the depth/stencil buffer

    It's recommended that you create a helper function which returns an
    initialized sg_swapchain struct by value. This can then be directly plugged
    into the sg_begin_pass function like this:

        sg_begin_pass(&(sg_pass){ .swapchain = sglue_swapchain() });

    As an example for such a helper function check out the function sglue_swapchain()
    in the sokol_glue.h header.

    For offscreen render passes, the render target images used in a render pass
    are baked into an immutable sg_attachments object.

    For a simple offscreen scenario with one color-, one depth-stencil-render
    target and without multisampling, creating an attachment object looks like this:

    First create two render target images, one with a color pixel format,
    and one with the depth- or depth-stencil pixel format. Both images
    must have the same dimensions:

        const sg_image color_img = sg_make_image(&(sg_image_desc){
            .render_target = true,
            .width = 256,
            .height = 256,
            .pixel_format = SG_PIXELFORMAT_RGBA8,
            .sample_count = 1,
        });
        const sg_image depth_img = sg_make_image(&(sg_image_desc){
            .render_target = true,
            .width = 256,
            .height = 256,
            .pixel_format = SG_PIXELFORMAT_DEPTH,
            .sample_count = 1,
        });

    NOTE: when creating render target images, have in mind that some default values
    are aligned with the default environment attributes in the sg_environment struct
    that was passed into the sg_setup() call:

        - the default value for sg_image_desc.pixel_format is taken from
          sg_environment.defaults.color_format
        - the default value for sg_image_desc.sample_count is taken from
          sg_environment.defaults.sample_count
        - the default value for sg_image_desc.num_mipmaps is always 1

    Next create an attachments object:

        const sg_attachments atts = sg_make_attachments(&(sg_attachments_desc){
            .colors[0].image = color_img,
            .depth_stencil.image = depth_img,
        });

    This attachments object is then passed into the sg_begin_pass() function
    in place of the swapchain struct:

        sg_begin_pass(&(sg_pass){ .attachments = atts });

    Swapchain and offscreen passes form dependency trees each with a swapchain
    pass at the root, offscreen passes as nodes, and render target images as
    dependencies between passes.

    sg_pass_action structs are used to define actions that should happen at the
    start and end of rendering passes (such as clearing pass attachments to a
    specific color or depth-value, or performing an MSAA resolve operation at
    the end of a pass).

    A typical sg_pass_action object which clears the color attachment to black
    might look like this:

        const sg_pass_action = {
            .colors[0] = {
                .load_action = SG_LOADACTION_CLEAR,
                .clear_value = { 0.0f, 0.0f, 0.0f, 1.0f }
            }
        };

    This omits the defaults for the color attachment store action, and
    the depth-stencil-attachments actions. The same pass action with the
    defaults explicitly filled in would look like this:

        const sg_pass_action pass_action = {
            .colors[0] = {
                .load_action = SG_LOADACTION_CLEAR,
                .store_action = SG_STOREACTION_STORE,
                .clear_value = { 0.0f, 0.0f, 0.0f, 1.0f }
            },
            .depth = = {
                .load_action = SG_LOADACTION_CLEAR,
                .store_action = SG_STOREACTION_DONTCARE,
                .clear_value = 1.0f,
            },
            .stencil = {
                .load_action = SG_LOADACTION_CLEAR,
                .store_action = SG_STOREACTION_DONTCARE,
                .clear_value = 0
            }
        };

    With the sg_pass object and sg_pass_action struct in place everything
    is ready now for the actual render pass:

    Using such this prepared sg_pass_action in a swapchain pass looks like
    this:

        sg_begin_pass(&(sg_pass){
            .action = pass_action,
            .swapchain = sglue_swapchain()
        });
        ...
        sg_end_pass();

    ...of alternatively in one offscreen pass:

        sg_begin_pass(&(sg_pass){
            .action = pass_action,
            .attachments = attachments,
        });
        ...
        sg_end_pass();

    Offscreen rendering can also go into a mipmap, or a slice/face of
    a cube-, array- or 3d-image (which some restrictions, for instance
    it's not possible to create a 3D image with a depth/stencil pixel format,
    these exceptions are generally caught by the sokol-gfx validation layer).

    The mipmap/slice selection happens at attachments creation time, for instance
    to render into mipmap 2 of slice 3 of an array texture:

        const sg_attachments atts = sg_make_attachments(&(sg_attachments_desc){
            .colors[0] = {
                .image = color_img,
                .mip_level = 2,
                .slice = 3,
            },
            .depth_stencil.image = depth_img,
        });

    If MSAA offscreen rendering is desired, the multi-sample rendering result
    must be 'resolved' into a separate 'resolve image', before that image can
    be used as texture.

    Creating a simple attachments object for multisampled rendering requires
    3 attachment images: the color attachment image which has a sample
    count > 1, a resolve attachment image of the same size and pixel format
    but a sample count == 1, and a depth/stencil attachment image with
    the same size and sample count as the color attachment image:

        const sg_image color_img = sg_make_image(&(sg_image_desc){
            .render_target = true,
            .width = 256,
            .height = 256,
            .pixel_format = SG_PIXELFORMAT_RGBA8,
            .sample_count = 4,
        });
        const sg_image resolve_img = sg_make_image(&(sg_image_desc){
            .render_target = true,
            .width = 256,
            .height = 256,
            .pixel_format = SG_PIXELFORMAT_RGBA8,
            .sample_count = 1,
        });
        const sg_image depth_img = sg_make_image(&(sg_image_desc){
            .render_target = true,
            .width = 256,
            .height = 256,
            .pixel_format = SG_PIXELFORMAT_DEPTH,
            .sample_count = 4,
        });

    ...create the attachments object:

        const sg_attachments atts = sg_make_attachments(&(sg_attachments_desc){
            .colors[0].image = color_img,
            .resolves[0].image = resolve_img,
            .depth_stencil.image = depth_img,
        });

    If an attachments object defines a resolve image in a specific resolve attachment slot,
    an 'msaa resolve operation' will happen in sg_end_pass().

    In this scenario, the content of the MSAA color attachment doesn't need to be
    preserved (since it's only needed inside sg_end_pass for the msaa-resolve), so
    the .store_action should be set to "don't care":

        const sg_pass_action = {
            .colors[0] = {
                .load_action = SG_LOADACTION_CLEAR,
                .store_action = SG_STOREACTION_DONTCARE,
                .clear_value = { 0.0f, 0.0f, 0.0f, 1.0f }
            }
        };

    The actual render pass looks as usual:

        sg_begin_pass(&(sg_pass){ .action = pass_action, .attachments = atts });
        ...
        sg_end_pass();

    ...after sg_end_pass() the only difference to the non-msaa scenario is that the
    rendering result which is going to be used as texture in a followup pass is
    in 'resolve_img', not in 'color_img' (in fact, trying to bind color_img as a
    texture would result in a validation error).


    ON COMPUTE PASSES
    =================
    Compute passes are used to update the content of storage buffers and
    storage images by running compute shader code on
    the GPU. Updating storage resources with a compute shader will almost always
    be more efficient than computing the same data on the CPU and then uploading
    it via `sg_update_buffer()` or `sg_update_image()`.

    NOTE: compute passes are only supported on the following platforms and
    backends:

        - macOS and iOS with Metal
        - Windows with D3D11 and OpenGL
        - Linux with OpenGL or GLES3.1+
        - Web with WebGPU
        - Android with GLES3.1+

    ...this means compute shaders can't be used on the following platform/backend
    combos (the same restrictions apply to using storage buffers without compute
    shaders):

        - macOS with GL
        - iOS with GLES3
        - Web with WebGL2

    A compute pass which only updates storage buffers is started with:

        sg_begin_pass(&(sg_pass){ .compute = true });

    ...if the compute pass updates storage images, the images must be 'bound'
    via an sg_attachments object:

        sg_begin_pass(&(sg_pass){ .compute = true, .attachments = attachments });

    Image objects in such a compute pass attachments object must be created with
    `storage_attachment` usage:

        sg_image storage_image = sg_make_image(&(sg_image_desc){
            .usage = {
                .storage_attachment = true,
            },
            // ...
        });

    ...a compute pass is finished with a regular:

        sg_end_pass();

    Typically the following functions will be called inside a compute pass:

        sg_apply_pipeline()
        sg_apply_bindings()
        sg_apply_uniforms()
        sg_dispatch()

    The following functions are disallowed inside a compute pass
    and will cause validation layer errors:

        sg_apply_viewport[f]()
        sg_apply_scissor_rect[f]()
        sg_draw()

    Only special 'compute shaders' and 'compute pipelines' can be used in
    compute passes. A compute shader only has a compute-function instead
    of a vertex- and fragment-function pair, and it doesn't accept vertex-
    and index-buffers as input, only storage-buffers, textures, non-filtering
    samplers and images via storage attachments (more details on compute shaders in
    the following section).

    A compute pipeline is created by providing a compute shader object,
    setting the .compute creation parameter to true and not defining any
    'render state':

        sg_pipeline pip = sg_make_pipeline(&(sg_pipeline_desc){
            .compute = true,
            .shader = compute_shader,
        });

    The sg_apply_bindings and sg_apply_uniforms calls are the same as in
    render passes, with the exception that no vertex- and index-buffers
    can be bound in the sg_apply_bindings call.

    Finally to kick off a compute workload, call sg_dispatch with the
    number of workgroups in the x, y and z-dimension:

        sg_dispatch(int num_groups_x, int num_groups_y, int num_groups_z)

    Also see the following compute-shader samples:

        - https://floooh.github.io/sokol-webgpu/instancing-compute-sapp.html
        - https://floooh.github.io/sokol-webgpu/computeboids-sapp.html
        - https://floooh.github.io/sokol-webgpu/imageblur-sapp.html


    ON SHADER CREATION
    ==================
    sokol-gfx doesn't come with an integrated shader cross-compiler, instead
    backend-specific shader sources or binary blobs need to be provided when
    creating a shader object, along with reflection information about the
    shader resource binding interface needed to bind sokol-gfx resources to the
    proper shader inputs.

    The easiest way to provide all this shader creation data is to use the
    sokol-shdc shader compiler tool to compile shaders from a common
    GLSL syntax into backend-specific sources or binary blobs, along with
    shader interface information and uniform blocks and storage buffer array items
    mapped to C structs.

    To create a shader using a C header which has been code-generated by sokol-shdc:

        // include the C header code-generated by sokol-shdc:
        #include "myshader.glsl.h"
        ...

        // create shader using a code-generated helper function from the C header:
        sg_shader shd = sg_make_shader(myshader_shader_desc(sg_query_backend()));

    The samples in the 'sapp' subdirectory of the sokol-samples project
    also use the sokol-shdc approach:

        https://github.com/floooh/sokol-samples/tree/master/sapp

    If you're planning to use sokol-shdc, you can stop reading here, instead
    continue with the sokol-shdc documentation:

        https://github.com/floooh/sokol-tools/blob/master/docs/sokol-shdc.md

    To create shaders with backend-specific shader code or binary blobs,
    the sg_make_shader() function requires the following information:

    - Shader code or shader binary blobs for the vertex- and fragment-, or the
      compute-shader-stage:
        - for the desktop GL backend, source code can be provided in '#version 410' or
          '#version 430', version 430 is required when using storage buffers and
          compute shaders support, but note that this is not available on macOS
        - for the GLES3 backend, source code must be provided in '#version 300 es' or
          '#version 310 es' syntax (version 310 is required for storage buffer and
          compute shader support, but note that this is not supported on WebGL2)
        - for the D3D11 backend, shaders can be provided as source or binary
          blobs, the source code should be in HLSL4.0 (for compatibility with old
          low-end GPUs) or preferably in HLSL5.0 syntax, note that when
          shader source code is provided for the D3D11 backend, sokol-gfx will
          dynamically load 'd3dcompiler_47.dll'
        - for the Metal backends, shaders can be provided as source or binary blobs, the
          MSL version should be in 'metal-1.1' (other versions may work but are not tested)
        - for the WebGPU backend, shaders must be provided as WGSL source code
        - optionally the following shader-code related attributes can be provided:
            - an entry function name (only on D3D11 or Metal, but not OpenGL)
            - on D3D11 only, a compilation target (default is "vs_4_0" and "ps_4_0")

    - Information about the input vertex attributes used by the vertex shader,
      most of that backend-specific:
        - An optional 'base type' (float, signed-/unsigned-int) for each vertex
          attribute. When provided, this used by the validation layer to check
          that the CPU-side input vertex format is compatible with the input
          vertex declaration of the vertex shader.
        - Metal: no location information needed since vertex attributes are always bound
          by their attribute location defined in the shader via '[[attribute(N)]]'
        - WebGPU: no location information needed since vertex attributes are always
          bound by their attribute location defined in the shader via `@location(N)`
        - GLSL: vertex attribute names can be optionally provided, in that case their
          location will be looked up by name, otherwise, the vertex attribute location
          can be defined with 'layout(location = N)'
        - D3D11: a 'semantic name' and 'semantic index' must be provided for each vertex
          attribute, e.g. if the vertex attribute is defined as 'TEXCOORD1' in the shader,
          the semantic name would be 'TEXCOORD', and the semantic index would be '1'

      NOTE that vertex attributes currently must not have gaps. This requirement
      may be relaxed in the future.

    - Specifically for Metal compute shaders, the 'number of threads per threadgroup'
      must be provided. Normally this is extracted by sokol-shdc from the GLSL
      shader source code. For instance the following statement in the input
      GLSL:

        layout(local_size_x=64, local_size_y=1, local_size_z=1) in;

      ...will be communicated to the sokol-gfx Metal backend in the
      code-generated sg_shader_desc struct:

        (sg_shader_desc){
            .mtl_threads_per_threadgroup = { .x = 64, .y = 1, .z = 1 },
        }

    - Information about each uniform block binding used in the shader:
        - the shader stage of the uniform block (vertex, fragment or compute)
        - the size of the uniform block in number of bytes
        - a memory layout hint (currently 'native' or 'std140') where 'native' defines a
          backend-specific memory layout which shouldn't be used for cross-platform code.
          Only std140 guarantees a backend-agnostic memory layout.
        - a backend-specific bind slot:
            - D3D11/HLSL: the buffer register N (`register(bN)`) where N is 0..7
            - Metal/MSL: the buffer bind slot N (`[[buffer(N)]]`) where N is 0..7
            - WebGPU: the binding N in `@group(0) @binding(N)` where N is 0..15
        - For GLSL only: a description of the internal uniform block layout, which maps
          member types and their offsets on the CPU side to uniform variable names
          in the GLSL shader
        - please also NOTE the documentation sections about UNIFORM DATA LAYOUT
          and CROSS-BACKEND COMMON UNIFORM DATA LAYOUT below!

    - A description of each storage buffer binding used in the shader:
        - the shader stage of the storage buffer
        - a boolean 'readonly' flag, this is used for validation and hazard
          tracking in some 3D backends. Note that in render passes, only
          readonly storage buffer bindings are allowed. In compute passes, any
          read/write storage buffer binding is assumed to be written to by the
          compute shader.
        - a backend-specific bind slot:
            - D3D11/HLSL:
                - for readonly storage buffer bindings: the texture register N
                  (`register(tN)`) where N is 0..23 (in HLSL, readonly storage
                  buffers and textures share the same bind space for
                  'shader resource views')
                - for read/write storage buffer buffer bindings: the UAV register N
                  (`register(uN)`) where N is 0..11 (in HLSL, readwrite storage
                  buffers use their own bind space for 'unordered access views')
            - Metal/MSL: the buffer bind slot N (`[[buffer(N)]]`) where N is 8..15
            - WebGPU/WGSL: the binding N in `@group(0) @binding(N)` where N is 0..127
            - GL/GLSL: the buffer binding N in `layout(binding=N)` where N is 0..7
        - note that storage buffer bindings are not supported on all backends
          and platforms

    - A description of each storage image binding used in the shader (only supported
      in compute shaders):
        - the shader stage (*must* be compute)
        - the expected image type:
            - SG_IMAGETYPE_2D
            - SG_IMAGETYPE_CUBE
            - SG_IMAGETYPE_3D
            - SG_IMAGETYPE_ARRAY
        - the 'access pixel format', this is currently limited to:
            - SG_PIXELFORMAT_RGBA8
            - SG_PIXELFORMAT_RGBA8SN/UI/SI
            - SG_PIXELFORMAT_RGBA16UI/SI/F
            - SG_PIXELFORMAT_R32UIUI/SI/F
            - SG_PIXELFORMAT_RG32UI/SI/F
            - SG_PIXELFORMAT_RGBA32UI/SI/F
        - the access type (readwrite or writeonly)
        - a backend-specific bind slot:
            - D3D11/HLSL: the UAV register N (`register(uN)` where N is 0..11, the
              bind slot must not collide with UAV storage buffer bindings
            - Metal/MSL: the texture bind slot N (`[[texture(N)]])` where N is 0..19,
              the bind slot must not collide with other texture bindings on the same
              stage
            - WebGPU/WGSL: the binding N in `@group(2) @binding(N)` where N is 0..3
            - GL/GLSL: the buffer binding N in `layout(binding=N)` where N is 0..3
        - note that storage image bindings are not supported on all backends and platforms

    - A description of each texture binding used in the shader:
        - the shader stage of the texture (vertex, fragment or compute)
        - the expected image type:
            - SG_IMAGETYPE_2D
            - SG_IMAGETYPE_CUBE
            - SG_IMAGETYPE_3D
            - SG_IMAGETYPE_ARRAY
        - the expected 'image sample type':
            - SG_IMAGESAMPLETYPE_FLOAT
            - SG_IMAGESAMPLETYPE_DEPTH
            - SG_IMAGESAMPLETYPE_SINT
            - SG_IMAGESAMPLETYPE_UINT
            - SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT
        - a flag whether the texture is expected to be multisampled
        - a backend-specific bind slot:
            - D3D11/HLSL: the texture register N (`register(tN)`) where N is 0..23
              (in HLSL, readonly storage buffers and texture share the same bind space)
            - Metal/MSL: the texture bind slot N (`[[texture(N)]]`) where N is 0..19
              (the bind slot must not collide with storage image bindings on the same stage)
            - WebGPU/WGSL: the binding N in `@group(0) @binding(N)` where N is 0..127

    - A description of each sampler used in the shader:
        - the shader stage of the sampler (vertex, fragment or compute)
        - the expected sampler type:
            - SG_SAMPLERTYPE_FILTERING,
            - SG_SAMPLERTYPE_NONFILTERING,
            - SG_SAMPLERTYPE_COMPARISON,
        - a backend-specific bind slot:
            - D3D11/HLSL: the sampler register N (`register(sN)`) where N is 0..15
            - Metal/MSL: the sampler bind slot N (`[[sampler(N)]]`) where N is 0..15
            - WebGPU/WGSL: the binding N in `@group(0) @binding(N)` where N is 0..127

    - An array of 'image-sampler-pairs' used by the shader to sample textures,
      for D3D11, Metal and WebGPU this is used for validation purposes to check
      whether the texture and sampler are compatible with each other (especially
      WebGPU is very picky about combining the correct
      texture-sample-type with the correct sampler-type). For GLSL an
      additional 'combined-image-sampler name' must be provided because 'OpenGL
      style GLSL' cannot handle separate texture and sampler objects, but still
      groups them into a traditional GLSL 'sampler object'.

    Compatibility rules for image-sample-type vs sampler-type are as follows:

        - SG_IMAGESAMPLETYPE_FLOAT => (SG_SAMPLERTYPE_FILTERING or SG_SAMPLERTYPE_NONFILTERING)
        - SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT => SG_SAMPLERTYPE_NONFILTERING
        - SG_IMAGESAMPLETYPE_SINT => SG_SAMPLERTYPE_NONFILTERING
        - SG_IMAGESAMPLETYPE_UINT => SG_SAMPLERTYPE_NONFILTERING
        - SG_IMAGESAMPLETYPE_DEPTH => SG_SAMPLERTYPE_COMPARISON

    Backend-specific bindslot ranges (not relevant when using sokol-shdc):

        - D3D11/HLSL:
            - separate bindslot space per shader stage
            - uniform block bindings (as cbuffer): `register(b0..b7)`
            - texture- and readonly storage buffer bindings: `register(t0..t23)`
            - read/write storage buffer and storage image bindings: `register(u0..u11)`
            - samplers: `register(s0..s15)`
        - Metal/MSL:
            - separate bindslot space per shader stage
            - uniform blocks: `[[buffer(0..7)]]`
            - storage buffers: `[[buffer(8..15)]]`
            - textures and storage image bindings: `[[texture(0..19)]]`
            - samplers: `[[sampler(0..15)]]`
        - WebGPU/WGSL:
            - common bindslot space across shader stages
            - uniform blocks: `@group(0) @binding(0..15)`
            - textures, samplers and storage buffers: `@group(1) @binding(0..127)`
            - storage image bindings: `@group(2) @binding(0..3)`
        - GL/GLSL:
            - uniforms and image-samplers are bound by name
            - storage buffer bindings: `layout(std430, binding=0..7)` (common
              bindslot space across shader stages)
            - storage image bindings: `layout(binding=0..3, [access_format])`

    For example code of how to create backend-specific shader objects,
    please refer to the following samples:

        - for D3D11:    https://github.com/floooh/sokol-samples/tree/master/d3d11
        - for Metal:    https://github.com/floooh/sokol-samples/tree/master/metal
        - for OpenGL:   https://github.com/floooh/sokol-samples/tree/master/glfw
        - for GLES3:    https://github.com/floooh/sokol-samples/tree/master/html5
        - for WebGPU:   https://github.com/floooh/sokol-samples/tree/master/wgpu


    ON SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT AND SG_SAMPLERTYPE_NONFILTERING
    ========================================================================
    The WebGPU backend introduces the concept of 'unfilterable-float' textures,
    which can only be combined with 'nonfiltering' samplers (this is a restriction
    specific to WebGPU, but since the same sokol-gfx code should work across
    all backend, the sokol-gfx validation layer also enforces this restriction
    - the alternative would be undefined behaviour in some backend APIs on
    some devices).

    The background is that some mobile devices (most notably iOS devices) can
    not perform linear filtering when sampling textures with certain pixel
    formats, most notable the 32F formats:

        - SG_PIXELFORMAT_R32F
        - SG_PIXELFORMAT_RG32F
        - SG_PIXELFORMAT_RGBA32F

    The information of whether a shader is going to be used with such an
    unfilterable-float texture must already be provided in the sg_shader_desc
    struct when creating the shader (see the above section "ON SHADER CREATION").

    If you are using the sokol-shdc shader compiler, the information whether a
    texture/sampler binding expects an 'unfilterable-float/nonfiltering'
    texture/sampler combination cannot be inferred from the shader source
    alone, you'll need to provide this hint via annotation-tags. For instance
    here is an example from the ozz-skin-sapp.c sample shader which samples an
    RGBA32F texture with skinning matrices in the vertex shader:

    ```glsl
    @image_sample_type joint_tex unfilterable_float
    uniform texture2D joint_tex;
    @sampler_type smp nonfiltering
    uniform sampler smp;
    ```

    This will result in SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT and
    SG_SAMPLERTYPE_NONFILTERING being written to the code-generated
    sg_shader_desc struct.


    ON VERTEX FORMATS
    =================
    Sokol-gfx implements the same strict mapping rules from CPU-side
    vertex component formats to GPU-side vertex input data types:

    - float and packed normalized CPU-side formats must be used as
      floating point base type in the vertex shader
    - packed signed-integer CPU-side formats must be used as signed
      integer base type in the vertex shader
    - packed unsigned-integer CPU-side formats must be used as unsigned
      integer base type in the vertex shader

    These mapping rules are enforced by the sokol-gfx validation layer,
    but only when sufficient reflection information is provided in
    `sg_shader_desc.attrs[].base_type`. This is the case when sokol-shdc
    is used, otherwise the default base_type will be SG_SHADERATTRBASETYPE_UNDEFINED
    which causes the sokol-gfx validation check to be skipped (of course you
    can also provide the per-attribute base type information manually when
    not using sokol-shdc).

    The detailed mapping rules from SG_VERTEXFORMAT_* to GLSL data types
    are as follows:

    - FLOAT[*] => float, vec*
    - BYTE4N => vec* (scaled to -1.0 .. +1.0)
    - UBYTE4N => vec* (scaled to 0.0 .. +1.0)
    - SHORT[*]N => vec* (scaled to -1.0 .. +1.0)
    - USHORT[*]N => vec* (scaled to 0.0 .. +1.0)
    - INT[*] => int, ivec*
    - UINT[*] => uint, uvec*
    - BYTE4 => int*
    - UBYTE4 => uint*
    - SHORT[*] => int*
    - USHORT[*] => uint*

    NOTE that sokol-gfx only provides vertex formats with sizes of a multiple
    of 4 (e.g. BYTE4N but not BYTE2N). This is because vertex components must
    be 4-byte aligned anyway.


    UNIFORM DATA LAYOUT:
    ====================
    NOTE: if you use the sokol-shdc shader compiler tool, you don't need to worry
    about the following details.

    The data that's passed into the sg_apply_uniforms() function must adhere to
    specific layout rules so that the GPU shader finds the uniform block
    items at the right offset.

    For the D3D11 and Metal backends, sokol-gfx only cares about the size of uniform
    blocks, but not about the internal layout. The data will just be copied into
    a uniform/constant buffer in a single operation and it's up you to arrange the
    CPU-side layout so that it matches the GPU side layout. This also means that with
    the D3D11 and Metal backends you are not limited to a 'cross-platform' subset
    of uniform variable types.

    If you ever only use one of the D3D11, Metal *or* WebGPU backend, you can stop reading here.

    For the GL backends, the internal layout of uniform blocks matters though,
    and you are limited to a small number of uniform variable types. This is
    because sokol-gfx must be able to locate the uniform block members in order
    to upload them to the GPU with glUniformXXX() calls.

    To describe the uniform block layout to sokol-gfx, the following information
    must be passed to the sg_make_shader() call in the sg_shader_desc struct:

        - a hint about the used packing rule (either SG_UNIFORMLAYOUT_NATIVE or
          SG_UNIFORMLAYOUT_STD140)
        - a list of the uniform block members types in the correct order they
          appear on the CPU side

    For example if the GLSL shader has the following uniform declarations:

        uniform mat4 mvp;
        uniform vec2 offset0;
        uniform vec2 offset1;
        uniform vec2 offset2;

    ...and on the CPU side, there's a similar C struct:

        typedef struct {
            float mvp[16];
            float offset0[2];
            float offset1[2];
            float offset2[2];
        } params_t;

    ...the uniform block description in the sg_shader_desc must look like this:

        sg_shader_desc desc = {
            .vs.uniform_blocks[0] = {
                .size = sizeof(params_t),
                .layout = SG_UNIFORMLAYOUT_NATIVE,  // this is the default and can be omitted
                .uniforms = {
                    // order must be the same as in 'params_t':
                    [0] = { .name = "mvp", .type = SG_UNIFORMTYPE_MAT4 },
                    [1] = { .name = "offset0", .type = SG_UNIFORMTYPE_VEC2 },
                    [2] = { .name = "offset1", .type = SG_UNIFORMTYPE_VEC2 },
                    [3] = { .name = "offset2", .type = SG_UNIFORMTYPE_VEC2 },
                }
            }
        };

    With this information sokol-gfx can now compute the correct offsets of the data items
    within the uniform block struct.

    The SG_UNIFORMLAYOUT_NATIVE packing rule works fine if only the GL backends are used,
    but for proper D3D11/Metal/GL a subset of the std140 layout must be used which is
    described in the next section:


    CROSS-BACKEND COMMON UNIFORM DATA LAYOUT
    ========================================
    For cross-platform / cross-3D-backend code it is important that the same uniform block
    layout on the CPU side can be used for all sokol-gfx backends. To achieve this,
    a common subset of the std140 layout must be used:

    - The uniform block layout hint in sg_shader_desc must be explicitly set to
      SG_UNIFORMLAYOUT_STD140.
    - Only the following GLSL uniform types can be used (with their associated sokol-gfx enums):
        - float => SG_UNIFORMTYPE_FLOAT
        - vec2  => SG_UNIFORMTYPE_FLOAT2
        - vec3  => SG_UNIFORMTYPE_FLOAT3
        - vec4  => SG_UNIFORMTYPE_FLOAT4
        - int   => SG_UNIFORMTYPE_INT
        - ivec2 => SG_UNIFORMTYPE_INT2
        - ivec3 => SG_UNIFORMTYPE_INT3
        - ivec4 => SG_UNIFORMTYPE_INT4
        - mat4  => SG_UNIFORMTYPE_MAT4
    - Alignment for those types must be as follows (in bytes):
        - float => 4
        - vec2  => 8
        - vec3  => 16
        - vec4  => 16
        - int   => 4
        - ivec2 => 8
        - ivec3 => 16
        - ivec4 => 16
        - mat4  => 16
    - Arrays are only allowed for the following types: vec4, int4, mat4.

    Note that the HLSL cbuffer layout rules are slightly different from the
    std140 layout rules, this means that the cbuffer declarations in HLSL code
    must be tweaked so that the layout is compatible with std140.

    The by far easiest way to tackle the common uniform block layout problem is
    to use the sokol-shdc shader cross-compiler tool!


    ON STORAGE BUFFERS
    ==================
    The two main purpose of storage buffers are:

        - to be populated by compute shaders with dynamically generated data
        - for providing random-access data to all shader stages

    Storage buffers can be used to pass large amounts of random access structured
    data from the CPU side to the shaders. They are similar to data textures, but are
    more convenient to use both on the CPU and shader side since they can be accessed
    in shaders as as a 1-dimensional array of struct items.

    Storage buffers are *NOT* supported on the following platform/backend combos:

    - macOS+GL (because storage buffers require GL 4.3, while macOS only goes up to GL 4.1)
    - platforms which only support a GLES3.0 context (WebGL2 and iOS)

    To use storage buffers, the following steps are required:

        - write a shader which uses storage buffers (vertex- and fragment-shaders
          can only read from storage buffers, while compute-shaders can both read
          and write storage buffers)
        - create one or more storage buffers via sg_make_buffer() with the
          `.usage.storage_buffer = true`
        - when creating a shader via sg_make_shader(), populate the sg_shader_desc
          struct with binding info (when using sokol-shdc, this step will be taken care
          of automatically)
            - which storage buffer bind slots on the vertex-, fragment- or compute-stage
              are occupied
            - whether the storage buffer on that bind slot is readonly (readonly
              bindings are required for vertex- and fragment-shaders, and in compute
              shaders the readonly flag is used to control hazard tracking in some
              3D backends)

        - when calling sg_apply_bindings(), apply the matching bind slots with the previously
          created storage buffers
        - ...and that's it.

    For more details, see the following backend-agnostic sokol samples:

    - simple vertex pulling from a storage buffer:
        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/vertexpull-sapp.c
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/vertexpull-sapp.glsl
    - instanced rendering via storage buffers (vertex- and instance-pulling):
        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/instancing-pull-sapp.c
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/instancing-pull-sapp.glsl
    - storage buffers both on the vertex- and fragment-stage:
        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/sbuftex-sapp.c
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/sbuftex-sapp.glsl
    - the Ozz animation sample rewritten to pull all rendering data from storage buffers:
        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/ozz-storagebuffer-sapp.cc
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/ozz-storagebuffer-sapp.glsl
    - the instancing sample modified to use compute shaders:
        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/instancing-compute-sapp.c
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/instancing-compute-sapp.glsl
    - the Compute Boids sample ported to sokol-gfx:
        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/computeboids-sapp.c
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/computeboids-sapp.glsl

    ...also see the following backend-specific vertex pulling samples (those also don't use sokol-shdc):

    - D3D11: https://github.com/floooh/sokol-samples/blob/master/d3d11/vertexpulling-d3d11.c
    - desktop GL: https://github.com/floooh/sokol-samples/blob/master/glfw/vertexpulling-glfw.c
    - Metal: https://github.com/floooh/sokol-samples/blob/master/metal/vertexpulling-metal.c
    - WebGPU: https://github.com/floooh/sokol-samples/blob/master/wgpu/vertexpulling-wgpu.c

    ...and the backend specific compute shader samples:

    - D3D11: https://github.com/floooh/sokol-samples/blob/master/d3d11/instancing-compute-d3d11.c
    - desktop GL: https://github.com/floooh/sokol-samples/blob/master/glfw/instancing-compute-glfw.c
    - Metal: https://github.com/floooh/sokol-samples/blob/master/metal/instancing-compute-metal.c
    - WebGPU: https://github.com/floooh/sokol-samples/blob/master/wgpu/instancing-compute-wgpu.c

    Storage buffer shader authoring caveats when using sokol-shdc:

        - declare a read-only storage buffer interface block with `layout(binding=N) readonly buffer [name] { ... }`
          (where 'N' is the index in `sg_bindings.storage_buffers[N]`)
        - ...or a read/write storage buffer interface block with `layout(binding=N) buffer [name] { ... }`
        - declare a struct which describes a single array item in the storage buffer interface block
        - only put a single flexible array member into the storage buffer interface block

    E.g. a complete example in 'sokol-shdc GLSL':

        ```glsl
        @vs
        // declare a struct:
        struct sb_vertex {
            vec3 pos;
            vec4 color;
        }
        // declare a buffer interface block with a single flexible struct array:
        layout(binding=0) readonly buffer vertices {
            sb_vertex vtx[];
        }
        // in the shader function, access the storage buffer like this:
        void main() {
            vec3 pos = vtx[gl_VertexIndex].pos;
            ...
        }
        @end
        ```

    In a compute shader you can read and write the same item in the same
    storage buffer (but you'll have to be careful for random access since
    many threads of the same compute function run in parallel):

        @cs
        struct sb_item {
            vec3 pos;
            vec3 vel;
        }
        layout(binding=0) buffer items_ssbo {
            sb_item items[];
        }
        layout(local_size_x=64, local_size_y=1, local_size_z=1) in;
        void main() {
            uint idx = gl_GlobalInvocationID.x;
            vec3 pos = items[idx].pos;
            ...
            items[idx].pos = pos;
        }
        @end

    Backend-specific storage-buffer caveats (not relevant when using sokol-shdc):

        D3D11:
            - storage buffers are created as 'raw' Byte Address Buffers
              (https://learn.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-resources-intro#raw-views-of-buffers)
            - in HLSL, use a ByteAddressBuffer for readonly access of the buffer content:
              (https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/sm5-object-byteaddressbuffer)
            - ...or RWByteAddressBuffer for read/write access:
              (https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/sm5-object-rwbyteaddressbuffer)
            - readonly-storage buffers and textures are both bound as 'shader-resource-view' and
              share the same bind slots (declared as `register(tN)` in HLSL), where N must be in the range 0..23)
            - read/write storage buffers and storage images are bound as 'unordered-access-view'
              (declared as `register(uN)` in HLSL where N is in the range 0..11)

        Metal:
            - in Metal there is no internal difference between vertex-, uniform- and
              storage-buffers, all are bound to the same 'buffer bind slots' with the
              following reserved ranges:
                - vertex shader stage:
                    - uniform buffers: slots 0..7
                    - storage buffers: slots 8..15
                    - vertex buffers: slots 15..23
                - fragment shader stage:
                    - uniform buffers: slots 0..7
                    - storage buffers: slots 8..15
            - this means in MSL, storage buffer bindings start at [[buffer(8)]] both in
              the vertex and fragment stage

        GL:
            - the GL backend doesn't use name-lookup to find storage buffer bindings, this
              means you must annotate buffers with `layout(std430, binding=N)` in GLSL
            - ...where N is 0..7 in the vertex shader, and 8..15 in the fragment shader

        WebGPU:
            - in WGSL, textures, samplers and storage buffers all use a shared
              bindspace across all shader stages on bindgroup 1:

              `@group(1) @binding(0..127)

    ON STORAGE IMAGES:
    ==================
    To write pixel data to texture objects in compute shaders, first an image
    object must be created with `storage_attachment usage`:

        sg_image storage_image = sg_make_image(&(sg_image_desc){
            .usage = {
                .storage_attachment = true,
            },
            .width = ...,
            .height = ...,
            .pixel_format = ...,
        });

    ...next the image object must be wrapped in an attachment object, this allows
    to pick a specific mipmap level or slice to be accessed by the compute shader:

        sg_attachments storage_attachment = sg_make_attachment(&(sg_attachments_desc){
            .storages[0] = {
                .image = storage_image,
                .mip_level = ...,
                .slice = ...,
            },
        });

    Finally 'bind' the storage image as pass attachment in the `sg_begin_pass`
    call of a compute pass:

        sg_begin_pass(&(sg_pass){ .compute = true, .attachments = storage_attachments });
        ...
        sg_end_pass();

    Storage attachments should only be accessed as `readwrite` or `writeonly` mode
    in compute shaders because if the limited bind space of up to 4 slots. For
    readonly access, just bind the storage image as regular texture via
    `sg_apply_bindings()`.

    For an example of using storage images in compute shaders see imageblur-sapp:

        - C code: https://github.com/floooh/sokol-samples/blob/master/sapp/imageblur-sapp.c
        - shader: https://github.com/floooh/sokol-samples/blob/master/sapp/imageblur-sapp.glsl

    NOTE: in the (hopefully not-too-distant) future, working with storage
    images will change by moving the resource binding from pass attachments to
    regular bindings via `sg_apply_bindings()`, but this requires the
    introduction of resource view objects into sokol-gfx (see planning
    ticket: https://github.com/floooh/sokol/issues/1252)

    TRACE HOOKS:
    ============
    sokol_gfx.h optionally allows to install "trace hook" callbacks for
    each public API functions. When a public API function is called, and
    a trace hook callback has been installed for this function, the
    callback will be invoked with the parameters and result of the function.
    This is useful for things like debugging- and profiling-tools, or
    keeping track of resource creation and destruction.

    To use the trace hook feature:

    --- Define SOKOL_TRACE_HOOKS before including the implementation.

    --- Setup an sg_trace_hooks structure with your callback function
        pointers (keep all function pointers you're not interested
        in zero-initialized), optionally set the user_data member
        in the sg_trace_hooks struct.

    --- Install the trace hooks by calling sg_install_trace_hooks(),
        the return value of this function is another sg_trace_hooks
        struct which contains the previously set of trace hooks.
        You should keep this struct around, and call those previous
        functions pointers from your own trace callbacks for proper
        chaining.

    As an example of how trace hooks are used, have a look at the
    imgui/sokol_gfx_imgui.h header which implements a realtime
    debugging UI for sokol_gfx.h on top of Dear ImGui.


    MEMORY ALLOCATION OVERRIDE
    ==========================
    You can override the memory allocation functions at initialization time
    like this:

        void* my_alloc(size_t size, void* user_data) {
            return malloc(size);
        }

        void my_free(void* ptr, void* user_data) {
            free(ptr);
        }

        ...
            sg_setup(&(sg_desc){
                // ...
                .allocator = {
                    .alloc_fn = my_alloc,
                    .free_fn = my_free,
                    .user_data = ...,
                }
            });
        ...

    If no overrides are provided, malloc and free will be used.

    This only affects memory allocation calls done by sokol_gfx.h
    itself though, not any allocations in OS libraries.


    ERROR REPORTING AND LOGGING
    ===========================
    To get any logging information at all you need to provide a logging callback in the setup call
    the easiest way is to use sokol_log.h:

        #include "sokol_log.h"

        sg_setup(&(sg_desc){ .logger.func = slog_func });

    To override logging with your own callback, first write a logging function like this:

        void my_log(const char* tag,                // e.g. 'sg'
                    uint32_t log_level,             // 0=panic, 1=error, 2=warn, 3=info
                    uint32_t log_item_id,           // SG_LOGITEM_*
                    const char* message_or_null,    // a message string, may be nullptr in release mode
                    uint32_t line_nr,               // line number in sokol_gfx.h
                    const char* filename_or_null,   // source filename, may be nullptr in release mode
                    void* user_data)
        {
            ...
        }

    ...and then setup sokol-gfx like this:

        sg_setup(&(sg_desc){
            .logger = {
                .func = my_log,
                .user_data = my_user_data,
            }
        });

    The provided logging function must be reentrant (e.g. be callable from
    different threads).

    If you don't want to provide your own custom logger it is highly recommended to use
    the standard logger in sokol_log.h instead, otherwise you won't see any warnings or
    errors.


    COMMIT LISTENERS
    ================
    It's possible to hook callback functions into sokol-gfx which are called from
    inside sg_commit() in unspecified order. This is mainly useful for libraries
    that build on top of sokol_gfx.h to be notified about the end/start of a frame.

    To add a commit listener, call:

        static void my_commit_listener(void* user_data) {
            ...
        }

        bool success = sg_add_commit_listener((sg_commit_listener){
            .func = my_commit_listener,
            .user_data = ...,
        });

    The function returns false if the internal array of commit listeners is full,
    or the same commit listener had already been added.

    If the function returns true, my_commit_listener() will be called each frame
    from inside sg_commit().

    By default, 1024 distinct commit listeners can be added, but this number
    can be tweaked in the sg_setup() call:

        sg_setup(&(sg_desc){
            .max_commit_listeners = 2048,
        });

    An sg_commit_listener item is equal to another if both the function
    pointer and user_data field are equal.

    To remove a commit listener:

        bool success = sg_remove_commit_listener((sg_commit_listener){
            .func = my_commit_listener,
            .user_data = ...,
        });

    ...where the .func and .user_data field are equal to a previous
    sg_add_commit_listener() call. The function returns true if the commit
    listener item was found and removed, and false otherwise.


    RESOURCE CREATION AND DESTRUCTION IN DETAIL
    ===========================================
    The 'vanilla' way to create resource objects is with the 'make functions':

        sg_buffer sg_make_buffer(const sg_buffer_desc* desc)
        sg_image sg_make_image(const sg_image_desc* desc)
        sg_sampler sg_make_sampler(const sg_sampler_desc* desc)
        sg_shader sg_make_shader(const sg_shader_desc* desc)
        sg_pipeline sg_make_pipeline(const sg_pipeline_desc* desc)
        sg_attachments sg_make_attachments(const sg_attachments_desc* desc)

    This will result in one of three cases:

        1. The returned handle is invalid. This happens when there are no more
           free slots in the resource pool for this resource type. An invalid
           handle is associated with the INVALID resource state, for instance:

                sg_buffer buf = sg_make_buffer(...)
                if (sg_query_buffer_state(buf) == SG_RESOURCESTATE_INVALID) {
                    // buffer pool is exhausted
                }

        2. The returned handle is valid, but creating the underlying resource
           has failed for some reason. This results in a resource object in the
           FAILED state. The reason *why* resource creation has failed differ
           by resource type. Look for log messages with more details. A failed
           resource state can be checked with:

                sg_buffer buf = sg_make_buffer(...)
                if (sg_query_buffer_state(buf) == SG_RESOURCESTATE_FAILED) {
                    // creating the resource has failed
                }

        3. And finally, if everything goes right, the returned resource is
           in resource state VALID and ready to use. This can be checked
           with:

                sg_buffer buf = sg_make_buffer(...)
                if (sg_query_buffer_state(buf) == SG_RESOURCESTATE_VALID) {
                    // creating the resource has failed
                }

    When calling the 'make functions', the created resource goes through a number
    of states:

        - INITIAL: the resource slot associated with the new resource is currently
          free (technically, there is no resource yet, just an empty pool slot)
        - ALLOC: a handle for the new resource has been allocated, this just means
          a pool slot has been reserved.
        - VALID or FAILED: in VALID state any 3D API backend resource objects have
          been successfully created, otherwise if anything went wrong, the resource
          will be in FAILED state.

    Sometimes it makes sense to first grab a handle, but initialize the
    underlying resource at a later time. For instance when loading data
    asynchronously from a slow data source, you may know what buffers and
    textures are needed at an early stage of the loading process, but actually
    loading the buffer or texture content can only be completed at a later time.

    For such situations, sokol-gfx resource objects can be created in two steps.
    You can allocate a handle upfront with one of the 'alloc functions':

        sg_buffer sg_alloc_buffer(void)
        sg_image sg_alloc_image(void)
        sg_sampler sg_alloc_sampler(void)
        sg_shader sg_alloc_shader(void)
        sg_pipeline sg_alloc_pipeline(void)
        sg_attachments sg_alloc_attachments(void)

    This will return a handle with the underlying resource object in the
    ALLOC state:

        sg_image img = sg_alloc_image();
        if (sg_query_image_state(img) == SG_RESOURCESTATE_ALLOC) {
            // allocating an image handle has succeeded, otherwise
            // the image pool is full
        }

    Such an 'incomplete' handle can be used in most sokol-gfx rendering functions
    without doing any harm, sokol-gfx will simply skip any rendering operation
    that involve resources which are not in VALID state.

    At a later time (for instance once the texture has completed loading
    asynchronously), the resource creation can be completed by calling one of
    the 'init functions', those functions take an existing resource handle and
    'desc struct':

        void sg_init_buffer(sg_buffer buf, const sg_buffer_desc* desc)
        void sg_init_image(sg_image img, const sg_image_desc* desc)
        void sg_init_sampler(sg_sampler smp, const sg_sampler_desc* desc)
        void sg_init_shader(sg_shader shd, const sg_shader_desc* desc)
        void sg_init_pipeline(sg_pipeline pip, const sg_pipeline_desc* desc)
        void sg_init_attachments(sg_attachments atts, const sg_attachments_desc* desc)

    The init functions expect a resource in ALLOC state, and after the function
    returns, the resource will be either in VALID or FAILED state. Calling
    an 'alloc function' followed by the matching 'init function' is fully
    equivalent with calling the 'make function' alone.

    Destruction can also happen as a two-step process. The 'uninit functions'
    will put a resource object from the VALID or FAILED state back into the
    ALLOC state:

        void sg_uninit_buffer(sg_buffer buf)
        void sg_uninit_image(sg_image img)
        void sg_uninit_sampler(sg_sampler smp)
        void sg_uninit_shader(sg_shader shd)
        void sg_uninit_pipeline(sg_pipeline pip)
        void sg_uninit_attachments(sg_attachments pass)

    Calling the 'uninit functions' with a resource that is not in the VALID or
    FAILED state is a no-op.

    To finally free the pool slot for recycling call the 'dealloc functions':

        void sg_dealloc_buffer(sg_buffer buf)
        void sg_dealloc_image(sg_image img)
        void sg_dealloc_sampler(sg_sampler smp)
        void sg_dealloc_shader(sg_shader shd)
        void sg_dealloc_pipeline(sg_pipeline pip)
        void sg_dealloc_attachments(sg_attachments atts)

    Calling the 'dealloc functions' on a resource that's not in ALLOC state is
    a no-op, but will generate a warning log message.

    Calling an 'uninit function' and 'dealloc function' in sequence is equivalent
    with calling the associated 'destroy function':

        void sg_destroy_buffer(sg_buffer buf)
        void sg_destroy_image(sg_image img)
        void sg_destroy_sampler(sg_sampler smp)
        void sg_destroy_shader(sg_shader shd)
        void sg_destroy_pipeline(sg_pipeline pip)
        void sg_destroy_attachments(sg_attachments atts)

    The 'destroy functions' can be called on resources in any state and generally
    do the right thing (for instance if the resource is in ALLOC state, the destroy
    function will be equivalent to the 'dealloc function' and skip the 'uninit part').

    And finally to close the circle, the 'fail functions' can be called to manually
    put a resource in ALLOC state into the FAILED state:

        sg_fail_buffer(sg_buffer buf)
        sg_fail_image(sg_image img)
        sg_fail_sampler(sg_sampler smp)
        sg_fail_shader(sg_shader shd)
        sg_fail_pipeline(sg_pipeline pip)
        sg_fail_attachments(sg_attachments atts)

    This is recommended if anything went wrong outside of sokol-gfx during asynchronous
    resource setup (for instance a file loading operation failed). In this case,
    the 'fail function' should be called instead of the 'init function'.

    Calling a 'fail function' on a resource that's not in ALLOC state is a no-op,
    but will generate a warning log message.

    NOTE: that two-step resource creation usually only makes sense for buffers
    and images, but not for samplers, shaders, pipelines or attachments. Most notably, trying
    to create a pipeline object with a shader that's not in VALID state will
    trigger a validation layer error, or if the validation layer is disabled,
    result in a pipeline object in FAILED state. Same when trying to create
    an attachments object with invalid image objects.


    WEBGPU CAVEATS
    ==============
    For a general overview and design notes of the WebGPU backend see:

        https://floooh.github.io/2023/10/16/sokol-webgpu.html

    In general, don't expect an automatic speedup when switching from the WebGL2
    backend to the WebGPU backend. Some WebGPU functions currently actually
    have a higher CPU overhead than similar WebGL2 functions, leading to the
    paradoxical situation that some WebGPU code may be slower than similar WebGL2
    code.

    - when writing WGSL shader code by hand, a specific bind-slot convention
      must be used:

      All uniform block structs must use `@group(0)` and bindings in the
      range 0..15

        @group(0) @binding(0..15)

      All textures, samplers and storage buffers must use `@group(1)` and
      bindings must be in the range 0..127:

        @group(1) @binding(0..127)

      All storage image attachments must use `@group(2)` and bindings
      must be in the range 0..3:

        @group(2) @binding(0..3)

      Note that the number of texture, sampler and storage buffer bindings
      is still limited despite the large bind range:

        - up to 16 textures and sampler across all shader stages
        - up to 8 storage buffers across all shader stages

      If you use sokol-shdc to generate WGSL shader code, you don't need to worry
      about the above binding conventions since sokol-shdc.

    - The sokol-gfx WebGPU backend uses the sg_desc.uniform_buffer_size item
      to allocate a single per-frame uniform buffer which must be big enough
      to hold all data written by sg_apply_uniforms() during a single frame,
      including a worst-case 256-byte alignment (e.g. each sg_apply_uniform
      call will cost at least 256 bytes of uniform buffer size). The default size
      is 4 MB, which is enough for 16384 sg_apply_uniform() calls per
      frame (assuming the uniform data 'payload' is less than 256 bytes
      per call). These rules are the same as for the Metal backend, so if
      you are already using the Metal backend you'll be fine.

    - sg_apply_bindings(): the sokol-gfx WebGPU backend implements a bindgroup
      cache to prevent excessive creation and destruction of BindGroup objects
      when calling sg_apply_bindings(). The number of slots in the bindgroups
      cache is defined in sg_desc.wgpu_bindgroups_cache_size when calling
      sg_setup. The cache size must be a power-of-2 number, with the default being
      1024. The bindgroups cache behaviour can be observed by calling the new
      function sg_query_frame_stats(), where the following struct items are
      of interest:

        .wgpu.num_bindgroup_cache_hits
        .wgpu.num_bindgroup_cache_misses
        .wgpu.num_bindgroup_cache_collisions
        .wgpu_num_bindgroup_cache_invalidates
        .wgpu.num_bindgroup_cache_vs_hash_key_mismatch

      The value to pay attention to is `.wgpu.num_bindgroup_cache_collisions`,
      if this number is consistently higher than a few percent of the
      .wgpu.num_set_bindgroup value, it might be a good idea to bump the
      bindgroups cache size to the next power-of-2.

    - sg_apply_viewport(): WebGPU currently has a unique restriction that viewport
      rectangles must be contained entirely within the framebuffer. As a shitty
      workaround sokol_gfx.h will clip incoming viewport rectangles against
      the framebuffer, but this will distort the clipspace-to-screenspace mapping.
      There's no proper way to handle this inside sokol_gfx.h, this must be fixed
      in a future WebGPU update (see: https://github.com/gpuweb/gpuweb/issues/373
      and https://github.com/gpuweb/gpuweb/pull/5025)

    - The sokol shader compiler generally adds `diagnostic(off, derivative_uniformity);`
      into the WGSL output. Currently only the Chrome WebGPU implementation seems
      to recognize this.

    - Likewise, the following sokol-gfx pixel formats are not supported in WebGPU:
      R16, R16SN, RG16, RG16SN, RGBA16, RGBA16SN.
      Unlike unsupported vertex formats, unsupported pixel formats can be queried
      in cross-backend code via sg_query_pixelformat() though.

    - The Emscripten WebGPU shim currently doesn't support the Closure minification
      post-link-step (e.g. currently the emcc argument '--closure 1' or '--closure 2'
      will generate broken Javascript code.

    - sokol-gfx requires the WebGPU device feature `depth32float-stencil8` to be enabled
      (this should be widely supported)

    - sokol-gfx expects that the WebGPU device feature `float32-filterable` to *not* be
      enabled (since this would exclude all iOS devices)


    LICENSE
    =======
    zlib/libpng license

    Copyright (c) 2018 Andre Weissflog

    This software is provided 'as-is', without any express or implied warranty.
    In no event will the authors be held liable for any damages arising from the
    use of this software.

    Permission is granted to anyone to use this software for any purpose,
    including commercial applications, and to alter it and redistribute it
    freely, subject to the following restrictions:

        1. The origin of this software must not be misrepresented; you must not
        claim that you wrote the original software. If you use this software in a
        product, an acknowledgment in the product documentation would be
        appreciated but is not required.

        2. Altered source versions must be plainly marked as such, and must not
        be misrepresented as being the original software.

        3. This notice may not be removed or altered from any source
        distribution.
*/
#define SOKOL_GFX_INCLUDED (1)
#include <stddef.h>     // size_t
#include <stdint.h>
#include <stdbool.h>

#if defined(SOKOL_API_DECL) && !defined(SOKOL_GFX_API_DECL)
#define SOKOL_GFX_API_DECL SOKOL_API_DECL
#endif
#ifndef SOKOL_GFX_API_DECL
#if defined(_WIN32) && defined(SOKOL_DLL) && defined(SOKOL_GFX_IMPL)
#define SOKOL_GFX_API_DECL __declspec(dllexport)
#elif defined(_WIN32) && defined(SOKOL_DLL)
#define SOKOL_GFX_API_DECL __declspec(dllimport)
#else
#define SOKOL_GFX_API_DECL extern
#endif
#endif

#ifdef __cplusplus
extern "C" {
#endif

/*
    Resource id typedefs:

    sg_buffer:      vertex- and index-buffers
    sg_image:       images used as textures and render-pass attachments
    sg_sampler      sampler objects describing how a texture is sampled in a shader
    sg_shader:      vertex- and fragment-shaders and shader interface information
    sg_pipeline:    associated shader and vertex-layouts, and render states
    sg_attachments: a baked collection of render pass attachment images

    Instead of pointers, resource creation functions return a 32-bit
    handle which uniquely identifies the resource object.

    The 32-bit resource id is split into a 16-bit pool index in the lower bits,
    and a 16-bit 'generation counter' in the upper bits. The index allows fast
    pool lookups, and combined with the generation-counter it allows to detect
    'dangling accesses' (trying to use an object which no longer exists, and
    its pool slot has been reused for a new object)

    The resource ids are wrapped into a strongly-typed struct so that
    trying to pass an incompatible resource id is a compile error.
*/
typedef struct sg_buffer        { uint32_t id; } sg_buffer;
typedef struct sg_image         { uint32_t id; } sg_image;
typedef struct sg_sampler       { uint32_t id; } sg_sampler;
typedef struct sg_shader        { uint32_t id; } sg_shader;
typedef struct sg_pipeline      { uint32_t id; } sg_pipeline;
typedef struct sg_attachments   { uint32_t id; } sg_attachments;

/*
    sg_range is a pointer-size-pair struct used to pass memory blobs into
    sokol-gfx. When initialized from a value type (array or struct), you can
    use the SG_RANGE() macro to build an sg_range struct. For functions which
    take either a sg_range pointer, or a (C++) sg_range reference, use the
    SG_RANGE_REF macro as a solution which compiles both in C and C++.
*/
typedef struct sg_range {
    const void* ptr;
    size_t size;
} sg_range;

// disabling this for every includer isn't great, but the warnings are also quite pointless
#if defined(_MSC_VER)
#pragma warning(disable:4221)   // /W4 only: nonstandard extension used: 'x': cannot be initialized using address of automatic variable 'y'
#pragma warning(disable:4204)   // VS2015: nonstandard extension used: non-constant aggregate initializer
#endif
#if defined(__cplusplus)
#define SG_RANGE(x) sg_range{ &x, sizeof(x) }
#define SG_RANGE_REF(x) sg_range{ &x, sizeof(x) }
#else
#define SG_RANGE(x) (sg_range){ &x, sizeof(x) }
#define SG_RANGE_REF(x) &(sg_range){ &x, sizeof(x) }
#endif

// various compile-time constants in the public API
enum {
    SG_INVALID_ID = 0,
    SG_NUM_INFLIGHT_FRAMES = 2,
    SG_MAX_COLOR_ATTACHMENTS = 4,
    SG_MAX_STORAGE_ATTACHMENTS = 4,
    SG_MAX_UNIFORMBLOCK_MEMBERS = 16,
    SG_MAX_VERTEX_ATTRIBUTES = 16,
    SG_MAX_MIPMAPS = 16,
    SG_MAX_TEXTUREARRAY_LAYERS = 128,
    SG_MAX_UNIFORMBLOCK_BINDSLOTS = 8,
    SG_MAX_VERTEXBUFFER_BINDSLOTS = 8,
    SG_MAX_IMAGE_BINDSLOTS = 16,
    SG_MAX_SAMPLER_BINDSLOTS = 16,
    SG_MAX_STORAGEBUFFER_BINDSLOTS = 8,
    SG_MAX_IMAGE_SAMPLER_PAIRS = 16,
};

/*
    sg_color

    An RGBA color value.
*/
typedef struct sg_color { float r, g, b, a; } sg_color;

/*
    sg_backend

    The active 3D-API backend, use the function sg_query_backend()
    to get the currently active backend.
*/
typedef enum sg_backend {
    SG_BACKEND_GLCORE,
    SG_BACKEND_GLES3,
    SG_BACKEND_D3D11,
    SG_BACKEND_METAL_IOS,
    SG_BACKEND_METAL_MACOS,
    SG_BACKEND_METAL_SIMULATOR,
    SG_BACKEND_WGPU,
    SG_BACKEND_DUMMY,
} sg_backend;

/*
    sg_pixel_format

    sokol_gfx.h basically uses the same pixel formats as WebGPU, since these
    are supported on most newer GPUs.

    A pixelformat name consist of three parts:

        - components (R, RG, RGB or RGBA)
        - bit width per component (8, 16 or 32)
        - component data type:
            - unsigned normalized (no postfix)
            - signed normalized (SN postfix)
            - unsigned integer (UI postfix)
            - signed integer (SI postfix)
            - float (F postfix)

    Not all pixel formats can be used for everything, call sg_query_pixelformat()
    to inspect the capabilities of a given pixelformat. The function returns
    an sg_pixelformat_info struct with the following members:

        - sample: the pixelformat can be sampled as texture at least with
                  nearest filtering
        - filter: the pixelformat can be sampled as texture with linear
                  filtering
        - render: the pixelformat can be used as render-pass attachment
        - blend:  blending is supported when used as render-pass attachment
        - msaa:   multisample-antialiasing is supported when used
                  as render-pass attachment
        - depth:  the pixelformat can be used for depth-stencil attachments
        - compressed: this is a block-compressed format
        - bytes_per_pixel: the numbers of bytes in a pixel (0 for compressed formats)

    The default pixel format for texture images is SG_PIXELFORMAT_RGBA8.

    The default pixel format for render target images is platform-dependent
    and taken from the sg_environment struct passed into sg_setup(). Typically
    the default formats are:

        - for the Metal, D3D11 and WebGPU backends: SG_PIXELFORMAT_BGRA8
        - for GL backends: SG_PIXELFORMAT_RGBA8
*/
typedef enum sg_pixel_format {
    _SG_PIXELFORMAT_DEFAULT,    // value 0 reserved for default-init
    SG_PIXELFORMAT_NONE,

    SG_PIXELFORMAT_R8,
    SG_PIXELFORMAT_R8SN,
    SG_PIXELFORMAT_R8UI,
    SG_PIXELFORMAT_R8SI,

    SG_PIXELFORMAT_R16,
    SG_PIXELFORMAT_R16SN,
    SG_PIXELFORMAT_R16UI,
    SG_PIXELFORMAT_R16SI,
    SG_PIXELFORMAT_R16F,
    SG_PIXELFORMAT_RG8,
    SG_PIXELFORMAT_RG8SN,
    SG_PIXELFORMAT_RG8UI,
    SG_PIXELFORMAT_RG8SI,

    SG_PIXELFORMAT_R32UI,
    SG_PIXELFORMAT_R32SI,
    SG_PIXELFORMAT_R32F,
    SG_PIXELFORMAT_RG16,
    SG_PIXELFORMAT_RG16SN,
    SG_PIXELFORMAT_RG16UI,
    SG_PIXELFORMAT_RG16SI,
    SG_PIXELFORMAT_RG16F,
    SG_PIXELFORMAT_RGBA8,
    SG_PIXELFORMAT_SRGB8A8,
    SG_PIXELFORMAT_RGBA8SN,
    SG_PIXELFORMAT_RGBA8UI,
    SG_PIXELFORMAT_RGBA8SI,
    SG_PIXELFORMAT_BGRA8,
    SG_PIXELFORMAT_RGB10A2,
    SG_PIXELFORMAT_RG11B10F,
    SG_PIXELFORMAT_RGB9E5,

    SG_PIXELFORMAT_RG32UI,
    SG_PIXELFORMAT_RG32SI,
    SG_PIXELFORMAT_RG32F,
    SG_PIXELFORMAT_RGBA16,
    SG_PIXELFORMAT_RGBA16SN,
    SG_PIXELFORMAT_RGBA16UI,
    SG_PIXELFORMAT_RGBA16SI,
    SG_PIXELFORMAT_RGBA16F,

    SG_PIXELFORMAT_RGBA32UI,
    SG_PIXELFORMAT_RGBA32SI,
    SG_PIXELFORMAT_RGBA32F,

    // NOTE: when adding/removing pixel formats before DEPTH, also update sokol_app.h/_SAPP_PIXELFORMAT_*
    SG_PIXELFORMAT_DEPTH,
    SG_PIXELFORMAT_DEPTH_STENCIL,

    // NOTE: don't put any new compressed format in front of here
    SG_PIXELFORMAT_BC1_RGBA,
    SG_PIXELFORMAT_BC2_RGBA,
    SG_PIXELFORMAT_BC3_RGBA,
    SG_PIXELFORMAT_BC3_SRGBA,
    SG_PIXELFORMAT_BC4_R,
    SG_PIXELFORMAT_BC4_RSN,
    SG_PIXELFORMAT_BC5_RG,
    SG_PIXELFORMAT_BC5_RGSN,
    SG_PIXELFORMAT_BC6H_RGBF,
    SG_PIXELFORMAT_BC6H_RGBUF,
    SG_PIXELFORMAT_BC7_RGBA,
    SG_PIXELFORMAT_BC7_SRGBA,
    SG_PIXELFORMAT_ETC2_RGB8,
    SG_PIXELFORMAT_ETC2_SRGB8,
    SG_PIXELFORMAT_ETC2_RGB8A1,
    SG_PIXELFORMAT_ETC2_RGBA8,
    SG_PIXELFORMAT_ETC2_SRGB8A8,
    SG_PIXELFORMAT_EAC_R11,
    SG_PIXELFORMAT_EAC_R11SN,
    SG_PIXELFORMAT_EAC_RG11,
    SG_PIXELFORMAT_EAC_RG11SN,

    SG_PIXELFORMAT_ASTC_4x4_RGBA,
    SG_PIXELFORMAT_ASTC_4x4_SRGBA,

    _SG_PIXELFORMAT_NUM,
    _SG_PIXELFORMAT_FORCE_U32 = 0x7FFFFFFF
} sg_pixel_format;

/*
    Runtime information about a pixel format, returned by sg_query_pixelformat().
*/
typedef struct sg_pixelformat_info {
    bool sample;            // pixel format can be sampled in shaders at least with nearest filtering
    bool filter;            // pixel format can be sampled with linear filtering
    bool render;            // pixel format can be used as render-pass attachment
    bool blend;             // pixel format supports alpha-blending when used as render-pass attachment
    bool msaa;              // pixel format supports MSAA when used as render-pass attachment
    bool depth;             // pixel format is a depth format
    bool compressed;        // true if this is a hardware-compressed format
    bool read;              // true if format supports compute shader read access
    bool write;             // true if format supports compute shader write access
    int bytes_per_pixel;    // NOTE: this is 0 for compressed formats, use sg_query_row_pitch() / sg_query_surface_pitch() as alternative
} sg_pixelformat_info;

/*
    Runtime information about available optional features, returned by sg_query_features()
*/
typedef struct sg_features {
    bool origin_top_left;               // framebuffer- and texture-origin is in top left corner
    bool image_clamp_to_border;         // border color and clamp-to-border uv-wrap mode is supported
    bool mrt_independent_blend_state;   // multiple-render-target rendering can use per-render-target blend state
    bool mrt_independent_write_mask;    // multiple-render-target rendering can use per-render-target color write masks
    bool compute;                       // storage buffers and compute shaders are supported
    bool msaa_image_bindings;           // if true, multisampled images can be bound as texture resources
    bool separate_buffer_types;         // cannot use the same buffer for vertex and indices (onlu WebGL2)
} sg_features;

/*
    Runtime information about resource limits, returned by sg_query_limit()
*/
typedef struct sg_limits {
    int max_image_size_2d;          // max width/height of SG_IMAGETYPE_2D images
    int max_image_size_cube;        // max width/height of SG_IMAGETYPE_CUBE images
    int max_image_size_3d;          // max width/height/depth of SG_IMAGETYPE_3D images
    int max_image_size_array;       // max width/height of SG_IMAGETYPE_ARRAY images
    int max_image_array_layers;     // max number of layers in SG_IMAGETYPE_ARRAY images
    int max_vertex_attrs;           // max number of vertex attributes, clamped to SG_MAX_VERTEX_ATTRIBUTES
    int gl_max_vertex_uniform_components;    // <= GL_MAX_VERTEX_UNIFORM_COMPONENTS (only on GL backends)
    int gl_max_combined_texture_image_units; // <= GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS (only on GL backends)
} sg_limits;

/*
    sg_resource_state

    The current state of a resource in its resource pool.
    Resources start in the INITIAL state, which means the
    pool slot is unoccupied and can be allocated. When a resource is
    created, first an id is allocated, and the resource pool slot
    is set to state ALLOC. After allocation, the resource is
    initialized, which may result in the VALID or FAILED state. The
    reason why allocation and initialization are separate is because
    some resource types (e.g. buffers and images) might be asynchronously
    initialized by the user application. If a resource which is not
    in the VALID state is attempted to be used for rendering, rendering
    operations will silently be dropped.

    The special INVALID state is returned in sg_query_xxx_state() if no
    resource object exists for the provided resource id.
*/
typedef enum sg_resource_state {
    SG_RESOURCESTATE_INITIAL,
    SG_RESOURCESTATE_ALLOC,
    SG_RESOURCESTATE_VALID,
    SG_RESOURCESTATE_FAILED,
    SG_RESOURCESTATE_INVALID,
    _SG_RESOURCESTATE_FORCE_U32 = 0x7FFFFFFF
} sg_resource_state;

/*
    sg_index_type

    Indicates whether indexed rendering (fetching vertex-indices from an
    index buffer) is used, and if yes, the index data type (16- or 32-bits).

    This is used in the sg_pipeline_desc.index_type member when creating a
    pipeline object.

    The default index type is SG_INDEXTYPE_NONE.
*/
typedef enum sg_index_type {
    _SG_INDEXTYPE_DEFAULT,   // value 0 reserved for default-init
    SG_INDEXTYPE_NONE,
    SG_INDEXTYPE_UINT16,
    SG_INDEXTYPE_UINT32,
    _SG_INDEXTYPE_NUM,
    _SG_INDEXTYPE_FORCE_U32 = 0x7FFFFFFF
} sg_index_type;

/*
    sg_image_type

    Indicates the basic type of an image object (2D-texture, cubemap,
    3D-texture or 2D-array-texture). Used in the sg_image_desc.type member when
    creating an image, and in sg_shader_image_desc to describe a sampled texture
    in the shader (both must match and will be checked in the validation layer
    when calling sg_apply_bindings).

    The default image type when creating an image is SG_IMAGETYPE_2D.
*/
typedef enum sg_image_type {
    _SG_IMAGETYPE_DEFAULT,  // value 0 reserved for default-init
    SG_IMAGETYPE_2D,
    SG_IMAGETYPE_CUBE,
    SG_IMAGETYPE_3D,
    SG_IMAGETYPE_ARRAY,
    _SG_IMAGETYPE_NUM,
    _SG_IMAGETYPE_FORCE_U32 = 0x7FFFFFFF
} sg_image_type;

/*
    sg_image_sample_type

    The basic data type of a texture sample as expected by a shader.
    Must be provided in sg_shader_image and used by the validation
    layer in sg_apply_bindings() to check if the provided image object
    is compatible with what the shader expects. Apart from the sokol-gfx
    validation layer, WebGPU is the only backend API which actually requires
    matching texture and sampler type to be provided upfront for validation
    (other 3D APIs treat texture/sampler type mismatches as undefined behaviour).

    NOTE that the following texture pixel formats require the use
    of SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT, combined with a sampler
    of type SG_SAMPLERTYPE_NONFILTERING:

    - SG_PIXELFORMAT_R32F
    - SG_PIXELFORMAT_RG32F
    - SG_PIXELFORMAT_RGBA32F

    (when using sokol-shdc, also check out the meta tags `@image_sample_type`
    and `@sampler_type`)
*/
typedef enum sg_image_sample_type {
    _SG_IMAGESAMPLETYPE_DEFAULT,  // value 0 reserved for default-init
    SG_IMAGESAMPLETYPE_FLOAT,
    SG_IMAGESAMPLETYPE_DEPTH,
    SG_IMAGESAMPLETYPE_SINT,
    SG_IMAGESAMPLETYPE_UINT,
    SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT,
    _SG_IMAGESAMPLETYPE_NUM,
    _SG_IMAGESAMPLETYPE_FORCE_U32 = 0x7FFFFFFF
} sg_image_sample_type;

/*
    sg_sampler_type

    The basic type of a texture sampler (sampling vs comparison) as
    defined in a shader. Must be provided in sg_shader_sampler_desc.

    sg_image_sample_type and sg_sampler_type for a texture/sampler
    pair must be compatible with each other, specifically only
    the following pairs are allowed:

    - SG_IMAGESAMPLETYPE_FLOAT => (SG_SAMPLERTYPE_FILTERING or SG_SAMPLERTYPE_NONFILTERING)
    - SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT => SG_SAMPLERTYPE_NONFILTERING
    - SG_IMAGESAMPLETYPE_SINT => SG_SAMPLERTYPE_NONFILTERING
    - SG_IMAGESAMPLETYPE_UINT => SG_SAMPLERTYPE_NONFILTERING
    - SG_IMAGESAMPLETYPE_DEPTH => SG_SAMPLERTYPE_COMPARISON
*/
typedef enum sg_sampler_type {
    _SG_SAMPLERTYPE_DEFAULT,
    SG_SAMPLERTYPE_FILTERING,
    SG_SAMPLERTYPE_NONFILTERING,
    SG_SAMPLERTYPE_COMPARISON,
    _SG_SAMPLERTYPE_NUM,
    _SG_SAMPLERTYPE_FORCE_U32,
} sg_sampler_type;

/*
    sg_cube_face

    The cubemap faces. Use these as indices in the sg_image_desc.content
    array.
*/
typedef enum sg_cube_face {
    SG_CUBEFACE_POS_X,
    SG_CUBEFACE_NEG_X,
    SG_CUBEFACE_POS_Y,
    SG_CUBEFACE_NEG_Y,
    SG_CUBEFACE_POS_Z,
    SG_CUBEFACE_NEG_Z,
    SG_CUBEFACE_NUM,
    _SG_CUBEFACE_FORCE_U32 = 0x7FFFFFFF
} sg_cube_face;

/*
    sg_primitive_type

    This is the common subset of 3D primitive types supported across all 3D
    APIs. This is used in the sg_pipeline_desc.primitive_type member when
    creating a pipeline object.

    The default primitive type is SG_PRIMITIVETYPE_TRIANGLES.
*/
typedef enum sg_primitive_type {
    _SG_PRIMITIVETYPE_DEFAULT,  // value 0 reserved for default-init
    SG_PRIMITIVETYPE_POINTS,
    SG_PRIMITIVETYPE_LINES,
    SG_PRIMITIVETYPE_LINE_STRIP,
    SG_PRIMITIVETYPE_TRIANGLES,
    SG_PRIMITIVETYPE_TRIANGLE_STRIP,
    _SG_PRIMITIVETYPE_NUM,
    _SG_PRIMITIVETYPE_FORCE_U32 = 0x7FFFFFFF
} sg_primitive_type;

/*
    sg_filter

    The filtering mode when sampling a texture image. This is
    used in the sg_sampler_desc.min_filter, sg_sampler_desc.mag_filter
    and sg_sampler_desc.mipmap_filter members when creating a sampler object.

    For the default is SG_FILTER_NEAREST.
*/
typedef enum sg_filter {
    _SG_FILTER_DEFAULT, // value 0 reserved for default-init
    SG_FILTER_NEAREST,
    SG_FILTER_LINEAR,
    _SG_FILTER_NUM,
    _SG_FILTER_FORCE_U32 = 0x7FFFFFFF
} sg_filter;

/*
    sg_wrap

    The texture coordinates wrapping mode when sampling a texture
    image. This is used in the sg_image_desc.wrap_u, .wrap_v
    and .wrap_w members when creating an image.

    The default wrap mode is SG_WRAP_REPEAT.

    NOTE: SG_WRAP_CLAMP_TO_BORDER is not supported on all backends
    and platforms. To check for support, call sg_query_features()
    and check the "clamp_to_border" boolean in the returned
    sg_features struct.

    Platforms which don't support SG_WRAP_CLAMP_TO_BORDER will silently fall back
    to SG_WRAP_CLAMP_TO_EDGE without a validation error.
*/
typedef enum sg_wrap {
    _SG_WRAP_DEFAULT,   // value 0 reserved for default-init
    SG_WRAP_REPEAT,
    SG_WRAP_CLAMP_TO_EDGE,
    SG_WRAP_CLAMP_TO_BORDER,
    SG_WRAP_MIRRORED_REPEAT,
    _SG_WRAP_NUM,
    _SG_WRAP_FORCE_U32 = 0x7FFFFFFF
} sg_wrap;

/*
    sg_border_color

    The border color to use when sampling a texture, and the UV wrap
    mode is SG_WRAP_CLAMP_TO_BORDER.

    The default border color is SG_BORDERCOLOR_OPAQUE_BLACK
*/
typedef enum sg_border_color {
    _SG_BORDERCOLOR_DEFAULT,    // value 0 reserved for default-init
    SG_BORDERCOLOR_TRANSPARENT_BLACK,
    SG_BORDERCOLOR_OPAQUE_BLACK,
    SG_BORDERCOLOR_OPAQUE_WHITE,
    _SG_BORDERCOLOR_NUM,
    _SG_BORDERCOLOR_FORCE_U32 = 0x7FFFFFFF
} sg_border_color;

/*
    sg_vertex_format

    The data type of a vertex component. This is used to describe
    the layout of input vertex data when creating a pipeline object.

    NOTE that specific mapping rules exist from the CPU-side vertex
    formats to the vertex attribute base type in the vertex shader code
    (see doc header section 'ON VERTEX FORMATS').
*/
typedef enum sg_vertex_format {
    SG_VERTEXFORMAT_INVALID,
    SG_VERTEXFORMAT_FLOAT,
    SG_VERTEXFORMAT_FLOAT2,
    SG_VERTEXFORMAT_FLOAT3,
    SG_VERTEXFORMAT_FLOAT4,
    SG_VERTEXFORMAT_INT,
    SG_VERTEXFORMAT_INT2,
    SG_VERTEXFORMAT_INT3,
    SG_VERTEXFORMAT_INT4,
    SG_VERTEXFORMAT_UINT,
    SG_VERTEXFORMAT_UINT2,
    SG_VERTEXFORMAT_UINT3,
    SG_VERTEXFORMAT_UINT4,
    SG_VERTEXFORMAT_BYTE4,
    SG_VERTEXFORMAT_BYTE4N,
    SG_VERTEXFORMAT_UBYTE4,
    SG_VERTEXFORMAT_UBYTE4N,
    SG_VERTEXFORMAT_SHORT2,
    SG_VERTEXFORMAT_SHORT2N,
    SG_VERTEXFORMAT_USHORT2,
    SG_VERTEXFORMAT_USHORT2N,
    SG_VERTEXFORMAT_SHORT4,
    SG_VERTEXFORMAT_SHORT4N,
    SG_VERTEXFORMAT_USHORT4,
    SG_VERTEXFORMAT_USHORT4N,
    SG_VERTEXFORMAT_UINT10_N2,
    SG_VERTEXFORMAT_HALF2,
    SG_VERTEXFORMAT_HALF4,
    _SG_VERTEXFORMAT_NUM,
    _SG_VERTEXFORMAT_FORCE_U32 = 0x7FFFFFFF
} sg_vertex_format;

/*
    sg_vertex_step

    Defines whether the input pointer of a vertex input stream is advanced
    'per vertex' or 'per instance'. The default step-func is
    SG_VERTEXSTEP_PER_VERTEX. SG_VERTEXSTEP_PER_INSTANCE is used with
    instanced-rendering.

    The vertex-step is part of the vertex-layout definition
    when creating pipeline objects.
*/
typedef enum sg_vertex_step {
    _SG_VERTEXSTEP_DEFAULT,     // value 0 reserved for default-init
    SG_VERTEXSTEP_PER_VERTEX,
    SG_VERTEXSTEP_PER_INSTANCE,
    _SG_VERTEXSTEP_NUM,
    _SG_VERTEXSTEP_FORCE_U32 = 0x7FFFFFFF
} sg_vertex_step;

/*
    sg_uniform_type

    The data type of a uniform block member. This is used to
    describe the internal layout of uniform blocks when creating
    a shader object. This is only required for the GL backend, all
    other backends will ignore the interior layout of uniform blocks.
*/
typedef enum sg_uniform_type {
    SG_UNIFORMTYPE_INVALID,
    SG_UNIFORMTYPE_FLOAT,
    SG_UNIFORMTYPE_FLOAT2,
    SG_UNIFORMTYPE_FLOAT3,
    SG_UNIFORMTYPE_FLOAT4,
    SG_UNIFORMTYPE_INT,
    SG_UNIFORMTYPE_INT2,
    SG_UNIFORMTYPE_INT3,
    SG_UNIFORMTYPE_INT4,
    SG_UNIFORMTYPE_MAT4,
    _SG_UNIFORMTYPE_NUM,
    _SG_UNIFORMTYPE_FORCE_U32 = 0x7FFFFFFF
} sg_uniform_type;

/*
    sg_uniform_layout

    A hint for the interior memory layout of uniform blocks. This is
    only relevant for the GL backend where the internal layout
    of uniform blocks must be known to sokol-gfx. For all other backends the
    internal memory layout of uniform blocks doesn't matter, sokol-gfx
    will just pass uniform data as an opaque memory blob to the
    3D backend.

    SG_UNIFORMLAYOUT_NATIVE (default)
        Native layout means that a 'backend-native' memory layout
        is used. For the GL backend this means that uniforms
        are packed tightly in memory (e.g. there are no padding
        bytes).

    SG_UNIFORMLAYOUT_STD140
        The memory layout is a subset of std140. Arrays are only
        allowed for the FLOAT4, INT4 and MAT4. Alignment is as
        is as follows:

            FLOAT, INT:         4 byte alignment
            FLOAT2, INT2:       8 byte alignment
            FLOAT3, INT3:       16 byte alignment(!)
            FLOAT4, INT4:       16 byte alignment
            MAT4:               16 byte alignment
            FLOAT4[], INT4[]:   16 byte alignment

        The overall size of the uniform block must be a multiple
        of 16.

    For more information search for 'UNIFORM DATA LAYOUT' in the documentation block
    at the start of the header.
*/
typedef enum sg_uniform_layout {
    _SG_UNIFORMLAYOUT_DEFAULT,     // value 0 reserved for default-init
    SG_UNIFORMLAYOUT_NATIVE,       // default: layout depends on currently active backend
    SG_UNIFORMLAYOUT_STD140,       // std140: memory layout according to std140
    _SG_UNIFORMLAYOUT_NUM,
    _SG_UNIFORMLAYOUT_FORCE_U32 = 0x7FFFFFFF
} sg_uniform_layout;

/*
    sg_cull_mode

    The face-culling mode, this is used in the
    sg_pipeline_desc.cull_mode member when creating a
    pipeline object.

    The default cull mode is SG_CULLMODE_NONE
*/
typedef enum sg_cull_mode {
    _SG_CULLMODE_DEFAULT,   // value 0 reserved for default-init
    SG_CULLMODE_NONE,
    SG_CULLMODE_FRONT,
    SG_CULLMODE_BACK,
    _SG_CULLMODE_NUM,
    _SG_CULLMODE_FORCE_U32 = 0x7FFFFFFF
} sg_cull_mode;

/*
    sg_face_winding

    The vertex-winding rule that determines a front-facing primitive. This
    is used in the member sg_pipeline_desc.face_winding
    when creating a pipeline object.

    The default winding is SG_FACEWINDING_CW (clockwise)
*/
typedef enum sg_face_winding {
    _SG_FACEWINDING_DEFAULT,    // value 0 reserved for default-init
    SG_FACEWINDING_CCW,
    SG_FACEWINDING_CW,
    _SG_FACEWINDING_NUM,
    _SG_FACEWINDING_FORCE_U32 = 0x7FFFFFFF
} sg_face_winding;

/*
    sg_compare_func

    The compare-function for configuring depth- and stencil-ref tests
    in pipeline objects, and for texture samplers which perform a comparison
    instead of regular sampling operation.

    Used in the following structs:

    sg_pipeline_desc
        .depth
            .compare
        .stencil
            .front.compare
            .back.compare

    sg_sampler_desc
        .compare

    The default compare func for depth- and stencil-tests is
    SG_COMPAREFUNC_ALWAYS.

    The default compare func for samplers is SG_COMPAREFUNC_NEVER.
*/
typedef enum sg_compare_func {
    _SG_COMPAREFUNC_DEFAULT,    // value 0 reserved for default-init
    SG_COMPAREFUNC_NEVER,
    SG_COMPAREFUNC_LESS,
    SG_COMPAREFUNC_EQUAL,
    SG_COMPAREFUNC_LESS_EQUAL,
    SG_COMPAREFUNC_GREATER,
    SG_COMPAREFUNC_NOT_EQUAL,
    SG_COMPAREFUNC_GREATER_EQUAL,
    SG_COMPAREFUNC_ALWAYS,
    _SG_COMPAREFUNC_NUM,
    _SG_COMPAREFUNC_FORCE_U32 = 0x7FFFFFFF
} sg_compare_func;

/*
    sg_stencil_op

    The operation performed on a currently stored stencil-value when a
    comparison test passes or fails. This is used when creating a pipeline
    object in the following sg_pipeline_desc struct items:

    sg_pipeline_desc
        .stencil
            .front
                .fail_op
                .depth_fail_op
                .pass_op
            .back
                .fail_op
                .depth_fail_op
                .pass_op

    The default value is SG_STENCILOP_KEEP.
*/
typedef enum sg_stencil_op {
    _SG_STENCILOP_DEFAULT,      // value 0 reserved for default-init
    SG_STENCILOP_KEEP,
    SG_STENCILOP_ZERO,
    SG_STENCILOP_REPLACE,
    SG_STENCILOP_INCR_CLAMP,
    SG_STENCILOP_DECR_CLAMP,
    SG_STENCILOP_INVERT,
    SG_STENCILOP_INCR_WRAP,
    SG_STENCILOP_DECR_WRAP,
    _SG_STENCILOP_NUM,
    _SG_STENCILOP_FORCE_U32 = 0x7FFFFFFF
} sg_stencil_op;

/*
    sg_blend_factor

    The source and destination factors in blending operations.
    This is used in the following members when creating a pipeline object:

    sg_pipeline_desc
        .colors[i]
            .blend
                .src_factor_rgb
                .dst_factor_rgb
                .src_factor_alpha
                .dst_factor_alpha

    The default value is SG_BLENDFACTOR_ONE for source
    factors, and for the destination SG_BLENDFACTOR_ZERO if the associated
    blend-op is ADD, SUBTRACT or REVERSE_SUBTRACT or SG_BLENDFACTOR_ONE
    if the associated blend-op is MIN or MAX.
*/
typedef enum sg_blend_factor {
    _SG_BLENDFACTOR_DEFAULT,    // value 0 reserved for default-init
    SG_BLENDFACTOR_ZERO,
    SG_BLENDFACTOR_ONE,
    SG_BLENDFACTOR_SRC_COLOR,
    SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR,
    SG_BLENDFACTOR_SRC_ALPHA,
    SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA,
    SG_BLENDFACTOR_DST_COLOR,
    SG_BLENDFACTOR_ONE_MINUS_DST_COLOR,
    SG_BLENDFACTOR_DST_ALPHA,
    SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA,
    SG_BLENDFACTOR_SRC_ALPHA_SATURATED,
    SG_BLENDFACTOR_BLEND_COLOR,
    SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR,
    SG_BLENDFACTOR_BLEND_ALPHA,
    SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA,
    _SG_BLENDFACTOR_NUM,
    _SG_BLENDFACTOR_FORCE_U32 = 0x7FFFFFFF
} sg_blend_factor;

/*
    sg_blend_op

    Describes how the source and destination values are combined in the
    fragment blending operation. It is used in the following struct items
    when creating a pipeline object:

    sg_pipeline_desc
        .colors[i]
            .blend
                .op_rgb
                .op_alpha

    The default value is SG_BLENDOP_ADD.
*/
typedef enum sg_blend_op {
    _SG_BLENDOP_DEFAULT,    // value 0 reserved for default-init
    SG_BLENDOP_ADD,
    SG_BLENDOP_SUBTRACT,
    SG_BLENDOP_REVERSE_SUBTRACT,
    SG_BLENDOP_MIN,
    SG_BLENDOP_MAX,
    _SG_BLENDOP_NUM,
    _SG_BLENDOP_FORCE_U32 = 0x7FFFFFFF
} sg_blend_op;

/*
    sg_color_mask

    Selects the active color channels when writing a fragment color to the
    framebuffer. This is used in the members
    sg_pipeline_desc.colors[i].write_mask when creating a pipeline object.

    The default colormask is SG_COLORMASK_RGBA (write all colors channels)

    NOTE: since the color mask value 0 is reserved for the default value
    (SG_COLORMASK_RGBA), use SG_COLORMASK_NONE if all color channels
    should be disabled.
*/
typedef enum sg_color_mask {
    _SG_COLORMASK_DEFAULT = 0,    // value 0 reserved for default-init
    SG_COLORMASK_NONE   = 0x10,   // special value for 'all channels disabled
    SG_COLORMASK_R      = 0x1,
    SG_COLORMASK_G      = 0x2,
    SG_COLORMASK_RG     = 0x3,
    SG_COLORMASK_B      = 0x4,
    SG_COLORMASK_RB     = 0x5,
    SG_COLORMASK_GB     = 0x6,
    SG_COLORMASK_RGB    = 0x7,
    SG_COLORMASK_A      = 0x8,
    SG_COLORMASK_RA     = 0x9,
    SG_COLORMASK_GA     = 0xA,
    SG_COLORMASK_RGA    = 0xB,
    SG_COLORMASK_BA     = 0xC,
    SG_COLORMASK_RBA    = 0xD,
    SG_COLORMASK_GBA    = 0xE,
    SG_COLORMASK_RGBA   = 0xF,
    _SG_COLORMASK_FORCE_U32 = 0x7FFFFFFF
} sg_color_mask;

/*
    sg_load_action

    Defines the load action that should be performed at the start of a render pass:

    SG_LOADACTION_CLEAR:        clear the render target
    SG_LOADACTION_LOAD:         load the previous content of the render target
    SG_LOADACTION_DONTCARE:     leave the render target in an undefined state

    This is used in the sg_pass_action structure.

    The default load action for all pass attachments is SG_LOADACTION_CLEAR,
    with the values rgba = { 0.5f, 0.5f, 0.5f, 1.0f }, depth=1.0f and stencil=0.

    If you want to override the default behaviour, it is important to not
    only set the clear color, but the 'action' field as well (as long as this
    is _SG_LOADACTION_DEFAULT, the value fields will be ignored).
*/
typedef enum sg_load_action {
    _SG_LOADACTION_DEFAULT,
    SG_LOADACTION_CLEAR,
    SG_LOADACTION_LOAD,
    SG_LOADACTION_DONTCARE,
    _SG_LOADACTION_FORCE_U32 = 0x7FFFFFFF
} sg_load_action;

/*
    sg_store_action

    Defines the store action that should be performed at the end of a render pass:

    SG_STOREACTION_STORE:       store the rendered content to the color attachment image
    SG_STOREACTION_DONTCARE:    allows the GPU to discard the rendered content
*/
typedef enum sg_store_action {
    _SG_STOREACTION_DEFAULT,
    SG_STOREACTION_STORE,
    SG_STOREACTION_DONTCARE,
    _SG_STOREACTION_FORCE_U32 = 0x7FFFFFFF
} sg_store_action;


/*
    sg_pass_action

    The sg_pass_action struct defines the actions to be performed
    at the start and end of a render pass.

    - at the start of the pass: whether the render attachments should be cleared,
      loaded with their previous content, or start in an undefined state
    - for clear operations: the clear value (color, depth, or stencil values)
    - at the end of the pass: whether the rendering result should be
      stored back into the render attachment or discarded
*/
typedef struct sg_color_attachment_action {
    sg_load_action load_action;         // default: SG_LOADACTION_CLEAR
    sg_store_action store_action;       // default: SG_STOREACTION_STORE
    sg_color clear_value;               // default: { 0.5f, 0.5f, 0.5f, 1.0f }
} sg_color_attachment_action;

typedef struct sg_depth_attachment_action {
    sg_load_action load_action;         // default: SG_LOADACTION_CLEAR
    sg_store_action store_action;       // default: SG_STOREACTION_DONTCARE
    float clear_value;                  // default: 1.0
} sg_depth_attachment_action;

typedef struct sg_stencil_attachment_action {
    sg_load_action load_action;         // default: SG_LOADACTION_CLEAR
    sg_store_action store_action;       // default: SG_STOREACTION_DONTCARE
    uint8_t clear_value;                // default: 0
} sg_stencil_attachment_action;

typedef struct sg_pass_action {
    sg_color_attachment_action colors[SG_MAX_COLOR_ATTACHMENTS];
    sg_depth_attachment_action depth;
    sg_stencil_attachment_action stencil;
} sg_pass_action;

/*
    sg_swapchain

    Used in sg_begin_pass() to provide details about an external swapchain
    (pixel formats, sample count and backend-API specific render surface objects).

    The following information must be provided:

    - the width and height of the swapchain surfaces in number of pixels,
    - the pixel format of the render- and optional msaa-resolve-surface
    - the pixel format of the optional depth- or depth-stencil-surface
    - the MSAA sample count for the render and depth-stencil surface

    If the pixel formats and MSAA sample counts are left zero-initialized,
    their defaults are taken from the sg_environment struct provided in the
    sg_setup() call.

    The width and height *must* be > 0.

    Additionally the following backend API specific objects must be passed in
    as 'type erased' void pointers:

    GL:
        - on all GL backends, a GL framebuffer object must be provided. This
          can be zero for the default framebuffer.

    D3D11:
        - an ID3D11RenderTargetView for the rendering surface, without
          MSAA rendering this surface will also be displayed
        - an optional ID3D11DepthStencilView for the depth- or depth/stencil
          buffer surface
        - when MSAA rendering is used, another ID3D11RenderTargetView
          which serves as MSAA resolve target and will be displayed

    WebGPU (same as D3D11, except different types)
        - a WGPUTextureView for the rendering surface, without
          MSAA rendering this surface will also be displayed
        - an optional WGPUTextureView for the depth- or depth/stencil
          buffer surface
        - when MSAA rendering is used, another WGPUTextureView
          which serves as MSAA resolve target and will be displayed

    Metal (NOTE that the roles of provided surfaces is slightly different
    than on D3D11 or WebGPU in case of MSAA vs non-MSAA rendering):

        - A current CAMetalDrawable (NOT an MTLDrawable!) which will be presented.
          This will either be rendered to directly (if no MSAA is used), or serve
          as MSAA-resolve target.
        - an optional MTLTexture for the depth- or depth-stencil buffer
        - an optional multisampled MTLTexture which serves as intermediate
          rendering surface which will then be resolved into the
          CAMetalDrawable.

    NOTE that for Metal you must use an ObjC __bridge cast to
    properly tunnel the ObjC object id through a C void*, e.g.:

        swapchain.metal.current_drawable = (__bridge const void*) [mtkView currentDrawable];

    On all other backends you shouldn't need to mess with the reference count.

    It's a good practice to write a helper function which returns an initialized
    sg_swapchain structs, which can then be plugged directly into
    sg_pass.swapchain. Look at the function sglue_swapchain() in the sokol_glue.h
    as an example.
*/
typedef struct sg_metal_swapchain {
    const void* current_drawable;       // CAMetalDrawable (NOT MTLDrawable!!!)
    const void* depth_stencil_texture;  // MTLTexture
    const void* msaa_color_texture;     // MTLTexture
} sg_metal_swapchain;

typedef struct sg_d3d11_swapchain {
    const void* render_view;            // ID3D11RenderTargetView
    const void* resolve_view;           // ID3D11RenderTargetView
    const void* depth_stencil_view;     // ID3D11DepthStencilView
} sg_d3d11_swapchain;

typedef struct sg_wgpu_swapchain {
    const void* render_view;            // WGPUTextureView
    const void* resolve_view;           // WGPUTextureView
    const void* depth_stencil_view;     // WGPUTextureView
} sg_wgpu_swapchain;

typedef struct sg_gl_swapchain {
    uint32_t framebuffer;               // GL framebuffer object
} sg_gl_swapchain;

typedef struct sg_swapchain {
    int width;
    int height;
    int sample_count;
    sg_pixel_format color_format;
    sg_pixel_format depth_format;
    sg_metal_swapchain metal;
    sg_d3d11_swapchain d3d11;
    sg_wgpu_swapchain wgpu;
    sg_gl_swapchain gl;
} sg_swapchain;

/*
    sg_pass

    The sg_pass structure is passed as argument into the sg_begin_pass()
    function.

    For a swapchain render pass, provide an sg_pass_action and sg_swapchain
    struct (for instance via the sglue_swapchain() helper function from
    sokol_glue.h):

        sg_begin_pass(&(sg_pass){
            .action = { ... },
            .swapchain = sglue_swapchain(),
        });

    For an offscreen render pass, provide an sg_pass_action struct and
    an sg_attachments handle:

        sg_begin_pass(&(sg_pass){
            .action = { ... },
            .attachments = attachments,
        });

    You can also omit the .action object to get default pass action behaviour
    (clear to color=grey, depth=1 and stencil=0).

    For a compute pass, just set the sg_pass.compute boolean to true:

        sg_begin_pass(&(sg_pass){ .compute = true });
*/
typedef struct sg_pass {
    uint32_t _start_canary;
    bool compute;
    sg_pass_action action;
    sg_attachments attachments;
    sg_swapchain swapchain;
    const char* label;
    uint32_t _end_canary;
} sg_pass;

/*
    sg_bindings

    The sg_bindings structure defines the buffers, images and
    samplers resource bindings for the next draw call.

    To update the resource bindings, call sg_apply_bindings() with
    a pointer to a populated sg_bindings struct. Note that
    sg_apply_bindings() must be called after sg_apply_pipeline()
    and that bindings are not preserved across sg_apply_pipeline()
    calls, even when the new pipeline uses the same 'bindings layout'.

    A resource binding struct contains:

    - 1..N vertex buffers
    - 0..N vertex buffer offsets
    - 0..1 index buffers
    - 0..1 index buffer offsets
    - 0..N images
    - 0..N samplers
    - 0..N storage buffers

    Where 'N' is defined in the following constants:

    - SG_MAX_VERTEXBUFFER_BINDSLOTS
    - SG_MAX_IMAGE_BINDLOTS
    - SG_MAX_SAMPLER_BINDSLOTS
    - SG_MAX_STORAGEBUFFER_BINDGLOTS

    Note that inside compute passes vertex- and index-buffer-bindings are
    disallowed.

    When using sokol-shdc for shader authoring, the `layout(binding=N)`
    annotation in the shader code directly maps to the slot index for that
    resource type in the bindings struct, for instance the following vertex-
    and fragment-shader interface for sokol-shdc:

        @vs vs
        layout(binding=0) uniform vs_params { ... };
        layout(binding=0) readonly buffer ssbo { ... };
        layout(binding=0) uniform texture2D vs_tex;
        layout(binding=0) uniform sampler vs_smp;
        ...
        @end

        @fs fs
        layout(binding=1) uniform fs_params { ... };
        layout(binding=1) uniform texture2D fs_tex;
        layout(binding=1) uniform sampler fs_smp;
        ...
        @end

    ...would map to the following sg_bindings struct:

        const sg_bindings bnd = {
            .vertex_buffers[0] = ...,
            .images[0] = vs_tex,
            .images[1] = fs_tex,
            .samplers[0] = vs_smp,
            .samplers[1] = fs_smp,
            .storage_buffers[0] = ssbo,
        };

    ...alternatively you can use code-generated slot indices:

        const sg_bindings bnd = {
            .vertex_buffers[0] = ...,
            .images[IMG_vs_tex] = vs_tex,
            .images[IMG_fs_tex] = fs_tex,
            .samplers[SMP_vs_smp] = vs_smp,
            .samplers[SMP_fs_smp] = fs_smp,
            .storage_buffers[SBUF_ssbo] = ssbo,
        };

    Resource bindslots for a specific shader/pipeline may have gaps, and an
    sg_bindings struct may have populated bind slots which are not used by a
    specific shader. This allows to use the same sg_bindings struct across
    different shader variants.

    When not using sokol-shdc, the bindslot indices in the sg_bindings
    struct need to match the per-resource reflection info slot indices
    in the sg_shader_desc struct (for details about that see the
    sg_shader_desc struct documentation).

    The optional buffer offsets can be used to put different unrelated
    chunks of vertex- and/or index-data into the same buffer objects.
*/
typedef struct sg_bindings {
    uint32_t _start_canary;
    sg_buffer vertex_buffers[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    int vertex_buffer_offsets[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    sg_buffer index_buffer;
    int index_buffer_offset;
    sg_image images[SG_MAX_IMAGE_BINDSLOTS];
    sg_sampler samplers[SG_MAX_SAMPLER_BINDSLOTS];
    sg_buffer storage_buffers[SG_MAX_STORAGEBUFFER_BINDSLOTS];
    uint32_t _end_canary;
} sg_bindings;

/*
    sg_buffer_usage

    Describes how a buffer object is going to be used:

    .vertex_buffer (default: true)
        the buffer will bound as vertex buffer via sg_bindings.vertex_buffers[]
    .index_buffer (default: false)
        the buffer will bound as index buffer via sg_bindings.index_buffer
    .storage_buffer (default: false)
        the buffer will bound as storage buffer via sg_bindings.storage_buffers[]
    .immutable (default: true)
        the buffer content will never be updated from the CPU side (but
        may be written to by a compute shader)
    .dynamic_update (default: false)
        the buffer content will be infrequently updated from the CPU side
    .stream_upate (default: false)
        the buffer content will be updated each frame from the CPU side
*/
typedef struct sg_buffer_usage {
    bool vertex_buffer;
    bool index_buffer;
    bool storage_buffer;
    bool immutable;
    bool dynamic_update;
    bool stream_update;
} sg_buffer_usage;

/*
    sg_buffer_desc

    Creation parameters for sg_buffer objects, used in the sg_make_buffer() call.

    The default configuration is:

    .size:      0       (*must* be >0 for buffers without data)
    .usage              .vertex_buffer = true, .immutable = true
    .data.ptr   0       (*must* be valid for immutable buffers without storage buffer usage)
    .data.size  0       (*must* be > 0 for immutable buffers without storage buffer usage)
    .label      0       (optional string label)

    For immutable buffers which are initialized with initial data,
    keep the .size item zero-initialized, and set the size together with the
    pointer to the initial data in the .data item.

    For immutable or mutable buffers without initial data, keep the .data item
    zero-initialized, and set the buffer size in the .size item instead.

    You can also set both size values, but currently both size values must
    be identical (this may change in the future when the dynamic resource
    management may become more flexible).

    NOTE: Immutable buffers without storage-buffer-usage *must* be created
    with initial content, this restriction doesn't apply to storage buffer usage,
    because storage buffers may also get their initial content by running
    a compute shader on them.

    NOTE: Buffers without initial data will have undefined content, e.g.
    do *not* expect the buffer to be zero-initialized!

    ADVANCED TOPIC: Injecting native 3D-API buffers:

    The following struct members allow to inject your own GL, Metal
    or D3D11 buffers into sokol_gfx:

    .gl_buffers[SG_NUM_INFLIGHT_FRAMES]
    .mtl_buffers[SG_NUM_INFLIGHT_FRAMES]
    .d3d11_buffer

    You must still provide all other struct items except the .data item, and
    these must match the creation parameters of the native buffers you provide.
    For sg_buffer_desc.usage.immutable buffers, only provide a single native
    3D-API buffer, otherwise you need to provide SG_NUM_INFLIGHT_FRAMES buffers
    (only for GL and Metal, not D3D11). Providing multiple buffers for GL and
    Metal is necessary because sokol_gfx will rotate through them when calling
    sg_update_buffer() to prevent lock-stalls.

    Note that it is expected that immutable injected buffer have already been
    initialized with content, and the .content member must be 0!

    Also you need to call sg_reset_state_cache() after calling native 3D-API
    functions, and before calling any sokol_gfx function.
*/
typedef struct sg_buffer_desc {
    uint32_t _start_canary;
    size_t size;
    sg_buffer_usage usage;
    sg_range data;
    const char* label;
    // optionally inject backend-specific resources
    uint32_t gl_buffers[SG_NUM_INFLIGHT_FRAMES];
    const void* mtl_buffers[SG_NUM_INFLIGHT_FRAMES];
    const void* d3d11_buffer;
    const void* wgpu_buffer;
    uint32_t _end_canary;
} sg_buffer_desc;

/*
    sg_image_usage

    Describes how the image object is going to be used:

    .render_attachment (default: false)
        the image object is used as color-, resolve- or depth-stencil-
        attachment in a render pass
    .storage_attachment (default: false)
        the image object is used as storage-attachment in a
        compute pass (to be written to by compute shaders)
    .immutable (default: true)
        the image content cannot be updated from the CPU side
        (but may be updated by the GPU in a render- or compute-pass)
    .dynamic_update (default: false)
        the image content is updated infrequently by the CPU
    .stream_update (default: false)
        the image content is updated each frame by the CPU via

    Note that the usage as texture binding is implicit and always allowed.
*/
typedef struct sg_image_usage {
    bool render_attachment;
    bool storage_attachment;
    bool immutable;
    bool dynamic_update;
    bool stream_update;
} sg_image_usage;

/*
    sg_image_data

    Defines the content of an image through a 2D array of sg_range structs.
    The first array dimension is the cubemap face, and the second array
    dimension the mipmap level.
*/
typedef struct sg_image_data {
    sg_range subimage[SG_CUBEFACE_NUM][SG_MAX_MIPMAPS];
} sg_image_data;

/*
    sg_image_desc

    Creation parameters for sg_image objects, used in the sg_make_image() call.

    The default configuration is:

    .type               SG_IMAGETYPE_2D
    .usage              .immutable = true
    .width              0 (must be set to >0)
    .height             0 (must be set to >0)
    .num_slices         1 (3D textures: depth; array textures: number of layers)
    .num_mipmaps        1
    .pixel_format       SG_PIXELFORMAT_RGBA8 for textures, or sg_desc.environment.defaults.color_format for render targets
    .sample_count       1 for textures, or sg_desc.environment.defaults.sample_count for render targets
    .data               an sg_image_data struct to define the initial content
    .label              0 (optional string label for trace hooks)

    Q: Why is the default sample_count for render targets identical with the
    "default sample count" from sg_desc.environment.defaults.sample_count?

    A: So that it matches the default sample count in pipeline objects. Even
    though it is a bit strange/confusing that offscreen render targets by default
    get the same sample count as 'default swapchains', but it's better that
    an offscreen render target created with default parameters matches
    a pipeline object created with default parameters.

    NOTE:

    Regular (non-attachment) images with usage.immutable must be fully initialized by
    providing a valid .data member which points to initialization data.

    Images with usage.render_attachment or usage.storage_attachment must
    *not* be created with initial content. Be aware that the initial
    content of render- and storage-attachment images is undefined.

    ADVANCED TOPIC: Injecting native 3D-API textures:

    The following struct members allow to inject your own GL, Metal or D3D11
    textures into sokol_gfx:

    .gl_textures[SG_NUM_INFLIGHT_FRAMES]
    .mtl_textures[SG_NUM_INFLIGHT_FRAMES]
    .d3d11_texture
    .d3d11_shader_resource_view
    .wgpu_texture
    .wgpu_texture_view

    For GL, you can also specify the texture target or leave it empty to use
    the default texture target for the image type (GL_TEXTURE_2D for
    SG_IMAGETYPE_2D etc)

    For D3D11 and WebGPU, either only provide a texture, or both a texture and
    shader-resource-view / texture-view object. If you want to use access the
    injected texture in a shader you *must* provide a shader-resource-view.

    The same rules apply as for injecting native buffers (see sg_buffer_desc
    documentation for more details).
*/
typedef struct sg_image_desc {
    uint32_t _start_canary;
    sg_image_type type;
    sg_image_usage usage;
    int width;
    int height;
    int num_slices;
    int num_mipmaps;
    sg_pixel_format pixel_format;
    int sample_count;
    sg_image_data data;
    const char* label;
    // optionally inject backend-specific resources
    uint32_t gl_textures[SG_NUM_INFLIGHT_FRAMES];
    uint32_t gl_texture_target;
    const void* mtl_textures[SG_NUM_INFLIGHT_FRAMES];
    const void* d3d11_texture;
    const void* d3d11_shader_resource_view;
    const void* wgpu_texture;
    const void* wgpu_texture_view;
    uint32_t _end_canary;
} sg_image_desc;

/*
    sg_sampler_desc

    Creation parameters for sg_sampler objects, used in the sg_make_sampler() call

    .min_filter:        SG_FILTER_NEAREST
    .mag_filter:        SG_FILTER_NEAREST
    .mipmap_filter      SG_FILTER_NEAREST
    .wrap_u:            SG_WRAP_REPEAT
    .wrap_v:            SG_WRAP_REPEAT
    .wrap_w:            SG_WRAP_REPEAT (only SG_IMAGETYPE_3D)
    .min_lod            0.0f
    .max_lod            FLT_MAX
    .border_color       SG_BORDERCOLOR_OPAQUE_BLACK
    .compare            SG_COMPAREFUNC_NEVER
    .max_anisotropy     1 (must be 1..16)

*/
typedef struct sg_sampler_desc {
    uint32_t _start_canary;
    sg_filter min_filter;
    sg_filter mag_filter;
    sg_filter mipmap_filter;
    sg_wrap wrap_u;
    sg_wrap wrap_v;
    sg_wrap wrap_w;
    float min_lod;
    float max_lod;
    sg_border_color border_color;
    sg_compare_func compare;
    uint32_t max_anisotropy;
    const char* label;
    // optionally inject backend-specific resources
    uint32_t gl_sampler;
    const void* mtl_sampler;
    const void* d3d11_sampler;
    const void* wgpu_sampler;
    uint32_t _end_canary;
} sg_sampler_desc;

/*
    sg_shader_desc

    Used as parameter of sg_make_shader() to create a shader object which
    communicates shader source or bytecode and shader interface
    reflection information to sokol-gfx.

    If you use sokol-shdc you can ignore the following information since
    the sg_shader_desc struct will be code-generated.

    Otherwise you need to provide the following information to the
    sg_make_shader() call:

    - a vertex- and fragment-shader function:
        - the shader source or bytecode
        - an optional entry point name
        - for D3D11: an optional compile target when source code is provided
          (the defaults are "vs_4_0" and "ps_4_0")

    - ...or alternatively, a compute function:
        - the shader source or bytecode
        - an optional entry point name
        - for D3D11: an optional compile target when source code is provided
          (the default is "cs_5_0")

    - vertex attributes required by some backends (not for compute shaders):
        - the vertex attribute base type (undefined, float, signed int, unsigned int),
          this information is only used in the validation layer to check that the
          pipeline object vertex formats are compatible with the input vertex attribute
          type used in the vertex shader. NOTE that the default base type
          'undefined' skips the validation layer check.
        - for the GL backend: optional vertex attribute names used for name lookup
        - for the D3D11 backend: semantic names and indices

    - only for compute shaders on the Metal backend:
        - the workgroup size aka 'threads per thread-group'

          In other 3D APIs this is declared in the shader code:
            - GLSL: `layout(local_size_x=x, local_size_y=y, local_size_y=z) in;`
            - HLSL: `[numthreads(x, y, z)]`
            - WGSL: `@workgroup_size(x, y, z)`
          ...but in Metal the workgroup size is declared on the CPU side

    - reflection information for each uniform block binding used by the shader:
        - the shader stage the uniform block appears in (SG_SHADERSTAGE_*)
        - the size in bytes of the uniform block
        - backend-specific bindslots:
            - HLSL: the constant buffer register `register(b0..7)`
            - MSL: the buffer attribute `[[buffer(0..7)]]`
            - WGSL: the binding in `@group(0) @binding(0..15)`
        - GLSL only: a description of the uniform block interior
            - the memory layout standard (SG_UNIFORMLAYOUT_*)
            - for each member in the uniform block:
                - the member type (SG_UNIFORM_*)
                - if the member is an array, the array count
                - the member name

    - reflection information for each texture binding used by the shader:
        - the shader stage the texture appears in (SG_SHADERSTAGE_*)
        - the image type (SG_IMAGETYPE_*)
        - the image-sample type (SG_IMAGESAMPLETYPE_*)
        - whether the texture is multisampled
        - backend specific bindslots:
            - HLSL: the texture register `register(t0..23)`
            - MSL: the texture attribute `[[texture(0..19)]]`
            - WGSL: the binding in `@group(1) @binding(0..127)`

    - reflection information for each sampler used by the shader:
        - the shader stage the sampler appears in (SG_SHADERSTAGE_*)
        - the sampler type (SG_SAMPLERTYPE_*)
        - backend specific bindslots:
            - HLSL: the sampler register `register(s0..15)`
            - MSL: the sampler attribute `[[sampler(0..15)]]`
            - WGSL: the binding in `@group(0) @binding(0..127)`

    - reflection information for each storage buffer binding used by the shader:
        - the shader stage the storage buffer appears in (SG_SHADERSTAGE_*)
        - whether the storage buffer is readonly
        - backend specific bindslots:
            - HLSL:
                - for readonly storage buffer bindings: `register(t0..23)`
                - for read/write storage buffer bindings: `register(u0..11)`
            - MSL: the buffer attribute `[[buffer(8..15)]]`
            - WGSL: the binding in `@group(1) @binding(0..127)`
            - GL: the binding in `layout(binding=0..7)`

    - reflection information for each storage image binding used by the shader:
        - the shader stage (*must* be SG_SHADERSTAGE_COMPUTE)
        - whether the storage image is writeonly or readwrite (for readonly
          access use a regular texture binding instead)
        - the image type expected by the shader (SG_IMAGETYPE_*)
        - the access pixel format expected by the shader (SG_PIXELFORMAT_*),
          note that only a subset of pixel formats is allowed for storage image
          bindings
        - backend specific bindslots:
            - HLSL: the UAV register `register(u0..u11)`
            - MSL: the texture attribute `[[texture(0..19)]]`
            - WGSL: the binding in `@group(2) @binding(0..3)`
            - GLSL: the binding in `layout(binding=0..3, [access_format])`

    - reflection information for each combined image-sampler object
      used by the shader:
        - the shader stage (SG_SHADERSTAGE_*)
        - the texture's array index in the sg_shader_desc.images[] array
        - the sampler's array index in the sg_shader_desc.samplers[] array
        - GLSL only: the name of the combined image-sampler object

    The number and order of items in the sg_shader_desc.attrs[]
    array corresponds to the items in sg_pipeline_desc.layout.attrs.

        - sg_shader_desc.attrs[N] => sg_pipeline_desc.layout.attrs[N]

    NOTE that vertex attribute indices currently cannot have gaps.

    The items index in the sg_shader_desc.uniform_blocks[] array corresponds
    to the ub_slot arg in sg_apply_uniforms():

        - sg_shader_desc.uniform_blocks[N] => sg_apply_uniforms(N, ...)

    The items in the shader_desc images, samplers and storage_buffers
    arrays correspond to the same array items in the sg_bindings struct:

        - sg_shader_desc.images[N] => sg_bindings.images[N]
        - sg_shader_desc.samplers[N] => sg_bindings.samplers[N]
        - sg_shader_desc.storage_buffers[N] => sg_bindings.storage_buffers[N]

    For all GL backends, shader source-code must be provided. For D3D11 and Metal,
    either shader source-code or byte-code can be provided.

    NOTE that the uniform block, image, sampler, storage_buffer and
    storage_image arrays may have gaps. This allows to use the same sg_bindings
    struct for different related shader variants.

    For D3D11, if source code is provided, the d3dcompiler_47.dll will be loaded
    on demand. If this fails, shader creation will fail. When compiling HLSL
    source code, you can provide an optional target string via
    sg_shader_stage_desc.d3d11_target, the default target is "vs_4_0" for the
    vertex shader stage and "ps_4_0" for the pixel shader stage.
*/
typedef enum sg_shader_stage {
    SG_SHADERSTAGE_NONE,
    SG_SHADERSTAGE_VERTEX,
    SG_SHADERSTAGE_FRAGMENT,
    SG_SHADERSTAGE_COMPUTE,
    _SG_SHADERSTAGE_FORCE_U32 = 0x7FFFFFFF,
} sg_shader_stage;

typedef struct sg_shader_function {
    const char* source;
    sg_range bytecode;
    const char* entry;
    const char* d3d11_target;   // default: "vs_4_0" or "ps_4_0"
} sg_shader_function;

typedef enum sg_shader_attr_base_type {
    SG_SHADERATTRBASETYPE_UNDEFINED,
    SG_SHADERATTRBASETYPE_FLOAT,
    SG_SHADERATTRBASETYPE_SINT,
    SG_SHADERATTRBASETYPE_UINT,
    _SG_SHADERATTRBASETYPE_FORCE_U32 = 0x7FFFFFFF,
} sg_shader_attr_base_type;

typedef struct sg_shader_vertex_attr {
    sg_shader_attr_base_type base_type;  // default: UNDEFINED (disables validation)
    const char* glsl_name;      // [optional] GLSL attribute name
    const char* hlsl_sem_name;  // HLSL semantic name
    uint8_t hlsl_sem_index;     // HLSL semantic index
} sg_shader_vertex_attr;

typedef struct sg_glsl_shader_uniform {
    sg_uniform_type type;
    uint16_t array_count;       // 0 or 1 for scalars, >1 for arrays
    const char* glsl_name;      // glsl name binding is required on GL 4.1 and WebGL2
} sg_glsl_shader_uniform;

typedef struct sg_shader_uniform_block {
    sg_shader_stage stage;
    uint32_t size;
    uint8_t hlsl_register_b_n;  // HLSL register(bn)
    uint8_t msl_buffer_n;       // MSL [[buffer(n)]]
    uint8_t wgsl_group0_binding_n; // WGSL @group(0) @binding(n)
    sg_uniform_layout layout;
    sg_glsl_shader_uniform glsl_uniforms[SG_MAX_UNIFORMBLOCK_MEMBERS];
} sg_shader_uniform_block;

typedef struct sg_shader_image {
    sg_shader_stage stage;
    sg_image_type image_type;
    sg_image_sample_type sample_type;
    bool multisampled;
    uint8_t hlsl_register_t_n;      // HLSL register(tn) bind slot
    uint8_t msl_texture_n;          // MSL [[texture(n)]] bind slot
    uint8_t wgsl_group1_binding_n;  // WGSL @group(1) @binding(n) bind slot
} sg_shader_image;

typedef struct sg_shader_sampler {
    sg_shader_stage stage;
    sg_sampler_type sampler_type;
    uint8_t hlsl_register_s_n;      // HLSL register(sn) bind slot
    uint8_t msl_sampler_n;          // MSL [[sampler(n)]] bind slot
    uint8_t wgsl_group1_binding_n;  // WGSL @group(1) @binding(n) bind slot
} sg_shader_sampler;

typedef struct sg_shader_storage_buffer {
    sg_shader_stage stage;
    bool readonly;
    uint8_t hlsl_register_t_n;      // HLSL register(tn) bind slot (for readonly access)
    uint8_t hlsl_register_u_n;      // HLSL register(un) bind slot (for read/write access)
    uint8_t msl_buffer_n;           // MSL [[buffer(n)]] bind slot
    uint8_t wgsl_group1_binding_n;  // WGSL @group(1) @binding(n) bind slot
    uint8_t glsl_binding_n;         // GLSL layout(binding=n)
} sg_shader_storage_buffer;

typedef struct sg_shader_storage_image {
    sg_shader_stage stage;          // must be NONE or COMPUTE
    sg_image_type image_type;
    sg_pixel_format access_format;  // shader-access pixel format
    bool writeonly;                 // false means read/write access
    uint8_t hlsl_register_u_n;      // HLSL register(un) bind slot
    uint8_t msl_texture_n;          // MSL [[texture(n)]] bind slot
    uint8_t wgsl_group2_binding_n;  // WGSL @group(2) @binding(n) bind slot
    uint8_t glsl_binding_n;         // GLSL layout(binding=n)
} sg_shader_storage_image;

typedef struct sg_shader_image_sampler_pair {
    sg_shader_stage stage;
    uint8_t image_slot;
    uint8_t sampler_slot;
    const char* glsl_name;          // glsl name binding required because of GL 4.1 and WebGL2
} sg_shader_image_sampler_pair;

typedef struct sg_mtl_shader_threads_per_threadgroup {
    int x, y, z;
} sg_mtl_shader_threads_per_threadgroup;

typedef struct sg_shader_desc {
    uint32_t _start_canary;
    sg_shader_function vertex_func;
    sg_shader_function fragment_func;
    sg_shader_function compute_func;
    sg_shader_vertex_attr attrs[SG_MAX_VERTEX_ATTRIBUTES];
    sg_shader_uniform_block uniform_blocks[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
    sg_shader_storage_buffer storage_buffers[SG_MAX_STORAGEBUFFER_BINDSLOTS];
    sg_shader_image images[SG_MAX_IMAGE_BINDSLOTS];
    sg_shader_sampler samplers[SG_MAX_SAMPLER_BINDSLOTS];
    sg_shader_image_sampler_pair image_sampler_pairs[SG_MAX_IMAGE_SAMPLER_PAIRS];
    sg_shader_storage_image storage_images[SG_MAX_STORAGE_ATTACHMENTS];
    sg_mtl_shader_threads_per_threadgroup mtl_threads_per_threadgroup;
    const char* label;
    uint32_t _end_canary;
} sg_shader_desc;

/*
    sg_pipeline_desc

    The sg_pipeline_desc struct defines all creation parameters for an
    sg_pipeline object, used as argument to the sg_make_pipeline() function:

    Pipeline objects come in two flavours:

    - render pipelines for use in render passes
    - compute pipelines for use in compute passes

    A compute pipeline only requires a compute shader object but no
    'render state', while a render pipeline requires a vertex/fragment shader
    object and additional render state declarations:

    - the vertex layout for all input vertex buffers
    - a shader object
    - the 3D primitive type (points, lines, triangles, ...)
    - the index type (none, 16- or 32-bit)
    - all the fixed-function-pipeline state (depth-, stencil-, blend-state, etc...)

    If the vertex data has no gaps between vertex components, you can omit
    the .layout.buffers[].stride and layout.attrs[].offset items (leave them
    default-initialized to 0), sokol-gfx will then compute the offsets and
    strides from the vertex component formats (.layout.attrs[].format).
    Please note that ALL vertex attribute offsets must be 0 in order for the
    automatic offset computation to kick in.

    Note that if you use vertex-pulling from storage buffers instead of
    fixed-function vertex input you can simply omit the entire nested .layout
    struct.

    The default configuration is as follows:

    .compute:               false (must be set to true for a compute pipeline)
    .shader:                0 (must be initialized with a valid sg_shader id!)
    .layout:
        .buffers[]:         vertex buffer layouts
            .stride:        0 (if no stride is given it will be computed)
            .step_func      SG_VERTEXSTEP_PER_VERTEX
            .step_rate      1
        .attrs[]:           vertex attribute declarations
            .buffer_index   0 the vertex buffer bind slot
            .offset         0 (offsets can be omitted if the vertex layout has no gaps)
            .format         SG_VERTEXFORMAT_INVALID (must be initialized!)
    .depth:
        .pixel_format:      sg_desc.context.depth_format
        .compare:           SG_COMPAREFUNC_ALWAYS
        .write_enabled:     false
        .bias:              0.0f
        .bias_slope_scale:  0.0f
        .bias_clamp:        0.0f
    .stencil:
        .enabled:           false
        .front/back:
            .compare:       SG_COMPAREFUNC_ALWAYS
            .fail_op:       SG_STENCILOP_KEEP
            .depth_fail_op: SG_STENCILOP_KEEP
            .pass_op:       SG_STENCILOP_KEEP
        .read_mask:         0
        .write_mask:        0
        .ref:               0
    .color_count            1
    .colors[0..color_count]
        .pixel_format       sg_desc.context.color_format
        .write_mask:        SG_COLORMASK_RGBA
        .blend:
            .enabled:           false
            .src_factor_rgb:    SG_BLENDFACTOR_ONE
            .dst_factor_rgb:    SG_BLENDFACTOR_ZERO
            .op_rgb:            SG_BLENDOP_ADD
            .src_factor_alpha:  SG_BLENDFACTOR_ONE
            .dst_factor_alpha:  SG_BLENDFACTOR_ZERO
            .op_alpha:          SG_BLENDOP_ADD
    .primitive_type:            SG_PRIMITIVETYPE_TRIANGLES
    .index_type:                SG_INDEXTYPE_NONE
    .cull_mode:                 SG_CULLMODE_NONE
    .face_winding:              SG_FACEWINDING_CW
    .sample_count:              sg_desc.context.sample_count
    .blend_color:               (sg_color) { 0.0f, 0.0f, 0.0f, 0.0f }
    .alpha_to_coverage_enabled: false
    .label  0       (optional string label for trace hooks)
*/
typedef struct sg_vertex_buffer_layout_state {
    int stride;
    sg_vertex_step step_func;
    int step_rate;
} sg_vertex_buffer_layout_state;

typedef struct sg_vertex_attr_state {
    int buffer_index;
    int offset;
    sg_vertex_format format;
} sg_vertex_attr_state;

typedef struct sg_vertex_layout_state {
    sg_vertex_buffer_layout_state buffers[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    sg_vertex_attr_state attrs[SG_MAX_VERTEX_ATTRIBUTES];
} sg_vertex_layout_state;

typedef struct sg_stencil_face_state {
    sg_compare_func compare;
    sg_stencil_op fail_op;
    sg_stencil_op depth_fail_op;
    sg_stencil_op pass_op;
} sg_stencil_face_state;

typedef struct sg_stencil_state {
    bool enabled;
    sg_stencil_face_state front;
    sg_stencil_face_state back;
    uint8_t read_mask;
    uint8_t write_mask;
    uint8_t ref;
} sg_stencil_state;

typedef struct sg_depth_state {
    sg_pixel_format pixel_format;
    sg_compare_func compare;
    bool write_enabled;
    float bias;
    float bias_slope_scale;
    float bias_clamp;
} sg_depth_state;

typedef struct sg_blend_state {
    bool enabled;
    sg_blend_factor src_factor_rgb;
    sg_blend_factor dst_factor_rgb;
    sg_blend_op op_rgb;
    sg_blend_factor src_factor_alpha;
    sg_blend_factor dst_factor_alpha;
    sg_blend_op op_alpha;
} sg_blend_state;

typedef struct sg_color_target_state {
    sg_pixel_format pixel_format;
    sg_color_mask write_mask;
    sg_blend_state blend;
} sg_color_target_state;

typedef struct sg_pipeline_desc {
    uint32_t _start_canary;
    bool compute;
    sg_shader shader;
    sg_vertex_layout_state layout;
    sg_depth_state depth;
    sg_stencil_state stencil;
    int color_count;
    sg_color_target_state colors[SG_MAX_COLOR_ATTACHMENTS];
    sg_primitive_type primitive_type;
    sg_index_type index_type;
    sg_cull_mode cull_mode;
    sg_face_winding face_winding;
    int sample_count;
    sg_color blend_color;
    bool alpha_to_coverage_enabled;
    const char* label;
    uint32_t _end_canary;
} sg_pipeline_desc;

/*
    sg_attachments_desc

    Creation parameters for an sg_attachments object, used as argument to the
    sg_make_attachments() function.

    An attachments object bundles either bundles 'render attachments' for
    a render pass, or 'storage attachments' for a compute pass which writes
    to storage images.

    Render attachments are:

        - 0..4 color attachment images
        - 0..4 msaa-resolve attachment images
        - 0 or one depth-stencil attachment image

    Note that all types of render attachment images must be created with
    `sg_image_desc.usage.render_attachment = true`. At least one color-attachment
    or depth-stencil-attachment image must be provided in a render pass
    (only providing a depth-stencil-attachment is useful for depth-only passes).

    Alternatively provide 1..4 storage attachment images which must be created
    with `sg_image_desc.usage.storage_attachment = true`.

    An sg_attachments object cannot have both render- and storage-attachments.

    Each attachment definition consists of an image object, and two additional indices
    describing which subimage the pass will render into: one mipmap index, and if the image
    is a cubemap, array-texture or 3D-texture, the face-index, array-layer or
    depth-slice.

    All attachments must have the same width and height.

    All color attachments and the depth-stencil attachment must have the
    same sample count.

    If a resolve attachment is set, an MSAA-resolve operation from the
    associated color attachment image into the resolve attachment image will take
    place in the sg_end_pass() function. In this case, the color attachment
    must have a (sample_count>1), and the resolve attachment a
    (sample_count==1). The resolve attachment also must have the same pixel
    format as the color attachment.

    NOTE that MSAA depth-stencil attachments cannot be msaa-resolved!
*/
typedef struct sg_attachment_desc {
    sg_image image;
    int mip_level;
    int slice;      // cube texture: face; array texture: layer; 3D texture: slice
} sg_attachment_desc;

typedef struct sg_attachments_desc {
    uint32_t _start_canary;
    sg_attachment_desc colors[SG_MAX_COLOR_ATTACHMENTS];
    sg_attachment_desc resolves[SG_MAX_COLOR_ATTACHMENTS];
    sg_attachment_desc depth_stencil;
    sg_attachment_desc storages[SG_MAX_STORAGE_ATTACHMENTS];
    const char* label;
    uint32_t _end_canary;
} sg_attachments_desc;

/*
    sg_trace_hooks

    Installable callback functions to keep track of the sokol-gfx calls,
    this is useful for debugging, or keeping track of resource creation
    and destruction.

    Trace hooks are installed with sg_install_trace_hooks(), this returns
    another sg_trace_hooks struct with the previous set of
    trace hook function pointers. These should be invoked by the
    new trace hooks to form a proper call chain.
*/
typedef struct sg_trace_hooks {
    void* user_data;
    void (*reset_state_cache)(void* user_data);
    void (*make_buffer)(const sg_buffer_desc* desc, sg_buffer result, void* user_data);
    void (*make_image)(const sg_image_desc* desc, sg_image result, void* user_data);
    void (*make_sampler)(const sg_sampler_desc* desc, sg_sampler result, void* user_data);
    void (*make_shader)(const sg_shader_desc* desc, sg_shader result, void* user_data);
    void (*make_pipeline)(const sg_pipeline_desc* desc, sg_pipeline result, void* user_data);
    void (*make_attachments)(const sg_attachments_desc* desc, sg_attachments result, void* user_data);
    void (*destroy_buffer)(sg_buffer buf, void* user_data);
    void (*destroy_image)(sg_image img, void* user_data);
    void (*destroy_sampler)(sg_sampler smp, void* user_data);
    void (*destroy_shader)(sg_shader shd, void* user_data);
    void (*destroy_pipeline)(sg_pipeline pip, void* user_data);
    void (*destroy_attachments)(sg_attachments atts, void* user_data);
    void (*update_buffer)(sg_buffer buf, const sg_range* data, void* user_data);
    void (*update_image)(sg_image img, const sg_image_data* data, void* user_data);
    void (*append_buffer)(sg_buffer buf, const sg_range* data, int result, void* user_data);
    void (*begin_pass)(const sg_pass* pass, void* user_data);
    void (*apply_viewport)(int x, int y, int width, int height, bool origin_top_left, void* user_data);
    void (*apply_scissor_rect)(int x, int y, int width, int height, bool origin_top_left, void* user_data);
    void (*apply_pipeline)(sg_pipeline pip, void* user_data);
    void (*apply_bindings)(const sg_bindings* bindings, void* user_data);
    void (*apply_uniforms)(int ub_index, const sg_range* data, void* user_data);
    void (*draw)(int base_element, int num_elements, int num_instances, void* user_data);
    void (*dispatch)(int num_groups_x, int num_groups_y, int num_groups_z, void* user_data);
    void (*end_pass)(void* user_data);
    void (*commit)(void* user_data);
    void (*alloc_buffer)(sg_buffer result, void* user_data);
    void (*alloc_image)(sg_image result, void* user_data);
    void (*alloc_sampler)(sg_sampler result, void* user_data);
    void (*alloc_shader)(sg_shader result, void* user_data);
    void (*alloc_pipeline)(sg_pipeline result, void* user_data);
    void (*alloc_attachments)(sg_attachments result, void* user_data);
    void (*dealloc_buffer)(sg_buffer buf_id, void* user_data);
    void (*dealloc_image)(sg_image img_id, void* user_data);
    void (*dealloc_sampler)(sg_sampler smp_id, void* user_data);
    void (*dealloc_shader)(sg_shader shd_id, void* user_data);
    void (*dealloc_pipeline)(sg_pipeline pip_id, void* user_data);
    void (*dealloc_attachments)(sg_attachments atts_id, void* user_data);
    void (*init_buffer)(sg_buffer buf_id, const sg_buffer_desc* desc, void* user_data);
    void (*init_image)(sg_image img_id, const sg_image_desc* desc, void* user_data);
    void (*init_sampler)(sg_sampler smp_id, const sg_sampler_desc* desc, void* user_data);
    void (*init_shader)(sg_shader shd_id, const sg_shader_desc* desc, void* user_data);
    void (*init_pipeline)(sg_pipeline pip_id, const sg_pipeline_desc* desc, void* user_data);
    void (*init_attachments)(sg_attachments atts_id, const sg_attachments_desc* desc, void* user_data);
    void (*uninit_buffer)(sg_buffer buf_id, void* user_data);
    void (*uninit_image)(sg_image img_id, void* user_data);
    void (*uninit_sampler)(sg_sampler smp_id, void* user_data);
    void (*uninit_shader)(sg_shader shd_id, void* user_data);
    void (*uninit_pipeline)(sg_pipeline pip_id, void* user_data);
    void (*uninit_attachments)(sg_attachments atts_id, void* user_data);
    void (*fail_buffer)(sg_buffer buf_id, void* user_data);
    void (*fail_image)(sg_image img_id, void* user_data);
    void (*fail_sampler)(sg_sampler smp_id, void* user_data);
    void (*fail_shader)(sg_shader shd_id, void* user_data);
    void (*fail_pipeline)(sg_pipeline pip_id, void* user_data);
    void (*fail_attachments)(sg_attachments atts_id, void* user_data);
    void (*push_debug_group)(const char* name, void* user_data);
    void (*pop_debug_group)(void* user_data);
} sg_trace_hooks;

/*
    sg_buffer_info
    sg_image_info
    sg_sampler_info
    sg_shader_info
    sg_pipeline_info
    sg_attachments_info

    These structs contain various internal resource attributes which
    might be useful for debug-inspection. Please don't rely on the
    actual content of those structs too much, as they are quite closely
    tied to sokol_gfx.h internals and may change more frequently than
    the other public API elements.

    The *_info structs are used as the return values of the following functions:

    sg_query_buffer_info()
    sg_query_image_info()
    sg_query_sampler_info()
    sg_query_shader_info()
    sg_query_pipeline_info()
    sg_query_attachments_info()
*/
typedef struct sg_slot_info {
    sg_resource_state state;    // the current state of this resource slot
    uint32_t res_id;            // type-neutral resource if (e.g. sg_buffer.id)
} sg_slot_info;

typedef struct sg_buffer_info {
    sg_slot_info slot;              // resource pool slot info
    uint32_t update_frame_index;    // frame index of last sg_update_buffer()
    uint32_t append_frame_index;    // frame index of last sg_append_buffer()
    int append_pos;                 // current position in buffer for sg_append_buffer()
    bool append_overflow;           // is buffer in overflow state (due to sg_append_buffer)
    int num_slots;                  // number of renaming-slots for dynamically updated buffers
    int active_slot;                // currently active write-slot for dynamically updated buffers
} sg_buffer_info;

typedef struct sg_image_info {
    sg_slot_info slot;              // resource pool slot info
    uint32_t upd_frame_index;       // frame index of last sg_update_image()
    int num_slots;                  // number of renaming-slots for dynamically updated images
    int active_slot;                // currently active write-slot for dynamically updated images
} sg_image_info;

typedef struct sg_sampler_info {
    sg_slot_info slot;              // resource pool slot info
} sg_sampler_info;

typedef struct sg_shader_info {
    sg_slot_info slot;              // resource pool slot info
} sg_shader_info;

typedef struct sg_pipeline_info {
    sg_slot_info slot;              // resource pool slot info
} sg_pipeline_info;

typedef struct sg_attachments_info {
    sg_slot_info slot;              // resource pool slot info
} sg_attachments_info;

/*
    sg_frame_stats

    Allows to track generic and backend-specific stats about a
    render frame. Obtained by calling sg_query_frame_stats(). The returned
    struct contains information about the *previous* frame.
*/
typedef struct sg_frame_stats_gl {
    uint32_t num_bind_buffer;
    uint32_t num_active_texture;
    uint32_t num_bind_texture;
    uint32_t num_bind_sampler;
    uint32_t num_use_program;
    uint32_t num_render_state;
    uint32_t num_vertex_attrib_pointer;
    uint32_t num_vertex_attrib_divisor;
    uint32_t num_enable_vertex_attrib_array;
    uint32_t num_disable_vertex_attrib_array;
    uint32_t num_uniform;
    uint32_t num_memory_barriers;
} sg_frame_stats_gl;

typedef struct sg_frame_stats_d3d11_pass {
    uint32_t num_om_set_render_targets;
    uint32_t num_clear_render_target_view;
    uint32_t num_clear_depth_stencil_view;
    uint32_t num_resolve_subresource;
} sg_frame_stats_d3d11_pass;

typedef struct sg_frame_stats_d3d11_pipeline {
    uint32_t num_rs_set_state;
    uint32_t num_om_set_depth_stencil_state;
    uint32_t num_om_set_blend_state;
    uint32_t num_ia_set_primitive_topology;
    uint32_t num_ia_set_input_layout;
    uint32_t num_vs_set_shader;
    uint32_t num_vs_set_constant_buffers;
    uint32_t num_ps_set_shader;
    uint32_t num_ps_set_constant_buffers;
    uint32_t num_cs_set_shader;
    uint32_t num_cs_set_constant_buffers;
} sg_frame_stats_d3d11_pipeline;

typedef struct sg_frame_stats_d3d11_bindings {
    uint32_t num_ia_set_vertex_buffers;
    uint32_t num_ia_set_index_buffer;
    uint32_t num_vs_set_shader_resources;
    uint32_t num_vs_set_samplers;
    uint32_t num_ps_set_shader_resources;
    uint32_t num_ps_set_samplers;
    uint32_t num_cs_set_shader_resources;
    uint32_t num_cs_set_samplers;
    uint32_t num_cs_set_unordered_access_views;
} sg_frame_stats_d3d11_bindings;

typedef struct sg_frame_stats_d3d11_uniforms {
    uint32_t num_update_subresource;
} sg_frame_stats_d3d11_uniforms;

typedef struct sg_frame_stats_d3d11_draw {
    uint32_t num_draw_indexed_instanced;
    uint32_t num_draw_indexed;
    uint32_t num_draw_instanced;
    uint32_t num_draw;
} sg_frame_stats_d3d11_draw;

typedef struct sg_frame_stats_d3d11 {
    sg_frame_stats_d3d11_pass pass;
    sg_frame_stats_d3d11_pipeline pipeline;
    sg_frame_stats_d3d11_bindings bindings;
    sg_frame_stats_d3d11_uniforms uniforms;
    sg_frame_stats_d3d11_draw draw;
    uint32_t num_map;
    uint32_t num_unmap;
} sg_frame_stats_d3d11;

typedef struct sg_frame_stats_metal_idpool {
    uint32_t num_added;
    uint32_t num_released;
    uint32_t num_garbage_collected;
} sg_frame_stats_metal_idpool;

typedef struct sg_frame_stats_metal_pipeline {
    uint32_t num_set_blend_color;
    uint32_t num_set_cull_mode;
    uint32_t num_set_front_facing_winding;
    uint32_t num_set_stencil_reference_value;
    uint32_t num_set_depth_bias;
    uint32_t num_set_render_pipeline_state;
    uint32_t num_set_depth_stencil_state;
} sg_frame_stats_metal_pipeline;

typedef struct sg_frame_stats_metal_bindings {
    uint32_t num_set_vertex_buffer;
    uint32_t num_set_vertex_texture;
    uint32_t num_set_vertex_sampler_state;
    uint32_t num_set_fragment_buffer;
    uint32_t num_set_fragment_texture;
    uint32_t num_set_fragment_sampler_state;
    uint32_t num_set_compute_buffer;
    uint32_t num_set_compute_texture;
    uint32_t num_set_compute_sampler_state;
} sg_frame_stats_metal_bindings;

typedef struct sg_frame_stats_metal_uniforms {
    uint32_t num_set_vertex_buffer_offset;
    uint32_t num_set_fragment_buffer_offset;
    uint32_t num_set_compute_buffer_offset;
} sg_frame_stats_metal_uniforms;

typedef struct sg_frame_stats_metal {
    sg_frame_stats_metal_idpool idpool;
    sg_frame_stats_metal_pipeline pipeline;
    sg_frame_stats_metal_bindings bindings;
    sg_frame_stats_metal_uniforms uniforms;
} sg_frame_stats_metal;

typedef struct sg_frame_stats_wgpu_uniforms {
    uint32_t num_set_bindgroup;
    uint32_t size_write_buffer;
} sg_frame_stats_wgpu_uniforms;

typedef struct sg_frame_stats_wgpu_bindings {
    uint32_t num_set_vertex_buffer;
    uint32_t num_skip_redundant_vertex_buffer;
    uint32_t num_set_index_buffer;
    uint32_t num_skip_redundant_index_buffer;
    uint32_t num_create_bindgroup;
    uint32_t num_discard_bindgroup;
    uint32_t num_set_bindgroup;
    uint32_t num_skip_redundant_bindgroup;
    uint32_t num_bindgroup_cache_hits;
    uint32_t num_bindgroup_cache_misses;
    uint32_t num_bindgroup_cache_collisions;
    uint32_t num_bindgroup_cache_invalidates;
    uint32_t num_bindgroup_cache_hash_vs_key_mismatch;
} sg_frame_stats_wgpu_bindings;

typedef struct sg_frame_stats_wgpu {
    sg_frame_stats_wgpu_uniforms uniforms;
    sg_frame_stats_wgpu_bindings bindings;
} sg_frame_stats_wgpu;

typedef struct sg_frame_stats {
    uint32_t frame_index;   // current frame counter, starts at 0

    uint32_t num_passes;
    uint32_t num_apply_viewport;
    uint32_t num_apply_scissor_rect;
    uint32_t num_apply_pipeline;
    uint32_t num_apply_bindings;
    uint32_t num_apply_uniforms;
    uint32_t num_draw;
    uint32_t num_dispatch;
    uint32_t num_update_buffer;
    uint32_t num_append_buffer;
    uint32_t num_update_image;

    uint32_t size_apply_uniforms;
    uint32_t size_update_buffer;
    uint32_t size_append_buffer;
    uint32_t size_update_image;

    sg_frame_stats_gl gl;
    sg_frame_stats_d3d11 d3d11;
    sg_frame_stats_metal metal;
    sg_frame_stats_wgpu wgpu;
} sg_frame_stats;

/*
    sg_log_item

    An enum with a unique item for each log message, warning, error
    and validation layer message. Note that these messages are only
    visible when a logger function is installed in the sg_setup() call.
*/
#define _SG_LOG_ITEMS \
    _SG_LOGITEM_XMACRO(OK, "Ok") \
    _SG_LOGITEM_XMACRO(MALLOC_FAILED, "memory allocation failed") \
    _SG_LOGITEM_XMACRO(GL_TEXTURE_FORMAT_NOT_SUPPORTED, "pixel format not supported for texture (gl)") \
    _SG_LOGITEM_XMACRO(GL_3D_TEXTURES_NOT_SUPPORTED, "3d textures not supported (gl)") \
    _SG_LOGITEM_XMACRO(GL_ARRAY_TEXTURES_NOT_SUPPORTED, "array textures not supported (gl)") \
    _SG_LOGITEM_XMACRO(GL_STORAGEBUFFER_GLSL_BINDING_OUT_OF_RANGE, "GLSL storage buffer bindslot is out of range (must be 0..7) (gl)") \
    _SG_LOGITEM_XMACRO(GL_STORAGEIMAGE_GLSL_BINDING_OUT_OF_RANGE, "GLSL storage image bindslot is out of range (must be 0..3) (gl)") \
    _SG_LOGITEM_XMACRO(GL_SHADER_COMPILATION_FAILED, "shader compilation failed (gl)") \
    _SG_LOGITEM_XMACRO(GL_SHADER_LINKING_FAILED, "shader linking failed (gl)") \
    _SG_LOGITEM_XMACRO(GL_VERTEX_ATTRIBUTE_NOT_FOUND_IN_SHADER, "vertex attribute not found in shader; NOTE: may be caused by GL driver's GLSL compiler removing unused globals") \
    _SG_LOGITEM_XMACRO(GL_UNIFORMBLOCK_NAME_NOT_FOUND_IN_SHADER, "uniform block name not found in shader; NOTE: may be caused by GL driver's GLSL compiler removing unused globals") \
    _SG_LOGITEM_XMACRO(GL_IMAGE_SAMPLER_NAME_NOT_FOUND_IN_SHADER, "image-sampler name not found in shader; NOTE: may be caused by GL driver's GLSL compiler removing unused globals") \
    _SG_LOGITEM_XMACRO(GL_FRAMEBUFFER_STATUS_UNDEFINED, "framebuffer completeness check failed with GL_FRAMEBUFFER_UNDEFINED (gl)") \
    _SG_LOGITEM_XMACRO(GL_FRAMEBUFFER_STATUS_INCOMPLETE_ATTACHMENT, "framebuffer completeness check failed with GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT (gl)") \
    _SG_LOGITEM_XMACRO(GL_FRAMEBUFFER_STATUS_INCOMPLETE_MISSING_ATTACHMENT, "framebuffer completeness check failed with GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT (gl)") \
    _SG_LOGITEM_XMACRO(GL_FRAMEBUFFER_STATUS_UNSUPPORTED, "framebuffer completeness check failed with GL_FRAMEBUFFER_UNSUPPORTED (gl)") \
    _SG_LOGITEM_XMACRO(GL_FRAMEBUFFER_STATUS_INCOMPLETE_MULTISAMPLE, "framebuffer completeness check failed with GL_FRAMEBUFFER_INCOMPLETE_MULTISAMPLE (gl)") \
    _SG_LOGITEM_XMACRO(GL_FRAMEBUFFER_STATUS_UNKNOWN, "framebuffer completeness check failed (unknown reason) (gl)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_BUFFER_FAILED, "CreateBuffer() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_BUFFER_SRV_FAILED, "CreateShaderResourceView() failed for storage buffer (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_BUFFER_UAV_FAILED, "CreateUnorderedAccessView() failed for storage buffer (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_DEPTH_TEXTURE_UNSUPPORTED_PIXEL_FORMAT, "pixel format not supported for depth-stencil texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_DEPTH_TEXTURE_FAILED, "CreateTexture2D() failed for depth-stencil texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_2D_TEXTURE_UNSUPPORTED_PIXEL_FORMAT, "pixel format not supported for 2d-, cube- or array-texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_2D_TEXTURE_FAILED, "CreateTexture2D() failed for 2d-, cube- or array-texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_2D_SRV_FAILED, "CreateShaderResourceView() failed for 2d-, cube- or array-texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_3D_TEXTURE_UNSUPPORTED_PIXEL_FORMAT, "pixel format not supported for 3D texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_3D_TEXTURE_FAILED, "CreateTexture3D() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_3D_SRV_FAILED, "CreateShaderResourceView() failed for 3d texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_MSAA_TEXTURE_FAILED, "CreateTexture2D() failed for MSAA render target texture (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_SAMPLER_STATE_FAILED, "CreateSamplerState() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_UNIFORMBLOCK_HLSL_REGISTER_B_OUT_OF_RANGE, "uniform block 'hlsl_register_b_n' is out of range (must be 0..7)") \
    _SG_LOGITEM_XMACRO(D3D11_STORAGEBUFFER_HLSL_REGISTER_T_OUT_OF_RANGE, "storage buffer 'hlsl_register_t_n' is out of range (must be 0..23)") \
    _SG_LOGITEM_XMACRO(D3D11_STORAGEBUFFER_HLSL_REGISTER_U_OUT_OF_RANGE, "storage buffer 'hlsl_register_u_n' is out of range (must be 0..11)") \
    _SG_LOGITEM_XMACRO(D3D11_IMAGE_HLSL_REGISTER_T_OUT_OF_RANGE, "image 'hlsl_register_t_n' is out of range (must be 0..23)") \
    _SG_LOGITEM_XMACRO(D3D11_SAMPLER_HLSL_REGISTER_S_OUT_OF_RANGE, "sampler 'hlsl_register_s_n' is out of rang (must be 0..15)") \
    _SG_LOGITEM_XMACRO(D3D11_STORAGEIMAGE_HLSL_REGISTER_U_OUT_OF_RANGE, "storage image 'hlsl_register_u_n' is out of range (must be 0..11)") \
    _SG_LOGITEM_XMACRO(D3D11_LOAD_D3DCOMPILER_47_DLL_FAILED, "loading d3dcompiler_47.dll failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_SHADER_COMPILATION_FAILED, "shader compilation failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_SHADER_COMPILATION_OUTPUT, "") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_CONSTANT_BUFFER_FAILED, "CreateBuffer() failed for uniform constant buffer (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_INPUT_LAYOUT_FAILED, "CreateInputLayout() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_RASTERIZER_STATE_FAILED, "CreateRasterizerState() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_DEPTH_STENCIL_STATE_FAILED, "CreateDepthStencilState() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_BLEND_STATE_FAILED, "CreateBlendState() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_RTV_FAILED, "CreateRenderTargetView() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_DSV_FAILED, "CreateDepthStencilView() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_CREATE_UAV_FAILED, "CreateUnorderedAccessView() failed (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_MAP_FOR_UPDATE_BUFFER_FAILED, "Map() failed when updating buffer (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_MAP_FOR_APPEND_BUFFER_FAILED, "Map() failed when appending to buffer (d3d11)") \
    _SG_LOGITEM_XMACRO(D3D11_MAP_FOR_UPDATE_IMAGE_FAILED, "Map() failed when updating image (d3d11)") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_BUFFER_FAILED, "failed to create buffer object (metal)") \
    _SG_LOGITEM_XMACRO(METAL_TEXTURE_FORMAT_NOT_SUPPORTED, "pixel format not supported for texture (metal)") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_TEXTURE_FAILED, "failed to create texture object (metal)") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_SAMPLER_FAILED, "failed to create sampler object (metal)") \
    _SG_LOGITEM_XMACRO(METAL_SHADER_COMPILATION_FAILED, "shader compilation failed (metal)") \
    _SG_LOGITEM_XMACRO(METAL_SHADER_CREATION_FAILED, "shader creation failed (metal)") \
    _SG_LOGITEM_XMACRO(METAL_SHADER_COMPILATION_OUTPUT, "") \
    _SG_LOGITEM_XMACRO(METAL_SHADER_ENTRY_NOT_FOUND, "shader entry function not found (metal)") \
    _SG_LOGITEM_XMACRO(METAL_UNIFORMBLOCK_MSL_BUFFER_SLOT_OUT_OF_RANGE, "uniform block 'msl_buffer_n' is out of range (must be 0..7)") \
    _SG_LOGITEM_XMACRO(METAL_STORAGEBUFFER_MSL_BUFFER_SLOT_OUT_OF_RANGE, "storage buffer 'msl_buffer_n' is out of range (must be 8..15)") \
    _SG_LOGITEM_XMACRO(METAL_STORAGEIMAGE_MSL_TEXTURE_SLOT_OUT_OF_RANGE, "storage image 'msl_texture_n' is out of range (must be 0..19)") \
    _SG_LOGITEM_XMACRO(METAL_IMAGE_MSL_TEXTURE_SLOT_OUT_OF_RANGE, "image 'msl_texture_n' is out of range (must be 0..19)") \
    _SG_LOGITEM_XMACRO(METAL_SAMPLER_MSL_SAMPLER_SLOT_OUT_OF_RANGE, "sampler 'msl_sampler_n' is out of range (must be 0..15)") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_CPS_FAILED, "failed to create compute pipeline state (metal)") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_CPS_OUTPUT, "") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_RPS_FAILED, "failed to create render pipeline state (metal)") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_RPS_OUTPUT, "") \
    _SG_LOGITEM_XMACRO(METAL_CREATE_DSS_FAILED, "failed to create depth stencil state (metal)") \
    _SG_LOGITEM_XMACRO(WGPU_BINDGROUPS_POOL_EXHAUSTED, "bindgroups pool exhausted (increase sg_desc.bindgroups_cache_size) (wgpu)") \
    _SG_LOGITEM_XMACRO(WGPU_BINDGROUPSCACHE_SIZE_GREATER_ONE, "sg_desc.wgpu_bindgroups_cache_size must be > 1 (wgpu)") \
    _SG_LOGITEM_XMACRO(WGPU_BINDGROUPSCACHE_SIZE_POW2, "sg_desc.wgpu_bindgroups_cache_size must be a power of 2 (wgpu)") \
    _SG_LOGITEM_XMACRO(WGPU_CREATEBINDGROUP_FAILED, "wgpuDeviceCreateBindGroup failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_BUFFER_FAILED, "wgpuDeviceCreateBuffer() failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_TEXTURE_FAILED, "wgpuDeviceCreateTexture() failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_TEXTURE_VIEW_FAILED, "wgpuTextureCreateView() failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_SAMPLER_FAILED, "wgpuDeviceCreateSampler() failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_SHADER_MODULE_FAILED, "wgpuDeviceCreateShaderModule() failed") \
    _SG_LOGITEM_XMACRO(WGPU_SHADER_CREATE_BINDGROUP_LAYOUT_FAILED, "wgpuDeviceCreateBindGroupLayout() for shader stage failed") \
    _SG_LOGITEM_XMACRO(WGPU_UNIFORMBLOCK_WGSL_GROUP0_BINDING_OUT_OF_RANGE, "uniform block 'wgsl_group0_binding_n' is out of range (must be 0..15)") \
    _SG_LOGITEM_XMACRO(WGPU_STORAGEBUFFER_WGSL_GROUP1_BINDING_OUT_OF_RANGE, "storage buffer 'wgsl_group1_binding_n' is out of range (must be 0..127)") \
    _SG_LOGITEM_XMACRO(WGPU_IMAGE_WGSL_GROUP1_BINDING_OUT_OF_RANGE, "image 'wgsl_group1_binding_n' is out of range (must be 0..127)") \
    _SG_LOGITEM_XMACRO(WGPU_SAMPLER_WGSL_GROUP1_BINDING_OUT_OF_RANGE, "sampler 'wgsl_group1_binding_n' is out of range (must be 0..127)") \
    _SG_LOGITEM_XMACRO(WGPU_STORAGEIMAGE_WGSL_GROUP2_BINDING_OUT_OF_RANGE, "storage image 'wgsl_group2_binding_n' is out of range (must be 0..3)") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_PIPELINE_LAYOUT_FAILED, "wgpuDeviceCreatePipelineLayout() failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_RENDER_PIPELINE_FAILED, "wgpuDeviceCreateRenderPipeline() failed") \
    _SG_LOGITEM_XMACRO(WGPU_CREATE_COMPUTE_PIPELINE_FAILED, "wgpuDeviceCreateComputePipeline() failed") \
    _SG_LOGITEM_XMACRO(WGPU_ATTACHMENTS_CREATE_TEXTURE_VIEW_FAILED, "wgpuTextureCreateView() failed in create attachments") \
    _SG_LOGITEM_XMACRO(IDENTICAL_COMMIT_LISTENER, "attempting to add identical commit listener") \
    _SG_LOGITEM_XMACRO(COMMIT_LISTENER_ARRAY_FULL, "commit listener array full") \
    _SG_LOGITEM_XMACRO(TRACE_HOOKS_NOT_ENABLED, "sg_install_trace_hooks() called, but SOKOL_TRACE_HOOKS is not defined") \
    _SG_LOGITEM_XMACRO(DEALLOC_BUFFER_INVALID_STATE, "sg_dealloc_buffer(): buffer must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(DEALLOC_IMAGE_INVALID_STATE, "sg_dealloc_image(): image must be in alloc state") \
    _SG_LOGITEM_XMACRO(DEALLOC_SAMPLER_INVALID_STATE, "sg_dealloc_sampler(): sampler must be in alloc state") \
    _SG_LOGITEM_XMACRO(DEALLOC_SHADER_INVALID_STATE, "sg_dealloc_shader(): shader must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(DEALLOC_PIPELINE_INVALID_STATE, "sg_dealloc_pipeline(): pipeline must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(DEALLOC_ATTACHMENTS_INVALID_STATE, "sg_dealloc_attachments(): attachments must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(INIT_BUFFER_INVALID_STATE, "sg_init_buffer(): buffer must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(INIT_IMAGE_INVALID_STATE, "sg_init_image(): image must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(INIT_SAMPLER_INVALID_STATE, "sg_init_sampler(): sampler must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(INIT_SHADER_INVALID_STATE, "sg_init_shader(): shader must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(INIT_PIPELINE_INVALID_STATE, "sg_init_pipeline(): pipeline must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(INIT_ATTACHMENTS_INVALID_STATE, "sg_init_attachments(): pass must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(UNINIT_BUFFER_INVALID_STATE, "sg_uninit_buffer(): buffer must be in VALID or FAILED state") \
    _SG_LOGITEM_XMACRO(UNINIT_IMAGE_INVALID_STATE, "sg_uninit_image(): image must be in VALID or FAILED state") \
    _SG_LOGITEM_XMACRO(UNINIT_SAMPLER_INVALID_STATE, "sg_uninit_sampler(): sampler must be in VALID or FAILED state") \
    _SG_LOGITEM_XMACRO(UNINIT_SHADER_INVALID_STATE, "sg_uninit_shader(): shader must be in VALID or FAILED state") \
    _SG_LOGITEM_XMACRO(UNINIT_PIPELINE_INVALID_STATE, "sg_uninit_pipeline(): pipeline must be in VALID or FAILED state") \
    _SG_LOGITEM_XMACRO(UNINIT_ATTACHMENTS_INVALID_STATE, "sg_uninit_attachments(): attachments must be in VALID or FAILED state") \
    _SG_LOGITEM_XMACRO(FAIL_BUFFER_INVALID_STATE, "sg_fail_buffer(): buffer must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(FAIL_IMAGE_INVALID_STATE, "sg_fail_image(): image must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(FAIL_SAMPLER_INVALID_STATE, "sg_fail_sampler(): sampler must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(FAIL_SHADER_INVALID_STATE, "sg_fail_shader(): shader must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(FAIL_PIPELINE_INVALID_STATE, "sg_fail_pipeline(): pipeline must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(FAIL_ATTACHMENTS_INVALID_STATE, "sg_fail_attachments(): attachments must be in ALLOC state") \
    _SG_LOGITEM_XMACRO(BUFFER_POOL_EXHAUSTED, "buffer pool exhausted") \
    _SG_LOGITEM_XMACRO(IMAGE_POOL_EXHAUSTED, "image pool exhausted") \
    _SG_LOGITEM_XMACRO(SAMPLER_POOL_EXHAUSTED, "sampler pool exhausted") \
    _SG_LOGITEM_XMACRO(SHADER_POOL_EXHAUSTED, "shader pool exhausted") \
    _SG_LOGITEM_XMACRO(PIPELINE_POOL_EXHAUSTED, "pipeline pool exhausted") \
    _SG_LOGITEM_XMACRO(PASS_POOL_EXHAUSTED, "pass pool exhausted") \
    _SG_LOGITEM_XMACRO(BEGINPASS_ATTACHMENT_INVALID, "sg_begin_pass: an attachment was provided that no longer exists") \
    _SG_LOGITEM_XMACRO(APPLY_BINDINGS_STORAGE_BUFFER_TRACKER_EXHAUSTED, "sg_apply_bindings: too many read/write storage buffers in pass (bump sg_desc.max_dispatch_calls_per_pass") \
    _SG_LOGITEM_XMACRO(DRAW_WITHOUT_BINDINGS, "attempting to draw without resource bindings") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_CANARY, "sg_buffer_desc not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_IMMUTABLE_DYNAMIC_STREAM, "sg_buffer_desc.usage: only one of .immutable, .dynamic_update, .stream_update can be true") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_SEPARATE_BUFFER_TYPES, "sg_buffer_desc.usage: on WebGL2, only one of .vertex_buffer or .index_buffer can be true (check sg_features.separate_buffer_types)") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_EXPECT_NONZERO_SIZE, "sg_buffer_desc.size must be greater zero") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_EXPECT_MATCHING_DATA_SIZE, "sg_buffer_desc.size and .data.size must be equal") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_EXPECT_ZERO_DATA_SIZE, "sg_buffer_desc.data.size expected to be zero") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_EXPECT_NO_DATA, "sg_buffer_desc.data.ptr must be null for dynamic/stream buffers") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_EXPECT_DATA, "sg_buffer_desc: initial content data must be provided for immutable buffers without storage buffer usage") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_STORAGEBUFFER_SUPPORTED, "storage buffers not supported by the backend 3D API (requires OpenGL >= 4.3)") \
    _SG_LOGITEM_XMACRO(VALIDATE_BUFFERDESC_STORAGEBUFFER_SIZE_MULTIPLE_4, "size of storage buffers must be a multiple of 4") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDATA_NODATA, "sg_image_data: no data (.ptr and/or .size is zero)") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDATA_DATA_SIZE, "sg_image_data: data size doesn't match expected surface size") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_CANARY, "sg_image_desc not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_IMMUTABLE_DYNAMIC_STREAM, "sg_image_desc.usage: only one of .immutable, .dynamic_update, .stream_update can be true") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDER_VS_STORAGE_ATTACHMENT, "sg_image_desc.usage: only one of .render_attachment or .storage_attachment can be true") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_WIDTH, "sg_image_desc.width must be > 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_HEIGHT, "sg_image_desc.height must be > 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_NONRT_PIXELFORMAT, "invalid pixel format for non-render-target image") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_MSAA_BUT_NO_ATTACHMENT, "non-attachment images cannot be multisampled") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_DEPTH_3D_IMAGE, "3D images cannot have a depth/stencil image format") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_ATTACHMENT_EXPECT_IMMUTABLE, "render/storage attachment images must be sg_image_usage.immutable") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_ATTACHMENT_EXPECT_NO_DATA, "render/storage attachment images cannot be initialized with data") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDERATTACHMENT_NO_MSAA_SUPPORT, "multisampling not supported for this pixel format") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_NUM_MIPMAPS, "multisample images must have num_mipmaps == 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_3D_IMAGE, "3D images cannot have a sample_count > 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_CUBE_IMAGE, "cube images cannot have sample_count > 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_ARRAY_IMAGE, "array images cannot have sample_count > 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_RENDERATTACHMENT_PIXELFORMAT, "invalid pixel format for render attachment image") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_STORAGEATTACHMENT_PIXELFORMAT, "invalid pixel format for storage attachment image") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_STORAGEATTACHMENT_EXPECT_NO_MSAA, "storage attachment images cannot be multisampled") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_INJECTED_NO_DATA, "images with injected textures cannot be initialized with data") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_DYNAMIC_NO_DATA, "dynamic/stream-update images cannot be initialized with data") \
    _SG_LOGITEM_XMACRO(VALIDATE_IMAGEDESC_COMPRESSED_IMMUTABLE, "compressed images must be immutable") \
    _SG_LOGITEM_XMACRO(VALIDATE_SAMPLERDESC_CANARY, "sg_sampler_desc not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_SAMPLERDESC_ANISTROPIC_REQUIRES_LINEAR_FILTERING, "sg_sampler_desc.max_anisotropy > 1 requires min/mag/mipmap_filter to be SG_FILTER_LINEAR") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_CANARY, "sg_shader_desc not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_VERTEX_SOURCE, "vertex shader source code expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_FRAGMENT_SOURCE, "fragment shader source code expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_COMPUTE_SOURCE, "compute shader source code expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_VERTEX_SOURCE_OR_BYTECODE, "vertex shader source or byte code expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_FRAGMENT_SOURCE_OR_BYTECODE, "fragment shader source or byte code expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_COMPUTE_SOURCE_OR_BYTECODE, "compute shader source or byte code expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_INVALID_SHADER_COMBO, "cannot combine compute shaders with vertex or fragment shaders") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_NO_BYTECODE_SIZE, "shader byte code length (in bytes) required") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_METAL_THREADS_PER_THREADGROUP, "sg_shader_desc.mtl_threads_per_threadgroup must be initialized for compute shaders (metal)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_NO_CONT_MEMBERS, "uniform block members must occupy continuous slots") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_SIZE_IS_ZERO, "bound uniform block size cannot be zero") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_METAL_BUFFER_SLOT_OUT_OF_RANGE, "uniform block 'msl_buffer_n' is out of range (must be 0..7)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_METAL_BUFFER_SLOT_COLLISION, "uniform block 'msl_buffer_n' must be unique across uniform blocks and storage buffers in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_HLSL_REGISTER_B_OUT_OF_RANGE, "uniform block 'hlsl_register_b_n' is out of range (must be 0..7)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_HLSL_REGISTER_B_COLLISION, "uniform block 'hlsl_register_b_n' must be unique across uniform blocks in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_WGSL_GROUP0_BINDING_OUT_OF_RANGE, "uniform block 'wgsl_group0_binding_n' is out of range (must be 0..15)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_WGSL_GROUP0_BINDING_COLLISION, "uniform block 'wgsl_group0_binding_n' must be unique across all uniform blocks") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_NO_MEMBERS, "GL backend requires uniform block member declarations") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_UNIFORM_GLSL_NAME, "uniform block member 'glsl_name' missing") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_SIZE_MISMATCH, "size of uniform block members doesn't match uniform block size") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_ARRAY_COUNT, "uniform array count must be >= 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_UNIFORMBLOCK_STD140_ARRAY_TYPE, "uniform arrays only allowed for FLOAT4, INT4, MAT4 in std140 layout") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_METAL_BUFFER_SLOT_OUT_OF_RANGE, "storage buffer 'msl_buffer_n' is out of range (must be 8..15)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_METAL_BUFFER_SLOT_COLLISION, "storage buffer 'msl_buffer_n' must be unique across uniform blocks and storage buffer in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_T_OUT_OF_RANGE, "storage buffer 'hlsl_register_t_n' is out of range (must be 0..23)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_T_COLLISION, "storage_buffer 'hlsl_register_t_n' must be unique across read-only storage buffers and images in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_U_OUT_OF_RANGE, "storage buffer 'hlsl_register_u_n' is out of range (must be 0..11)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_U_COLLISION, "storage_buffer 'hlsl_register_u_n' must be unique across read/write storage buffers and storage images in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_GLSL_BINDING_OUT_OF_RANGE, "storage buffer 'glsl_binding_n' is out of range (must be 0..7)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_GLSL_BINDING_COLLISION, "storage buffer 'glsl_binding_n' must be unique across shader stages") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_WGSL_GROUP1_BINDING_OUT_OF_RANGE, "storage buffer 'wgsl_group1_binding_n' is out of range (must be 0..127)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEBUFFER_WGSL_GROUP1_BINDING_COLLISION, "storage buffer 'wgsl_group1_binding_n' must be unique across all images, samplers and storage buffers") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_EXPECT_COMPUTE_STAGE, "storage images are only allowed on the compute stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_METAL_TEXTURE_SLOT_OUT_OF_RANGE, "storage image 'msl_texture_n' is out of range (must be 0..19") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_METAL_TEXTURE_SLOT_COLLISION, "storage image 'msl_texture_n' must be unique across images and storage images in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_HLSL_REGISTER_U_OUT_OF_RANGE, "storage image 'hlsl_register_u_n' is out of range (must be 0..11)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_HLSL_REGISTER_U_COLLISION, "storage image 'hlsl_register_u_n' must be unique across storage images and read/write storage buffers in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_GLSL_BINDING_OUT_OF_RANGE, "storage image 'glsl_binding_n' is out of range (must be 0..4)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_GLSL_BINDING_COLLISION, "storage image 'glsl_binding_n' must be unique across shader stages") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_WGSL_GROUP2_BINDING_OUT_OF_RANGE, "storage image 'wgsl_group2_binding_n' is out of range (must be 0..7)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_STORAGEIMAGE_WGSL_GROUP2_BINDING_COLLISION, "storage image 'wgsl_group2_binding_n' must be unique in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_METAL_TEXTURE_SLOT_OUT_OF_RANGE, "image 'msl_texture_n' is out of range (must be 0..19)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_METAL_TEXTURE_SLOT_COLLISION, "image 'msl_texture_n' must be unique across images and storage images in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_HLSL_REGISTER_T_OUT_OF_RANGE, "image 'hlsl_register_t_n' is out of range (must be 0..23)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_HLSL_REGISTER_T_COLLISION, "image 'hlsl_register_t_n' must be unique across images and storage buffers in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_WGSL_GROUP1_BINDING_OUT_OF_RANGE, "image 'wgsl_group1_binding_n' is out of range (must be 0..127)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_WGSL_GROUP1_BINDING_COLLISION, "image 'wgsl_group1_binding_n' must be unique across all images, samplers and storage buffers") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_METAL_SAMPLER_SLOT_OUT_OF_RANGE, "sampler 'msl_sampler_n' is out of range (must be 0..15)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_METAL_SAMPLER_SLOT_COLLISION, "sampler 'msl_sampler_n' must be unique in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_HLSL_REGISTER_S_OUT_OF_RANGE, "sampler 'hlsl_register_s_n' is out of rang (must be 0..15)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_HLSL_REGISTER_S_COLLISION, "sampler 'hlsl_register_s_n' must be unique in same shader stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_WGSL_GROUP1_BINDING_OUT_OF_RANGE, "sampler 'wgsl_group1_binding_n' is out of range (must be 0..127)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_WGSL_GROUP1_BINDING_COLLISION, "sampler 'wgsl_group1_binding_n' must be unique across all images, samplers and storage buffers") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_IMAGE_SLOT_OUT_OF_RANGE, "image-sampler-pair image slot index is out of range (sg_shader_desc.image_sampler_pairs[].image_slot)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_SAMPLER_SLOT_OUT_OF_RANGE, "image-sampler-pair sampler slot index is out of range (sg_shader_desc.image_sampler_pairs[].sampler_slot)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_IMAGE_STAGE_MISMATCH, "image-sampler-pair stage doesn't match referenced image stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_SAMPLER_STAGE_MISMATCH, "image-sampler-pair stage doesn't match referenced sampler stage") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_GLSL_NAME, "image-sampler-pair 'glsl_name' missing") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_NONFILTERING_SAMPLER_REQUIRED, "image sample type UNFILTERABLE_FLOAT, UINT, SINT can only be used with NONFILTERING sampler") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_COMPARISON_SAMPLER_REQUIRED, "image sample type DEPTH can only be used with COMPARISON sampler") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_IMAGE_NOT_REFERENCED_BY_IMAGE_SAMPLER_PAIRS, "one or more images are not referenced by by image-sampler-pairs (sg_shader_desc.image_sampler_pairs[].image_slot)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_SAMPLER_NOT_REFERENCED_BY_IMAGE_SAMPLER_PAIRS, "one or more samplers are not referenced by image-sampler-pairs (sg_shader_desc.image_sampler_pairs[].sampler_slot)") \
    _SG_LOGITEM_XMACRO(VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG, "vertex attribute name/semantic string too long (max len 16)") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_CANARY, "sg_pipeline_desc not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_SHADER, "sg_pipeline_desc.shader missing or invalid") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_COMPUTE_SHADER_EXPECTED, "sg_pipeline_desc.shader must be a compute shader") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_NO_COMPUTE_SHADER_EXPECTED, "sg_pipeline_desc.compute is false, but shader is a compute shader") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_NO_CONT_ATTRS, "sg_pipeline_desc.layout.attrs is not continuous") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_ATTR_BASETYPE_MISMATCH, "sg_pipeline_desc.layout.attrs[].format is incompatible with sg_shader_desc.attrs[].base_type") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_LAYOUT_STRIDE4, "sg_pipeline_desc.layout.buffers[].stride must be multiple of 4") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_ATTR_SEMANTICS, "D3D11 missing vertex attribute semantics in shader") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_SHADER_READONLY_STORAGEBUFFERS, "sg_pipeline_desc.shader: only readonly storage buffer bindings allowed in render pipelines") \
    _SG_LOGITEM_XMACRO(VALIDATE_PIPELINEDESC_BLENDOP_MINMAX_REQUIRES_BLENDFACTOR_ONE, "SG_BLENDOP_MIN/MAX requires all blend factors to be SG_BLENDFACTOR_ONE") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_CANARY, "sg_attachments_desc not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_NO_ATTACHMENTS, "sg_attachments_desc no color, depth-stencil or storage attachments") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_NO_CONT_COLOR_ATTS, "color attachments must occupy continuous slots") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_IMAGE, "color attachment image is not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_MIPLEVEL, "color attachment mip level is higher than number of mipmaps in image") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_FACE, "color attachment image is cubemap, but face index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_LAYER, "color attachment image is array texture, but layer index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_SLICE, "color attachment image is 3d texture, but slice value is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_IMAGE_NO_RENDERATTACHMENT, "color attachment images must be sg_image_desc.usage.render_attachment=true") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_COLOR_INV_PIXELFORMAT, "color attachment images must be renderable color pixel format") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_IMAGE_SIZES, "all color and depth attachment images must have the same size") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_IMAGE_SAMPLE_COUNTS, "all color and depth attachment images must have the same sample count") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_COLOR_IMAGE_MSAA, "resolve attachments must have a color attachment image with sample count > 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE, "resolve attachment image not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_SAMPLE_COUNT, "pass resolve attachment image sample count must be 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_MIPLEVEL, "resolve attachment mip level is higher than number of mipmaps in image") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_FACE, "resolve attachment is cubemap, but face index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_LAYER, "resolve attachment is array texture, but layer index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_SLICE, "resolve attachment is 3d texture, but slice value is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_NO_RT, "resolve attachment image must have render_target=true") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_SIZES, "resolve attachment size must match color attachment image size") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_FORMAT, "resolve attachment pixel format must match color attachment pixel format") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_INV_PIXELFORMAT, "depth attachment image must be depth or depth-stencil pixel format") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE, "depth attachment image is not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_MIPLEVEL, "depth attachment mip level is higher than number of mipmaps in image") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_FACE, "depth attachment image is cubemap, but face index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_LAYER, "depth attachment image is array texture, but layer index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_SLICE, "depth attachment image is 3d texture, but slice value is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_NO_RENDERATTACHMENT, "depth attachment image must be sg_image_desc.usage.render_attachment=true") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_SIZES, "depth attachment image size must match color attachment image size") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_SAMPLE_COUNT, "depth attachment sample count must match color attachment sample count") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_IMAGE, "storage attachment image is not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_MIPLEVEL, "storage attachment mip level is higher than number of mipmaps in image") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_FACE, "storage attachment image is cubemap, but face index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_LAYER, "storage attachment image is array texture, but layer index is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_SLICE, "storage attachment image is 3d texture, but slice value is too big") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_IMAGE_NO_STORAGEATTACHMENT, "storage attachment images must be sg_image_desc.usage.storage_attachment=true") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_STORAGE_INV_PIXELFORMAT, "storage attachment pixel format must have .compute_readwrite or .compute_writeonly capabilities") \
    _SG_LOGITEM_XMACRO(VALIDATE_ATTACHMENTSDESC_RENDER_VS_STORAGE_ATTACHMENTS, "cannot use color/depth and storage attachment images on the same sg_attachments object") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_CANARY, "sg_begin_pass: pass struct not initialized") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_ATTACHMENTS_EXISTS, "sg_begin_pass: attachments object no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_ATTACHMENTS_VALID, "sg_begin_pass: attachments object not in resource state VALID") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_COMPUTEPASS_STORAGE_ATTACHMENTS_ONLY, "sg_begin_pass: only storage attachments allowed on compute pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_RENDERPASS_RENDER_ATTACHMENTS_ONLY, "sg_begin_pass: a render pass cannot have storage attachments") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_COLOR_ATTACHMENT_IMAGE, "sg_begin_pass: one or more color attachment images are not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_RESOLVE_ATTACHMENT_IMAGE, "sg_begin_pass: one or more resolve attachment images are not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_DEPTHSTENCIL_ATTACHMENT_IMAGE, "sg_begin_pass: one or more depth-stencil attachment images are not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_STORAGE_ATTACHMENT_IMAGE, "sg_begin_pass: one or more storage attachment images are not valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_WIDTH, "sg_begin_pass: expected pass.swapchain.width > 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_WIDTH_NOTSET, "sg_begin_pass: expected pass.swapchain.width == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_HEIGHT, "sg_begin_pass: expected pass.swapchain.height > 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_HEIGHT_NOTSET, "sg_begin_pass: expected pass.swapchain.height == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_SAMPLECOUNT, "sg_begin_pass: expected pass.swapchain.sample_count > 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_SAMPLECOUNT_NOTSET, "sg_begin_pass: expected pass.swapchain.sample_count == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_COLORFORMAT, "sg_begin_pass: expected pass.swapchain.color_format to be valid") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_COLORFORMAT_NOTSET, "sg_begin_pass: expected pass.swapchain.color_format to be unset") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_DEPTHFORMAT_NOTSET, "sg_begin_pass: expected pass.swapchain.depth_format to be unset") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_CURRENTDRAWABLE, "sg_begin_pass: expected pass.swapchain.metal.current_drawable != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_CURRENTDRAWABLE_NOTSET, "sg_begin_pass: expected pass.swapchain.metal.current_drawable == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_DEPTHSTENCILTEXTURE, "sg_begin_pass: expected pass.swapchain.metal.depth_stencil_texture != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_DEPTHSTENCILTEXTURE_NOTSET, "sg_begin_pass: expected pass.swapchain.metal.depth_stencil_texture == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_MSAACOLORTEXTURE, "sg_begin_pass: expected pass.swapchain.metal.msaa_color_texture != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_MSAACOLORTEXTURE_NOTSET, "sg_begin_pass: expected pass.swapchain.metal.msaa_color_texture == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RENDERVIEW, "sg_begin_pass: expected pass.swapchain.d3d11.render_view != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RENDERVIEW_NOTSET, "sg_begin_pass: expected pass.swapchain.d3d11.render_view == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RESOLVEVIEW, "sg_begin_pass: expected pass.swapchain.d3d11.resolve_view != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RESOLVEVIEW_NOTSET, "sg_begin_pass: expected pass.swapchain.d3d11.resolve_view == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_DEPTHSTENCILVIEW, "sg_begin_pass: expected pass.swapchain.d3d11.depth_stencil_view != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_DEPTHSTENCILVIEW_NOTSET, "sg_begin_pass: expected pass.swapchain.d3d11.depth_stencil_view == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RENDERVIEW, "sg_begin_pass: expected pass.swapchain.wgpu.render_view != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RENDERVIEW_NOTSET, "sg_begin_pass: expected pass.swapchain.wgpu.render_view == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RESOLVEVIEW, "sg_begin_pass: expected pass.swapchain.wgpu.resolve_view != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RESOLVEVIEW_NOTSET, "sg_begin_pass: expected pass.swapchain.wgpu.resolve_view == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_DEPTHSTENCILVIEW, "sg_begin_pass: expected pass.swapchain.wgpu.depth_stencil_view != 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_DEPTHSTENCILVIEW_NOTSET, "sg_begin_pass: expected pass.swapchain.wgpu.depth_stencil_view == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_BEGINPASS_SWAPCHAIN_GL_EXPECT_FRAMEBUFFER_NOTSET, "sg_begin_pass: expected pass.swapchain.gl.framebuffer == 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_AVP_RENDERPASS_EXPECTED, "sg_apply_viewport: must be called in a render pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_ASR_RENDERPASS_EXPECTED, "sg_apply_scissor_rect: must be called in a render pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_PIPELINE_VALID_ID, "sg_apply_pipeline: invalid pipeline id provided") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_PIPELINE_EXISTS, "sg_apply_pipeline: pipeline object no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_PIPELINE_VALID, "sg_apply_pipeline: pipeline object not in valid state") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_PASS_EXPECTED, "sg_apply_pipeline: must be called in a pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_SHADER_EXISTS, "sg_apply_pipeline: shader object no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_SHADER_VALID, "sg_apply_pipeline: shader object not in valid state") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_COMPUTEPASS_EXPECTED, "sg_apply_pipeline: trying to apply compute pipeline in render pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_RENDERPASS_EXPECTED, "sg_apply_pipeline: trying to apply render pipeline in compute pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_CURPASS_ATTACHMENTS_EXISTS, "sg_apply_pipeline: current pass attachments no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_CURPASS_ATTACHMENTS_VALID, "sg_apply_pipeline: current pass attachments not in valid state") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_ATT_COUNT, "sg_apply_pipeline: number of pipeline color attachments doesn't match number of pass color attachments") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_COLOR_FORMAT, "sg_apply_pipeline: pipeline color attachment pixel format doesn't match pass color attachment pixel format") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_DEPTH_FORMAT, "sg_apply_pipeline: pipeline depth pixel_format doesn't match pass depth attachment pixel format") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_SAMPLE_COUNT, "sg_apply_pipeline: pipeline MSAA sample count doesn't match render pass attachment sample count") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_EXPECTED_STORAGE_ATTACHMENT_IMAGE, "sg_apply_pipeline: shader expects storage image binding but compute pass doesn't have storage attachment image at expected bind slot") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_STORAGE_ATTACHMENT_IMAGE_EXISTS, "sg_apply_pipeline: compute pass storage image attachment no longer exists") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_STORAGE_ATTACHMENT_IMAGE_VALID, "sg_apply_pipeline: compute pass storage image attachment is not in valid state") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_STORAGE_ATTACHMENT_PIXELFORMAT, "sg_apply_pipeline: compute pass storage image attachment pixel format doesn't match sg_shader_desc.storage_images[].access_format") \
    _SG_LOGITEM_XMACRO(VALIDATE_APIP_STORAGE_ATTACHMENT_IMAGE_TYPE, "sg_apply_pipeline: compute pass storage image attachment image type doesn't match sg_shader_desc.storage_images[].image_type") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_PASS_EXPECTED, "sg_apply_bindings: must be called in a pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EMPTY_BINDINGS, "sg_apply_bindings: the provided sg_bindings struct is empty") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_PIPELINE, "sg_apply_bindings: must be called after sg_apply_pipeline") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_PIPELINE_EXISTS, "sg_apply_bindings: currently applied pipeline object no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_PIPELINE_VALID, "sg_apply_bindings: currently applied pipeline object not in valid state") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_COMPUTE_EXPECTED_NO_VBS, "sg_apply_bindings: vertex buffer bindings not allowed in a compute pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_COMPUTE_EXPECTED_NO_IB, "sg_apply_bindings: index buffer binding not allowed in compute pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_VB, "sg_apply_bindings: vertex buffer binding is missing or buffer handle is invalid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_VB_EXISTS, "sg_apply_bindings: vertex buffer no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_VB_TYPE, "sg_apply_bindings: buffer in vertex buffer slot doesn't have vertex buffer usage (sg_buffer_desc.usage.storage_buffer)") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_VB_OVERFLOW, "sg_apply_bindings: buffer in vertex buffer slot is overflown") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_NO_IB, "sg_apply_bindings: pipeline object defines indexed rendering, but no index buffer provided") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IB, "sg_apply_bindings: pipeline object defines non-indexed rendering, but index buffer provided") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IB_EXISTS, "sg_apply_bindings: index buffer no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IB_TYPE, "sg_apply_bindings: buffer in index buffer slot doesn't have index buffer usage (sg_buffer_desc.usage.index_buffer)") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IB_OVERFLOW, "sg_apply_bindings: buffer in index buffer slot is overflown") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_IMAGE_BINDING, "sg_apply_bindings: image binding is missing or the image handle is invalid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMG_EXISTS, "sg_apply_bindings: bound image no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMAGE_TYPE_MISMATCH, "sg_apply_bindings: type of bound image doesn't match shader desc") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_MULTISAMPLED_IMAGE, "sg_apply_bindings: expected image with sample_count > 1") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMAGE_MSAA, "sg_apply_bindings: cannot bind image with sample_count>1") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_FILTERABLE_IMAGE, "sg_apply_bindings: filterable image expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_DEPTH_IMAGE, "sg_apply_bindings: depth image expected") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_SAMPLER_BINDING, "sg_apply_bindings: sampler binding is missing or the sampler handle is invalid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_UNEXPECTED_SAMPLER_COMPARE_NEVER, "sg_apply_bindings: shader expects SG_SAMPLERTYPE_COMPARISON but sampler has SG_COMPAREFUNC_NEVER") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_SAMPLER_COMPARE_NEVER, "sg_apply_bindings: shader expects SG_SAMPLERTYPE_FILTERING or SG_SAMPLERTYPE_NONFILTERING but sampler doesn't have SG_COMPAREFUNC_NEVER") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_NONFILTERING_SAMPLER, "sg_apply_bindings: shader expected SG_SAMPLERTYPE_NONFILTERING, but sampler has SG_FILTER_LINEAR filters") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_SMP_EXISTS, "sg_apply_bindings: bound sampler no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_EXPECTED_STORAGEBUFFER_BINDING, "sg_apply_bindings: storage buffer binding is missing or the buffer handle is invalid") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_STORAGEBUFFER_EXISTS, "sg_apply_bindings: bound storage buffer no longer alive") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_STORAGEBUFFER_BINDING_BUFFERTYPE, "sg_apply_bindings: buffer bound to storage buffer slot doesn't have storage buffer usage (sg_buffer_desc.usage.storage_buffer)") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_STORAGEBUFFER_READWRITE_IMMUTABLE, "sg_apply_bindings: storage buffers bound as read/write must have usage immutable") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMAGE_BINDING_VS_DEPTHSTENCIL_ATTACHMENT, "sg_apply_bindings: cannot bind image in the same pass it is used as depth-stencil attachment") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMAGE_BINDING_VS_COLOR_ATTACHMENT, "sg_apply_bindings: cannot bind image in the same pass it is used as color attachment") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMAGE_BINDING_VS_RESOLVE_ATTACHMENT, "sg_apply_bindings: cannot bind image in the same pass it is used as resolve attachment") \
    _SG_LOGITEM_XMACRO(VALIDATE_ABND_IMAGE_BINDING_VS_STORAGE_ATTACHMENT, "sg_apply_bindings: cannot bind image in the same pass it is used as storage attachment") \
    _SG_LOGITEM_XMACRO(VALIDATE_AU_PASS_EXPECTED, "sg_apply_uniforms: must be called in a pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_AU_NO_PIPELINE, "sg_apply_uniforms: must be called after sg_apply_pipeline()") \
    _SG_LOGITEM_XMACRO(VALIDATE_AU_NO_UNIFORMBLOCK_AT_SLOT, "sg_apply_uniforms: no uniform block declaration at this shader stage UB slot") \
    _SG_LOGITEM_XMACRO(VALIDATE_AU_SIZE, "sg_apply_uniforms: data size doesn't match declared uniform block size") \
    _SG_LOGITEM_XMACRO(VALIDATE_DRAW_RENDERPASS_EXPECTED, "sg_draw: must be called in a render pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_DRAW_BASEELEMENT, "sg_draw: base_element cannot be < 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_DRAW_NUMELEMENTS, "sg_draw: num_elements cannot be < 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_DRAW_NUMINSTANCES, "sg_draw: num_instances cannot be < 0") \
    _SG_LOGITEM_XMACRO(VALIDATE_DRAW_REQUIRED_BINDINGS_OR_UNIFORMS_MISSING, "sg_draw: call to sg_apply_bindings() and/or sg_apply_uniforms() missing after sg_apply_pipeline()") \
    _SG_LOGITEM_XMACRO(VALIDATE_DISPATCH_COMPUTEPASS_EXPECTED, "sg_dispatch: must be called in a compute pass") \
    _SG_LOGITEM_XMACRO(VALIDATE_DISPATCH_NUMGROUPSX, "sg_dispatch: num_groups_x must be >=0 and <65536") \
    _SG_LOGITEM_XMACRO(VALIDATE_DISPATCH_NUMGROUPSY, "sg_dispatch: num_groups_y must be >=0 and <65536") \
    _SG_LOGITEM_XMACRO(VALIDATE_DISPATCH_NUMGROUPSZ, "sg_dispatch: num_groups_z must be >=0 and <65536") \
    _SG_LOGITEM_XMACRO(VALIDATE_DISPATCH_REQUIRED_BINDINGS_OR_UNIFORMS_MISSING, "sg_dispatch: call to sg_apply_bindings() and/or sg_apply_uniforms() missing after sg_apply_pipeline()") \
    _SG_LOGITEM_XMACRO(VALIDATE_UPDATEBUF_USAGE, "sg_update_buffer: cannot update immutable buffer") \
    _SG_LOGITEM_XMACRO(VALIDATE_UPDATEBUF_SIZE, "sg_update_buffer: update size is bigger than buffer size") \
    _SG_LOGITEM_XMACRO(VALIDATE_UPDATEBUF_ONCE, "sg_update_buffer: only one update allowed per buffer and frame") \
    _SG_LOGITEM_XMACRO(VALIDATE_UPDATEBUF_APPEND, "sg_update_buffer: cannot call sg_update_buffer and sg_append_buffer in same frame") \
    _SG_LOGITEM_XMACRO(VALIDATE_APPENDBUF_USAGE, "sg_append_buffer: cannot append to immutable buffer") \
    _SG_LOGITEM_XMACRO(VALIDATE_APPENDBUF_SIZE, "sg_append_buffer: overall appended size is bigger than buffer size") \
    _SG_LOGITEM_XMACRO(VALIDATE_APPENDBUF_UPDATE, "sg_append_buffer: cannot call sg_append_buffer and sg_update_buffer in same frame") \
    _SG_LOGITEM_XMACRO(VALIDATE_UPDIMG_USAGE, "sg_update_image: cannot update immutable image") \
    _SG_LOGITEM_XMACRO(VALIDATE_UPDIMG_ONCE, "sg_update_image: only one update allowed per image and frame") \
    _SG_LOGITEM_XMACRO(VALIDATION_FAILED, "validation layer checks failed") \

#define _SG_LOGITEM_XMACRO(item,msg) SG_LOGITEM_##item,
typedef enum sg_log_item {
    _SG_LOG_ITEMS
} sg_log_item;
#undef _SG_LOGITEM_XMACRO

/*
    sg_desc

    The sg_desc struct contains configuration values for sokol_gfx,
    it is used as parameter to the sg_setup() call.

    The default configuration is:

    .buffer_pool_size               128
    .image_pool_size                128
    .sampler_pool_size              64
    .shader_pool_size               32
    .pipeline_pool_size             64
    .attachments_pool_size          16
    .uniform_buffer_size            4 MB (4*1024*1024)
    .max_dispatch_calls_per_pass    1024
    .max_commit_listeners           1024
    .disable_validation             false
    .mtl_force_managed_storage_mode false
    .wgpu_disable_bindgroups_cache  false
    .wgpu_bindgroups_cache_size     1024

    .allocator.alloc_fn     0 (in this case, malloc() will be called)
    .allocator.free_fn      0 (in this case, free() will be called)
    .allocator.user_data    0

    .environment.defaults.color_format: default value depends on selected backend:
        all GL backends:    SG_PIXELFORMAT_RGBA8
        Metal and D3D11:    SG_PIXELFORMAT_BGRA8
        WebGPU:             *no default* (must be queried from WebGPU swapchain object)
    .environment.defaults.depth_format: SG_PIXELFORMAT_DEPTH_STENCIL
    .environment.defaults.sample_count: 1

    Metal specific:
        (NOTE: All Objective-C object references are transferred through
        a bridged cast (__bridge const void*) to sokol_gfx, which will use an
        unretained bridged cast (__bridge id<xxx>) to retrieve the Objective-C
        references back. Since the bridge cast is unretained, the caller
        must hold a strong reference to the Objective-C object until sg_setup()
        returns.

        .mtl_force_managed_storage_mode
            when enabled, Metal buffers and texture resources are created in managed storage
            mode, otherwise sokol-gfx will decide whether to create buffers and
            textures in managed or shared storage mode (this is mainly a debugging option)
        .mtl_use_command_buffer_with_retained_references
            when true, the sokol-gfx Metal backend will use Metal command buffers which
            bump the reference count of resource objects as long as they are inflight,
            this is slower than the default command-buffer-with-unretained-references
            method, this may be a workaround when confronted with lifetime validation
            errors from the Metal validation layer until a proper fix has been implemented
        .environment.metal.device
            a pointer to the MTLDevice object

    D3D11 specific:
        .environment.d3d11.device
            a pointer to the ID3D11Device object, this must have been created
            before sg_setup() is called
        .environment.d3d11.device_context
            a pointer to the ID3D11DeviceContext object
        .d3d11_shader_debugging
            set this to true to compile shaders which are provided as HLSL source
            code with debug information and without optimization, this allows
            shader debugging in tools like RenderDoc, to output source code
            instead of byte code from sokol-shdc, omit the `--binary` cmdline
            option

    WebGPU specific:
        .wgpu_disable_bindgroups_cache
            When this is true, the WebGPU backend will create and immediately
            release a BindGroup object in the sg_apply_bindings() call, only
            use this for debugging purposes.
        .wgpu_bindgroups_cache_size
            The size of the bindgroups cache for re-using BindGroup objects
            between sg_apply_bindings() calls. The smaller the cache size,
            the more likely are cache slot collisions which will cause
            a BindGroups object to be destroyed and a new one created.
            Use the information returned by sg_query_stats() to check
            if this is a frequent occurrence, and increase the cache size as
            needed (the default is 1024).
            NOTE: wgpu_bindgroups_cache_size must be a power-of-2 number!
        .environment.wgpu.device
            a WGPUDevice handle

    When using sokol_gfx.h and sokol_app.h together, consider using the
    helper function sglue_environment() in the sokol_glue.h header to
    initialize the sg_desc.environment nested struct. sglue_environment() returns
    a completely initialized sg_environment struct with information
    provided by sokol_app.h.
*/
typedef struct sg_environment_defaults {
    sg_pixel_format color_format;
    sg_pixel_format depth_format;
    int sample_count;
} sg_environment_defaults;

typedef struct sg_metal_environment {
    const void* device;
} sg_metal_environment;

typedef struct sg_d3d11_environment {
    const void* device;
    const void* device_context;
} sg_d3d11_environment;

typedef struct sg_wgpu_environment {
    const void* device;
} sg_wgpu_environment;

typedef struct sg_environment {
    sg_environment_defaults defaults;
    sg_metal_environment metal;
    sg_d3d11_environment d3d11;
    sg_wgpu_environment wgpu;
} sg_environment;

/*
    sg_commit_listener

    Used with function sg_add_commit_listener() to add a callback
    which will be called in sg_commit(). This is useful for libraries
    building on top of sokol-gfx to be notified about when a frame
    ends (instead of having to guess, or add a manual 'new-frame'
    function.
*/
typedef struct sg_commit_listener {
    void (*func)(void* user_data);
    void* user_data;
} sg_commit_listener;

/*
    sg_allocator

    Used in sg_desc to provide custom memory-alloc and -free functions
    to sokol_gfx.h. If memory management should be overridden, both the
    alloc_fn and free_fn function must be provided (e.g. it's not valid to
    override one function but not the other).
*/
typedef struct sg_allocator {
    void* (*alloc_fn)(size_t size, void* user_data);
    void (*free_fn)(void* ptr, void* user_data);
    void* user_data;
} sg_allocator;

/*
    sg_logger

    Used in sg_desc to provide a logging function. Please be aware
    that without logging function, sokol-gfx will be completely
    silent, e.g. it will not report errors, warnings and
    validation layer messages. For maximum error verbosity,
    compile in debug mode (e.g. NDEBUG *not* defined) and provide a
    compatible logger function in the sg_setup() call
    (for instance the standard logging function from sokol_log.h).
*/
typedef struct sg_logger {
    void (*func)(
        const char* tag,                // always "sg"
        uint32_t log_level,             // 0=panic, 1=error, 2=warning, 3=info
        uint32_t log_item_id,           // SG_LOGITEM_*
        const char* message_or_null,    // a message string, may be nullptr in release mode
        uint32_t line_nr,               // line number in sokol_gfx.h
        const char* filename_or_null,   // source filename, may be nullptr in release mode
        void* user_data);
    void* user_data;
} sg_logger;

typedef struct sg_desc {
    uint32_t _start_canary;
    int buffer_pool_size;
    int image_pool_size;
    int sampler_pool_size;
    int shader_pool_size;
    int pipeline_pool_size;
    int attachments_pool_size;
    int uniform_buffer_size;
    int max_dispatch_calls_per_pass;    // max expected number of dispatch calls per pass (default: 1024)
    int max_commit_listeners;
    bool disable_validation;    // disable validation layer even in debug mode, useful for tests
    bool d3d11_shader_debugging;    // if true, HLSL shaders are compiled with D3DCOMPILE_DEBUG | D3DCOMPILE_SKIP_OPTIMIZATION
    bool mtl_force_managed_storage_mode; // for debugging: use Metal managed storage mode for resources even with UMA
    bool mtl_use_command_buffer_with_retained_references;    // Metal: use a managed MTLCommandBuffer which ref-counts used resources
    bool wgpu_disable_bindgroups_cache;  // set to true to disable the WebGPU backend BindGroup cache
    int wgpu_bindgroups_cache_size;      // number of slots in the WebGPU bindgroup cache (must be 2^N)
    sg_allocator allocator;
    sg_logger logger; // optional log function override
    sg_environment environment;
    uint32_t _end_canary;
} sg_desc;

// setup and misc functions
SOKOL_GFX_API_DECL void sg_setup(const sg_desc* desc);
SOKOL_GFX_API_DECL void sg_shutdown(void);
SOKOL_GFX_API_DECL bool sg_isvalid(void);
SOKOL_GFX_API_DECL void sg_reset_state_cache(void);
SOKOL_GFX_API_DECL sg_trace_hooks sg_install_trace_hooks(const sg_trace_hooks* trace_hooks);
SOKOL_GFX_API_DECL void sg_push_debug_group(const char* name);
SOKOL_GFX_API_DECL void sg_pop_debug_group(void);
SOKOL_GFX_API_DECL bool sg_add_commit_listener(sg_commit_listener listener);
SOKOL_GFX_API_DECL bool sg_remove_commit_listener(sg_commit_listener listener);

// resource creation, destruction and updating
SOKOL_GFX_API_DECL sg_buffer sg_make_buffer(const sg_buffer_desc* desc);
SOKOL_GFX_API_DECL sg_image sg_make_image(const sg_image_desc* desc);
SOKOL_GFX_API_DECL sg_sampler sg_make_sampler(const sg_sampler_desc* desc);
SOKOL_GFX_API_DECL sg_shader sg_make_shader(const sg_shader_desc* desc);
SOKOL_GFX_API_DECL sg_pipeline sg_make_pipeline(const sg_pipeline_desc* desc);
SOKOL_GFX_API_DECL sg_attachments sg_make_attachments(const sg_attachments_desc* desc);
SOKOL_GFX_API_DECL void sg_destroy_buffer(sg_buffer buf);
SOKOL_GFX_API_DECL void sg_destroy_image(sg_image img);
SOKOL_GFX_API_DECL void sg_destroy_sampler(sg_sampler smp);
SOKOL_GFX_API_DECL void sg_destroy_shader(sg_shader shd);
SOKOL_GFX_API_DECL void sg_destroy_pipeline(sg_pipeline pip);
SOKOL_GFX_API_DECL void sg_destroy_attachments(sg_attachments atts);
SOKOL_GFX_API_DECL void sg_update_buffer(sg_buffer buf, const sg_range* data);
SOKOL_GFX_API_DECL void sg_update_image(sg_image img, const sg_image_data* data);
SOKOL_GFX_API_DECL int sg_append_buffer(sg_buffer buf, const sg_range* data);
SOKOL_GFX_API_DECL bool sg_query_buffer_overflow(sg_buffer buf);
SOKOL_GFX_API_DECL bool sg_query_buffer_will_overflow(sg_buffer buf, size_t size);

// render and compute functions
SOKOL_GFX_API_DECL void sg_begin_pass(const sg_pass* pass);
SOKOL_GFX_API_DECL void sg_apply_viewport(int x, int y, int width, int height, bool origin_top_left);
SOKOL_GFX_API_DECL void sg_apply_viewportf(float x, float y, float width, float height, bool origin_top_left);
SOKOL_GFX_API_DECL void sg_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left);
SOKOL_GFX_API_DECL void sg_apply_scissor_rectf(float x, float y, float width, float height, bool origin_top_left);
SOKOL_GFX_API_DECL void sg_apply_pipeline(sg_pipeline pip);
SOKOL_GFX_API_DECL void sg_apply_bindings(const sg_bindings* bindings);
SOKOL_GFX_API_DECL void sg_apply_uniforms(int ub_slot, const sg_range* data);
SOKOL_GFX_API_DECL void sg_draw(int base_element, int num_elements, int num_instances);
SOKOL_GFX_API_DECL void sg_dispatch(int num_groups_x, int num_groups_y, int num_groups_z);
SOKOL_GFX_API_DECL void sg_end_pass(void);
SOKOL_GFX_API_DECL void sg_commit(void);

// getting information
SOKOL_GFX_API_DECL sg_desc sg_query_desc(void);
SOKOL_GFX_API_DECL sg_backend sg_query_backend(void);
SOKOL_GFX_API_DECL sg_features sg_query_features(void);
SOKOL_GFX_API_DECL sg_limits sg_query_limits(void);
SOKOL_GFX_API_DECL sg_pixelformat_info sg_query_pixelformat(sg_pixel_format fmt);
SOKOL_GFX_API_DECL int sg_query_row_pitch(sg_pixel_format fmt, int width, int row_align_bytes);
SOKOL_GFX_API_DECL int sg_query_surface_pitch(sg_pixel_format fmt, int width, int height, int row_align_bytes);
// get current state of a resource (INITIAL, ALLOC, VALID, FAILED, INVALID)
SOKOL_GFX_API_DECL sg_resource_state sg_query_buffer_state(sg_buffer buf);
SOKOL_GFX_API_DECL sg_resource_state sg_query_image_state(sg_image img);
SOKOL_GFX_API_DECL sg_resource_state sg_query_sampler_state(sg_sampler smp);
SOKOL_GFX_API_DECL sg_resource_state sg_query_shader_state(sg_shader shd);
SOKOL_GFX_API_DECL sg_resource_state sg_query_pipeline_state(sg_pipeline pip);
SOKOL_GFX_API_DECL sg_resource_state sg_query_attachments_state(sg_attachments atts);
// get runtime information about a resource
SOKOL_GFX_API_DECL sg_buffer_info sg_query_buffer_info(sg_buffer buf);
SOKOL_GFX_API_DECL sg_image_info sg_query_image_info(sg_image img);
SOKOL_GFX_API_DECL sg_sampler_info sg_query_sampler_info(sg_sampler smp);
SOKOL_GFX_API_DECL sg_shader_info sg_query_shader_info(sg_shader shd);
SOKOL_GFX_API_DECL sg_pipeline_info sg_query_pipeline_info(sg_pipeline pip);
SOKOL_GFX_API_DECL sg_attachments_info sg_query_attachments_info(sg_attachments atts);
// get desc structs matching a specific resource (NOTE that not all creation attributes may be provided)
SOKOL_GFX_API_DECL sg_buffer_desc sg_query_buffer_desc(sg_buffer buf);
SOKOL_GFX_API_DECL sg_image_desc sg_query_image_desc(sg_image img);
SOKOL_GFX_API_DECL sg_sampler_desc sg_query_sampler_desc(sg_sampler smp);
SOKOL_GFX_API_DECL sg_shader_desc sg_query_shader_desc(sg_shader shd);
SOKOL_GFX_API_DECL sg_pipeline_desc sg_query_pipeline_desc(sg_pipeline pip);
SOKOL_GFX_API_DECL sg_attachments_desc sg_query_attachments_desc(sg_attachments atts);
// get resource creation desc struct with their default values replaced
SOKOL_GFX_API_DECL sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc* desc);
SOKOL_GFX_API_DECL sg_image_desc sg_query_image_defaults(const sg_image_desc* desc);
SOKOL_GFX_API_DECL sg_sampler_desc sg_query_sampler_defaults(const sg_sampler_desc* desc);
SOKOL_GFX_API_DECL sg_shader_desc sg_query_shader_defaults(const sg_shader_desc* desc);
SOKOL_GFX_API_DECL sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc* desc);
SOKOL_GFX_API_DECL sg_attachments_desc sg_query_attachments_defaults(const sg_attachments_desc* desc);
// assorted query functions
SOKOL_GFX_API_DECL size_t sg_query_buffer_size(sg_buffer buf);
SOKOL_GFX_API_DECL sg_buffer_usage sg_query_buffer_usage(sg_buffer buf);
SOKOL_GFX_API_DECL sg_image_type sg_query_image_type(sg_image img);
SOKOL_GFX_API_DECL int sg_query_image_width(sg_image img);
SOKOL_GFX_API_DECL int sg_query_image_height(sg_image img);
SOKOL_GFX_API_DECL int sg_query_image_num_slices(sg_image img);
SOKOL_GFX_API_DECL int sg_query_image_num_mipmaps(sg_image img);
SOKOL_GFX_API_DECL sg_pixel_format sg_query_image_pixelformat(sg_image img);
SOKOL_GFX_API_DECL sg_image_usage sg_query_image_usage(sg_image img);
SOKOL_GFX_API_DECL int sg_query_image_sample_count(sg_image img);

// separate resource allocation and initialization (for async setup)
SOKOL_GFX_API_DECL sg_buffer sg_alloc_buffer(void);
SOKOL_GFX_API_DECL sg_image sg_alloc_image(void);
SOKOL_GFX_API_DECL sg_sampler sg_alloc_sampler(void);
SOKOL_GFX_API_DECL sg_shader sg_alloc_shader(void);
SOKOL_GFX_API_DECL sg_pipeline sg_alloc_pipeline(void);
SOKOL_GFX_API_DECL sg_attachments sg_alloc_attachments(void);
SOKOL_GFX_API_DECL void sg_dealloc_buffer(sg_buffer buf);
SOKOL_GFX_API_DECL void sg_dealloc_image(sg_image img);
SOKOL_GFX_API_DECL void sg_dealloc_sampler(sg_sampler smp);
SOKOL_GFX_API_DECL void sg_dealloc_shader(sg_shader shd);
SOKOL_GFX_API_DECL void sg_dealloc_pipeline(sg_pipeline pip);
SOKOL_GFX_API_DECL void sg_dealloc_attachments(sg_attachments attachments);
SOKOL_GFX_API_DECL void sg_init_buffer(sg_buffer buf, const sg_buffer_desc* desc);
SOKOL_GFX_API_DECL void sg_init_image(sg_image img, const sg_image_desc* desc);
SOKOL_GFX_API_DECL void sg_init_sampler(sg_sampler smg, const sg_sampler_desc* desc);
SOKOL_GFX_API_DECL void sg_init_shader(sg_shader shd, const sg_shader_desc* desc);
SOKOL_GFX_API_DECL void sg_init_pipeline(sg_pipeline pip, const sg_pipeline_desc* desc);
SOKOL_GFX_API_DECL void sg_init_attachments(sg_attachments attachments, const sg_attachments_desc* desc);
SOKOL_GFX_API_DECL void sg_uninit_buffer(sg_buffer buf);
SOKOL_GFX_API_DECL void sg_uninit_image(sg_image img);
SOKOL_GFX_API_DECL void sg_uninit_sampler(sg_sampler smp);
SOKOL_GFX_API_DECL void sg_uninit_shader(sg_shader shd);
SOKOL_GFX_API_DECL void sg_uninit_pipeline(sg_pipeline pip);
SOKOL_GFX_API_DECL void sg_uninit_attachments(sg_attachments atts);
SOKOL_GFX_API_DECL void sg_fail_buffer(sg_buffer buf);
SOKOL_GFX_API_DECL void sg_fail_image(sg_image img);
SOKOL_GFX_API_DECL void sg_fail_sampler(sg_sampler smp);
SOKOL_GFX_API_DECL void sg_fail_shader(sg_shader shd);
SOKOL_GFX_API_DECL void sg_fail_pipeline(sg_pipeline pip);
SOKOL_GFX_API_DECL void sg_fail_attachments(sg_attachments atts);

// frame stats
SOKOL_GFX_API_DECL void sg_enable_frame_stats(void);
SOKOL_GFX_API_DECL void sg_disable_frame_stats(void);
SOKOL_GFX_API_DECL bool sg_frame_stats_enabled(void);
SOKOL_GFX_API_DECL sg_frame_stats sg_query_frame_stats(void);

/* Backend-specific structs and functions, these may come in handy for mixing
   sokol-gfx rendering with 'native backend' rendering functions.

   This group of functions will be expanded as needed.
*/

typedef struct sg_d3d11_buffer_info {
    const void* buf;      // ID3D11Buffer*
} sg_d3d11_buffer_info;

typedef struct sg_d3d11_image_info {
    const void* tex2d;    // ID3D11Texture2D*
    const void* tex3d;    // ID3D11Texture3D*
    const void* res;      // ID3D11Resource* (either tex2d or tex3d)
    const void* srv;      // ID3D11ShaderResourceView*
} sg_d3d11_image_info;

typedef struct sg_d3d11_sampler_info {
    const void* smp;      // ID3D11SamplerState*
} sg_d3d11_sampler_info;

typedef struct sg_d3d11_shader_info {
    const void* cbufs[SG_MAX_UNIFORMBLOCK_BINDSLOTS]; // ID3D11Buffer* (constant buffers by bind slot)
    const void* vs;   // ID3D11VertexShader*
    const void* fs;   // ID3D11PixelShader*
} sg_d3d11_shader_info;

typedef struct sg_d3d11_pipeline_info {
    const void* il;   // ID3D11InputLayout*
    const void* rs;   // ID3D11RasterizerState*
    const void* dss;  // ID3D11DepthStencilState*
    const void* bs;   // ID3D11BlendState*
} sg_d3d11_pipeline_info;

typedef struct sg_d3d11_attachments_info {
    const void* color_rtv[SG_MAX_COLOR_ATTACHMENTS];      // ID3D11RenderTargetView
    const void* resolve_rtv[SG_MAX_COLOR_ATTACHMENTS];    // ID3D11RenderTargetView
    const void* dsv;  // ID3D11DepthStencilView
} sg_d3d11_attachments_info;

typedef struct sg_mtl_buffer_info {
    const void* buf[SG_NUM_INFLIGHT_FRAMES];  // id<MTLBuffer>
    int active_slot;
} sg_mtl_buffer_info;

typedef struct sg_mtl_image_info {
    const void* tex[SG_NUM_INFLIGHT_FRAMES]; // id<MTLTexture>
    int active_slot;
} sg_mtl_image_info;

typedef struct sg_mtl_sampler_info {
    const void* smp;  // id<MTLSamplerState>
} sg_mtl_sampler_info;

typedef struct sg_mtl_shader_info {
    const void* vertex_lib;     // id<MTLLibrary>
    const void* fragment_lib;   // id<MTLLibrary>
    const void* vertex_func;    // id<MTLFunction>
    const void* fragment_func;  // id<MTLFunction>
} sg_mtl_shader_info;

typedef struct sg_mtl_pipeline_info {
    const void* rps;      // id<MTLRenderPipelineState>
    const void* dss;      // id<MTLDepthStencilState>
} sg_mtl_pipeline_info;

typedef struct sg_wgpu_buffer_info {
    const void* buf;  // WGPUBuffer
} sg_wgpu_buffer_info;

typedef struct sg_wgpu_image_info {
    const void* tex;  // WGPUTexture
    const void* view; // WGPUTextureView
} sg_wgpu_image_info;

typedef struct sg_wgpu_sampler_info {
    const void* smp;  // WGPUSampler
} sg_wgpu_sampler_info;

typedef struct sg_wgpu_shader_info {
    const void* vs_mod;   // WGPUShaderModule
    const void* fs_mod;   // WGPUShaderModule
    const void* bgl;      // WGPUBindGroupLayout;
} sg_wgpu_shader_info;

typedef struct sg_wgpu_pipeline_info {
    const void* render_pipeline;   // WGPURenderPipeline
    const void* compute_pipeline;  // WGPUComputePipeline
} sg_wgpu_pipeline_info;

typedef struct sg_wgpu_attachments_info {
    const void* color_view[SG_MAX_COLOR_ATTACHMENTS];     // WGPUTextureView
    const void* resolve_view[SG_MAX_COLOR_ATTACHMENTS];    // WGPUTextureView
    const void* ds_view;  // WGPUTextureView
} sg_wgpu_attachments_info;

typedef struct sg_gl_buffer_info {
    uint32_t buf[SG_NUM_INFLIGHT_FRAMES];
    int active_slot;
} sg_gl_buffer_info;

typedef struct sg_gl_image_info {
    uint32_t tex[SG_NUM_INFLIGHT_FRAMES];
    uint32_t tex_target;
    uint32_t msaa_render_buffer;
    int active_slot;
} sg_gl_image_info;

typedef struct sg_gl_sampler_info {
    uint32_t smp;
} sg_gl_sampler_info;

typedef struct sg_gl_shader_info {
    uint32_t prog;
} sg_gl_shader_info;

typedef struct sg_gl_attachments_info {
    uint32_t framebuffer;
    uint32_t msaa_resolve_framebuffer[SG_MAX_COLOR_ATTACHMENTS];
} sg_gl_attachments_info;

// D3D11: return ID3D11Device
SOKOL_GFX_API_DECL const void* sg_d3d11_device(void);
// D3D11: return ID3D11DeviceContext
SOKOL_GFX_API_DECL const void* sg_d3d11_device_context(void);
// D3D11: get internal buffer resource objects
SOKOL_GFX_API_DECL sg_d3d11_buffer_info sg_d3d11_query_buffer_info(sg_buffer buf);
// D3D11: get internal image resource objects
SOKOL_GFX_API_DECL sg_d3d11_image_info sg_d3d11_query_image_info(sg_image img);
// D3D11: get internal sampler resource objects
SOKOL_GFX_API_DECL sg_d3d11_sampler_info sg_d3d11_query_sampler_info(sg_sampler smp);
// D3D11: get internal shader resource objects
SOKOL_GFX_API_DECL sg_d3d11_shader_info sg_d3d11_query_shader_info(sg_shader shd);
// D3D11: get internal pipeline resource objects
SOKOL_GFX_API_DECL sg_d3d11_pipeline_info sg_d3d11_query_pipeline_info(sg_pipeline pip);
// D3D11: get internal pass resource objects
SOKOL_GFX_API_DECL sg_d3d11_attachments_info sg_d3d11_query_attachments_info(sg_attachments atts);

// Metal: return __bridge-casted MTLDevice
SOKOL_GFX_API_DECL const void* sg_mtl_device(void);
// Metal: return __bridge-casted MTLRenderCommandEncoder when inside render pass (otherwise zero)
SOKOL_GFX_API_DECL const void* sg_mtl_render_command_encoder(void);
// Metal: return __bridge-casted MTLComputeCommandEncoder when inside compute pass (otherwise zero)
SOKOL_GFX_API_DECL const void* sg_mtl_compute_command_encoder(void);
// Metal: get internal __bridge-casted buffer resource objects
SOKOL_GFX_API_DECL sg_mtl_buffer_info sg_mtl_query_buffer_info(sg_buffer buf);
// Metal: get internal __bridge-casted image resource objects
SOKOL_GFX_API_DECL sg_mtl_image_info sg_mtl_query_image_info(sg_image img);
// Metal: get internal __bridge-casted sampler resource objects
SOKOL_GFX_API_DECL sg_mtl_sampler_info sg_mtl_query_sampler_info(sg_sampler smp);
// Metal: get internal __bridge-casted shader resource objects
SOKOL_GFX_API_DECL sg_mtl_shader_info sg_mtl_query_shader_info(sg_shader shd);
// Metal: get internal __bridge-casted pipeline resource objects
SOKOL_GFX_API_DECL sg_mtl_pipeline_info sg_mtl_query_pipeline_info(sg_pipeline pip);

// WebGPU: return WGPUDevice object
SOKOL_GFX_API_DECL const void* sg_wgpu_device(void);
// WebGPU: return WGPUQueue object
SOKOL_GFX_API_DECL const void* sg_wgpu_queue(void);
// WebGPU: return this frame's WGPUCommandEncoder
SOKOL_GFX_API_DECL const void* sg_wgpu_command_encoder(void);
// WebGPU: return WGPURenderPassEncoder of current pass (returns 0 when outside pass or in a compute pass)
SOKOL_GFX_API_DECL const void* sg_wgpu_render_pass_encoder(void);
// WebGPU: return WGPUComputePassEncoder of current pass (returns 0 when outside pass or in a render pass)
SOKOL_GFX_API_DECL const void* sg_wgpu_compute_pass_encoder(void);
// WebGPU: get internal buffer resource objects
SOKOL_GFX_API_DECL sg_wgpu_buffer_info sg_wgpu_query_buffer_info(sg_buffer buf);
// WebGPU: get internal image resource objects
SOKOL_GFX_API_DECL sg_wgpu_image_info sg_wgpu_query_image_info(sg_image img);
// WebGPU: get internal sampler resource objects
SOKOL_GFX_API_DECL sg_wgpu_sampler_info sg_wgpu_query_sampler_info(sg_sampler smp);
// WebGPU: get internal shader resource objects
SOKOL_GFX_API_DECL sg_wgpu_shader_info sg_wgpu_query_shader_info(sg_shader shd);
// WebGPU: get internal pipeline resource objects
SOKOL_GFX_API_DECL sg_wgpu_pipeline_info sg_wgpu_query_pipeline_info(sg_pipeline pip);
// WebGPU: get internal pass resource objects
SOKOL_GFX_API_DECL sg_wgpu_attachments_info sg_wgpu_query_attachments_info(sg_attachments atts);

// GL: get internal buffer resource objects
SOKOL_GFX_API_DECL sg_gl_buffer_info sg_gl_query_buffer_info(sg_buffer buf);
// GL: get internal image resource objects
SOKOL_GFX_API_DECL sg_gl_image_info sg_gl_query_image_info(sg_image img);
// GL: get internal sampler resource objects
SOKOL_GFX_API_DECL sg_gl_sampler_info sg_gl_query_sampler_info(sg_sampler smp);
// GL: get internal shader resource objects
SOKOL_GFX_API_DECL sg_gl_shader_info sg_gl_query_shader_info(sg_shader shd);
// GL: get internal pass resource objects
SOKOL_GFX_API_DECL sg_gl_attachments_info sg_gl_query_attachments_info(sg_attachments atts);

#ifdef __cplusplus
} // extern "C"

// reference-based equivalents for c++
inline void sg_setup(const sg_desc& desc) { return sg_setup(&desc); }

inline sg_buffer sg_make_buffer(const sg_buffer_desc& desc) { return sg_make_buffer(&desc); }
inline sg_image sg_make_image(const sg_image_desc& desc) { return sg_make_image(&desc); }
inline sg_sampler sg_make_sampler(const sg_sampler_desc& desc) { return sg_make_sampler(&desc); }
inline sg_shader sg_make_shader(const sg_shader_desc& desc) { return sg_make_shader(&desc); }
inline sg_pipeline sg_make_pipeline(const sg_pipeline_desc& desc) { return sg_make_pipeline(&desc); }
inline sg_attachments sg_make_attachments(const sg_attachments_desc& desc) { return sg_make_attachments(&desc); }
inline void sg_update_image(sg_image img, const sg_image_data& data) { return sg_update_image(img, &data); }

inline void sg_begin_pass(const sg_pass& pass) { return sg_begin_pass(&pass); }
inline void sg_apply_bindings(const sg_bindings& bindings) { return sg_apply_bindings(&bindings); }
inline void sg_apply_uniforms(int ub_slot, const sg_range& data) { return sg_apply_uniforms(ub_slot, &data); }

inline sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc& desc) { return sg_query_buffer_defaults(&desc); }
inline sg_image_desc sg_query_image_defaults(const sg_image_desc& desc) { return sg_query_image_defaults(&desc); }
inline sg_sampler_desc sg_query_sampler_defaults(const sg_sampler_desc& desc) { return sg_query_sampler_defaults(&desc); }
inline sg_shader_desc sg_query_shader_defaults(const sg_shader_desc& desc) { return sg_query_shader_defaults(&desc); }
inline sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc& desc) { return sg_query_pipeline_defaults(&desc); }
inline sg_attachments_desc sg_query_attachments_defaults(const sg_attachments_desc& desc) { return sg_query_attachments_defaults(&desc); }

inline void sg_init_buffer(sg_buffer buf, const sg_buffer_desc& desc) { return sg_init_buffer(buf, &desc); }
inline void sg_init_image(sg_image img, const sg_image_desc& desc) { return sg_init_image(img, &desc); }
inline void sg_init_sampler(sg_sampler smp, const sg_sampler_desc& desc) { return sg_init_sampler(smp, &desc); }
inline void sg_init_shader(sg_shader shd, const sg_shader_desc& desc) { return sg_init_shader(shd, &desc); }
inline void sg_init_pipeline(sg_pipeline pip, const sg_pipeline_desc& desc) { return sg_init_pipeline(pip, &desc); }
inline void sg_init_attachments(sg_attachments atts, const sg_attachments_desc& desc) { return sg_init_attachments(atts, &desc); }

inline void sg_update_buffer(sg_buffer buf_id, const sg_range& data) { return sg_update_buffer(buf_id, &data); }
inline int sg_append_buffer(sg_buffer buf_id, const sg_range& data) { return sg_append_buffer(buf_id, &data); }
#endif
#endif // SOKOL_GFX_INCLUDED

// ██ ███    ███ ██████  ██      ███████ ███    ███ ███████ ███    ██ ████████  █████  ████████ ██  ██████  ███    ██
// ██ ████  ████ ██   ██ ██      ██      ████  ████ ██      ████   ██    ██    ██   ██    ██    ██ ██    ██ ████   ██
// ██ ██ ████ ██ ██████  ██      █████   ██ ████ ██ █████   ██ ██  ██    ██    ███████    ██    ██ ██    ██ ██ ██  ██
// ██ ██  ██  ██ ██      ██      ██      ██  ██  ██ ██      ██  ██ ██    ██    ██   ██    ██    ██ ██    ██ ██  ██ ██
// ██ ██      ██ ██      ███████ ███████ ██      ██ ███████ ██   ████    ██    ██   ██    ██    ██  ██████  ██   ████
//
// >>implementation
#ifdef SOKOL_GFX_IMPL
#define SOKOL_GFX_IMPL_INCLUDED (1)

#if !(defined(SOKOL_GLCORE)||defined(SOKOL_GLES3)||defined(SOKOL_D3D11)||defined(SOKOL_METAL)||defined(SOKOL_WGPU)||defined(SOKOL_DUMMY_BACKEND))
#error "Please select a backend with SOKOL_GLCORE, SOKOL_GLES3, SOKOL_D3D11, SOKOL_METAL, SOKOL_WGPU or SOKOL_DUMMY_BACKEND"
#endif
#if defined(SOKOL_MALLOC) || defined(SOKOL_CALLOC) || defined(SOKOL_FREE)
#error "SOKOL_MALLOC/CALLOC/FREE macros are no longer supported, please use sg_desc.allocator to override memory allocation functions"
#endif

#include <stdlib.h> // malloc, free, qsort
#include <string.h> // memset
#include <float.h> // FLT_MAX

#ifndef SOKOL_API_IMPL
    #define SOKOL_API_IMPL
#endif
#ifndef SOKOL_DEBUG
    #ifndef NDEBUG
        #define SOKOL_DEBUG
    #endif
#endif
#ifndef SOKOL_ASSERT
    #include <assert.h>
    #define SOKOL_ASSERT(c) assert(c)
#endif
#ifndef SOKOL_UNREACHABLE
    #define SOKOL_UNREACHABLE SOKOL_ASSERT(false)
#endif

#ifndef _SOKOL_PRIVATE
    #if defined(__GNUC__) || defined(__clang__)
        #define _SOKOL_PRIVATE __attribute__((unused)) static
    #else
        #define _SOKOL_PRIVATE static
    #endif
#endif

#ifndef _SOKOL_UNUSED
    #define _SOKOL_UNUSED(x) (void)(x)
#endif

#if defined(SOKOL_TRACE_HOOKS)
#define _SG_TRACE_ARGS(fn, ...) if (_sg.hooks.fn) { _sg.hooks.fn(__VA_ARGS__, _sg.hooks.user_data); }
#define _SG_TRACE_NOARGS(fn) if (_sg.hooks.fn) { _sg.hooks.fn(_sg.hooks.user_data); }
#else
#define _SG_TRACE_ARGS(fn, ...)
#define _SG_TRACE_NOARGS(fn)
#endif

// default clear values
#ifndef SG_DEFAULT_CLEAR_RED
#define SG_DEFAULT_CLEAR_RED (0.5f)
#endif
#ifndef SG_DEFAULT_CLEAR_GREEN
#define SG_DEFAULT_CLEAR_GREEN (0.5f)
#endif
#ifndef SG_DEFAULT_CLEAR_BLUE
#define SG_DEFAULT_CLEAR_BLUE (0.5f)
#endif
#ifndef SG_DEFAULT_CLEAR_ALPHA
#define SG_DEFAULT_CLEAR_ALPHA (1.0f)
#endif
#ifndef SG_DEFAULT_CLEAR_DEPTH
#define SG_DEFAULT_CLEAR_DEPTH (1.0f)
#endif
#ifndef SG_DEFAULT_CLEAR_STENCIL
#define SG_DEFAULT_CLEAR_STENCIL (0)
#endif

#ifdef _MSC_VER
#pragma warning(push)
#pragma warning(disable:4115)   // named type definition in parentheses
#pragma warning(disable:4505)   // unreferenced local function has been removed
#pragma warning(disable:4201)   // nonstandard extension used: nameless struct/union (needed by d3d11.h)
#pragma warning(disable:4054)   // 'type cast': from function pointer
#pragma warning(disable:4055)   // 'type cast': from data pointer
#endif

#if defined(SOKOL_D3D11)
    #ifndef D3D11_NO_HELPERS
    #define D3D11_NO_HELPERS
    #endif
    #ifndef WIN32_LEAN_AND_MEAN
    #define WIN32_LEAN_AND_MEAN
    #endif
    #ifndef NOMINMAX
    #define NOMINMAX
    #endif
    #include <d3d11.h>
    #include <d3dcompiler.h>
    #ifdef _MSC_VER
    #pragma comment (lib, "kernel32")
    #pragma comment (lib, "user32")
    #pragma comment (lib, "dxgi")
    #pragma comment (lib, "d3d11")
    #endif
#elif defined(SOKOL_METAL)
    // see https://clang.llvm.org/docs/LanguageExtensions.html#automatic-reference-counting
    #if !defined(__cplusplus)
        #if __has_feature(objc_arc) && !__has_feature(objc_arc_fields)
            #error "sokol_gfx.h requires __has_feature(objc_arc_field) if ARC is enabled (use a more recent compiler version)"
        #endif
    #endif
    #include <TargetConditionals.h>
    #include <AvailabilityMacros.h>
    #if defined(TARGET_OS_IPHONE) && !TARGET_OS_IPHONE
        #define _SG_TARGET_MACOS (1)
    #else
        #define _SG_TARGET_IOS (1)
        #if defined(TARGET_IPHONE_SIMULATOR) && TARGET_IPHONE_SIMULATOR
            #define _SG_TARGET_IOS_SIMULATOR (1)
        #endif
    #endif
    #import <Metal/Metal.h>
    #import <QuartzCore/CoreAnimation.h> // needed for CAMetalDrawable
#elif defined(SOKOL_WGPU)
    #include <webgpu/webgpu.h>
    #if defined(__EMSCRIPTEN__)
        #include <emscripten/emscripten.h>
    #endif
#elif defined(SOKOL_GLCORE) || defined(SOKOL_GLES3)
    #define _SOKOL_ANY_GL (1)

    // include platform specific GL headers (or on Win32: use an embedded GL loader)
    #if !defined(SOKOL_EXTERNAL_GL_LOADER)
        #if defined(_WIN32)
            #if defined(SOKOL_GLCORE)
                #define _SOKOL_USE_WIN32_GL_LOADER (1)
                #ifndef WIN32_LEAN_AND_MEAN
                #define WIN32_LEAN_AND_MEAN
                #endif
                #ifndef NOMINMAX
                #define NOMINMAX
                #endif
                #include <windows.h>
                #pragma comment (lib, "kernel32")   // GetProcAddress()
                #define _SOKOL_GL_HAS_COMPUTE (1)
                #define _SOKOL_GL_HAS_TEXSTORAGE (1)
            #endif
        #elif defined(__APPLE__)
            #include <TargetConditionals.h>
            #ifndef GL_SILENCE_DEPRECATION
                #define GL_SILENCE_DEPRECATION
            #endif
            #if defined(TARGET_OS_IPHONE) && !TARGET_OS_IPHONE
                #include <OpenGL/gl3.h>
            #else
                #include <OpenGLES/ES3/gl.h>
                #include <OpenGLES/ES3/glext.h>
                #define _SOKOL_GL_HAS_TEXSTORAGE (1)
            #endif
        #elif defined(__EMSCRIPTEN__)
            #if defined(SOKOL_GLES3)
                #include <GLES3/gl3.h>
                #define _SOKOL_GL_HAS_TEXSTORAGE (1)
            #endif
        #elif defined(__ANDROID__)
            #include <GLES3/gl31.h>
            #define _SOKOL_GL_HAS_COMPUTE (1)
            #define _SOKOL_GL_HAS_TEXSTORAGE (1)
        #elif defined(__linux__) || defined(__unix__)
            #if defined(SOKOL_GLCORE)
                #define GL_GLEXT_PROTOTYPES
                #include <GL/gl.h>
            #else
                #include <GLES3/gl31.h>
                #include <GLES3/gl3ext.h>
            #endif
            #define _SOKOL_GL_HAS_COMPUTE (1)
            #define _SOKOL_GL_HAS_TEXSTORAGE (1)
        #endif
    #endif

    // optional GL loader definitions (only on Win32)
    #if defined(_SOKOL_USE_WIN32_GL_LOADER)
        #define __gl_h_ 1
        #define __gl32_h_ 1
        #define __gl31_h_ 1
        #define __GL_H__ 1
        #define __glext_h_ 1
        #define __GLEXT_H_ 1
        #define __gltypes_h_ 1
        #define __glcorearb_h_ 1
        #define __gl_glcorearb_h_ 1
        #define GL_APIENTRY APIENTRY

        typedef unsigned int  GLenum;
        typedef unsigned int  GLuint;
        typedef int  GLsizei;
        typedef char  GLchar;
        typedef ptrdiff_t  GLintptr;
        typedef ptrdiff_t  GLsizeiptr;
        typedef double  GLclampd;
        typedef unsigned short  GLushort;
        typedef unsigned char  GLubyte;
        typedef unsigned char  GLboolean;
        typedef uint64_t  GLuint64;
        typedef double  GLdouble;
        typedef unsigned short  GLhalf;
        typedef float  GLclampf;
        typedef unsigned int  GLbitfield;
        typedef signed char  GLbyte;
        typedef short  GLshort;
        typedef void  GLvoid;
        typedef int64_t  GLint64;
        typedef float  GLfloat;
        typedef int  GLint;
        #define GL_INT_2_10_10_10_REV 0x8D9F
        #define GL_R32F 0x822E
        #define GL_PROGRAM_POINT_SIZE 0x8642
        #define GL_DEPTH_ATTACHMENT 0x8D00
        #define GL_DEPTH_STENCIL_ATTACHMENT 0x821A
        #define GL_COLOR_ATTACHMENT2 0x8CE2
        #define GL_COLOR_ATTACHMENT0 0x8CE0
        #define GL_R16F 0x822D
        #define GL_COLOR_ATTACHMENT22 0x8CF6
        #define GL_DRAW_FRAMEBUFFER 0x8CA9
        #define GL_FRAMEBUFFER_COMPLETE 0x8CD5
        #define GL_NUM_EXTENSIONS 0x821D
        #define GL_INFO_LOG_LENGTH 0x8B84
        #define GL_VERTEX_SHADER 0x8B31
        #define GL_INCR 0x1E02
        #define GL_DYNAMIC_DRAW 0x88E8
        #define GL_STATIC_DRAW 0x88E4
        #define GL_TEXTURE_CUBE_MAP_POSITIVE_Z 0x8519
        #define GL_TEXTURE_CUBE_MAP 0x8513
        #define GL_FUNC_SUBTRACT 0x800A
        #define GL_FUNC_REVERSE_SUBTRACT 0x800B
        #define GL_CONSTANT_COLOR 0x8001
        #define GL_DECR_WRAP 0x8508
        #define GL_R8 0x8229
        #define GL_LINEAR_MIPMAP_LINEAR 0x2703
        #define GL_ELEMENT_ARRAY_BUFFER 0x8893
        #define GL_SHORT 0x1402
        #define GL_DEPTH_TEST 0x0B71
        #define GL_TEXTURE_CUBE_MAP_NEGATIVE_Y 0x8518
        #define GL_LINK_STATUS 0x8B82
        #define GL_TEXTURE_CUBE_MAP_POSITIVE_Y 0x8517
        #define GL_SAMPLE_ALPHA_TO_COVERAGE 0x809E
        #define GL_RGBA16F 0x881A
        #define GL_CONSTANT_ALPHA 0x8003
        #define GL_READ_FRAMEBUFFER 0x8CA8
        #define GL_TEXTURE0 0x84C0
        #define GL_TEXTURE_MIN_LOD 0x813A
        #define GL_CLAMP_TO_EDGE 0x812F
        #define GL_UNSIGNED_SHORT_5_6_5 0x8363
        #define GL_TEXTURE_WRAP_R 0x8072
        #define GL_UNSIGNED_SHORT_5_5_5_1 0x8034
        #define GL_NEAREST_MIPMAP_NEAREST 0x2700
        #define GL_UNSIGNED_SHORT_4_4_4_4 0x8033
        #define GL_SRC_ALPHA_SATURATE 0x0308
        #define GL_STREAM_DRAW 0x88E0
        #define GL_ONE 1
        #define GL_NEAREST_MIPMAP_LINEAR 0x2702
        #define GL_RGB10_A2 0x8059
        #define GL_RGBA8 0x8058
        #define GL_SRGB8_ALPHA8 0x8C43
        #define GL_COLOR_ATTACHMENT1 0x8CE1
        #define GL_RGBA4 0x8056
        #define GL_RGB8 0x8051
        #define GL_ARRAY_BUFFER 0x8892
        #define GL_STENCIL 0x1802
        #define GL_TEXTURE_2D 0x0DE1
        #define GL_DEPTH 0x1801
        #define GL_FRONT 0x0404
        #define GL_STENCIL_BUFFER_BIT 0x00000400
        #define GL_REPEAT 0x2901
        #define GL_RGBA 0x1908
        #define GL_TEXTURE_CUBE_MAP_POSITIVE_X 0x8515
        #define GL_DECR 0x1E03
        #define GL_FRAGMENT_SHADER 0x8B30
        #define GL_COMPUTE_SHADER 0x91B9
        #define GL_FLOAT 0x1406
        #define GL_TEXTURE_MAX_LOD 0x813B
        #define GL_DEPTH_COMPONENT 0x1902
        #define GL_ONE_MINUS_DST_ALPHA 0x0305
        #define GL_COLOR 0x1800
        #define GL_TEXTURE_2D_ARRAY 0x8C1A
        #define GL_TRIANGLES 0x0004
        #define GL_UNSIGNED_BYTE 0x1401
        #define GL_TEXTURE_MAG_FILTER 0x2800
        #define GL_ONE_MINUS_CONSTANT_ALPHA 0x8004
        #define GL_NONE 0
        #define GL_SRC_COLOR 0x0300
        #define GL_BYTE 0x1400
        #define GL_TEXTURE_CUBE_MAP_NEGATIVE_Z 0x851A
        #define GL_LINE_STRIP 0x0003
        #define GL_TEXTURE_3D 0x806F
        #define GL_CW 0x0900
        #define GL_LINEAR 0x2601
        #define GL_RENDERBUFFER 0x8D41
        #define GL_GEQUAL 0x0206
        #define GL_COLOR_BUFFER_BIT 0x00004000
        #define GL_RGBA32F 0x8814
        #define GL_BLEND 0x0BE2
        #define GL_ONE_MINUS_SRC_ALPHA 0x0303
        #define GL_ONE_MINUS_CONSTANT_COLOR 0x8002
        #define GL_TEXTURE_WRAP_T 0x2803
        #define GL_TEXTURE_WRAP_S 0x2802
        #define GL_TEXTURE_MIN_FILTER 0x2801
        #define GL_LINEAR_MIPMAP_NEAREST 0x2701
        #define GL_EXTENSIONS 0x1F03
        #define GL_NO_ERROR 0
        #define GL_REPLACE 0x1E01
        #define GL_KEEP 0x1E00
        #define GL_CCW 0x0901
        #define GL_TEXTURE_CUBE_MAP_NEGATIVE_X 0x8516
        #define GL_RGB 0x1907
        #define GL_TRIANGLE_STRIP 0x0005
        #define GL_FALSE 0
        #define GL_ZERO 0
        #define GL_CULL_FACE 0x0B44
        #define GL_INVERT 0x150A
        #define GL_INT 0x1404
        #define GL_UNSIGNED_INT 0x1405
        #define GL_UNSIGNED_SHORT 0x1403
        #define GL_NEAREST 0x2600
        #define GL_SCISSOR_TEST 0x0C11
        #define GL_LEQUAL 0x0203
        #define GL_STENCIL_TEST 0x0B90
        #define GL_DITHER 0x0BD0
        #define GL_DEPTH_COMPONENT32F 0x8CAC
        #define GL_EQUAL 0x0202
        #define GL_FRAMEBUFFER 0x8D40
        #define GL_RGB5 0x8050
        #define GL_LINES 0x0001
        #define GL_DEPTH_BUFFER_BIT 0x00000100
        #define GL_SRC_ALPHA 0x0302
        #define GL_INCR_WRAP 0x8507
        #define GL_LESS 0x0201
        #define GL_MULTISAMPLE 0x809D
        #define GL_FRAMEBUFFER_BINDING 0x8CA6
        #define GL_BACK 0x0405
        #define GL_ALWAYS 0x0207
        #define GL_FUNC_ADD 0x8006
        #define GL_ONE_MINUS_DST_COLOR 0x0307
        #define GL_NOTEQUAL 0x0205
        #define GL_DST_COLOR 0x0306
        #define GL_COMPILE_STATUS 0x8B81
        #define GL_RED 0x1903
        #define GL_COLOR_ATTACHMENT3 0x8CE3
        #define GL_DST_ALPHA 0x0304
        #define GL_RGB5_A1 0x8057
        #define GL_GREATER 0x0204
        #define GL_POLYGON_OFFSET_FILL 0x8037
        #define GL_TRUE 1
        #define GL_NEVER 0x0200
        #define GL_POINTS 0x0000
        #define GL_ONE_MINUS_SRC_COLOR 0x0301
        #define GL_MIRRORED_REPEAT 0x8370
        #define GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS 0x8B4D
        #define GL_R11F_G11F_B10F 0x8C3A
        #define GL_UNSIGNED_INT_10F_11F_11F_REV 0x8C3B
        #define GL_RGB9_E5 0x8C3D
        #define GL_UNSIGNED_INT_5_9_9_9_REV 0x8C3E
        #define GL_RGBA32UI 0x8D70
        #define GL_RGB32UI 0x8D71
        #define GL_RGBA16UI 0x8D76
        #define GL_RGB16UI 0x8D77
        #define GL_RGBA8UI 0x8D7C
        #define GL_RGB8UI 0x8D7D
        #define GL_RGBA32I 0x8D82
        #define GL_RGB32I 0x8D83
        #define GL_RGBA16I 0x8D88
        #define GL_RGB16I 0x8D89
        #define GL_RGBA8I 0x8D8E
        #define GL_RGB8I 0x8D8F
        #define GL_RED_INTEGER 0x8D94
        #define GL_RG 0x8227
        #define GL_RG_INTEGER 0x8228
        #define GL_R8 0x8229
        #define GL_R16 0x822A
        #define GL_RG8 0x822B
        #define GL_RG16 0x822C
        #define GL_R16F 0x822D
        #define GL_R32F 0x822E
        #define GL_RG16F 0x822F
        #define GL_RG32F 0x8230
        #define GL_R8I 0x8231
        #define GL_R8UI 0x8232
        #define GL_R16I 0x8233
        #define GL_R16UI 0x8234
        #define GL_R32I 0x8235
        #define GL_R32UI 0x8236
        #define GL_RG8I 0x8237
        #define GL_RG8UI 0x8238
        #define GL_RG16I 0x8239
        #define GL_RG16UI 0x823A
        #define GL_RG32I 0x823B
        #define GL_RG32UI 0x823C
        #define GL_RGBA_INTEGER 0x8D99
        #define GL_R8_SNORM 0x8F94
        #define GL_RG8_SNORM 0x8F95
        #define GL_RGB8_SNORM 0x8F96
        #define GL_RGBA8_SNORM 0x8F97
        #define GL_R16_SNORM 0x8F98
        #define GL_RG16_SNORM 0x8F99
        #define GL_RGB16_SNORM 0x8F9A
        #define GL_RGBA16_SNORM 0x8F9B
        #define GL_RGBA16 0x805B
        #define GL_MAX_TEXTURE_SIZE 0x0D33
        #define GL_MAX_CUBE_MAP_TEXTURE_SIZE 0x851C
        #define GL_MAX_3D_TEXTURE_SIZE 0x8073
        #define GL_MAX_ARRAY_TEXTURE_LAYERS 0x88FF
        #define GL_MAX_VERTEX_ATTRIBS 0x8869
        #define GL_CLAMP_TO_BORDER 0x812D
        #define GL_TEXTURE_BORDER_COLOR 0x1004
        #define GL_CURRENT_PROGRAM 0x8B8D
        #define GL_MAX_VERTEX_UNIFORM_COMPONENTS  0x8B4A
        #define GL_UNPACK_ALIGNMENT 0x0CF5
        #define GL_FRAMEBUFFER_SRGB 0x8DB9
        #define GL_TEXTURE_COMPARE_MODE 0x884C
        #define GL_TEXTURE_COMPARE_FUNC 0x884D
        #define GL_COMPARE_REF_TO_TEXTURE 0x884E
        #define GL_TEXTURE_CUBE_MAP_SEAMLESS 0x884F
        #define GL_TEXTURE_MAX_LEVEL 0x813D
        #define GL_FRAMEBUFFER_UNDEFINED 0x8219
        #define GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT 0x8CD6
        #define GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT 0x8CD7
        #define GL_FRAMEBUFFER_UNSUPPORTED 0x8CDD
        #define GL_FRAMEBUFFER_INCOMPLETE_MULTISAMPLE 0x8D56
        #define GL_MAJOR_VERSION 0x821B
        #define GL_MINOR_VERSION 0x821C
        #define GL_TEXTURE_2D_MULTISAMPLE 0x9100
        #define GL_TEXTURE_2D_MULTISAMPLE_ARRAY 0x9102
        #define GL_SHADER_STORAGE_BARRIER_BIT 0x2000
        #define GL_VERTEX_ATTRIB_ARRAY_BARRIER_BIT 0x00000001
        #define GL_ELEMENT_ARRAY_BARRIER_BIT 0x00000002
        #define GL_TEXTURE_FETCH_BARRIER_BIT 0x00000008
        #define GL_SHADER_IMAGE_ACCESS_BARRIER_BIT 0x00000020
        #define GL_MIN 0x8007
        #define GL_MAX 0x8008
        #define GL_WRITE_ONLY 0x88B9
        #define GL_READ_WRITE 0x88BA
    #endif

    #ifndef GL_UNSIGNED_INT_2_10_10_10_REV
    #define GL_UNSIGNED_INT_2_10_10_10_REV 0x8368
    #endif
    #ifndef GL_UNSIGNED_INT_24_8
    #define GL_UNSIGNED_INT_24_8 0x84FA
    #endif
    #ifndef GL_TEXTURE_MAX_ANISOTROPY_EXT
    #define GL_TEXTURE_MAX_ANISOTROPY_EXT 0x84FE
    #endif
    #ifndef GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT
    #define GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT 0x84FF
    #endif
    #ifndef GL_COMPRESSED_RGBA_S3TC_DXT1_EXT
    #define GL_COMPRESSED_RGBA_S3TC_DXT1_EXT 0x83F1
    #endif
    #ifndef GL_COMPRESSED_RGBA_S3TC_DXT3_EXT
    #define GL_COMPRESSED_RGBA_S3TC_DXT3_EXT 0x83F2
    #endif
    #ifndef GL_COMPRESSED_RGBA_S3TC_DXT5_EXT
    #define GL_COMPRESSED_RGBA_S3TC_DXT5_EXT 0x83F3
    #endif
    #ifndef GL_COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT
    #define GL_COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT 0x8C4F
    #endif
    #ifndef GL_COMPRESSED_RED_RGTC1
    #define GL_COMPRESSED_RED_RGTC1 0x8DBB
    #endif
    #ifndef GL_COMPRESSED_SIGNED_RED_RGTC1
    #define GL_COMPRESSED_SIGNED_RED_RGTC1 0x8DBC
    #endif
    #ifndef GL_COMPRESSED_RED_GREEN_RGTC2
    #define GL_COMPRESSED_RED_GREEN_RGTC2 0x8DBD
    #endif
    #ifndef GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2
    #define GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2 0x8DBE
    #endif
    #ifndef GL_COMPRESSED_RGBA_BPTC_UNORM_ARB
    #define GL_COMPRESSED_RGBA_BPTC_UNORM_ARB 0x8E8C
    #endif
    #ifndef GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB
    #define GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB 0x8E8D
    #endif
    #ifndef GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB
    #define GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB 0x8E8E
    #endif
    #ifndef GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB
    #define GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB 0x8E8F
    #endif
    #ifndef GL_COMPRESSED_RGB8_ETC2
    #define GL_COMPRESSED_RGB8_ETC2 0x9274
    #endif
    #ifndef GL_COMPRESSED_SRGB8_ETC2
    #define GL_COMPRESSED_SRGB8_ETC2 0x9275
    #endif
    #ifndef GL_COMPRESSED_RGBA8_ETC2_EAC
    #define GL_COMPRESSED_RGBA8_ETC2_EAC 0x9278
    #endif
    #ifndef GL_COMPRESSED_SRGB8_ALPHA8_ETC2_EAC
    #define GL_COMPRESSED_SRGB8_ALPHA8_ETC2_EAC 0x9279
    #endif
    #ifndef GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2
    #define GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2 0x9276
    #endif
    #ifndef GL_COMPRESSED_R11_EAC
    #define GL_COMPRESSED_R11_EAC 0x9270
    #endif
    #ifndef GL_COMPRESSED_SIGNED_R11_EAC
    #define GL_COMPRESSED_SIGNED_R11_EAC 0x9271
    #endif
    #ifndef GL_COMPRESSED_RG11_EAC
    #define GL_COMPRESSED_RG11_EAC 0x9272
    #endif
    #ifndef GL_COMPRESSED_SIGNED_RG11_EAC
    #define GL_COMPRESSED_SIGNED_RG11_EAC 0x9273
    #endif
    #ifndef GL_COMPRESSED_RGBA_ASTC_4x4_KHR
    #define GL_COMPRESSED_RGBA_ASTC_4x4_KHR 0x93B0
    #endif
    #ifndef GL_COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR
    #define GL_COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR 0x93D0
    #endif
    #ifndef GL_DEPTH24_STENCIL8
    #define GL_DEPTH24_STENCIL8 0x88F0
    #endif
    #ifndef GL_HALF_FLOAT
    #define GL_HALF_FLOAT 0x140B
    #endif
    #ifndef GL_DEPTH_STENCIL
    #define GL_DEPTH_STENCIL 0x84F9
    #endif
    #ifndef GL_LUMINANCE
    #define GL_LUMINANCE 0x1909
    #endif
    #ifndef GL_COMPUTE_SHADER
    #define GL_COMPUTE_SHADER 0x91B9
    #endif
    #ifndef _SG_GL_CHECK_ERROR
    #define _SG_GL_CHECK_ERROR() { SOKOL_ASSERT(glGetError() == GL_NO_ERROR); }
    #endif
#endif

#if defined(SOKOL_GLES3)
    // on WebGL2, GL_FRAMEBUFFER_UNDEFINED technically doesn't exist (it is defined
    // in the Emscripten headers, but may not exist in other WebGL2 shims)
    // see: https://github.com/floooh/sokol/pull/933
    #ifndef GL_FRAMEBUFFER_UNDEFINED
    #define GL_FRAMEBUFFER_UNDEFINED 0x8219
    #endif
#endif

// make some GL constants generally available to simplify compilation,
// use of those constants will be filtered by runtime flags
#ifndef GL_SHADER_STORAGE_BUFFER
#define GL_SHADER_STORAGE_BUFFER 0x90D2
#endif

// ███████ ████████ ██████  ██    ██  ██████ ████████ ███████
// ██         ██    ██   ██ ██    ██ ██         ██    ██
// ███████    ██    ██████  ██    ██ ██         ██    ███████
//      ██    ██    ██   ██ ██    ██ ██         ██         ██
// ███████    ██    ██   ██  ██████   ██████    ██    ███████
//
// >>structs
// resource pool slots
typedef struct {
    uint32_t id;
    sg_resource_state state;
} _sg_slot_t;

// resource pool housekeeping struct
typedef struct {
    int size;
    int queue_top;
    uint32_t* gen_ctrs;
    int* free_queue;
} _sg_pool_t;

_SOKOL_PRIVATE void _sg_pool_init(_sg_pool_t* pool, int num);
_SOKOL_PRIVATE void _sg_pool_discard(_sg_pool_t* pool);
_SOKOL_PRIVATE int _sg_pool_alloc_index(_sg_pool_t* pool);
_SOKOL_PRIVATE void _sg_pool_free_index(_sg_pool_t* pool, int slot_index);
_SOKOL_PRIVATE void _sg_slot_reset(_sg_slot_t* slot);
_SOKOL_PRIVATE uint32_t _sg_slot_alloc(_sg_pool_t* pool, _sg_slot_t* slot, int slot_index);
_SOKOL_PRIVATE int _sg_slot_index(uint32_t id);

// resource func forward decls
struct _sg_pools_s;
struct _sg_buffer_s;
_SOKOL_PRIVATE struct _sg_buffer_s* _sg_lookup_buffer(const struct _sg_pools_s* p, uint32_t buf_id);

// resource tracking (for keeping track of gpu-written storage resources
typedef struct {
    uint32_t size;
    uint32_t cur;
    uint32_t* items;
} _sg_tracker_t;

_SOKOL_PRIVATE void _sg_tracker_init(_sg_tracker_t* tracker, uint32_t num);
_SOKOL_PRIVATE void _sg_tracker_discard(_sg_tracker_t* tracker);
_SOKOL_PRIVATE void _sg_tracker_reset(_sg_tracker_t* tracker);
_SOKOL_PRIVATE bool _sg_tracker_add(_sg_tracker_t* tracker, uint32_t res_id);

// constants
enum {
    _SG_STRING_SIZE = 32,
    _SG_SLOT_SHIFT = 16,
    _SG_SLOT_MASK = (1<<_SG_SLOT_SHIFT)-1,
    _SG_MAX_POOL_SIZE = (1<<_SG_SLOT_SHIFT),
    _SG_DEFAULT_BUFFER_POOL_SIZE = 128,
    _SG_DEFAULT_IMAGE_POOL_SIZE = 128,
    _SG_DEFAULT_SAMPLER_POOL_SIZE = 64,
    _SG_DEFAULT_SHADER_POOL_SIZE = 32,
    _SG_DEFAULT_PIPELINE_POOL_SIZE = 64,
    _SG_DEFAULT_ATTACHMENTS_POOL_SIZE = 16,
    _SG_DEFAULT_UB_SIZE = 4 * 1024 * 1024,
    _SG_DEFAULT_MAX_DISPATCH_CALLS_PER_PASS = 1024,
    _SG_DEFAULT_MAX_COMMIT_LISTENERS = 1024,
    _SG_DEFAULT_WGPU_BINDGROUP_CACHE_SIZE = 1024,
};

// fixed-size string
typedef struct {
    char buf[_SG_STRING_SIZE];
} _sg_str_t;

// helper macros
#define _sg_def(val, def) (((val) == 0) ? (def) : (val))
#define _sg_def_flt(val, def) (((val) == 0.0f) ? (def) : (val))
#define _sg_min(a,b) (((a)<(b))?(a):(b))
#define _sg_max(a,b) (((a)>(b))?(a):(b))
#define _sg_clamp(v,v0,v1) (((v)<(v0))?(v0):(((v)>(v1))?(v1):(v)))
#define _sg_fequal(val,cmp,delta) ((((val)-(cmp))> -(delta))&&(((val)-(cmp))<(delta)))
#define _sg_ispow2(val) ((val&(val-1))==0)
#define _sg_stats_add(key,val) {if(_sg.stats_enabled){ _sg.stats.key+=val;}}

_SOKOL_PRIVATE void* _sg_malloc_clear(size_t size);
_SOKOL_PRIVATE void _sg_free(void* ptr);
_SOKOL_PRIVATE void _sg_clear(void* ptr, size_t size);

typedef struct {
    int size;
    int append_pos;
    bool append_overflow;
    uint32_t update_frame_index;
    uint32_t append_frame_index;
    int num_slots;
    int active_slot;
    sg_buffer_usage usage;
} _sg_buffer_common_t;

_SOKOL_PRIVATE void _sg_buffer_common_init(_sg_buffer_common_t* cmn, const sg_buffer_desc* desc) {
    cmn->size = (int)desc->size;
    cmn->append_pos = 0;
    cmn->append_overflow = false;
    cmn->update_frame_index = 0;
    cmn->append_frame_index = 0;
    cmn->num_slots = desc->usage.immutable ? 1 : SG_NUM_INFLIGHT_FRAMES;
    cmn->active_slot = 0;
    cmn->usage = desc->usage;
}

typedef struct {
    uint32_t upd_frame_index;
    int num_slots;
    int active_slot;
    sg_image_type type;
    int width;
    int height;
    int num_slices;
    int num_mipmaps;
    sg_image_usage usage;
    sg_pixel_format pixel_format;
    int sample_count;
} _sg_image_common_t;

_SOKOL_PRIVATE void _sg_image_common_init(_sg_image_common_t* cmn, const sg_image_desc* desc) {
    cmn->upd_frame_index = 0;
    cmn->num_slots = desc->usage.immutable ? 1 : SG_NUM_INFLIGHT_FRAMES;
    cmn->active_slot = 0;
    cmn->type = desc->type;
    cmn->width = desc->width;
    cmn->height = desc->height;
    cmn->num_slices = desc->num_slices;
    cmn->num_mipmaps = desc->num_mipmaps;
    cmn->usage = desc->usage;
    cmn->pixel_format = desc->pixel_format;
    cmn->sample_count = desc->sample_count;
}

typedef struct {
    sg_filter min_filter;
    sg_filter mag_filter;
    sg_filter mipmap_filter;
    sg_wrap wrap_u;
    sg_wrap wrap_v;
    sg_wrap wrap_w;
    float min_lod;
    float max_lod;
    sg_border_color border_color;
    sg_compare_func compare;
    uint32_t max_anisotropy;
} _sg_sampler_common_t;

_SOKOL_PRIVATE void _sg_sampler_common_init(_sg_sampler_common_t* cmn, const sg_sampler_desc* desc) {
    cmn->min_filter = desc->min_filter;
    cmn->mag_filter = desc->mag_filter;
    cmn->mipmap_filter = desc->mipmap_filter;
    cmn->wrap_u = desc->wrap_u;
    cmn->wrap_v = desc->wrap_v;
    cmn->wrap_w = desc->wrap_w;
    cmn->min_lod = desc->min_lod;
    cmn->max_lod = desc->max_lod;
    cmn->border_color = desc->border_color;
    cmn->compare = desc->compare;
    cmn->max_anisotropy = desc->max_anisotropy;
}

typedef struct {
    sg_shader_attr_base_type base_type;
} _sg_shader_attr_t;

typedef struct {
    sg_shader_stage stage;
    uint32_t size;
} _sg_shader_uniform_block_t;

typedef struct {
    sg_shader_stage stage;
    bool readonly;
} _sg_shader_storage_buffer_t;

typedef struct {
    sg_shader_stage stage;
    sg_image_type image_type;
    sg_pixel_format access_format;
    bool writeonly;
} _sg_shader_storage_image_t;

typedef struct {
    sg_shader_stage stage;
    sg_image_type image_type;
    sg_image_sample_type sample_type;
    bool multisampled;
} _sg_shader_image_t;

typedef struct {
    sg_shader_stage stage;
    sg_sampler_type sampler_type;
} _sg_shader_sampler_t;

// combined image sampler mappings, only needed on GL
typedef struct {
    sg_shader_stage stage;
    uint8_t image_slot;
    uint8_t sampler_slot;
} _sg_shader_image_sampler_t;

typedef struct {
    uint32_t required_bindings_and_uniforms;
    bool is_compute;
    _sg_shader_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];
    _sg_shader_uniform_block_t uniform_blocks[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
    _sg_shader_storage_buffer_t storage_buffers[SG_MAX_STORAGEBUFFER_BINDSLOTS];
    _sg_shader_image_t images[SG_MAX_IMAGE_BINDSLOTS];
    _sg_shader_sampler_t samplers[SG_MAX_SAMPLER_BINDSLOTS];
    _sg_shader_image_sampler_t image_samplers[SG_MAX_IMAGE_SAMPLER_PAIRS];
    _sg_shader_storage_image_t storage_images[SG_MAX_STORAGE_ATTACHMENTS];
} _sg_shader_common_t;

_SOKOL_PRIVATE void _sg_shader_common_init(_sg_shader_common_t* cmn, const sg_shader_desc* desc) {
    cmn->is_compute = desc->compute_func.source || desc->compute_func.bytecode.ptr;
    for (size_t i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {
        cmn->attrs[i].base_type = desc->attrs[i].base_type;
    }
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        const sg_shader_uniform_block* src = &desc->uniform_blocks[i];
        _sg_shader_uniform_block_t* dst = &cmn->uniform_blocks[i];
        if (src->stage != SG_SHADERSTAGE_NONE) {
            cmn->required_bindings_and_uniforms |= (1 << i);
            dst->stage = src->stage;
            dst->size = src->size;
        }
    }
    const uint32_t required_bindings_flag = (1 << SG_MAX_UNIFORMBLOCK_BINDSLOTS);
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        const sg_shader_storage_buffer* src = &desc->storage_buffers[i];
        _sg_shader_storage_buffer_t* dst = &cmn->storage_buffers[i];
        if (src->stage != SG_SHADERSTAGE_NONE) {
            cmn->required_bindings_and_uniforms |= required_bindings_flag;
            dst->stage = src->stage;
            dst->readonly = src->readonly;
        }
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        const sg_shader_image* src = &desc->images[i];
        _sg_shader_image_t* dst = &cmn->images[i];
        if (src->stage != SG_SHADERSTAGE_NONE) {
            cmn->required_bindings_and_uniforms |= required_bindings_flag;
            dst->stage = src->stage;
            dst->image_type = src->image_type;
            dst->sample_type = src->sample_type;
            dst->multisampled = src->multisampled;
        }
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        const sg_shader_sampler* src = &desc->samplers[i];
        _sg_shader_sampler_t* dst = &cmn->samplers[i];
        if (src->stage != SG_SHADERSTAGE_NONE) {
            cmn->required_bindings_and_uniforms |= required_bindings_flag;
            dst->stage = src->stage;
            dst->sampler_type = src->sampler_type;
        }
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_SAMPLER_PAIRS; i++) {
        const sg_shader_image_sampler_pair* src = &desc->image_sampler_pairs[i];
        _sg_shader_image_sampler_t* dst = &cmn->image_samplers[i];
        if (src->stage != SG_SHADERSTAGE_NONE) {
            dst->stage = src->stage;
            SOKOL_ASSERT((src->image_slot >= 0) && (src->image_slot < SG_MAX_IMAGE_BINDSLOTS));
            SOKOL_ASSERT(desc->images[src->image_slot].stage == src->stage);
            dst->image_slot = src->image_slot;
            SOKOL_ASSERT((src->sampler_slot >= 0) && (src->sampler_slot < SG_MAX_SAMPLER_BINDSLOTS));
            SOKOL_ASSERT(desc->samplers[src->sampler_slot].stage == src->stage);
            dst->sampler_slot = src->sampler_slot;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const sg_shader_storage_image* src = &desc->storage_images[i];
        _sg_shader_storage_image_t* dst = &cmn->storage_images[i];
        if (src->stage != SG_SHADERSTAGE_NONE) {
            dst->stage = src->stage;
            dst->image_type = src->image_type;
            dst->access_format = src->access_format;
            dst->writeonly = src->writeonly;
        }
    }
}

typedef struct {
    bool vertex_buffer_layout_active[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    bool use_instanced_draw;
    bool is_compute;
    uint32_t required_bindings_and_uniforms;
    sg_shader shader_id;
    sg_vertex_layout_state layout;
    sg_depth_state depth;
    sg_stencil_state stencil;
    int color_count;
    sg_color_target_state colors[SG_MAX_COLOR_ATTACHMENTS];
    sg_primitive_type primitive_type;
    sg_index_type index_type;
    sg_cull_mode cull_mode;
    sg_face_winding face_winding;
    int sample_count;
    sg_color blend_color;
    bool alpha_to_coverage_enabled;
} _sg_pipeline_common_t;

_SOKOL_PRIVATE void _sg_pipeline_common_init(_sg_pipeline_common_t* cmn, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT((desc->color_count >= 0) && (desc->color_count <= SG_MAX_COLOR_ATTACHMENTS));

    // FIXME: most of this isn't needed for compute pipelines

    const uint32_t required_bindings_flag = (1 << SG_MAX_UNIFORMBLOCK_BINDSLOTS);
    for (int i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
        const sg_vertex_attr_state* a_state = &desc->layout.attrs[i];
        if (a_state->format != SG_VERTEXFORMAT_INVALID) {
            SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
            cmn->vertex_buffer_layout_active[a_state->buffer_index] = true;
            cmn->required_bindings_and_uniforms |= required_bindings_flag;
        }
    }
    cmn->is_compute = desc->compute;
    cmn->use_instanced_draw = false;
    cmn->shader_id = desc->shader;
    cmn->layout = desc->layout;
    cmn->depth = desc->depth;
    cmn->stencil = desc->stencil;
    cmn->color_count = desc->color_count;
    for (int i = 0; i < desc->color_count; i++) {
        cmn->colors[i] = desc->colors[i];
    }
    cmn->primitive_type = desc->primitive_type;
    cmn->index_type = desc->index_type;
    if (cmn->index_type != SG_INDEXTYPE_NONE) {
        cmn->required_bindings_and_uniforms |= required_bindings_flag;
    }
    cmn->cull_mode = desc->cull_mode;
    cmn->face_winding = desc->face_winding;
    cmn->sample_count = desc->sample_count;
    cmn->blend_color = desc->blend_color;
    cmn->alpha_to_coverage_enabled = desc->alpha_to_coverage_enabled;
}

typedef struct {
    sg_image image_id;
    int mip_level;
    int slice;
} _sg_attachment_common_t;

typedef struct {
    int width;
    int height;
    int num_colors;
    bool has_render_attachments;
    bool has_storage_attachments;
    _sg_attachment_common_t colors[SG_MAX_COLOR_ATTACHMENTS];
    _sg_attachment_common_t resolves[SG_MAX_COLOR_ATTACHMENTS];
    _sg_attachment_common_t depth_stencil;
    _sg_attachment_common_t storages[SG_MAX_STORAGE_ATTACHMENTS];
} _sg_attachments_common_t;

_SOKOL_PRIVATE void _sg_attachment_common_init(_sg_attachment_common_t* cmn, const sg_attachment_desc* desc) {
    cmn->image_id = desc->image;
    cmn->mip_level = desc->mip_level;
    cmn->slice = desc->slice;
}

_SOKOL_PRIVATE void _sg_attachments_common_init(_sg_attachments_common_t* cmn, const sg_attachments_desc* desc, int width, int height) {
    // NOTE: width/height will be 0 for storage image attachments
    cmn->width = width;
    cmn->height = height;
    for (size_t i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        if (desc->colors[i].image.id != SG_INVALID_ID) {
            cmn->num_colors++;
            _sg_attachment_common_init(&cmn->colors[i], &desc->colors[i]);
            _sg_attachment_common_init(&cmn->resolves[i], &desc->resolves[i]);
            cmn->has_render_attachments = true;
        }
    }
    if (desc->depth_stencil.image.id != SG_INVALID_ID) {
        _sg_attachment_common_init(&cmn->depth_stencil, &desc->depth_stencil);
        cmn->has_render_attachments = true;
    }
    // NOTE: storage attachment slots may be non-continuous,
    // so a 'num_storages' doesn't make sense
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (desc->storages[i].image.id != SG_INVALID_ID) {
            cmn->has_storage_attachments = true;
            _sg_attachment_common_init(&cmn->storages[i], &desc->storages[i]);
        }
    }
}

#if defined(SOKOL_DUMMY_BACKEND)
typedef struct _sg_buffer_s {
    _sg_slot_t slot;
    _sg_buffer_common_t cmn;
} _sg_dummy_buffer_t;
typedef _sg_dummy_buffer_t _sg_buffer_t;

typedef struct _sg_image_s {
    _sg_slot_t slot;
    _sg_image_common_t cmn;
} _sg_dummy_image_t;
typedef _sg_dummy_image_t _sg_image_t;

typedef struct _sg_sampler_s {
    _sg_slot_t slot;
    _sg_sampler_common_t cmn;
} _sg_dummy_sampler_t;
typedef _sg_dummy_sampler_t _sg_sampler_t;

typedef struct _sg_shader_s {
    _sg_slot_t slot;
    _sg_shader_common_t cmn;
} _sg_dummy_shader_t;
typedef _sg_dummy_shader_t _sg_shader_t;

typedef struct _sg_pipeline_s {
    _sg_slot_t slot;
    _sg_shader_t* shader;
    _sg_pipeline_common_t cmn;
} _sg_dummy_pipeline_t;
typedef _sg_dummy_pipeline_t _sg_pipeline_t;

typedef struct {
    _sg_image_t* image;
} _sg_dummy_attachment_t;

typedef struct _sg_attachments_s {
    _sg_slot_t slot;
    _sg_attachments_common_t cmn;
    struct {
        _sg_dummy_attachment_t colors[SG_MAX_COLOR_ATTACHMENTS];
        _sg_dummy_attachment_t resolves[SG_MAX_COLOR_ATTACHMENTS];
        _sg_dummy_attachment_t depth_stencil;
        _sg_dummy_attachment_t storages[SG_MAX_STORAGE_ATTACHMENTS];
    } dmy;
} _sg_dummy_attachments_t;
typedef _sg_dummy_attachments_t _sg_attachments_t;

#elif defined(_SOKOL_ANY_GL)

typedef enum {
    _SG_GL_GPUDIRTY_VERTEXBUFFER = (1<<0),
    _SG_GL_GPUDIRTY_INDEXBUFFER = (1<<1),
    _SG_GL_GPUDIRTY_STORAGEBUFFER = (1<<2),
    _SG_GL_GPUDIRTY_BUFFER_ALL = _SG_GL_GPUDIRTY_VERTEXBUFFER | _SG_GL_GPUDIRTY_INDEXBUFFER | _SG_GL_GPUDIRTY_STORAGEBUFFER,
} _sg_gl_gpudirty_t;

typedef struct _sg_buffer_s {
    _sg_slot_t slot;
    _sg_buffer_common_t cmn;
    struct {
        GLuint buf[SG_NUM_INFLIGHT_FRAMES];
        bool injected;  // if true, external buffers were injected with sg_buffer_desc.gl_buffers
        uint8_t gpu_dirty_flags; // combination of _sg_gl_gpudirty_t flags
    } gl;
} _sg_gl_buffer_t;
typedef _sg_gl_buffer_t _sg_buffer_t;

typedef struct _sg_image_s {
    _sg_slot_t slot;
    _sg_image_common_t cmn;
    struct {
        GLenum target;
        GLuint msaa_render_buffer;
        GLuint tex[SG_NUM_INFLIGHT_FRAMES];
        bool injected;  // if true, external textures were injected with sg_image_desc.gl_textures
    } gl;
} _sg_gl_image_t;
typedef _sg_gl_image_t _sg_image_t;

typedef struct _sg_sampler_s {
    _sg_slot_t slot;
    _sg_sampler_common_t cmn;
    struct {
        GLuint smp;
        bool injected;  // true if external sampler was injects in sg_sampler_desc.gl_sampler
    } gl;
} _sg_gl_sampler_t;
typedef _sg_gl_sampler_t _sg_sampler_t;

typedef struct {
    GLint gl_loc;
    sg_uniform_type type;
    uint16_t count;
    uint16_t offset;
} _sg_gl_uniform_t;

typedef struct {
    int num_uniforms;
    _sg_gl_uniform_t uniforms[SG_MAX_UNIFORMBLOCK_MEMBERS];
} _sg_gl_uniform_block_t;

typedef struct {
    _sg_str_t name;
} _sg_gl_shader_attr_t;

typedef struct _sg_shader_s {
    _sg_slot_t slot;
    _sg_shader_common_t cmn;
    struct {
        GLuint prog;
        _sg_gl_shader_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];
        _sg_gl_uniform_block_t uniform_blocks[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
        uint8_t sbuf_binding[SG_MAX_STORAGEBUFFER_BINDSLOTS];
        uint8_t simg_binding[SG_MAX_STORAGE_ATTACHMENTS];
        int8_t tex_slot[SG_MAX_IMAGE_SAMPLER_PAIRS]; // GL texture unit index
    } gl;
} _sg_gl_shader_t;
typedef _sg_gl_shader_t _sg_shader_t;

typedef struct {
    int8_t vb_index;        // -1 if attr is not enabled
    int8_t divisor;         // -1 if not initialized
    uint8_t stride;
    uint8_t size;
    uint8_t normalized;
    int offset;
    GLenum type;
    sg_shader_attr_base_type base_type;
} _sg_gl_attr_t;

typedef struct _sg_pipeline_s {
    _sg_slot_t slot;
    _sg_pipeline_common_t cmn;
    _sg_shader_t* shader;
    struct {
        _sg_gl_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];
        sg_depth_state depth;
        sg_stencil_state stencil;
        sg_primitive_type primitive_type;
        sg_blend_state blend;
        sg_color_mask color_write_mask[SG_MAX_COLOR_ATTACHMENTS];
        sg_cull_mode cull_mode;
        sg_face_winding face_winding;
        int sample_count;
        bool alpha_to_coverage_enabled;
    } gl;
} _sg_gl_pipeline_t;
typedef _sg_gl_pipeline_t _sg_pipeline_t;

typedef struct {
    _sg_image_t* image;
} _sg_gl_attachment_t;

typedef struct _sg_attachments_s {
    _sg_slot_t slot;
    _sg_attachments_common_t cmn;
    struct {
        GLuint fb;
        _sg_gl_attachment_t colors[SG_MAX_COLOR_ATTACHMENTS];
        _sg_gl_attachment_t resolves[SG_MAX_COLOR_ATTACHMENTS];
        _sg_gl_attachment_t depth_stencil;
        _sg_gl_attachment_t storages[SG_MAX_STORAGE_ATTACHMENTS];
        GLuint msaa_resolve_framebuffer[SG_MAX_COLOR_ATTACHMENTS];
    } gl;
} _sg_gl_attachments_t;
typedef _sg_gl_attachments_t _sg_attachments_t;

typedef struct {
    _sg_gl_attr_t gl_attr;
    GLuint gl_vbuf;
} _sg_gl_cache_attr_t;

typedef struct {
    GLenum target;
    GLuint texture;
    GLuint sampler;
} _sg_gl_cache_texture_sampler_bind_slot;

#define _SG_GL_MAX_SBUF_BINDINGS (SG_MAX_STORAGEBUFFER_BINDSLOTS)
#define _SG_GL_MAX_SIMG_BINDINGS (SG_MAX_STORAGE_ATTACHMENTS)
#define _SG_GL_MAX_IMG_SMP_BINDINGS (SG_MAX_IMAGE_SAMPLER_PAIRS)
typedef struct {
    sg_depth_state depth;
    sg_stencil_state stencil;
    sg_blend_state blend;
    sg_color_mask color_write_mask[SG_MAX_COLOR_ATTACHMENTS];
    sg_cull_mode cull_mode;
    sg_face_winding face_winding;
    bool polygon_offset_enabled;
    int sample_count;
    sg_color blend_color;
    bool alpha_to_coverage_enabled;
    _sg_gl_cache_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];
    GLuint vertex_buffer;
    GLuint index_buffer;
    GLuint storage_buffer;  // general bind point
    GLuint storage_buffers[_SG_GL_MAX_SBUF_BINDINGS];
    GLuint stored_vertex_buffer;
    GLuint stored_index_buffer;
    GLuint stored_storage_buffer;
    GLuint prog;
    _sg_gl_cache_texture_sampler_bind_slot texture_samplers[_SG_GL_MAX_IMG_SMP_BINDINGS];
    _sg_gl_cache_texture_sampler_bind_slot stored_texture_sampler;
    int cur_ib_offset;
    GLenum cur_primitive_type;
    GLenum cur_index_type;
    GLenum cur_active_texture;
    _sg_pipeline_t* cur_pipeline;
    sg_pipeline cur_pipeline_id;
} _sg_gl_state_cache_t;

typedef struct {
    bool valid;
    GLuint vao;
    _sg_gl_state_cache_t cache;
    bool ext_anisotropic;
    GLint max_anisotropy;
    sg_store_action color_store_actions[SG_MAX_COLOR_ATTACHMENTS];
    sg_store_action depth_store_action;
    sg_store_action stencil_store_action;
    #if _SOKOL_USE_WIN32_GL_LOADER
    HINSTANCE opengl32_dll;
    #endif
} _sg_gl_backend_t;

#elif defined(SOKOL_D3D11)

typedef struct _sg_buffer_s {
    _sg_slot_t slot;
    _sg_buffer_common_t cmn;
    struct {
        ID3D11Buffer* buf;
        ID3D11ShaderResourceView* srv;
        ID3D11UnorderedAccessView* uav;
    } d3d11;
} _sg_d3d11_buffer_t;
typedef _sg_d3d11_buffer_t _sg_buffer_t;

typedef struct _sg_image_s {
    _sg_slot_t slot;
    _sg_image_common_t cmn;
    struct {
        DXGI_FORMAT format;
        ID3D11Texture2D* tex2d;
        ID3D11Texture3D* tex3d;
        ID3D11Resource* res;    // either tex2d or tex3d
        ID3D11ShaderResourceView* srv;
    } d3d11;
} _sg_d3d11_image_t;
typedef _sg_d3d11_image_t _sg_image_t;

typedef struct _sg_sampler_s {
    _sg_slot_t slot;
    _sg_sampler_common_t cmn;
    struct {
        ID3D11SamplerState* smp;
    } d3d11;
} _sg_d3d11_sampler_t;
typedef _sg_d3d11_sampler_t _sg_sampler_t;

typedef struct {
    _sg_str_t sem_name;
    int sem_index;
} _sg_d3d11_shader_attr_t;

#define _SG_D3D11_MAX_STAGE_UB_BINDINGS (SG_MAX_UNIFORMBLOCK_BINDSLOTS)
#define _SG_D3D11_MAX_STAGE_SRV_BINDINGS (SG_MAX_IMAGE_BINDSLOTS + SG_MAX_STORAGEBUFFER_BINDSLOTS)
#define _SG_D3D11_MAX_STAGE_UAV_BINDINGS (SG_MAX_STORAGEBUFFER_BINDSLOTS + SG_MAX_STORAGE_ATTACHMENTS)
#define _SG_D3D11_MAX_STAGE_SMP_BINDINGS (SG_MAX_SAMPLER_BINDSLOTS)

typedef struct _sg_shader_s {
    _sg_slot_t slot;
    _sg_shader_common_t cmn;
    struct {
        _sg_d3d11_shader_attr_t attrs[SG_MAX_VERTEX_ATTRIBUTES];
        ID3D11VertexShader* vs;
        ID3D11PixelShader* fs;
        ID3D11ComputeShader* cs;
        void* vs_blob;
        size_t vs_blob_length;
        uint8_t ub_register_b_n[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
        uint8_t img_register_t_n[SG_MAX_IMAGE_BINDSLOTS];
        uint8_t smp_register_s_n[SG_MAX_SAMPLER_BINDSLOTS];
        uint8_t sbuf_register_t_n[SG_MAX_STORAGEBUFFER_BINDSLOTS];
        uint8_t sbuf_register_u_n[SG_MAX_STORAGEBUFFER_BINDSLOTS];
        uint8_t simg_register_u_n[SG_MAX_STORAGE_ATTACHMENTS];
        ID3D11Buffer* all_cbufs[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
        ID3D11Buffer* vs_cbufs[_SG_D3D11_MAX_STAGE_UB_BINDINGS];
        ID3D11Buffer* fs_cbufs[_SG_D3D11_MAX_STAGE_UB_BINDINGS];
        ID3D11Buffer* cs_cbufs[_SG_D3D11_MAX_STAGE_UB_BINDINGS];
    } d3d11;
} _sg_d3d11_shader_t;
typedef _sg_d3d11_shader_t _sg_shader_t;

typedef struct _sg_pipeline_s {
    _sg_slot_t slot;
    _sg_pipeline_common_t cmn;
    _sg_shader_t* shader;
    struct {
        UINT stencil_ref;
        UINT vb_strides[SG_MAX_VERTEXBUFFER_BINDSLOTS];
        D3D_PRIMITIVE_TOPOLOGY topology;
        DXGI_FORMAT index_format;
        ID3D11InputLayout* il;
        ID3D11RasterizerState* rs;
        ID3D11DepthStencilState* dss;
        ID3D11BlendState* bs;
    } d3d11;
} _sg_d3d11_pipeline_t;
typedef _sg_d3d11_pipeline_t _sg_pipeline_t;

typedef struct {
    _sg_image_t* image;
    union {
        ID3D11RenderTargetView* rtv;
        ID3D11DepthStencilView* dsv;
        ID3D11UnorderedAccessView* uav;
    } view;
} _sg_d3d11_attachment_t;

typedef struct _sg_attachments_s {
    _sg_slot_t slot;
    _sg_attachments_common_t cmn;
    struct {
        _sg_d3d11_attachment_t colors[SG_MAX_COLOR_ATTACHMENTS];
        _sg_d3d11_attachment_t resolves[SG_MAX_COLOR_ATTACHMENTS];
        _sg_d3d11_attachment_t depth_stencil;
        _sg_d3d11_attachment_t storages[SG_MAX_STORAGE_ATTACHMENTS];
    } d3d11;
} _sg_d3d11_attachments_t;
typedef _sg_d3d11_attachments_t _sg_attachments_t;

typedef struct {
    bool valid;
    ID3D11Device* dev;
    ID3D11DeviceContext* ctx;
    bool use_indexed_draw;
    bool use_instanced_draw;
    _sg_pipeline_t* cur_pipeline;
    sg_pipeline cur_pipeline_id;
    struct {
        ID3D11RenderTargetView* render_view;
        ID3D11RenderTargetView* resolve_view;
    } cur_pass;
    // on-demand loaded d3dcompiler_47.dll handles
    HINSTANCE d3dcompiler_dll;
    bool d3dcompiler_dll_load_failed;
    pD3DCompile D3DCompile_func;
    // global subresourcedata array for texture updates
    D3D11_SUBRESOURCE_DATA subres_data[SG_MAX_MIPMAPS * SG_MAX_TEXTUREARRAY_LAYERS];
} _sg_d3d11_backend_t;

#elif defined(SOKOL_METAL)

#if defined(_SG_TARGET_MACOS) || defined(_SG_TARGET_IOS_SIMULATOR)
#define _SG_MTL_UB_ALIGN (256)
#else
#define _SG_MTL_UB_ALIGN (16)
#endif
#define _SG_MTL_INVALID_SLOT_INDEX (0)

typedef struct {
    uint32_t frame_index;   // frame index at which it is safe to release this resource
    int slot_index;
} _sg_mtl_release_item_t;

typedef struct {
    NSMutableArray* pool;
    int num_slots;
    int free_queue_top;
    int* free_queue;
    int release_queue_front;
    int release_queue_back;
    _sg_mtl_release_item_t* release_queue;
} _sg_mtl_idpool_t;

typedef struct _sg_buffer_s {
    _sg_slot_t slot;
    _sg_buffer_common_t cmn;
    struct {
        int buf[SG_NUM_INFLIGHT_FRAMES];  // index into _sg_mtl_pool
    } mtl;
} _sg_mtl_buffer_t;
typedef _sg_mtl_buffer_t _sg_buffer_t;

typedef struct _sg_image_s {
    _sg_slot_t slot;
    _sg_image_common_t cmn;
    struct {
        int tex[SG_NUM_INFLIGHT_FRAMES];
    } mtl;
} _sg_mtl_image_t;
typedef _sg_mtl_image_t _sg_image_t;

typedef struct _sg_sampler_s {
    _sg_slot_t slot;
    _sg_sampler_common_t cmn;
    struct {
        int sampler_state;
    } mtl;
} _sg_mtl_sampler_t;
typedef _sg_mtl_sampler_t _sg_sampler_t;

typedef struct {
    int mtl_lib;
    int mtl_func;
} _sg_mtl_shader_func_t;

typedef struct _sg_shader_s {
    _sg_slot_t slot;
    _sg_shader_common_t cmn;
    struct {
        _sg_mtl_shader_func_t vertex_func;
        _sg_mtl_shader_func_t fragment_func;
        _sg_mtl_shader_func_t compute_func;
        MTLSize threads_per_threadgroup;
        uint8_t ub_buffer_n[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
        uint8_t img_texture_n[SG_MAX_IMAGE_BINDSLOTS];
        uint8_t smp_sampler_n[SG_MAX_SAMPLER_BINDSLOTS];
        uint8_t sbuf_buffer_n[SG_MAX_STORAGEBUFFER_BINDSLOTS];
        uint8_t simg_texture_n[SG_MAX_STORAGE_ATTACHMENTS];
    } mtl;
} _sg_mtl_shader_t;
typedef _sg_mtl_shader_t _sg_shader_t;

typedef struct _sg_pipeline_s {
    _sg_slot_t slot;
    _sg_pipeline_common_t cmn;
    _sg_shader_t* shader;
    struct {
        MTLPrimitiveType prim_type;
        int index_size;
        MTLIndexType index_type;
        MTLCullMode cull_mode;
        MTLWinding winding;
        uint32_t stencil_ref;
        MTLSize threads_per_threadgroup;
        int cps;    // MTLComputePipelineState
        int rps;    // MTLRenderPipelineState
        int dss;    // MTLDepthStencilState
    } mtl;
} _sg_mtl_pipeline_t;
typedef _sg_mtl_pipeline_t _sg_pipeline_t;

typedef struct {
    _sg_image_t* image;
} _sg_mtl_attachment_t;

typedef struct _sg_attachments_s {
    _sg_slot_t slot;
    _sg_attachments_common_t cmn;
    struct {
        _sg_mtl_attachment_t colors[SG_MAX_COLOR_ATTACHMENTS];
        _sg_mtl_attachment_t resolves[SG_MAX_COLOR_ATTACHMENTS];
        _sg_mtl_attachment_t depth_stencil;
        _sg_mtl_attachment_t storages[SG_MAX_STORAGE_ATTACHMENTS];
        int storage_views[SG_MAX_STORAGE_ATTACHMENTS];
    } mtl;
} _sg_mtl_attachments_t;
typedef _sg_mtl_attachments_t _sg_attachments_t;

// resource binding state cache
#define _SG_MTL_MAX_STAGE_UB_BINDINGS (SG_MAX_UNIFORMBLOCK_BINDSLOTS)
#define _SG_MTL_MAX_STAGE_UB_SBUF_BINDINGS (_SG_MTL_MAX_STAGE_UB_BINDINGS + SG_MAX_STORAGEBUFFER_BINDSLOTS)
#define _SG_MTL_MAX_STAGE_BUFFER_BINDINGS (_SG_MTL_MAX_STAGE_UB_SBUF_BINDINGS + SG_MAX_VERTEXBUFFER_BINDSLOTS)
#define _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS (SG_MAX_IMAGE_BINDSLOTS + SG_MAX_STORAGE_ATTACHMENTS)
#define _SG_MTL_MAX_STAGE_SAMPLER_BINDINGS (SG_MAX_SAMPLER_BINDSLOTS)
typedef struct {
    const _sg_pipeline_t* cur_pipeline;
    sg_pipeline cur_pipeline_id;
    const _sg_buffer_t* cur_indexbuffer;
    sg_buffer cur_indexbuffer_id;
    int cur_indexbuffer_offset;
    int cur_vs_buffer_offsets[_SG_MTL_MAX_STAGE_BUFFER_BINDINGS];
    uint32_t cur_vs_buffer_ids[_SG_MTL_MAX_STAGE_BUFFER_BINDINGS];
    uint32_t cur_fs_buffer_ids[_SG_MTL_MAX_STAGE_BUFFER_BINDINGS];
    uint32_t cur_cs_buffer_ids[_SG_MTL_MAX_STAGE_BUFFER_BINDINGS];
    uint32_t cur_vs_image_ids[_SG_MTL_MAX_STAGE_TEXTURE_BINDINGS];
    uint32_t cur_fs_image_ids[_SG_MTL_MAX_STAGE_TEXTURE_BINDINGS];
    uint32_t cur_vs_sampler_ids[_SG_MTL_MAX_STAGE_SAMPLER_BINDINGS];
    uint32_t cur_fs_sampler_ids[_SG_MTL_MAX_STAGE_SAMPLER_BINDINGS];
    uint32_t cur_cs_sampler_ids[_SG_MTL_MAX_STAGE_SAMPLER_BINDINGS];
    // NOTE: special case: uint64_t for storage images, because we need
    // to differentiate between storage pass attachments and regular
    // textures bound to compute stages (but both binding types live
    // in the texture bind space in Metal)
    uint64_t cur_cs_image_ids[_SG_MTL_MAX_STAGE_TEXTURE_BINDINGS];
} _sg_mtl_state_cache_t;

typedef struct {
    bool valid;
    bool use_shared_storage_mode;
    uint32_t cur_frame_rotate_index;
    int ub_size;
    int cur_ub_offset;
    uint8_t* cur_ub_base_ptr;
    _sg_mtl_state_cache_t state_cache;
    _sg_mtl_idpool_t idpool;
    dispatch_semaphore_t sem;
    id<MTLDevice> device;
    id<MTLCommandQueue> cmd_queue;
    id<MTLCommandBuffer> cmd_buffer;
    id<MTLRenderCommandEncoder> render_cmd_encoder;
    id<MTLComputeCommandEncoder> compute_cmd_encoder;
    id<CAMetalDrawable> cur_drawable;
    id<MTLBuffer> uniform_buffers[SG_NUM_INFLIGHT_FRAMES];
} _sg_mtl_backend_t;

#elif defined(SOKOL_WGPU)

#define _SG_WGPU_ROWPITCH_ALIGN (256)
#define _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE (1<<16) // also see WGPULimits.maxUniformBufferBindingSize
#define _SG_WGPU_MAX_BINDGROUPS (3) // 0: uniforms, 1: images, samplers, storage buffers, 2: storage images (only in compute passes)
#define _SG_WGPU_UB_BINDGROUP_INDEX (0)
#define _SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX (1)
#define _SG_WGPU_SIMG_BINDGROUP_INDEX (2)
#define _SG_WGPU_MAX_UB_BINDGROUP_ENTRIES (SG_MAX_UNIFORMBLOCK_BINDSLOTS)
#define _SG_WGPU_MAX_UB_BINDGROUP_BIND_SLOTS (2 * SG_MAX_UNIFORMBLOCK_BINDSLOTS)
#define _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES (SG_MAX_IMAGE_BINDSLOTS + SG_MAX_SAMPLER_BINDSLOTS + SG_MAX_STORAGEBUFFER_BINDSLOTS)
#define _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS (128)
#define _SG_WGPU_MAX_SIMG_BIND_SLOTS (SG_MAX_STORAGE_ATTACHMENTS)
#define _SG_WGPU_MAX_SIMG_BINDGROUP_ENTRIES (SG_MAX_STORAGE_ATTACHMENTS)

typedef struct _sg_buffer_s {
    _sg_slot_t slot;
    _sg_buffer_common_t cmn;
    struct {
        WGPUBuffer buf;
    } wgpu;
} _sg_wgpu_buffer_t;
typedef _sg_wgpu_buffer_t _sg_buffer_t;

typedef struct _sg_image_s {
    _sg_slot_t slot;
    _sg_image_common_t cmn;
    struct {
        WGPUTexture tex;
        WGPUTextureView view;
    } wgpu;
} _sg_wgpu_image_t;
typedef _sg_wgpu_image_t _sg_image_t;

typedef struct _sg_sampler_s {
    _sg_slot_t slot;
    _sg_sampler_common_t cmn;
    struct {
        WGPUSampler smp;
    } wgpu;
} _sg_wgpu_sampler_t;
typedef _sg_wgpu_sampler_t _sg_sampler_t;

typedef struct {
    WGPUShaderModule module;
    _sg_str_t entry;
} _sg_wgpu_shader_func_t;

typedef struct _sg_shader_s {
    _sg_slot_t slot;
    _sg_shader_common_t cmn;
    struct {
        _sg_wgpu_shader_func_t vertex_func;
        _sg_wgpu_shader_func_t fragment_func;
        _sg_wgpu_shader_func_t compute_func;
        WGPUBindGroupLayout bgl_ub;
        WGPUBindGroup bg_ub;
        WGPUBindGroupLayout bgl_img_smp_sbuf;
        WGPUBindGroupLayout bgl_simg;
        // a mapping of sokol-gfx bind slots to setBindGroup dynamic-offset-array indices
        uint8_t ub_num_dynoffsets;
        uint8_t ub_dynoffsets[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
        // indexed by sokol-gfx bind slot:
        uint8_t ub_grp0_bnd_n[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
        uint8_t img_grp1_bnd_n[SG_MAX_IMAGE_BINDSLOTS];
        uint8_t smp_grp1_bnd_n[SG_MAX_SAMPLER_BINDSLOTS];
        uint8_t sbuf_grp1_bnd_n[SG_MAX_STORAGEBUFFER_BINDSLOTS];
        uint8_t simg_grp2_bnd_n[SG_MAX_STORAGE_ATTACHMENTS];
    } wgpu;
} _sg_wgpu_shader_t;
typedef _sg_wgpu_shader_t _sg_shader_t;

typedef struct _sg_pipeline_s {
    _sg_slot_t slot;
    _sg_pipeline_common_t cmn;
    _sg_shader_t* shader;
    struct {
        WGPURenderPipeline rpip;
        WGPUComputePipeline cpip;
        WGPUColor blend_color;
    } wgpu;
} _sg_wgpu_pipeline_t;
typedef _sg_wgpu_pipeline_t _sg_pipeline_t;

typedef struct {
    _sg_image_t* image;
    WGPUTextureView view;
} _sg_wgpu_attachment_t;

typedef struct _sg_attachments_s {
    _sg_slot_t slot;
    _sg_attachments_common_t cmn;
    struct {
        _sg_wgpu_attachment_t colors[SG_MAX_COLOR_ATTACHMENTS];
        _sg_wgpu_attachment_t resolves[SG_MAX_COLOR_ATTACHMENTS];
        _sg_wgpu_attachment_t depth_stencil;
        _sg_wgpu_attachment_t storages[SG_MAX_STORAGE_ATTACHMENTS];
    } wgpu;
} _sg_wgpu_attachments_t;
typedef _sg_wgpu_attachments_t _sg_attachments_t;

// a pool of per-frame uniform buffers
typedef struct {
    uint32_t num_bytes;
    uint32_t offset;    // current offset into buf
    uint8_t* staging;   // intermediate buffer for uniform data updates
    WGPUBuffer buf;     // the GPU-side uniform buffer
    uint32_t bind_offsets[SG_MAX_UNIFORMBLOCK_BINDSLOTS];   // NOTE: index is sokol-gfx ub slot index!
} _sg_wgpu_uniform_buffer_t;

typedef struct {
    uint32_t id;
} _sg_wgpu_bindgroup_handle_t;

typedef enum {
    _SG_WGPU_BINDGROUPSCACHEITEMTYPE_NONE           = 0,
    _SG_WGPU_BINDGROUPSCACHEITEMTYPE_IMAGE          = 0x00001111,
    _SG_WGPU_BINDGROUPSCACHEITEMTYPE_SAMPLER        = 0x00002222,
    _SG_WGPU_BINDGROUPSCACHEITEMTYPE_STORAGEBUFFER  = 0x00003333,
    _SG_WGPU_BINDGROUPSCACHEITEMTYPE_PIPELINE       = 0x00004444,
} _sg_wgpu_bindgroups_cache_item_type_t;

#define _SG_WGPU_BINDGROUPSCACHEKEY_NUM_ITEMS (1 + _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES)
typedef struct {
    uint64_t hash;
    // the format of cache key items is BBBBTTTTIIIIIIII
    // where
    //  - BBBB is 2x the WGPU binding
    //  - TTTT is the _sg_wgpu_bindgroups_cache_item_type_t
    //  - IIIIIIII is the resource id
    //
    // where the item type is a per-resource-type bit pattern
    uint64_t items[_SG_WGPU_BINDGROUPSCACHEKEY_NUM_ITEMS];
} _sg_wgpu_bindgroups_cache_key_t;

typedef struct {
    uint32_t num;           // must be 2^n
    uint32_t index_mask;    // mask to turn hash into valid index
    _sg_wgpu_bindgroup_handle_t* items;
} _sg_wgpu_bindgroups_cache_t;

typedef struct {
    _sg_slot_t slot;
    WGPUBindGroup bindgroup;
    _sg_wgpu_bindgroups_cache_key_t key;
} _sg_wgpu_bindgroup_t;

typedef struct {
    _sg_pool_t pool;
    _sg_wgpu_bindgroup_t* bindgroups;
} _sg_wgpu_bindgroups_pool_t;

typedef struct {
    struct {
        sg_buffer buffer;
        uint64_t offset;
    } vbs[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    struct {
        sg_buffer buffer;
        uint64_t offset;
    } ib;
    _sg_wgpu_bindgroup_handle_t bg;
} _sg_wgpu_bindings_cache_t;

// the WGPU backend state
typedef struct {
    bool valid;
    bool use_indexed_draw;
    WGPUDevice dev;
    WGPUSupportedLimits limits;
    WGPUQueue queue;
    WGPUCommandEncoder cmd_enc;
    WGPURenderPassEncoder rpass_enc;
    WGPUComputePassEncoder cpass_enc;
    WGPUBindGroup empty_bind_group;
    const _sg_pipeline_t* cur_pipeline;
    sg_pipeline cur_pipeline_id;
    _sg_wgpu_uniform_buffer_t uniform;
    _sg_wgpu_bindings_cache_t bindings_cache;
    _sg_wgpu_bindgroups_cache_t bindgroups_cache;
    _sg_wgpu_bindgroups_pool_t bindgroups_pool;
} _sg_wgpu_backend_t;
#endif

// POOL STRUCTS

// this *MUST* remain 0
#define _SG_INVALID_SLOT_INDEX (0)

typedef struct _sg_pools_s {
    _sg_pool_t buffer_pool;
    _sg_pool_t image_pool;
    _sg_pool_t sampler_pool;
    _sg_pool_t shader_pool;
    _sg_pool_t pipeline_pool;
    _sg_pool_t attachments_pool;
    _sg_buffer_t* buffers;
    _sg_image_t* images;
    _sg_sampler_t* samplers;
    _sg_shader_t* shaders;
    _sg_pipeline_t* pipelines;
    _sg_attachments_t* attachments;
} _sg_pools_t;

typedef struct {
    int num;        // number of allocated commit listener items
    int upper;      // the current upper index (no valid items past this point)
    sg_commit_listener* items;
} _sg_commit_listeners_t;

// resolved pass attachments struct
typedef struct {
    _sg_image_t* color_images[SG_MAX_COLOR_ATTACHMENTS];
    _sg_image_t* resolve_images[SG_MAX_COLOR_ATTACHMENTS];
    _sg_image_t* ds_image;
    _sg_image_t* storage_images[SG_MAX_STORAGE_ATTACHMENTS];
} _sg_attachments_ptrs_t;

// resolved resource bindings struct
typedef struct {
    _sg_pipeline_t* pip;
    int vb_offsets[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    int ib_offset;
    _sg_buffer_t* vbs[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    _sg_buffer_t* ib;
    _sg_image_t* imgs[SG_MAX_IMAGE_BINDSLOTS];
    _sg_sampler_t* smps[SG_MAX_SAMPLER_BINDSLOTS];
    _sg_buffer_t* sbufs[SG_MAX_STORAGEBUFFER_BINDSLOTS];
    _sg_image_t* simgs[SG_MAX_STORAGE_ATTACHMENTS];
} _sg_bindings_ptrs_t;

typedef struct {
    bool sample;
    bool filter;
    bool render;
    bool blend;
    bool msaa;
    bool depth;
    bool read;
    bool write;
} _sg_pixelformat_info_t;

typedef struct {
    bool valid;
    sg_desc desc;       // original desc with default values patched in
    uint32_t frame_index;
    struct {
        bool valid;
        bool in_pass;
        bool is_compute;
        sg_attachments atts_id;     // SG_INVALID_ID in a swapchain pass
        _sg_attachments_t* atts;    // 0 in a swapchain pass
        int width;
        int height;
        struct {
            sg_pixel_format color_fmt;
            sg_pixel_format depth_fmt;
            int sample_count;
        } swapchain;
    } cur_pass;
    sg_pipeline cur_pipeline;
    bool next_draw_valid;
    uint32_t required_bindings_and_uniforms;    // used to check that bindings and uniforms are applied after applying pipeline
    uint32_t applied_bindings_and_uniforms;     // bits 0..7: uniform blocks, bit 8: bindings
    #if defined(SOKOL_DEBUG)
    sg_log_item validate_error;
    #endif
    struct {
        _sg_tracker_t readwrite_sbufs;  // tracks read/write storage buffers used in compute pass
    } compute;
    _sg_pools_t pools;
    sg_backend backend;
    sg_features features;
    sg_limits limits;
    _sg_pixelformat_info_t formats[_SG_PIXELFORMAT_NUM];
    bool stats_enabled;
    sg_frame_stats stats;
    sg_frame_stats prev_stats;
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_backend_t gl;
    #elif defined(SOKOL_METAL)
    _sg_mtl_backend_t mtl;
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_backend_t d3d11;
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_backend_t wgpu;
    #endif
    #if defined(SOKOL_TRACE_HOOKS)
    sg_trace_hooks hooks;
    #endif
    _sg_commit_listeners_t commit_listeners;
} _sg_state_t;
static _sg_state_t _sg;

// ██       ██████   ██████   ██████  ██ ███    ██  ██████
// ██      ██    ██ ██       ██       ██ ████   ██ ██
// ██      ██    ██ ██   ███ ██   ███ ██ ██ ██  ██ ██   ███
// ██      ██    ██ ██    ██ ██    ██ ██ ██  ██ ██ ██    ██
// ███████  ██████   ██████   ██████  ██ ██   ████  ██████
//
// >>logging
#if defined(SOKOL_DEBUG)
#define _SG_LOGITEM_XMACRO(item,msg) #item ": " msg,
static const char* _sg_log_messages[] = {
    _SG_LOG_ITEMS
};
#undef _SG_LOGITEM_XMACRO
#endif // SOKOL_DEBUG

#define _SG_PANIC(code) _sg_log(SG_LOGITEM_ ##code, 0, 0, __LINE__)
#define _SG_ERROR(code) _sg_log(SG_LOGITEM_ ##code, 1, 0, __LINE__)
#define _SG_WARN(code) _sg_log(SG_LOGITEM_ ##code, 2, 0, __LINE__)
#define _SG_INFO(code) _sg_log(SG_LOGITEM_ ##code, 3, 0, __LINE__)
#define _SG_LOGMSG(code,msg) _sg_log(SG_LOGITEM_ ##code, 3, msg, __LINE__)
#define _SG_VALIDATE(cond,code) if (!(cond)){ _sg.validate_error = SG_LOGITEM_ ##code; _sg_log(SG_LOGITEM_ ##code, 1, 0, __LINE__); }

static void _sg_log(sg_log_item log_item, uint32_t log_level, const char* msg, uint32_t line_nr) {
    if (_sg.desc.logger.func) {
        const char* filename = 0;
        #if defined(SOKOL_DEBUG)
            filename = __FILE__;
            if (0 == msg) {
                msg = _sg_log_messages[log_item];
            }
        #endif
        _sg.desc.logger.func("sg", log_level, (uint32_t)log_item, msg, line_nr, filename, _sg.desc.logger.user_data);
    } else {
        // for log level PANIC it would be 'undefined behaviour' to continue
        if (log_level == 0) {
            abort();
        }
    }
}

// ███    ███ ███████ ███    ███  ██████  ██████  ██    ██
// ████  ████ ██      ████  ████ ██    ██ ██   ██  ██  ██
// ██ ████ ██ █████   ██ ████ ██ ██    ██ ██████    ████
// ██  ██  ██ ██      ██  ██  ██ ██    ██ ██   ██    ██
// ██      ██ ███████ ██      ██  ██████  ██   ██    ██
//
// >>memory

// a helper macro to clear a struct with potentially ARC'ed ObjC references
#if defined(SOKOL_METAL)
    #if defined(__cplusplus)
        #define _SG_CLEAR_ARC_STRUCT(type, item) { item = type(); }
    #else
        #define _SG_CLEAR_ARC_STRUCT(type, item) { item = (type) { 0 }; }
    #endif
#else
    #define _SG_CLEAR_ARC_STRUCT(type, item) { _sg_clear(&item, sizeof(item)); }
#endif

_SOKOL_PRIVATE void _sg_clear(void* ptr, size_t size) {
    SOKOL_ASSERT(ptr && (size > 0));
    memset(ptr, 0, size);
}

_SOKOL_PRIVATE void* _sg_malloc(size_t size) {
    SOKOL_ASSERT(size > 0);
    void* ptr;
    if (_sg.desc.allocator.alloc_fn) {
        ptr = _sg.desc.allocator.alloc_fn(size, _sg.desc.allocator.user_data);
    } else {
        ptr = malloc(size);
    }
    if (0 == ptr) {
        _SG_PANIC(MALLOC_FAILED);
    }
    return ptr;
}

_SOKOL_PRIVATE void* _sg_malloc_clear(size_t size) {
    void* ptr = _sg_malloc(size);
    _sg_clear(ptr, size);
    return ptr;
}

_SOKOL_PRIVATE void _sg_free(void* ptr) {
    if (_sg.desc.allocator.free_fn) {
        _sg.desc.allocator.free_fn(ptr, _sg.desc.allocator.user_data);
    } else {
        free(ptr);
    }
}

_SOKOL_PRIVATE bool _sg_strempty(const _sg_str_t* str) {
    return 0 == str->buf[0];
}

_SOKOL_PRIVATE const char* _sg_strptr(const _sg_str_t* str) {
    return &str->buf[0];
}

_SOKOL_PRIVATE void _sg_strcpy(_sg_str_t* dst, const char* src) {
    SOKOL_ASSERT(dst);
    if (src) {
        #if defined(_MSC_VER)
        strncpy_s(dst->buf, _SG_STRING_SIZE, src, (_SG_STRING_SIZE-1));
        #else
        strncpy(dst->buf, src, _SG_STRING_SIZE);
        #endif
        dst->buf[_SG_STRING_SIZE-1] = 0;
    } else {
        _sg_clear(dst->buf, _SG_STRING_SIZE);
    }
}

// ██   ██ ███████ ██      ██████  ███████ ██████  ███████
// ██   ██ ██      ██      ██   ██ ██      ██   ██ ██
// ███████ █████   ██      ██████  █████   ██████  ███████
// ██   ██ ██      ██      ██      ██      ██   ██      ██
// ██   ██ ███████ ███████ ██      ███████ ██   ██ ███████
//
// >>helpers
_SOKOL_PRIVATE uint32_t _sg_align_u32(uint32_t val, uint32_t align) {
    SOKOL_ASSERT((align > 0) && ((align & (align - 1)) == 0));
    return (val + (align - 1)) & ~(align - 1);
}

typedef struct { int x, y, w, h; } _sg_recti_t;

_SOKOL_PRIVATE _sg_recti_t _sg_clipi(int x, int y, int w, int h, int clip_width, int clip_height) {
    x = _sg_min(_sg_max(0, x), clip_width-1);
    y = _sg_min(_sg_max(0, y), clip_height-1);
    if ((x + w) > clip_width) {
        w = clip_width - x;
    }
    if ((y + h) > clip_height) {
        h = clip_height - y;
    }
    w = _sg_max(w, 1);
    h = _sg_max(h, 1);
    const _sg_recti_t res = { x, y, w, h };
    return res;
}

_SOKOL_PRIVATE int _sg_vertexformat_bytesize(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:     return 4;
        case SG_VERTEXFORMAT_FLOAT2:    return 8;
        case SG_VERTEXFORMAT_FLOAT3:    return 12;
        case SG_VERTEXFORMAT_FLOAT4:    return 16;
        case SG_VERTEXFORMAT_INT:       return 4;
        case SG_VERTEXFORMAT_INT2:      return 8;
        case SG_VERTEXFORMAT_INT3:      return 12;
        case SG_VERTEXFORMAT_INT4:      return 16;
        case SG_VERTEXFORMAT_UINT:      return 4;
        case SG_VERTEXFORMAT_UINT2:     return 8;
        case SG_VERTEXFORMAT_UINT3:     return 12;
        case SG_VERTEXFORMAT_UINT4:     return 16;
        case SG_VERTEXFORMAT_BYTE4:     return 4;
        case SG_VERTEXFORMAT_BYTE4N:    return 4;
        case SG_VERTEXFORMAT_UBYTE4:    return 4;
        case SG_VERTEXFORMAT_UBYTE4N:   return 4;
        case SG_VERTEXFORMAT_SHORT2:    return 4;
        case SG_VERTEXFORMAT_SHORT2N:   return 4;
        case SG_VERTEXFORMAT_USHORT2:   return 4;
        case SG_VERTEXFORMAT_USHORT2N:  return 4;
        case SG_VERTEXFORMAT_SHORT4:    return 8;
        case SG_VERTEXFORMAT_SHORT4N:   return 8;
        case SG_VERTEXFORMAT_USHORT4:   return 8;
        case SG_VERTEXFORMAT_USHORT4N:  return 8;
        case SG_VERTEXFORMAT_UINT10_N2: return 4;
        case SG_VERTEXFORMAT_HALF2:     return 4;
        case SG_VERTEXFORMAT_HALF4:     return 8;
        case SG_VERTEXFORMAT_INVALID:   return 0;
        default:
            SOKOL_UNREACHABLE;
            return -1;
    }
}

_SOKOL_PRIVATE const char* _sg_vertexformat_to_string(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:     return "FLOAT";
        case SG_VERTEXFORMAT_FLOAT2:    return "FLOAT2";
        case SG_VERTEXFORMAT_FLOAT3:    return "FLOAT3";
        case SG_VERTEXFORMAT_FLOAT4:    return "FLOAT4";
        case SG_VERTEXFORMAT_INT:       return "INT";
        case SG_VERTEXFORMAT_INT2:      return "INT2";
        case SG_VERTEXFORMAT_INT3:      return "INT3";
        case SG_VERTEXFORMAT_INT4:      return "INT4";
        case SG_VERTEXFORMAT_UINT:      return "UINT";
        case SG_VERTEXFORMAT_UINT2:     return "UINT2";
        case SG_VERTEXFORMAT_UINT3:     return "UINT3";
        case SG_VERTEXFORMAT_UINT4:     return "UINT4";
        case SG_VERTEXFORMAT_BYTE4:     return "BYTE4";
        case SG_VERTEXFORMAT_BYTE4N:    return "BYTE4N";
        case SG_VERTEXFORMAT_UBYTE4:    return "UBYTE4";
        case SG_VERTEXFORMAT_UBYTE4N:   return "UBYTE4N";
        case SG_VERTEXFORMAT_SHORT2:    return "SHORT2";
        case SG_VERTEXFORMAT_SHORT2N:   return "SHORT2N";
        case SG_VERTEXFORMAT_USHORT2:   return "USHORT2";
        case SG_VERTEXFORMAT_USHORT2N:  return "USHORT2N";
        case SG_VERTEXFORMAT_SHORT4:    return "SHORT4";
        case SG_VERTEXFORMAT_SHORT4N:   return "SHORT4N";
        case SG_VERTEXFORMAT_USHORT4:   return "USHORT4";
        case SG_VERTEXFORMAT_USHORT4N:  return "USHORT4N";
        case SG_VERTEXFORMAT_UINT10_N2: return "UINT10_N2";
        case SG_VERTEXFORMAT_HALF2:     return "HALF2";
        case SG_VERTEXFORMAT_HALF4:     return "HALF4";
        default:
            SOKOL_UNREACHABLE;
            return "INVALID";
    }
}

_SOKOL_PRIVATE const char* _sg_shaderattrbasetype_to_string(sg_shader_attr_base_type b) {
    switch (b) {
        case SG_SHADERATTRBASETYPE_UNDEFINED:   return "UNDEFINED";
        case SG_SHADERATTRBASETYPE_FLOAT:       return "FLOAT";
        case SG_SHADERATTRBASETYPE_SINT:        return "SINT";
        case SG_SHADERATTRBASETYPE_UINT:        return "UINT";
        default:
            SOKOL_UNREACHABLE;
            return "INVALID";
    }
}

_SOKOL_PRIVATE sg_shader_attr_base_type _sg_vertexformat_basetype(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:
        case SG_VERTEXFORMAT_FLOAT2:
        case SG_VERTEXFORMAT_FLOAT3:
        case SG_VERTEXFORMAT_FLOAT4:
        case SG_VERTEXFORMAT_HALF2:
        case SG_VERTEXFORMAT_HALF4:
        case SG_VERTEXFORMAT_BYTE4N:
        case SG_VERTEXFORMAT_UBYTE4N:
        case SG_VERTEXFORMAT_SHORT2N:
        case SG_VERTEXFORMAT_USHORT2N:
        case SG_VERTEXFORMAT_SHORT4N:
        case SG_VERTEXFORMAT_USHORT4N:
        case SG_VERTEXFORMAT_UINT10_N2:
            return SG_SHADERATTRBASETYPE_FLOAT;
        case SG_VERTEXFORMAT_INT:
        case SG_VERTEXFORMAT_INT2:
        case SG_VERTEXFORMAT_INT3:
        case SG_VERTEXFORMAT_INT4:
        case SG_VERTEXFORMAT_BYTE4:
        case SG_VERTEXFORMAT_SHORT2:
        case SG_VERTEXFORMAT_SHORT4:
            return SG_SHADERATTRBASETYPE_SINT;
        case SG_VERTEXFORMAT_UINT:
        case SG_VERTEXFORMAT_UINT2:
        case SG_VERTEXFORMAT_UINT3:
        case SG_VERTEXFORMAT_UINT4:
        case SG_VERTEXFORMAT_UBYTE4:
        case SG_VERTEXFORMAT_USHORT2:
        case SG_VERTEXFORMAT_USHORT4:
            return SG_SHADERATTRBASETYPE_UINT;
        default:
            SOKOL_UNREACHABLE;
            return SG_SHADERATTRBASETYPE_UNDEFINED;
    }
}

_SOKOL_PRIVATE uint32_t _sg_uniform_alignment(sg_uniform_type type, int array_count, sg_uniform_layout ub_layout) {
    if (ub_layout == SG_UNIFORMLAYOUT_NATIVE) {
        return 1;
    } else {
        SOKOL_ASSERT(array_count > 0);
        if (array_count == 1) {
            switch (type) {
                case SG_UNIFORMTYPE_FLOAT:
                case SG_UNIFORMTYPE_INT:
                    return 4;
                case SG_UNIFORMTYPE_FLOAT2:
                case SG_UNIFORMTYPE_INT2:
                    return 8;
                case SG_UNIFORMTYPE_FLOAT3:
                case SG_UNIFORMTYPE_FLOAT4:
                case SG_UNIFORMTYPE_INT3:
                case SG_UNIFORMTYPE_INT4:
                    return 16;
                case SG_UNIFORMTYPE_MAT4:
                    return 16;
                default:
                    SOKOL_UNREACHABLE;
                    return 1;
            }
        } else {
            return 16;
        }
    }
}

_SOKOL_PRIVATE uint32_t _sg_uniform_size(sg_uniform_type type, int array_count, sg_uniform_layout ub_layout) {
    SOKOL_ASSERT(array_count > 0);
    if (array_count == 1) {
        switch (type) {
            case SG_UNIFORMTYPE_FLOAT:
            case SG_UNIFORMTYPE_INT:
                return 4;
            case SG_UNIFORMTYPE_FLOAT2:
            case SG_UNIFORMTYPE_INT2:
                return 8;
            case SG_UNIFORMTYPE_FLOAT3:
            case SG_UNIFORMTYPE_INT3:
                return 12;
            case SG_UNIFORMTYPE_FLOAT4:
            case SG_UNIFORMTYPE_INT4:
                return 16;
            case SG_UNIFORMTYPE_MAT4:
                return 64;
            default:
                SOKOL_UNREACHABLE;
                return 0;
        }
    } else {
        if (ub_layout == SG_UNIFORMLAYOUT_NATIVE) {
            switch (type) {
                case SG_UNIFORMTYPE_FLOAT:
                case SG_UNIFORMTYPE_INT:
                    return 4 * (uint32_t)array_count;
                case SG_UNIFORMTYPE_FLOAT2:
                case SG_UNIFORMTYPE_INT2:
                    return 8 * (uint32_t)array_count;
                case SG_UNIFORMTYPE_FLOAT3:
                case SG_UNIFORMTYPE_INT3:
                    return 12 * (uint32_t)array_count;
                case SG_UNIFORMTYPE_FLOAT4:
                case SG_UNIFORMTYPE_INT4:
                    return 16 * (uint32_t)array_count;
                case SG_UNIFORMTYPE_MAT4:
                    return 64 * (uint32_t)array_count;
                default:
                    SOKOL_UNREACHABLE;
                    return 0;
            }
        } else {
            switch (type) {
                case SG_UNIFORMTYPE_FLOAT:
                case SG_UNIFORMTYPE_FLOAT2:
                case SG_UNIFORMTYPE_FLOAT3:
                case SG_UNIFORMTYPE_FLOAT4:
                case SG_UNIFORMTYPE_INT:
                case SG_UNIFORMTYPE_INT2:
                case SG_UNIFORMTYPE_INT3:
                case SG_UNIFORMTYPE_INT4:
                    return 16 * (uint32_t)array_count;
                case SG_UNIFORMTYPE_MAT4:
                    return 64 * (uint32_t)array_count;
                default:
                    SOKOL_UNREACHABLE;
                    return 0;
            }
        }
    }
}

_SOKOL_PRIVATE bool _sg_is_compressed_pixel_format(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_BC1_RGBA:
        case SG_PIXELFORMAT_BC2_RGBA:
        case SG_PIXELFORMAT_BC3_RGBA:
        case SG_PIXELFORMAT_BC3_SRGBA:
        case SG_PIXELFORMAT_BC4_R:
        case SG_PIXELFORMAT_BC4_RSN:
        case SG_PIXELFORMAT_BC5_RG:
        case SG_PIXELFORMAT_BC5_RGSN:
        case SG_PIXELFORMAT_BC6H_RGBF:
        case SG_PIXELFORMAT_BC6H_RGBUF:
        case SG_PIXELFORMAT_BC7_RGBA:
        case SG_PIXELFORMAT_BC7_SRGBA:
        case SG_PIXELFORMAT_ETC2_RGB8:
        case SG_PIXELFORMAT_ETC2_SRGB8:
        case SG_PIXELFORMAT_ETC2_RGB8A1:
        case SG_PIXELFORMAT_ETC2_RGBA8:
        case SG_PIXELFORMAT_ETC2_SRGB8A8:
        case SG_PIXELFORMAT_EAC_R11:
        case SG_PIXELFORMAT_EAC_R11SN:
        case SG_PIXELFORMAT_EAC_RG11:
        case SG_PIXELFORMAT_EAC_RG11SN:
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA:
            return true;
        default:
            return false;
    }
}

_SOKOL_PRIVATE bool _sg_is_valid_attachment_color_format(sg_pixel_format fmt) {
    const int fmt_index = (int) fmt;
    SOKOL_ASSERT((fmt_index >= 0) && (fmt_index < _SG_PIXELFORMAT_NUM));
    return _sg.formats[fmt_index].render && !_sg.formats[fmt_index].depth;
}

_SOKOL_PRIVATE bool _sg_is_valid_attachment_depth_format(sg_pixel_format fmt) {
    const int fmt_index = (int) fmt;
    SOKOL_ASSERT((fmt_index >= 0) && (fmt_index < _SG_PIXELFORMAT_NUM));
    return _sg.formats[fmt_index].render && _sg.formats[fmt_index].depth;
}

_SOKOL_PRIVATE bool _sg_is_valid_attachment_storage_format(sg_pixel_format fmt) {
    const int fmt_index = (int) fmt;
    SOKOL_ASSERT((fmt_index >= 0) && (fmt_index < _SG_PIXELFORMAT_NUM));
    return _sg.formats[fmt_index].read || _sg.formats[fmt_index].write;
}

_SOKOL_PRIVATE bool _sg_is_depth_or_depth_stencil_format(sg_pixel_format fmt) {
    return (SG_PIXELFORMAT_DEPTH == fmt) || (SG_PIXELFORMAT_DEPTH_STENCIL == fmt);
}

_SOKOL_PRIVATE bool _sg_is_depth_stencil_format(sg_pixel_format fmt) {
    return (SG_PIXELFORMAT_DEPTH_STENCIL == fmt);
}

_SOKOL_PRIVATE int _sg_pixelformat_bytesize(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_R8:
        case SG_PIXELFORMAT_R8SN:
        case SG_PIXELFORMAT_R8UI:
        case SG_PIXELFORMAT_R8SI:
            return 1;
        case SG_PIXELFORMAT_R16:
        case SG_PIXELFORMAT_R16SN:
        case SG_PIXELFORMAT_R16UI:
        case SG_PIXELFORMAT_R16SI:
        case SG_PIXELFORMAT_R16F:
        case SG_PIXELFORMAT_RG8:
        case SG_PIXELFORMAT_RG8SN:
        case SG_PIXELFORMAT_RG8UI:
        case SG_PIXELFORMAT_RG8SI:
            return 2;
        case SG_PIXELFORMAT_R32UI:
        case SG_PIXELFORMAT_R32SI:
        case SG_PIXELFORMAT_R32F:
        case SG_PIXELFORMAT_RG16:
        case SG_PIXELFORMAT_RG16SN:
        case SG_PIXELFORMAT_RG16UI:
        case SG_PIXELFORMAT_RG16SI:
        case SG_PIXELFORMAT_RG16F:
        case SG_PIXELFORMAT_RGBA8:
        case SG_PIXELFORMAT_SRGB8A8:
        case SG_PIXELFORMAT_RGBA8SN:
        case SG_PIXELFORMAT_RGBA8UI:
        case SG_PIXELFORMAT_RGBA8SI:
        case SG_PIXELFORMAT_BGRA8:
        case SG_PIXELFORMAT_RGB10A2:
        case SG_PIXELFORMAT_RG11B10F:
        case SG_PIXELFORMAT_RGB9E5:
            return 4;
        case SG_PIXELFORMAT_RG32UI:
        case SG_PIXELFORMAT_RG32SI:
        case SG_PIXELFORMAT_RG32F:
        case SG_PIXELFORMAT_RGBA16:
        case SG_PIXELFORMAT_RGBA16SN:
        case SG_PIXELFORMAT_RGBA16UI:
        case SG_PIXELFORMAT_RGBA16SI:
        case SG_PIXELFORMAT_RGBA16F:
            return 8;
        case SG_PIXELFORMAT_RGBA32UI:
        case SG_PIXELFORMAT_RGBA32SI:
        case SG_PIXELFORMAT_RGBA32F:
            return 16;
        case SG_PIXELFORMAT_DEPTH:
        case SG_PIXELFORMAT_DEPTH_STENCIL:
            return 4;
        default:
            SOKOL_UNREACHABLE;
            return 0;
    }
}

_SOKOL_PRIVATE int _sg_roundup(int val, int round_to) {
    return (val+(round_to-1)) & ~(round_to-1);
}

_SOKOL_PRIVATE uint32_t _sg_roundup_u32(uint32_t val, uint32_t round_to) {
    return (val+(round_to-1)) & ~(round_to-1);
}

_SOKOL_PRIVATE uint64_t _sg_roundup_u64(uint64_t val, uint64_t round_to) {
    return (val+(round_to-1)) & ~(round_to-1);
}

_SOKOL_PRIVATE bool _sg_multiple_u64(uint64_t val, uint64_t of) {
    return (val & (of-1)) == 0;
}

/* return row pitch for an image

    see ComputePitch in https://github.com/microsoft/DirectXTex/blob/master/DirectXTex/DirectXTexUtil.cpp
*/
_SOKOL_PRIVATE int _sg_row_pitch(sg_pixel_format fmt, int width, int row_align) {
    int pitch;
    switch (fmt) {
        case SG_PIXELFORMAT_BC1_RGBA:
        case SG_PIXELFORMAT_BC4_R:
        case SG_PIXELFORMAT_BC4_RSN:
        case SG_PIXELFORMAT_ETC2_RGB8:
        case SG_PIXELFORMAT_ETC2_SRGB8:
        case SG_PIXELFORMAT_ETC2_RGB8A1:
        case SG_PIXELFORMAT_EAC_R11:
        case SG_PIXELFORMAT_EAC_R11SN:
            pitch = ((width + 3) / 4) * 8;
            pitch = pitch < 8 ? 8 : pitch;
            break;
        case SG_PIXELFORMAT_BC2_RGBA:
        case SG_PIXELFORMAT_BC3_RGBA:
        case SG_PIXELFORMAT_BC3_SRGBA:
        case SG_PIXELFORMAT_BC5_RG:
        case SG_PIXELFORMAT_BC5_RGSN:
        case SG_PIXELFORMAT_BC6H_RGBF:
        case SG_PIXELFORMAT_BC6H_RGBUF:
        case SG_PIXELFORMAT_BC7_RGBA:
        case SG_PIXELFORMAT_BC7_SRGBA:
        case SG_PIXELFORMAT_ETC2_RGBA8:
        case SG_PIXELFORMAT_ETC2_SRGB8A8:
        case SG_PIXELFORMAT_EAC_RG11:
        case SG_PIXELFORMAT_EAC_RG11SN:
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA:
            pitch = ((width + 3) / 4) * 16;
            pitch = pitch < 16 ? 16 : pitch;
            break;
        default:
            pitch = width * _sg_pixelformat_bytesize(fmt);
            break;
    }
    pitch = _sg_roundup(pitch, row_align);
    return pitch;
}

// compute the number of rows in a surface depending on pixel format
_SOKOL_PRIVATE int _sg_num_rows(sg_pixel_format fmt, int height) {
    int num_rows;
    switch (fmt) {
        case SG_PIXELFORMAT_BC1_RGBA:
        case SG_PIXELFORMAT_BC4_R:
        case SG_PIXELFORMAT_BC4_RSN:
        case SG_PIXELFORMAT_ETC2_RGB8:
        case SG_PIXELFORMAT_ETC2_SRGB8:
        case SG_PIXELFORMAT_ETC2_RGB8A1:
        case SG_PIXELFORMAT_ETC2_RGBA8:
        case SG_PIXELFORMAT_ETC2_SRGB8A8:
        case SG_PIXELFORMAT_EAC_R11:
        case SG_PIXELFORMAT_EAC_R11SN:
        case SG_PIXELFORMAT_EAC_RG11:
        case SG_PIXELFORMAT_EAC_RG11SN:
        case SG_PIXELFORMAT_BC2_RGBA:
        case SG_PIXELFORMAT_BC3_RGBA:
        case SG_PIXELFORMAT_BC3_SRGBA:
        case SG_PIXELFORMAT_BC5_RG:
        case SG_PIXELFORMAT_BC5_RGSN:
        case SG_PIXELFORMAT_BC6H_RGBF:
        case SG_PIXELFORMAT_BC6H_RGBUF:
        case SG_PIXELFORMAT_BC7_RGBA:
        case SG_PIXELFORMAT_BC7_SRGBA:
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA:
            num_rows = ((height + 3) / 4);
            break;
        default:
            num_rows = height;
            break;
    }
    if (num_rows < 1) {
        num_rows = 1;
    }
    return num_rows;
}

// return size of a mipmap level
_SOKOL_PRIVATE int _sg_miplevel_dim(int base_dim, int mip_level) {
    return _sg_max(base_dim >> mip_level, 1);
}

/* return pitch of a 2D subimage / texture slice
    see ComputePitch in https://github.com/microsoft/DirectXTex/blob/master/DirectXTex/DirectXTexUtil.cpp
*/
_SOKOL_PRIVATE int _sg_surface_pitch(sg_pixel_format fmt, int width, int height, int row_align) {
    int num_rows = _sg_num_rows(fmt, height);
    return num_rows * _sg_row_pitch(fmt, width, row_align);
}

// capability table pixel format helper functions
_SOKOL_PRIVATE void _sg_pixelformat_all(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->filter = true;
    pfi->blend = true;
    pfi->render = true;
    pfi->msaa = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_s(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_sf(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->filter = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_sr(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->render = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_sfr(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->filter = true;
    pfi->render = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_srmd(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->render = true;
    pfi->msaa = true;
    pfi->depth = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_srm(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->render = true;
    pfi->msaa = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_sfrm(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->filter = true;
    pfi->render = true;
    pfi->msaa = true;
}
_SOKOL_PRIVATE void _sg_pixelformat_sbrm(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->blend = true;
    pfi->render = true;
    pfi->msaa = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_sbr(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->blend = true;
    pfi->render = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_sfbr(_sg_pixelformat_info_t* pfi) {
    pfi->sample = true;
    pfi->filter = true;
    pfi->blend = true;
    pfi->render = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_compute_all(_sg_pixelformat_info_t* pfi) {
    pfi->read = true;
    pfi->write = true;
}

_SOKOL_PRIVATE void _sg_pixelformat_compute_writeonly(_sg_pixelformat_info_t* pfi) {
    pfi->read = false;
    pfi->write = true;
}

_SOKOL_PRIVATE sg_pass_action _sg_pass_action_defaults(const sg_pass_action* action) {
    SOKOL_ASSERT(action);
    sg_pass_action res = *action;
    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        if (res.colors[i].load_action == _SG_LOADACTION_DEFAULT) {
            res.colors[i].load_action = SG_LOADACTION_CLEAR;
            res.colors[i].clear_value.r = SG_DEFAULT_CLEAR_RED;
            res.colors[i].clear_value.g = SG_DEFAULT_CLEAR_GREEN;
            res.colors[i].clear_value.b = SG_DEFAULT_CLEAR_BLUE;
            res.colors[i].clear_value.a = SG_DEFAULT_CLEAR_ALPHA;
        }
        if (res.colors[i].store_action == _SG_STOREACTION_DEFAULT) {
            res.colors[i].store_action = SG_STOREACTION_STORE;
        }
    }
    if (res.depth.load_action == _SG_LOADACTION_DEFAULT) {
        res.depth.load_action = SG_LOADACTION_CLEAR;
        res.depth.clear_value = SG_DEFAULT_CLEAR_DEPTH;
    }
    if (res.depth.store_action == _SG_STOREACTION_DEFAULT) {
        res.depth.store_action = SG_STOREACTION_DONTCARE;
    }
    if (res.stencil.load_action == _SG_LOADACTION_DEFAULT) {
        res.stencil.load_action = SG_LOADACTION_CLEAR;
        res.stencil.clear_value = SG_DEFAULT_CLEAR_STENCIL;
    }
    if (res.stencil.store_action == _SG_STOREACTION_DEFAULT) {
        res.stencil.store_action = SG_STOREACTION_DONTCARE;
    }
    return res;
}

// ██████  ██    ██ ███    ███ ███    ███ ██    ██     ██████   █████   ██████ ██   ██ ███████ ███    ██ ██████
// ██   ██ ██    ██ ████  ████ ████  ████  ██  ██      ██   ██ ██   ██ ██      ██  ██  ██      ████   ██ ██   ██
// ██   ██ ██    ██ ██ ████ ██ ██ ████ ██   ████       ██████  ███████ ██      █████   █████   ██ ██  ██ ██   ██
// ██   ██ ██    ██ ██  ██  ██ ██  ██  ██    ██        ██   ██ ██   ██ ██      ██  ██  ██      ██  ██ ██ ██   ██
// ██████   ██████  ██      ██ ██      ██    ██        ██████  ██   ██  ██████ ██   ██ ███████ ██   ████ ██████
//
// >>dummy backend
#if defined(SOKOL_DUMMY_BACKEND)

_SOKOL_PRIVATE void _sg_dummy_setup_backend(const sg_desc* desc) {
    SOKOL_ASSERT(desc);
    _SOKOL_UNUSED(desc);
    _sg.backend = SG_BACKEND_DUMMY;
    for (int i = SG_PIXELFORMAT_R8; i < SG_PIXELFORMAT_BC1_RGBA; i++) {
        _sg.formats[i].sample = true;
        _sg.formats[i].filter = true;
        _sg.formats[i].render = true;
        _sg.formats[i].blend = true;
        _sg.formats[i].msaa = true;
    }
    _sg.formats[SG_PIXELFORMAT_DEPTH].depth = true;
    _sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL].depth = true;
}

_SOKOL_PRIVATE void _sg_dummy_discard_backend(void) {
    // empty
}

_SOKOL_PRIVATE void _sg_dummy_reset_state_cache(void) {
    // empty
}

_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(buf && desc);
    _SOKOL_UNUSED(buf);
    _SOKOL_UNUSED(desc);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_dummy_discard_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf);
    _SOKOL_UNUSED(buf);
}

_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_image(_sg_image_t* img, const sg_image_desc* desc) {
    SOKOL_ASSERT(img && desc);
    _SOKOL_UNUSED(img);
    _SOKOL_UNUSED(desc);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_dummy_discard_image(_sg_image_t* img) {
    SOKOL_ASSERT(img);
    _SOKOL_UNUSED(img);
}

_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(smp && desc);
    _SOKOL_UNUSED(smp);
    _SOKOL_UNUSED(desc);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_dummy_discard_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp);
    _SOKOL_UNUSED(smp);
}

_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    SOKOL_ASSERT(shd && desc);
    _SOKOL_UNUSED(shd);
    _SOKOL_UNUSED(desc);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_dummy_discard_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd);
    _SOKOL_UNUSED(shd);
}

_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(pip && desc);
    _SOKOL_UNUSED(desc);
    pip->shader = shd;
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_dummy_discard_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    _SOKOL_UNUSED(pip);
}

_SOKOL_PRIVATE sg_resource_state _sg_dummy_create_attachments(_sg_attachments_t* atts, const _sg_attachments_ptrs_t* atts_ptrs, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(atts && atts_ptrs && desc);

    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const sg_attachment_desc* color_desc = &desc->colors[i];
        _SOKOL_UNUSED(color_desc);
        SOKOL_ASSERT(color_desc->image.id != SG_INVALID_ID);
        SOKOL_ASSERT(0 == atts->dmy.colors[i].image);
        SOKOL_ASSERT(atts_ptrs->color_images[i]);
        _sg_image_t* clr_img = atts_ptrs->color_images[i];
        SOKOL_ASSERT(clr_img->slot.id == color_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_color_format(clr_img->cmn.pixel_format));
        atts->dmy.colors[i].image = clr_img;
        const sg_attachment_desc* resolve_desc = &desc->resolves[i];
        if (resolve_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->dmy.resolves[i].image);
            SOKOL_ASSERT(atts_ptrs->resolve_images[i]);
            _sg_image_t* rsv_img = atts_ptrs->resolve_images[i];
            SOKOL_ASSERT(rsv_img->slot.id == resolve_desc->image.id);
            SOKOL_ASSERT(clr_img->cmn.pixel_format == rsv_img->cmn.pixel_format);
            atts->dmy.resolves[i].image = rsv_img;
        }
    }
    SOKOL_ASSERT(0 == atts->dmy.depth_stencil.image);
    const sg_attachment_desc* ds_desc = &desc->depth_stencil;
    if (ds_desc->image.id != SG_INVALID_ID) {
        SOKOL_ASSERT(atts_ptrs->ds_image);
        _sg_image_t* ds_img = atts_ptrs->ds_image;
        SOKOL_ASSERT(ds_img->slot.id == ds_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_depth_format(ds_img->cmn.pixel_format));
        atts->dmy.depth_stencil.image = ds_img;
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_dummy_discard_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    _SOKOL_UNUSED(atts);
}

_SOKOL_PRIVATE _sg_image_t* _sg_dummy_attachments_color_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->dmy.colors[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_dummy_attachments_resolve_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->dmy.resolves[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_dummy_attachments_ds_image(const _sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    return atts->dmy.depth_stencil.image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_dummy_attachments_storage_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->dmy.storages[index].image;
}

_SOKOL_PRIVATE void _sg_dummy_begin_pass(const sg_pass* pass) {
    SOKOL_ASSERT(pass);
    _SOKOL_UNUSED(pass);
}

_SOKOL_PRIVATE void _sg_dummy_end_pass(void) {
    // empty
}

_SOKOL_PRIVATE void _sg_dummy_commit(void) {
    // empty
}

_SOKOL_PRIVATE void _sg_dummy_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {
    _SOKOL_UNUSED(x);
    _SOKOL_UNUSED(y);
    _SOKOL_UNUSED(w);
    _SOKOL_UNUSED(h);
    _SOKOL_UNUSED(origin_top_left);
}

_SOKOL_PRIVATE void _sg_dummy_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {
    _SOKOL_UNUSED(x);
    _SOKOL_UNUSED(y);
    _SOKOL_UNUSED(w);
    _SOKOL_UNUSED(h);
    _SOKOL_UNUSED(origin_top_left);
}

_SOKOL_PRIVATE void _sg_dummy_apply_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    _SOKOL_UNUSED(pip);
}

_SOKOL_PRIVATE bool _sg_dummy_apply_bindings(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(bnd);
    SOKOL_ASSERT(bnd->pip);
    _SOKOL_UNUSED(bnd);
    return true;
}

_SOKOL_PRIVATE void _sg_dummy_apply_uniforms(int ub_slot, const sg_range* data) {
    _SOKOL_UNUSED(ub_slot);
    _SOKOL_UNUSED(data);
}

_SOKOL_PRIVATE void _sg_dummy_draw(int base_element, int num_elements, int num_instances) {
    _SOKOL_UNUSED(base_element);
    _SOKOL_UNUSED(num_elements);
    _SOKOL_UNUSED(num_instances);
}

_SOKOL_PRIVATE void _sg_dummy_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    _SOKOL_UNUSED(num_groups_x);
    _SOKOL_UNUSED(num_groups_y);
    _SOKOL_UNUSED(num_groups_z);
}

_SOKOL_PRIVATE void _sg_dummy_update_buffer(_sg_buffer_t* buf, const sg_range* data) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    _SOKOL_UNUSED(data);
    if (++buf->cmn.active_slot >= buf->cmn.num_slots) {
        buf->cmn.active_slot = 0;
    }
}

_SOKOL_PRIVATE bool _sg_dummy_append_buffer(_sg_buffer_t* buf, const sg_range* data, bool new_frame) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    _SOKOL_UNUSED(data);
    if (new_frame) {
        if (++buf->cmn.active_slot >= buf->cmn.num_slots) {
            buf->cmn.active_slot = 0;
        }
    }
    return true;
}

_SOKOL_PRIVATE void _sg_dummy_update_image(_sg_image_t* img, const sg_image_data* data) {
    SOKOL_ASSERT(img && data);
    _SOKOL_UNUSED(data);
    if (++img->cmn.active_slot >= img->cmn.num_slots) {
        img->cmn.active_slot = 0;
    }
}

//  ██████  ██████  ███████ ███    ██  ██████  ██          ██████   █████   ██████ ██   ██ ███████ ███    ██ ██████
// ██    ██ ██   ██ ██      ████   ██ ██       ██          ██   ██ ██   ██ ██      ██  ██  ██      ████   ██ ██   ██
// ██    ██ ██████  █████   ██ ██  ██ ██   ███ ██          ██████  ███████ ██      █████   █████   ██ ██  ██ ██   ██
// ██    ██ ██      ██      ██  ██ ██ ██    ██ ██          ██   ██ ██   ██ ██      ██  ██  ██      ██  ██ ██ ██   ██
//  ██████  ██      ███████ ██   ████  ██████  ███████     ██████  ██   ██  ██████ ██   ██ ███████ ██   ████ ██████
//
// >>opengl backend
#elif defined(_SOKOL_ANY_GL)

// optional GL loader for win32
#if defined(_SOKOL_USE_WIN32_GL_LOADER)

#ifndef SG_GL_FUNCS_EXT
#define SG_GL_FUNCS_EXT
#endif

// X Macro list of GL function names and signatures
#define _SG_GL_FUNCS \
    SG_GL_FUNCS_EXT \
    _SG_XMACRO(glBindVertexArray,                 void, (GLuint array)) \
    _SG_XMACRO(glFramebufferTextureLayer,         void, (GLenum target, GLenum attachment, GLuint texture, GLint level, GLint layer)) \
    _SG_XMACRO(glGenFramebuffers,                 void, (GLsizei n, GLuint * framebuffers)) \
    _SG_XMACRO(glBindFramebuffer,                 void, (GLenum target, GLuint framebuffer)) \
    _SG_XMACRO(glBindRenderbuffer,                void, (GLenum target, GLuint renderbuffer)) \
    _SG_XMACRO(glGetStringi,                      const GLubyte *, (GLenum name, GLuint index)) \
    _SG_XMACRO(glClearBufferfi,                   void, (GLenum buffer, GLint drawbuffer, GLfloat depth, GLint stencil)) \
    _SG_XMACRO(glClearBufferfv,                   void, (GLenum buffer, GLint drawbuffer, const GLfloat * value)) \
    _SG_XMACRO(glClearBufferuiv,                  void, (GLenum buffer, GLint drawbuffer, const GLuint * value)) \
    _SG_XMACRO(glClearBufferiv,                   void, (GLenum buffer, GLint drawbuffer, const GLint * value)) \
    _SG_XMACRO(glDeleteRenderbuffers,             void, (GLsizei n, const GLuint * renderbuffers)) \
    _SG_XMACRO(glUniform1fv,                      void, (GLint location, GLsizei count, const GLfloat * value)) \
    _SG_XMACRO(glUniform2fv,                      void, (GLint location, GLsizei count, const GLfloat * value)) \
    _SG_XMACRO(glUniform3fv,                      void, (GLint location, GLsizei count, const GLfloat * value)) \
    _SG_XMACRO(glUniform4fv,                      void, (GLint location, GLsizei count, const GLfloat * value)) \
    _SG_XMACRO(glUniform1iv,                      void, (GLint location, GLsizei count, const GLint * value)) \
    _SG_XMACRO(glUniform2iv,                      void, (GLint location, GLsizei count, const GLint * value)) \
    _SG_XMACRO(glUniform3iv,                      void, (GLint location, GLsizei count, const GLint * value)) \
    _SG_XMACRO(glUniform4iv,                      void, (GLint location, GLsizei count, const GLint * value)) \
    _SG_XMACRO(glUniformMatrix4fv,                void, (GLint location, GLsizei count, GLboolean transpose, const GLfloat * value)) \
    _SG_XMACRO(glUseProgram,                      void, (GLuint program)) \
    _SG_XMACRO(glShaderSource,                    void, (GLuint shader, GLsizei count, const GLchar *const* string, const GLint * length)) \
    _SG_XMACRO(glLinkProgram,                     void, (GLuint program)) \
    _SG_XMACRO(glGetUniformLocation,              GLint, (GLuint program, const GLchar * name)) \
    _SG_XMACRO(glGetShaderiv,                     void, (GLuint shader, GLenum pname, GLint * params)) \
    _SG_XMACRO(glGetProgramInfoLog,               void, (GLuint program, GLsizei bufSize, GLsizei * length, GLchar * infoLog)) \
    _SG_XMACRO(glGetAttribLocation,               GLint, (GLuint program, const GLchar * name)) \
    _SG_XMACRO(glDisableVertexAttribArray,        void, (GLuint index)) \
    _SG_XMACRO(glDeleteShader,                    void, (GLuint shader)) \
    _SG_XMACRO(glDeleteProgram,                   void, (GLuint program)) \
    _SG_XMACRO(glCompileShader,                   void, (GLuint shader)) \
    _SG_XMACRO(glStencilFuncSeparate,             void, (GLenum face, GLenum func, GLint ref, GLuint mask)) \
    _SG_XMACRO(glStencilOpSeparate,               void, (GLenum face, GLenum sfail, GLenum dpfail, GLenum dppass)) \
    _SG_XMACRO(glRenderbufferStorageMultisample,  void, (GLenum target, GLsizei samples, GLenum internalformat, GLsizei width, GLsizei height)) \
    _SG_XMACRO(glDrawBuffers,                     void, (GLsizei n, const GLenum * bufs)) \
    _SG_XMACRO(glVertexAttribDivisor,             void, (GLuint index, GLuint divisor)) \
    _SG_XMACRO(glBufferSubData,                   void, (GLenum target, GLintptr offset, GLsizeiptr size, const void * data)) \
    _SG_XMACRO(glGenBuffers,                      void, (GLsizei n, GLuint * buffers)) \
    _SG_XMACRO(glCheckFramebufferStatus,          GLenum, (GLenum target)) \
    _SG_XMACRO(glFramebufferRenderbuffer,         void, (GLenum target, GLenum attachment, GLenum renderbuffertarget, GLuint renderbuffer)) \
    _SG_XMACRO(glCompressedTexImage2D,            void, (GLenum target, GLint level, GLenum internalformat, GLsizei width, GLsizei height, GLint border, GLsizei imageSize, const void * data)) \
    _SG_XMACRO(glCompressedTexImage3D,            void, (GLenum target, GLint level, GLenum internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLsizei imageSize, const void * data)) \
    _SG_XMACRO(glActiveTexture,                   void, (GLenum texture)) \
    _SG_XMACRO(glTexSubImage3D,                   void, (GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, const void * pixels)) \
    _SG_XMACRO(glRenderbufferStorage,             void, (GLenum target, GLenum internalformat, GLsizei width, GLsizei height)) \
    _SG_XMACRO(glGenTextures,                     void, (GLsizei n, GLuint * textures)) \
    _SG_XMACRO(glPolygonOffset,                   void, (GLfloat factor, GLfloat units)) \
    _SG_XMACRO(glDrawElements,                    void, (GLenum mode, GLsizei count, GLenum type, const void * indices)) \
    _SG_XMACRO(glDeleteFramebuffers,              void, (GLsizei n, const GLuint * framebuffers)) \
    _SG_XMACRO(glBlendEquationSeparate,           void, (GLenum modeRGB, GLenum modeAlpha)) \
    _SG_XMACRO(glDeleteTextures,                  void, (GLsizei n, const GLuint * textures)) \
    _SG_XMACRO(glGetProgramiv,                    void, (GLuint program, GLenum pname, GLint * params)) \
    _SG_XMACRO(glBindTexture,                     void, (GLenum target, GLuint texture)) \
    _SG_XMACRO(glTexImage3D,                      void, (GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, const void * pixels)) \
    _SG_XMACRO(glCreateShader,                    GLuint, (GLenum type)) \
    _SG_XMACRO(glTexSubImage2D,                   void, (GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, const void * pixels)) \
    _SG_XMACRO(glFramebufferTexture2D,            void, (GLenum target, GLenum attachment, GLenum textarget, GLuint texture, GLint level)) \
    _SG_XMACRO(glCreateProgram,                   GLuint, (void)) \
    _SG_XMACRO(glViewport,                        void, (GLint x, GLint y, GLsizei width, GLsizei height)) \
    _SG_XMACRO(glDeleteBuffers,                   void, (GLsizei n, const GLuint * buffers)) \
    _SG_XMACRO(glDrawArrays,                      void, (GLenum mode, GLint first, GLsizei count)) \
    _SG_XMACRO(glDrawElementsInstanced,           void, (GLenum mode, GLsizei count, GLenum type, const void * indices, GLsizei instancecount)) \
    _SG_XMACRO(glVertexAttribPointer,             void, (GLuint index, GLint size, GLenum type, GLboolean normalized, GLsizei stride, const void * pointer)) \
    _SG_XMACRO(glVertexAttribIPointer,            void, (GLuint index, GLint size, GLenum type, GLsizei stride, const void * pointer)) \
    _SG_XMACRO(glUniform1i,                       void, (GLint location, GLint v0)) \
    _SG_XMACRO(glDisable,                         void, (GLenum cap)) \
    _SG_XMACRO(glColorMask,                       void, (GLboolean red, GLboolean green, GLboolean blue, GLboolean alpha)) \
    _SG_XMACRO(glColorMaski,                      void, (GLuint buf, GLboolean red, GLboolean green, GLboolean blue, GLboolean alpha)) \
    _SG_XMACRO(glBindBuffer,                      void, (GLenum target, GLuint buffer)) \
    _SG_XMACRO(glDeleteVertexArrays,              void, (GLsizei n, const GLuint * arrays)) \
    _SG_XMACRO(glDepthMask,                       void, (GLboolean flag)) \
    _SG_XMACRO(glDrawArraysInstanced,             void, (GLenum mode, GLint first, GLsizei count, GLsizei instancecount)) \
    _SG_XMACRO(glScissor,                         void, (GLint x, GLint y, GLsizei width, GLsizei height)) \
    _SG_XMACRO(glGenRenderbuffers,                void, (GLsizei n, GLuint * renderbuffers)) \
    _SG_XMACRO(glBufferData,                      void, (GLenum target, GLsizeiptr size, const void * data, GLenum usage)) \
    _SG_XMACRO(glBlendFuncSeparate,               void, (GLenum sfactorRGB, GLenum dfactorRGB, GLenum sfactorAlpha, GLenum dfactorAlpha)) \
    _SG_XMACRO(glTexParameteri,                   void, (GLenum target, GLenum pname, GLint param)) \
    _SG_XMACRO(glGetIntegerv,                     void, (GLenum pname, GLint * data)) \
    _SG_XMACRO(glEnable,                          void, (GLenum cap)) \
    _SG_XMACRO(glBlitFramebuffer,                 void, (GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, GLint dstX0, GLint dstY0, GLint dstX1, GLint dstY1, GLbitfield mask, GLenum filter)) \
    _SG_XMACRO(glStencilMask,                     void, (GLuint mask)) \
    _SG_XMACRO(glAttachShader,                    void, (GLuint program, GLuint shader)) \
    _SG_XMACRO(glGetError,                        GLenum, (void)) \
    _SG_XMACRO(glBlendColor,                      void, (GLfloat red, GLfloat green, GLfloat blue, GLfloat alpha)) \
    _SG_XMACRO(glTexParameterf,                   void, (GLenum target, GLenum pname, GLfloat param)) \
    _SG_XMACRO(glTexParameterfv,                  void, (GLenum target, GLenum pname, const GLfloat* params)) \
    _SG_XMACRO(glGetShaderInfoLog,                void, (GLuint shader, GLsizei bufSize, GLsizei * length, GLchar * infoLog)) \
    _SG_XMACRO(glDepthFunc,                       void, (GLenum func)) \
    _SG_XMACRO(glStencilOp ,                      void, (GLenum fail, GLenum zfail, GLenum zpass)) \
    _SG_XMACRO(glStencilFunc,                     void, (GLenum func, GLint ref, GLuint mask)) \
    _SG_XMACRO(glEnableVertexAttribArray,         void, (GLuint index)) \
    _SG_XMACRO(glBlendFunc,                       void, (GLenum sfactor, GLenum dfactor)) \
    _SG_XMACRO(glReadBuffer,                      void, (GLenum src)) \
    _SG_XMACRO(glTexImage2D,                      void, (GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, const void * pixels)) \
    _SG_XMACRO(glGenVertexArrays,                 void, (GLsizei n, GLuint * arrays)) \
    _SG_XMACRO(glFrontFace,                       void, (GLenum mode)) \
    _SG_XMACRO(glCullFace,                        void, (GLenum mode)) \
    _SG_XMACRO(glPixelStorei,                     void, (GLenum pname, GLint param)) \
    _SG_XMACRO(glBindSampler,                     void, (GLuint unit, GLuint sampler)) \
    _SG_XMACRO(glGenSamplers,                     void, (GLsizei n, GLuint* samplers)) \
    _SG_XMACRO(glSamplerParameteri,               void, (GLuint sampler, GLenum pname, GLint param)) \
    _SG_XMACRO(glSamplerParameterf,               void, (GLuint sampler, GLenum pname, GLfloat param)) \
    _SG_XMACRO(glSamplerParameterfv,              void, (GLuint sampler, GLenum pname, const GLfloat* params)) \
    _SG_XMACRO(glDeleteSamplers,                  void, (GLsizei n, const GLuint* samplers)) \
    _SG_XMACRO(glBindBufferBase,                  void, (GLenum target, GLuint index, GLuint buffer)) \
    _SG_XMACRO(glTexImage2DMultisample,           void, (GLenum target, GLsizei samples, GLenum internalformat, GLsizei width, GLsizei height, GLboolean fixedsamplelocations)) \
    _SG_XMACRO(glTexImage3DMultisample,           void, (GLenum target, GLsizei samples, GLenum internalformat, GLsizei width, GLsizei height, GLsizei depth, GLboolean fixedsamplelocations)) \
    _SG_XMACRO(glDispatchCompute,                 void, (GLuint num_groups_x, GLuint num_groups_y, GLuint num_groups_z)) \
    _SG_XMACRO(glMemoryBarrier,                   void, (GLbitfield barriers)) \
    _SG_XMACRO(glBindImageTexture,                void, (GLuint unit, GLuint texture, GLint level, GLboolean layered, GLint layer, GLenum access, GLenum format)) \
    _SG_XMACRO(glTexStorage2DMultisample,         void, (GLenum target, GLsizei samples, GLenum internalformat, GLsizei width, GLsizei height, GLboolean fixedsamplelocations)) \
    _SG_XMACRO(glTexStorage2D,                    void, (GLenum target, GLsizei levels, GLenum internalformat, GLsizei width, GLsizei height)) \
    _SG_XMACRO(glTexStorage3DMultisample,         void, (GLenum target, GLsizei samples, GLenum internalformat, GLsizei width, GLsizei height, GLsizei depth, GLboolean fixedsamplelocations)) \
    _SG_XMACRO(glTexStorage3D,                    void, (GLenum target, GLsizei levels, GLenum internalformat, GLsizei width, GLsizei height, GLsizei depth)) \
    _SG_XMACRO(glCompressedTexSubImage2D,         void, (GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLsizei imageSize, const void *data)) \
    _SG_XMACRO(glCompressedTexSubImage3D,         void, (GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLsizei imageSize, const void *data))

// generate GL function pointer typedefs
#define _SG_XMACRO(name, ret, args) typedef ret (GL_APIENTRY* PFN_ ## name) args;
_SG_GL_FUNCS
#undef _SG_XMACRO

// generate GL function pointers
#define _SG_XMACRO(name, ret, args) static PFN_ ## name name;
_SG_GL_FUNCS
#undef _SG_XMACRO

// helper function to lookup GL functions in GL DLL
typedef PROC (WINAPI * _sg_wglGetProcAddress)(LPCSTR);
_SOKOL_PRIVATE void* _sg_gl_getprocaddr(const char* name, _sg_wglGetProcAddress wgl_getprocaddress) {
    void* proc_addr = (void*) wgl_getprocaddress(name);
    if (0 == proc_addr) {
        proc_addr = (void*) GetProcAddress(_sg.gl.opengl32_dll, name);
    }
    SOKOL_ASSERT(proc_addr);
    return proc_addr;
}

// populate GL function pointers
_SOKOL_PRIVATE  void _sg_gl_load_opengl(void) {
    SOKOL_ASSERT(0 == _sg.gl.opengl32_dll);
    _sg.gl.opengl32_dll = LoadLibraryA("opengl32.dll");
    SOKOL_ASSERT(_sg.gl.opengl32_dll);
    _sg_wglGetProcAddress wgl_getprocaddress = (_sg_wglGetProcAddress) GetProcAddress(_sg.gl.opengl32_dll, "wglGetProcAddress");
    SOKOL_ASSERT(wgl_getprocaddress);
    #define _SG_XMACRO(name, ret, args) name = (PFN_ ## name) _sg_gl_getprocaddr(#name, wgl_getprocaddress);
    _SG_GL_FUNCS
    #undef _SG_XMACRO
}

_SOKOL_PRIVATE void _sg_gl_unload_opengl(void) {
    SOKOL_ASSERT(_sg.gl.opengl32_dll);
    FreeLibrary(_sg.gl.opengl32_dll);
    _sg.gl.opengl32_dll = 0;
}
#endif // _SOKOL_USE_WIN32_GL_LOADER

//-- type translation ----------------------------------------------------------
_SOKOL_PRIVATE GLenum _sg_gl_buffer_target(const sg_buffer_usage* usg) {
    // NOTE: the buffer target returned here is only used for the bind point
    // to copy data into the buffer, expect for WebGL2, the bind point doesn't
    // need to match the later usage of the buffer (but because of the WebGL2
    // restriction we cannot simply select a random bind point, because in WebGL2
    // a buffer cannot 'switch' bind points later.
    if (usg->vertex_buffer) {
        return GL_ARRAY_BUFFER;
    } else if (usg->index_buffer) {
        return GL_ELEMENT_ARRAY_BUFFER;
    } else if (usg->storage_buffer) {
        return GL_SHADER_STORAGE_BUFFER;
    } else {
        SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_texture_target(sg_image_type t, int sample_count) {
    #if defined(SOKOL_GLCORE)
        const bool msaa = sample_count > 1;
        if (msaa) {
            switch (t) {
                case SG_IMAGETYPE_2D: return GL_TEXTURE_2D_MULTISAMPLE;
                case SG_IMAGETYPE_ARRAY: return GL_TEXTURE_2D_MULTISAMPLE_ARRAY;
                default: SOKOL_UNREACHABLE; return 0;
            }
        } else {
            switch (t) {
                case SG_IMAGETYPE_2D:   return GL_TEXTURE_2D;
                case SG_IMAGETYPE_CUBE: return GL_TEXTURE_CUBE_MAP;
                case SG_IMAGETYPE_3D:       return GL_TEXTURE_3D;
                case SG_IMAGETYPE_ARRAY:    return GL_TEXTURE_2D_ARRAY;
                default: SOKOL_UNREACHABLE; return 0;
            }
        }
    #else
        SOKOL_ASSERT(sample_count == 1); _SOKOL_UNUSED(sample_count);
        switch (t) {
            case SG_IMAGETYPE_2D:   return GL_TEXTURE_2D;
            case SG_IMAGETYPE_CUBE: return GL_TEXTURE_CUBE_MAP;
            case SG_IMAGETYPE_3D:       return GL_TEXTURE_3D;
            case SG_IMAGETYPE_ARRAY:    return GL_TEXTURE_2D_ARRAY;
            default: SOKOL_UNREACHABLE; return 0;
        }
    #endif
}

_SOKOL_PRIVATE GLenum _sg_gl_buffer_usage(const sg_buffer_usage* usg) {
    if (usg->immutable) {
        return GL_STATIC_DRAW;
    } else if (usg->dynamic_update) {
        return GL_DYNAMIC_DRAW;
    } else if (usg->stream_update) {
        return GL_STREAM_DRAW;
    } else {
        SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_shader_stage(sg_shader_stage stage) {
    switch (stage) {
        case SG_SHADERSTAGE_VERTEX:   return GL_VERTEX_SHADER;
        case SG_SHADERSTAGE_FRAGMENT: return GL_FRAGMENT_SHADER;
        case SG_SHADERSTAGE_COMPUTE:  return GL_COMPUTE_SHADER;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLint _sg_gl_vertexformat_size(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:     return 1;
        case SG_VERTEXFORMAT_FLOAT2:    return 2;
        case SG_VERTEXFORMAT_FLOAT3:    return 3;
        case SG_VERTEXFORMAT_FLOAT4:    return 4;
        case SG_VERTEXFORMAT_INT:       return 1;
        case SG_VERTEXFORMAT_INT2:      return 2;
        case SG_VERTEXFORMAT_INT3:      return 3;
        case SG_VERTEXFORMAT_INT4:      return 4;
        case SG_VERTEXFORMAT_UINT:      return 1;
        case SG_VERTEXFORMAT_UINT2:     return 2;
        case SG_VERTEXFORMAT_UINT3:     return 3;
        case SG_VERTEXFORMAT_UINT4:     return 4;
        case SG_VERTEXFORMAT_BYTE4:     return 4;
        case SG_VERTEXFORMAT_BYTE4N:    return 4;
        case SG_VERTEXFORMAT_UBYTE4:    return 4;
        case SG_VERTEXFORMAT_UBYTE4N:   return 4;
        case SG_VERTEXFORMAT_SHORT2:    return 2;
        case SG_VERTEXFORMAT_SHORT2N:   return 2;
        case SG_VERTEXFORMAT_USHORT2:   return 2;
        case SG_VERTEXFORMAT_USHORT2N:  return 2;
        case SG_VERTEXFORMAT_SHORT4:    return 4;
        case SG_VERTEXFORMAT_SHORT4N:   return 4;
        case SG_VERTEXFORMAT_USHORT4:   return 4;
        case SG_VERTEXFORMAT_USHORT4N:  return 4;
        case SG_VERTEXFORMAT_UINT10_N2: return 4;
        case SG_VERTEXFORMAT_HALF2:     return 2;
        case SG_VERTEXFORMAT_HALF4:     return 4;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_vertexformat_type(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:
        case SG_VERTEXFORMAT_FLOAT2:
        case SG_VERTEXFORMAT_FLOAT3:
        case SG_VERTEXFORMAT_FLOAT4:
            return GL_FLOAT;
        case SG_VERTEXFORMAT_INT:
        case SG_VERTEXFORMAT_INT2:
        case SG_VERTEXFORMAT_INT3:
        case SG_VERTEXFORMAT_INT4:
            return GL_INT;
        case SG_VERTEXFORMAT_UINT:
        case SG_VERTEXFORMAT_UINT2:
        case SG_VERTEXFORMAT_UINT3:
        case SG_VERTEXFORMAT_UINT4:
            return GL_UNSIGNED_INT;
        case SG_VERTEXFORMAT_BYTE4:
        case SG_VERTEXFORMAT_BYTE4N:
            return GL_BYTE;
        case SG_VERTEXFORMAT_UBYTE4:
        case SG_VERTEXFORMAT_UBYTE4N:
            return GL_UNSIGNED_BYTE;
        case SG_VERTEXFORMAT_SHORT2:
        case SG_VERTEXFORMAT_SHORT2N:
        case SG_VERTEXFORMAT_SHORT4:
        case SG_VERTEXFORMAT_SHORT4N:
            return GL_SHORT;
        case SG_VERTEXFORMAT_USHORT2:
        case SG_VERTEXFORMAT_USHORT2N:
        case SG_VERTEXFORMAT_USHORT4:
        case SG_VERTEXFORMAT_USHORT4N:
            return GL_UNSIGNED_SHORT;
        case SG_VERTEXFORMAT_UINT10_N2:
            return GL_UNSIGNED_INT_2_10_10_10_REV;
        case SG_VERTEXFORMAT_HALF2:
        case SG_VERTEXFORMAT_HALF4:
            return GL_HALF_FLOAT;
        default:
            SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLboolean _sg_gl_vertexformat_normalized(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_BYTE4N:
        case SG_VERTEXFORMAT_UBYTE4N:
        case SG_VERTEXFORMAT_SHORT2N:
        case SG_VERTEXFORMAT_USHORT2N:
        case SG_VERTEXFORMAT_SHORT4N:
        case SG_VERTEXFORMAT_USHORT4N:
        case SG_VERTEXFORMAT_UINT10_N2:
            return GL_TRUE;
        default:
            return GL_FALSE;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_primitive_type(sg_primitive_type t) {
    switch (t) {
        case SG_PRIMITIVETYPE_POINTS:           return GL_POINTS;
        case SG_PRIMITIVETYPE_LINES:            return GL_LINES;
        case SG_PRIMITIVETYPE_LINE_STRIP:       return GL_LINE_STRIP;
        case SG_PRIMITIVETYPE_TRIANGLES:        return GL_TRIANGLES;
        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return GL_TRIANGLE_STRIP;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_index_type(sg_index_type t) {
    switch (t) {
        case SG_INDEXTYPE_NONE:     return 0;
        case SG_INDEXTYPE_UINT16:   return GL_UNSIGNED_SHORT;
        case SG_INDEXTYPE_UINT32:   return GL_UNSIGNED_INT;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_compare_func(sg_compare_func cmp) {
    switch (cmp) {
        case SG_COMPAREFUNC_NEVER:          return GL_NEVER;
        case SG_COMPAREFUNC_LESS:           return GL_LESS;
        case SG_COMPAREFUNC_EQUAL:          return GL_EQUAL;
        case SG_COMPAREFUNC_LESS_EQUAL:     return GL_LEQUAL;
        case SG_COMPAREFUNC_GREATER:        return GL_GREATER;
        case SG_COMPAREFUNC_NOT_EQUAL:      return GL_NOTEQUAL;
        case SG_COMPAREFUNC_GREATER_EQUAL:  return GL_GEQUAL;
        case SG_COMPAREFUNC_ALWAYS:         return GL_ALWAYS;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_stencil_op(sg_stencil_op op) {
    switch (op) {
        case SG_STENCILOP_KEEP:         return GL_KEEP;
        case SG_STENCILOP_ZERO:         return GL_ZERO;
        case SG_STENCILOP_REPLACE:      return GL_REPLACE;
        case SG_STENCILOP_INCR_CLAMP:   return GL_INCR;
        case SG_STENCILOP_DECR_CLAMP:   return GL_DECR;
        case SG_STENCILOP_INVERT:       return GL_INVERT;
        case SG_STENCILOP_INCR_WRAP:    return GL_INCR_WRAP;
        case SG_STENCILOP_DECR_WRAP:    return GL_DECR_WRAP;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_blend_factor(sg_blend_factor f) {
    switch (f) {
        case SG_BLENDFACTOR_ZERO:                   return GL_ZERO;
        case SG_BLENDFACTOR_ONE:                    return GL_ONE;
        case SG_BLENDFACTOR_SRC_COLOR:              return GL_SRC_COLOR;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return GL_ONE_MINUS_SRC_COLOR;
        case SG_BLENDFACTOR_SRC_ALPHA:              return GL_SRC_ALPHA;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return GL_ONE_MINUS_SRC_ALPHA;
        case SG_BLENDFACTOR_DST_COLOR:              return GL_DST_COLOR;
        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return GL_ONE_MINUS_DST_COLOR;
        case SG_BLENDFACTOR_DST_ALPHA:              return GL_DST_ALPHA;
        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return GL_ONE_MINUS_DST_ALPHA;
        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return GL_SRC_ALPHA_SATURATE;
        case SG_BLENDFACTOR_BLEND_COLOR:            return GL_CONSTANT_COLOR;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return GL_ONE_MINUS_CONSTANT_COLOR;
        case SG_BLENDFACTOR_BLEND_ALPHA:            return GL_CONSTANT_ALPHA;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return GL_ONE_MINUS_CONSTANT_ALPHA;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_blend_op(sg_blend_op op) {
    switch (op) {
        case SG_BLENDOP_ADD:                return GL_FUNC_ADD;
        case SG_BLENDOP_SUBTRACT:           return GL_FUNC_SUBTRACT;
        case SG_BLENDOP_REVERSE_SUBTRACT:   return GL_FUNC_REVERSE_SUBTRACT;
        case SG_BLENDOP_MIN:                return GL_MIN;
        case SG_BLENDOP_MAX:                return GL_MAX;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_min_filter(sg_filter min_f, sg_filter mipmap_f) {
    if (min_f == SG_FILTER_NEAREST) {
        switch (mipmap_f) {
            case SG_FILTER_NEAREST: return GL_NEAREST_MIPMAP_NEAREST;
            case SG_FILTER_LINEAR:  return GL_NEAREST_MIPMAP_LINEAR;
            default: SOKOL_UNREACHABLE; return (GLenum)0;
        }
    } else if (min_f == SG_FILTER_LINEAR) {
        switch (mipmap_f) {
            case SG_FILTER_NEAREST: return GL_LINEAR_MIPMAP_NEAREST;
            case SG_FILTER_LINEAR:  return GL_LINEAR_MIPMAP_LINEAR;
            default: SOKOL_UNREACHABLE; return (GLenum)0;
        }
    } else {
        SOKOL_UNREACHABLE; return (GLenum)0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_mag_filter(sg_filter mag_f) {
    if (mag_f == SG_FILTER_NEAREST) {
        return GL_NEAREST;
    } else {
        return GL_LINEAR;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_wrap(sg_wrap w) {
    switch (w) {
        case SG_WRAP_CLAMP_TO_EDGE:     return GL_CLAMP_TO_EDGE;
        #if defined(SOKOL_GLCORE)
        case SG_WRAP_CLAMP_TO_BORDER:   return GL_CLAMP_TO_BORDER;
        #else
        case SG_WRAP_CLAMP_TO_BORDER:   return GL_CLAMP_TO_EDGE;
        #endif
        case SG_WRAP_REPEAT:            return GL_REPEAT;
        case SG_WRAP_MIRRORED_REPEAT:   return GL_MIRRORED_REPEAT;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_teximage_type(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_R8:
        case SG_PIXELFORMAT_R8UI:
        case SG_PIXELFORMAT_RG8:
        case SG_PIXELFORMAT_RG8UI:
        case SG_PIXELFORMAT_RGBA8:
        case SG_PIXELFORMAT_SRGB8A8:
        case SG_PIXELFORMAT_RGBA8UI:
        case SG_PIXELFORMAT_BGRA8:
            return GL_UNSIGNED_BYTE;
        case SG_PIXELFORMAT_R8SN:
        case SG_PIXELFORMAT_R8SI:
        case SG_PIXELFORMAT_RG8SN:
        case SG_PIXELFORMAT_RG8SI:
        case SG_PIXELFORMAT_RGBA8SN:
        case SG_PIXELFORMAT_RGBA8SI:
            return GL_BYTE;
        case SG_PIXELFORMAT_R16:
        case SG_PIXELFORMAT_R16UI:
        case SG_PIXELFORMAT_RG16:
        case SG_PIXELFORMAT_RG16UI:
        case SG_PIXELFORMAT_RGBA16:
        case SG_PIXELFORMAT_RGBA16UI:
            return GL_UNSIGNED_SHORT;
        case SG_PIXELFORMAT_R16SN:
        case SG_PIXELFORMAT_R16SI:
        case SG_PIXELFORMAT_RG16SN:
        case SG_PIXELFORMAT_RG16SI:
        case SG_PIXELFORMAT_RGBA16SN:
        case SG_PIXELFORMAT_RGBA16SI:
            return GL_SHORT;
        case SG_PIXELFORMAT_R16F:
        case SG_PIXELFORMAT_RG16F:
        case SG_PIXELFORMAT_RGBA16F:
            return GL_HALF_FLOAT;
        case SG_PIXELFORMAT_R32UI:
        case SG_PIXELFORMAT_RG32UI:
        case SG_PIXELFORMAT_RGBA32UI:
            return GL_UNSIGNED_INT;
        case SG_PIXELFORMAT_R32SI:
        case SG_PIXELFORMAT_RG32SI:
        case SG_PIXELFORMAT_RGBA32SI:
            return GL_INT;
        case SG_PIXELFORMAT_R32F:
        case SG_PIXELFORMAT_RG32F:
        case SG_PIXELFORMAT_RGBA32F:
            return GL_FLOAT;
        case SG_PIXELFORMAT_RGB10A2:
            return GL_UNSIGNED_INT_2_10_10_10_REV;
        case SG_PIXELFORMAT_RG11B10F:
            return GL_UNSIGNED_INT_10F_11F_11F_REV;
        case SG_PIXELFORMAT_RGB9E5:
            return GL_UNSIGNED_INT_5_9_9_9_REV;
        case SG_PIXELFORMAT_DEPTH:
            return GL_FLOAT;
        case SG_PIXELFORMAT_DEPTH_STENCIL:
            return GL_UNSIGNED_INT_24_8;
        default:
            SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_teximage_format(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_R8:
        case SG_PIXELFORMAT_R8SN:
        case SG_PIXELFORMAT_R16:
        case SG_PIXELFORMAT_R16SN:
        case SG_PIXELFORMAT_R16F:
        case SG_PIXELFORMAT_R32F:
            return GL_RED;
        case SG_PIXELFORMAT_R8UI:
        case SG_PIXELFORMAT_R8SI:
        case SG_PIXELFORMAT_R16UI:
        case SG_PIXELFORMAT_R16SI:
        case SG_PIXELFORMAT_R32UI:
        case SG_PIXELFORMAT_R32SI:
            return GL_RED_INTEGER;
        case SG_PIXELFORMAT_RG8:
        case SG_PIXELFORMAT_RG8SN:
        case SG_PIXELFORMAT_RG16:
        case SG_PIXELFORMAT_RG16SN:
        case SG_PIXELFORMAT_RG16F:
        case SG_PIXELFORMAT_RG32F:
            return GL_RG;
        case SG_PIXELFORMAT_RG8UI:
        case SG_PIXELFORMAT_RG8SI:
        case SG_PIXELFORMAT_RG16UI:
        case SG_PIXELFORMAT_RG16SI:
        case SG_PIXELFORMAT_RG32UI:
        case SG_PIXELFORMAT_RG32SI:
            return GL_RG_INTEGER;
        case SG_PIXELFORMAT_RGBA8:
        case SG_PIXELFORMAT_SRGB8A8:
        case SG_PIXELFORMAT_RGBA8SN:
        case SG_PIXELFORMAT_RGBA16:
        case SG_PIXELFORMAT_RGBA16SN:
        case SG_PIXELFORMAT_RGBA16F:
        case SG_PIXELFORMAT_RGBA32F:
        case SG_PIXELFORMAT_RGB10A2:
            return GL_RGBA;
        case SG_PIXELFORMAT_RGBA8UI:
        case SG_PIXELFORMAT_RGBA8SI:
        case SG_PIXELFORMAT_RGBA16UI:
        case SG_PIXELFORMAT_RGBA16SI:
        case SG_PIXELFORMAT_RGBA32UI:
        case SG_PIXELFORMAT_RGBA32SI:
            return GL_RGBA_INTEGER;
        case SG_PIXELFORMAT_RG11B10F:
        case SG_PIXELFORMAT_RGB9E5:
            return GL_RGB;
        case SG_PIXELFORMAT_DEPTH:
            return GL_DEPTH_COMPONENT;
        case SG_PIXELFORMAT_DEPTH_STENCIL:
            return GL_DEPTH_STENCIL;
        case SG_PIXELFORMAT_BC1_RGBA:
            return GL_COMPRESSED_RGBA_S3TC_DXT1_EXT;
        case SG_PIXELFORMAT_BC2_RGBA:
            return GL_COMPRESSED_RGBA_S3TC_DXT3_EXT;
        case SG_PIXELFORMAT_BC3_RGBA:
            return GL_COMPRESSED_RGBA_S3TC_DXT5_EXT;
        case SG_PIXELFORMAT_BC3_SRGBA:
            return GL_COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT;
        case SG_PIXELFORMAT_BC4_R:
            return GL_COMPRESSED_RED_RGTC1;
        case SG_PIXELFORMAT_BC4_RSN:
            return GL_COMPRESSED_SIGNED_RED_RGTC1;
        case SG_PIXELFORMAT_BC5_RG:
            return GL_COMPRESSED_RED_GREEN_RGTC2;
        case SG_PIXELFORMAT_BC5_RGSN:
            return GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2;
        case SG_PIXELFORMAT_BC6H_RGBF:
            return GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB;
        case SG_PIXELFORMAT_BC6H_RGBUF:
            return GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB;
        case SG_PIXELFORMAT_BC7_RGBA:
            return GL_COMPRESSED_RGBA_BPTC_UNORM_ARB;
        case SG_PIXELFORMAT_BC7_SRGBA:
            return GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB;
        case SG_PIXELFORMAT_ETC2_RGB8:
            return GL_COMPRESSED_RGB8_ETC2;
        case SG_PIXELFORMAT_ETC2_SRGB8:
            return GL_COMPRESSED_SRGB8_ETC2;
        case SG_PIXELFORMAT_ETC2_RGB8A1:
            return GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2;
        case SG_PIXELFORMAT_ETC2_RGBA8:
            return GL_COMPRESSED_RGBA8_ETC2_EAC;
        case SG_PIXELFORMAT_ETC2_SRGB8A8:
            return GL_COMPRESSED_SRGB8_ALPHA8_ETC2_EAC;
        case SG_PIXELFORMAT_EAC_R11:
            return GL_COMPRESSED_R11_EAC;
        case SG_PIXELFORMAT_EAC_R11SN:
            return GL_COMPRESSED_SIGNED_R11_EAC;
        case SG_PIXELFORMAT_EAC_RG11:
            return GL_COMPRESSED_RG11_EAC;
        case SG_PIXELFORMAT_EAC_RG11SN:
            return GL_COMPRESSED_SIGNED_RG11_EAC;
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:
            return GL_COMPRESSED_RGBA_ASTC_4x4_KHR;
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA:
            return GL_COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR;
        default:
            SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_teximage_internal_format(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_R8:         return GL_R8;
        case SG_PIXELFORMAT_R8SN:       return GL_R8_SNORM;
        case SG_PIXELFORMAT_R8UI:       return GL_R8UI;
        case SG_PIXELFORMAT_R8SI:       return GL_R8I;
        #if !defined(SOKOL_GLES3)
            case SG_PIXELFORMAT_R16:        return GL_R16;
            case SG_PIXELFORMAT_R16SN:      return GL_R16_SNORM;
        #endif
        case SG_PIXELFORMAT_R16UI:      return GL_R16UI;
        case SG_PIXELFORMAT_R16SI:      return GL_R16I;
        case SG_PIXELFORMAT_R16F:       return GL_R16F;
        case SG_PIXELFORMAT_RG8:        return GL_RG8;
        case SG_PIXELFORMAT_RG8SN:      return GL_RG8_SNORM;
        case SG_PIXELFORMAT_RG8UI:      return GL_RG8UI;
        case SG_PIXELFORMAT_RG8SI:      return GL_RG8I;
        case SG_PIXELFORMAT_R32UI:      return GL_R32UI;
        case SG_PIXELFORMAT_R32SI:      return GL_R32I;
        case SG_PIXELFORMAT_R32F:       return GL_R32F;
        #if !defined(SOKOL_GLES3)
            case SG_PIXELFORMAT_RG16:       return GL_RG16;
            case SG_PIXELFORMAT_RG16SN:     return GL_RG16_SNORM;
        #endif
        case SG_PIXELFORMAT_RG16UI:     return GL_RG16UI;
        case SG_PIXELFORMAT_RG16SI:     return GL_RG16I;
        case SG_PIXELFORMAT_RG16F:      return GL_RG16F;
        case SG_PIXELFORMAT_RGBA8:      return GL_RGBA8;
        case SG_PIXELFORMAT_SRGB8A8:    return GL_SRGB8_ALPHA8;
        case SG_PIXELFORMAT_RGBA8SN:    return GL_RGBA8_SNORM;
        case SG_PIXELFORMAT_RGBA8UI:    return GL_RGBA8UI;
        case SG_PIXELFORMAT_RGBA8SI:    return GL_RGBA8I;
        case SG_PIXELFORMAT_RGB10A2:    return GL_RGB10_A2;
        case SG_PIXELFORMAT_RG11B10F:   return GL_R11F_G11F_B10F;
        case SG_PIXELFORMAT_RGB9E5:     return GL_RGB9_E5;
        case SG_PIXELFORMAT_RG32UI:     return GL_RG32UI;
        case SG_PIXELFORMAT_RG32SI:     return GL_RG32I;
        case SG_PIXELFORMAT_RG32F:      return GL_RG32F;
        #if !defined(SOKOL_GLES3)
            case SG_PIXELFORMAT_RGBA16:     return GL_RGBA16;
            case SG_PIXELFORMAT_RGBA16SN:   return GL_RGBA16_SNORM;
        #endif
        case SG_PIXELFORMAT_RGBA16UI:   return GL_RGBA16UI;
        case SG_PIXELFORMAT_RGBA16SI:   return GL_RGBA16I;
        case SG_PIXELFORMAT_RGBA16F:    return GL_RGBA16F;
        case SG_PIXELFORMAT_RGBA32UI:   return GL_RGBA32UI;
        case SG_PIXELFORMAT_RGBA32SI:   return GL_RGBA32I;
        case SG_PIXELFORMAT_RGBA32F:    return GL_RGBA32F;
        case SG_PIXELFORMAT_DEPTH:      return GL_DEPTH_COMPONENT32F;
        case SG_PIXELFORMAT_DEPTH_STENCIL:      return GL_DEPTH24_STENCIL8;
        case SG_PIXELFORMAT_BC1_RGBA:           return GL_COMPRESSED_RGBA_S3TC_DXT1_EXT;
        case SG_PIXELFORMAT_BC2_RGBA:           return GL_COMPRESSED_RGBA_S3TC_DXT3_EXT;
        case SG_PIXELFORMAT_BC3_RGBA:           return GL_COMPRESSED_RGBA_S3TC_DXT5_EXT;
        case SG_PIXELFORMAT_BC3_SRGBA:          return GL_COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT;
        case SG_PIXELFORMAT_BC4_R:              return GL_COMPRESSED_RED_RGTC1;
        case SG_PIXELFORMAT_BC4_RSN:            return GL_COMPRESSED_SIGNED_RED_RGTC1;
        case SG_PIXELFORMAT_BC5_RG:             return GL_COMPRESSED_RED_GREEN_RGTC2;
        case SG_PIXELFORMAT_BC5_RGSN:           return GL_COMPRESSED_SIGNED_RED_GREEN_RGTC2;
        case SG_PIXELFORMAT_BC6H_RGBF:          return GL_COMPRESSED_RGB_BPTC_SIGNED_FLOAT_ARB;
        case SG_PIXELFORMAT_BC6H_RGBUF:         return GL_COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_ARB;
        case SG_PIXELFORMAT_BC7_RGBA:           return GL_COMPRESSED_RGBA_BPTC_UNORM_ARB;
        case SG_PIXELFORMAT_BC7_SRGBA:          return GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB;
        case SG_PIXELFORMAT_ETC2_RGB8:          return GL_COMPRESSED_RGB8_ETC2;
        case SG_PIXELFORMAT_ETC2_SRGB8:         return GL_COMPRESSED_SRGB8_ETC2;
        case SG_PIXELFORMAT_ETC2_RGB8A1:        return GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2;
        case SG_PIXELFORMAT_ETC2_RGBA8:         return GL_COMPRESSED_RGBA8_ETC2_EAC;
        case SG_PIXELFORMAT_ETC2_SRGB8A8:       return GL_COMPRESSED_SRGB8_ALPHA8_ETC2_EAC;
        case SG_PIXELFORMAT_EAC_R11:            return GL_COMPRESSED_R11_EAC;
        case SG_PIXELFORMAT_EAC_R11SN:          return GL_COMPRESSED_SIGNED_R11_EAC;
        case SG_PIXELFORMAT_EAC_RG11:           return GL_COMPRESSED_RG11_EAC;
        case SG_PIXELFORMAT_EAC_RG11SN:         return GL_COMPRESSED_SIGNED_RG11_EAC;
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:      return GL_COMPRESSED_RGBA_ASTC_4x4_KHR;
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA:     return GL_COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_cubeface_target(int face_index) {
    switch (face_index) {
        case 0: return GL_TEXTURE_CUBE_MAP_POSITIVE_X;
        case 1: return GL_TEXTURE_CUBE_MAP_NEGATIVE_X;
        case 2: return GL_TEXTURE_CUBE_MAP_POSITIVE_Y;
        case 3: return GL_TEXTURE_CUBE_MAP_NEGATIVE_Y;
        case 4: return GL_TEXTURE_CUBE_MAP_POSITIVE_Z;
        case 5: return GL_TEXTURE_CUBE_MAP_NEGATIVE_Z;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

// see: https://www.khronos.org/registry/OpenGL-Refpages/es3.0/html/glTexImage2D.xhtml
_SOKOL_PRIVATE void _sg_gl_init_pixelformats(bool has_bgra) {
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R8SN]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8SI]);
    #if !defined(SOKOL_GLES3)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16SN]);
    #endif
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16SI]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG8SN]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32SI]);
    #if !defined(SOKOL_GLES3)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16SN]);
    #endif
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16SI]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_SRGB8A8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);
    if (has_bgra) {
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_BGRA8]);
    }
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB10A2]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGB9E5]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    #if !defined(SOKOL_GLES3)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SN]);
    #endif
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);
    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH]);
    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL]);
}

// FIXME: OES_half_float_blend
_SOKOL_PRIVATE void _sg_gl_init_pixelformats_half_float(bool has_colorbuffer_half_float) {
    if (has_colorbuffer_half_float) {
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16F]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16F]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    } else {
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R16F]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG16F]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    }
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_float(bool has_colorbuffer_float, bool has_texture_float_linear, bool has_float_blend) {
    if (has_texture_float_linear) {
        if (has_colorbuffer_float) {
            if (has_float_blend) {
                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R32F]);
                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);
                _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
            } else {
                _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_R32F]);
                _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_RG32F]);
                _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
            }
            _sg_pixelformat_sfrm(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);
        } else {
            _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R32F]);
            _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG32F]);
            _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
            _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);
        }
    } else {
        if (has_colorbuffer_float) {
            _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_R32F]);
            _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RG32F]);
            _sg_pixelformat_sbrm(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
            _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);
        } else {
            _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_R32F]);
            _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RG32F]);
            _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
            _sg_pixelformat_s(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);
        }
    }
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_s3tc(void) {
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC1_RGBA]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC2_RGBA]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_RGBA]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_SRGBA]);
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_rgtc(void) {
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_R]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_RSN]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RG]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RGSN]);
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_bptc(void) {
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBF]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBUF]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_RGBA]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_SRGBA]);
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_etc2(void) {
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_SRGB8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8A1]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGBA8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_SRGB8A8]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_R11]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_R11SN]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_RG11]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_RG11SN]);
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_astc(void) {
     _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ASTC_4x4_RGBA]);
     _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ASTC_4x4_SRGBA]);
}

_SOKOL_PRIVATE void _sg_gl_init_pixelformats_compute(void) {
    // using Vulkan's conservative default caps (see: https://github.com/gpuweb/gpuweb/issues/513)
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
}

_SOKOL_PRIVATE void _sg_gl_init_limits(void) {
    _SG_GL_CHECK_ERROR();
    GLint gl_int;
    glGetIntegerv(GL_MAX_TEXTURE_SIZE, &gl_int);
    _SG_GL_CHECK_ERROR();
    _sg.limits.max_image_size_2d = gl_int;
    _sg.limits.max_image_size_array = gl_int;
    glGetIntegerv(GL_MAX_CUBE_MAP_TEXTURE_SIZE, &gl_int);
    _SG_GL_CHECK_ERROR();
    _sg.limits.max_image_size_cube = gl_int;
    glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &gl_int);
    _SG_GL_CHECK_ERROR();
    if (gl_int > SG_MAX_VERTEX_ATTRIBUTES) {
        gl_int = SG_MAX_VERTEX_ATTRIBUTES;
    }
    _sg.limits.max_vertex_attrs = gl_int;
    glGetIntegerv(GL_MAX_VERTEX_UNIFORM_COMPONENTS, &gl_int);
    _SG_GL_CHECK_ERROR();
    _sg.limits.gl_max_vertex_uniform_components = gl_int;
    glGetIntegerv(GL_MAX_3D_TEXTURE_SIZE, &gl_int);
    _SG_GL_CHECK_ERROR();
    _sg.limits.max_image_size_3d = gl_int;
    glGetIntegerv(GL_MAX_ARRAY_TEXTURE_LAYERS, &gl_int);
    _SG_GL_CHECK_ERROR();
    _sg.limits.max_image_array_layers = gl_int;
    if (_sg.gl.ext_anisotropic) {
        glGetIntegerv(GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT, &gl_int);
        _SG_GL_CHECK_ERROR();
        _sg.gl.max_anisotropy = gl_int;
    } else {
        _sg.gl.max_anisotropy = 1;
    }
    glGetIntegerv(GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS, &gl_int);
    _SG_GL_CHECK_ERROR();
    _sg.limits.gl_max_combined_texture_image_units = gl_int;
}

#if defined(SOKOL_GLCORE)
_SOKOL_PRIVATE void _sg_gl_init_caps_glcore(void) {
    _sg.backend = SG_BACKEND_GLCORE;

    GLint major_version = 0;
    GLint minor_version = 0;
    glGetIntegerv(GL_MAJOR_VERSION, &major_version);
    glGetIntegerv(GL_MINOR_VERSION, &minor_version);
    const int version = major_version * 100 + minor_version * 10;
    _sg.features.origin_top_left = false;
    _sg.features.image_clamp_to_border = true;
    _sg.features.mrt_independent_blend_state = false;
    _sg.features.mrt_independent_write_mask = true;
    _sg.features.compute = version >= 430;
    #if defined(__APPLE__)
    _sg.features.msaa_image_bindings = false;
    #else
    _sg.features.msaa_image_bindings = true;
    #endif

    // scan extensions
    bool has_s3tc = false;  // BC1..BC3
    bool has_rgtc = false;  // BC4 and BC5
    bool has_bptc = false;  // BC6H and BC7
    bool has_etc2 = false;
    bool has_astc = false;
    GLint num_ext = 0;
    glGetIntegerv(GL_NUM_EXTENSIONS, &num_ext);
    for (int i = 0; i < num_ext; i++) {
        const char* ext = (const char*) glGetStringi(GL_EXTENSIONS, (GLuint)i);
        if (ext) {
            if (strstr(ext, "_texture_compression_s3tc")) {
                has_s3tc = true;
            } else if (strstr(ext, "_texture_compression_rgtc")) {
                has_rgtc = true;
            } else if (strstr(ext, "_texture_compression_bptc")) {
                has_bptc = true;
            } else if (strstr(ext, "_ES3_compatibility")) {
                has_etc2 = true;
            } else if (strstr(ext, "_texture_filter_anisotropic")) {
                _sg.gl.ext_anisotropic = true;
            } else if (strstr(ext, "_texture_compression_astc_ldr")) {
                has_astc = true;
            }
        }
    }

    // limits
    _sg_gl_init_limits();

    // pixel formats
    const bool has_bgra = false;    // not a bug
    const bool has_colorbuffer_float = true;
    const bool has_colorbuffer_half_float = true;
    const bool has_texture_float_linear = true; // FIXME???
    const bool has_float_blend = true;
    _sg_gl_init_pixelformats(has_bgra);
    _sg_gl_init_pixelformats_float(has_colorbuffer_float, has_texture_float_linear, has_float_blend);
    _sg_gl_init_pixelformats_half_float(has_colorbuffer_half_float);
    if (has_s3tc) {
        _sg_gl_init_pixelformats_s3tc();
    }
    if (has_rgtc) {
        _sg_gl_init_pixelformats_rgtc();
    }
    if (has_bptc) {
        _sg_gl_init_pixelformats_bptc();
    }
    if (has_etc2) {
        _sg_gl_init_pixelformats_etc2();
    }
    if (has_astc) {
        _sg_gl_init_pixelformats_astc();
    }
    if (_sg.features.compute) {
        _sg_gl_init_pixelformats_compute();
    }
}
#endif

#if defined(SOKOL_GLES3)
_SOKOL_PRIVATE void _sg_gl_init_caps_gles3(void) {
    _sg.backend = SG_BACKEND_GLES3;

    GLint major_version = 0;
    GLint minor_version = 0;
    glGetIntegerv(GL_MAJOR_VERSION, &major_version);
    glGetIntegerv(GL_MINOR_VERSION, &minor_version);
    const int version = major_version * 100 + minor_version * 10;
    _sg.features.origin_top_left = false;
    _sg.features.image_clamp_to_border = false;
    _sg.features.mrt_independent_blend_state = false;
    _sg.features.mrt_independent_write_mask = false;
    _sg.features.compute = version >= 310;
    _sg.features.msaa_image_bindings = false;
    #if defined(__EMSCRIPTEN__)
    _sg.features.separate_buffer_types = true;
    #else
    _sg.features.separate_buffer_types = false;
    #endif

    bool has_s3tc = false;  // BC1..BC3
    bool has_rgtc = false;  // BC4 and BC5
    bool has_bptc = false;  // BC6H and BC7
    #if defined(__EMSCRIPTEN__)
        bool has_etc2 = false;
    #else
        bool has_etc2 = true;
    #endif
    bool has_astc = false;
    bool has_colorbuffer_float = false;
    bool has_colorbuffer_half_float = false;
    bool has_texture_float_linear = false;
    bool has_float_blend = false;
    GLint num_ext = 0;
    glGetIntegerv(GL_NUM_EXTENSIONS, &num_ext);
    for (int i = 0; i < num_ext; i++) {
        const char* ext = (const char*) glGetStringi(GL_EXTENSIONS, (GLuint)i);
        if (ext) {
            if (strstr(ext, "_texture_compression_s3tc")) {
                has_s3tc = true;
            } else if (strstr(ext, "_compressed_texture_s3tc")) {
                has_s3tc = true;
            } else if (strstr(ext, "_texture_compression_rgtc")) {
                has_rgtc = true;
            } else if (strstr(ext, "_texture_compression_bptc")) {
                has_bptc = true;
            } else if (strstr(ext, "_compressed_texture_etc")) {
                has_etc2 = true;
            } else if (strstr(ext, "_compressed_texture_astc")) {
                has_astc = true;
            } else if (strstr(ext, "_color_buffer_float")) {
                has_colorbuffer_float = true;
            } else if (strstr(ext, "_color_buffer_half_float")) {
                has_colorbuffer_half_float = true;
            } else if (strstr(ext, "_texture_float_linear")) {
                has_texture_float_linear = true;
            } else if (strstr(ext, "_float_blend")) {
                has_float_blend = true;
            } else if (strstr(ext, "_texture_filter_anisotropic")) {
                _sg.gl.ext_anisotropic = true;
            }
        }
    }

    /* on WebGL2, color_buffer_float also includes 16-bit formats
       see: https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_float
    */
    #if defined(__EMSCRIPTEN__)
    if (!has_colorbuffer_half_float && has_colorbuffer_float) {
        has_colorbuffer_half_float = has_colorbuffer_float;
    }
    #endif

    // limits
    _sg_gl_init_limits();

    // pixel formats
    const bool has_bgra = false;    // not a bug
    _sg_gl_init_pixelformats(has_bgra);
    _sg_gl_init_pixelformats_float(has_colorbuffer_float, has_texture_float_linear, has_float_blend);
    _sg_gl_init_pixelformats_half_float(has_colorbuffer_half_float);
    if (has_s3tc) {
        _sg_gl_init_pixelformats_s3tc();
    }
    if (has_rgtc) {
        _sg_gl_init_pixelformats_rgtc();
    }
    if (has_bptc) {
        _sg_gl_init_pixelformats_bptc();
    }
    if (has_etc2) {
        _sg_gl_init_pixelformats_etc2();
    }
    if (has_astc) {
        _sg_gl_init_pixelformats_astc();
    }
    if (_sg.features.compute) {
        _sg_gl_init_pixelformats_compute();
    }
}
#endif

//-- state cache implementation ------------------------------------------------
_SOKOL_PRIVATE void _sg_gl_cache_clear_buffer_bindings(bool force) {
    if (force || (_sg.gl.cache.vertex_buffer != 0)) {
        glBindBuffer(GL_ARRAY_BUFFER, 0);
        _sg.gl.cache.vertex_buffer = 0;
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
    if (force || (_sg.gl.cache.index_buffer != 0)) {
        glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);
        _sg.gl.cache.index_buffer = 0;
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
    if (force || (_sg.gl.cache.storage_buffer != 0)) {
        if (_sg.features.compute) {
            glBindBuffer(GL_SHADER_STORAGE_BUFFER, 0);
        }
        _sg.gl.cache.storage_buffer = 0;
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
    for (size_t i = 0; i < _SG_GL_MAX_SBUF_BINDINGS; i++) {
        if (force || (_sg.gl.cache.storage_buffers[i] != 0)) {
            if (_sg.features.compute) {
                glBindBufferBase(GL_SHADER_STORAGE_BUFFER, (GLuint)i, 0);
            }
            _sg.gl.cache.storage_buffers[i] = 0;
            _sg_stats_add(gl.num_bind_buffer, 1);
        }
    }
}

_SOKOL_PRIVATE void _sg_gl_cache_bind_buffer(GLenum target, GLuint buffer) {
    SOKOL_ASSERT((GL_ARRAY_BUFFER == target) || (GL_ELEMENT_ARRAY_BUFFER == target) || (GL_SHADER_STORAGE_BUFFER == target));
    if (target == GL_ARRAY_BUFFER) {
        if (_sg.gl.cache.vertex_buffer != buffer) {
            _sg.gl.cache.vertex_buffer = buffer;
            glBindBuffer(target, buffer);
            _sg_stats_add(gl.num_bind_buffer, 1);
        }
    } else if (target == GL_ELEMENT_ARRAY_BUFFER) {
        if (_sg.gl.cache.index_buffer != buffer) {
            _sg.gl.cache.index_buffer = buffer;
            glBindBuffer(target, buffer);
            _sg_stats_add(gl.num_bind_buffer, 1);
        }
    } else if (target == GL_SHADER_STORAGE_BUFFER) {
        if (_sg.gl.cache.storage_buffer != buffer) {
            _sg.gl.cache.storage_buffer = buffer;
            if (_sg.features.compute) {
                glBindBuffer(target, buffer);
            }
            _sg_stats_add(gl.num_bind_buffer, 1);
        }
    } else {
        SOKOL_UNREACHABLE;
    }
}

_SOKOL_PRIVATE void _sg_gl_cache_bind_storage_buffer(uint8_t glsl_binding_n, GLuint buffer) {
    SOKOL_ASSERT(glsl_binding_n < _SG_GL_MAX_SBUF_BINDINGS);
    if (_sg.gl.cache.storage_buffers[glsl_binding_n] != buffer) {
        _sg.gl.cache.storage_buffers[glsl_binding_n] = buffer;
        _sg.gl.cache.storage_buffer = buffer; // not a bug
        if (_sg.features.compute) {
            glBindBufferBase(GL_SHADER_STORAGE_BUFFER, glsl_binding_n, buffer);
        }
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
}

_SOKOL_PRIVATE void _sg_gl_cache_store_buffer_binding(GLenum target) {
    if (target == GL_ARRAY_BUFFER) {
        _sg.gl.cache.stored_vertex_buffer = _sg.gl.cache.vertex_buffer;
    } else if (target == GL_ELEMENT_ARRAY_BUFFER) {
        _sg.gl.cache.stored_index_buffer = _sg.gl.cache.index_buffer;
    } else if (target == GL_SHADER_STORAGE_BUFFER) {
        _sg.gl.cache.stored_storage_buffer = _sg.gl.cache.storage_buffer;
    } else {
        SOKOL_UNREACHABLE;
    }
}

_SOKOL_PRIVATE void _sg_gl_cache_restore_buffer_binding(GLenum target) {
    if (target == GL_ARRAY_BUFFER) {
        if (_sg.gl.cache.stored_vertex_buffer != 0) {
            // we only care about restoring valid ids
            _sg_gl_cache_bind_buffer(target, _sg.gl.cache.stored_vertex_buffer);
            _sg.gl.cache.stored_vertex_buffer = 0;
        }
    } else if (target == GL_ELEMENT_ARRAY_BUFFER) {
        if (_sg.gl.cache.stored_index_buffer != 0) {
            // we only care about restoring valid ids
            _sg_gl_cache_bind_buffer(target, _sg.gl.cache.stored_index_buffer);
            _sg.gl.cache.stored_index_buffer = 0;
        }
    } else if (target == GL_SHADER_STORAGE_BUFFER) {
        if (_sg.gl.cache.stored_storage_buffer != 0) {
            // we only care about restoring valid ids
            _sg_gl_cache_bind_buffer(target, _sg.gl.cache.stored_storage_buffer);
            _sg.gl.cache.stored_storage_buffer = 0;
        }
    } else {
        SOKOL_UNREACHABLE;
    }
}

// called from _sg_gl_discard_buffer()
_SOKOL_PRIVATE void _sg_gl_cache_invalidate_buffer(GLuint buf) {
    if (buf == _sg.gl.cache.vertex_buffer) {
        _sg.gl.cache.vertex_buffer = 0;
        glBindBuffer(GL_ARRAY_BUFFER, 0);
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
    if (buf == _sg.gl.cache.index_buffer) {
        _sg.gl.cache.index_buffer = 0;
        glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
    if (buf == _sg.gl.cache.storage_buffer) {
        _sg.gl.cache.storage_buffer = 0;
        glBindBuffer(GL_SHADER_STORAGE_BUFFER, 0);
        _sg_stats_add(gl.num_bind_buffer, 1);
    }
    for (size_t i = 0; i < _SG_GL_MAX_SBUF_BINDINGS; i++) {
        if (buf == _sg.gl.cache.storage_buffers[i]) {
            _sg.gl.cache.storage_buffers[i] = 0;
            _sg.gl.cache.storage_buffer = 0; // not a bug!
            glBindBufferBase(GL_SHADER_STORAGE_BUFFER, (GLuint)i, 0);
            _sg_stats_add(gl.num_bind_buffer, 1);
        }
    }
    if (buf == _sg.gl.cache.stored_vertex_buffer) {
        _sg.gl.cache.stored_vertex_buffer = 0;
    }
    if (buf == _sg.gl.cache.stored_index_buffer) {
        _sg.gl.cache.stored_index_buffer = 0;
    }
    if (buf == _sg.gl.cache.stored_storage_buffer) {
        _sg.gl.cache.stored_storage_buffer = 0;
    }
    for (int i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {
        if (buf == _sg.gl.cache.attrs[i].gl_vbuf) {
            _sg.gl.cache.attrs[i].gl_vbuf = 0;
        }
    }
}

_SOKOL_PRIVATE void _sg_gl_cache_active_texture(GLenum texture) {
    _SG_GL_CHECK_ERROR();
    if (_sg.gl.cache.cur_active_texture != texture) {
        _sg.gl.cache.cur_active_texture = texture;
        glActiveTexture(texture);
        _sg_stats_add(gl.num_active_texture, 1);
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_cache_clear_texture_sampler_bindings(bool force) {
    _SG_GL_CHECK_ERROR();
    for (int i = 0; (i < _SG_GL_MAX_IMG_SMP_BINDINGS) && (i < _sg.limits.gl_max_combined_texture_image_units); i++) {
        if (force || (_sg.gl.cache.texture_samplers[i].texture != 0)) {
            GLenum gl_texture_unit = (GLenum) (GL_TEXTURE0 + i);
            glActiveTexture(gl_texture_unit);
            _sg_stats_add(gl.num_active_texture, 1);
            glBindTexture(GL_TEXTURE_2D, 0);
            glBindTexture(GL_TEXTURE_CUBE_MAP, 0);
            glBindTexture(GL_TEXTURE_3D, 0);
            glBindTexture(GL_TEXTURE_2D_ARRAY, 0);
            _sg_stats_add(gl.num_bind_texture, 4);
            glBindSampler((GLuint)i, 0);
            _sg_stats_add(gl.num_bind_sampler, 1);
            _sg.gl.cache.texture_samplers[i].target = 0;
            _sg.gl.cache.texture_samplers[i].texture = 0;
            _sg.gl.cache.texture_samplers[i].sampler = 0;
            _sg.gl.cache.cur_active_texture = gl_texture_unit;
        }
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_cache_bind_texture_sampler(int8_t gl_tex_slot, GLenum target, GLuint texture, GLuint sampler) {
    /* it's valid to call this function with target=0 and/or texture=0
       target=0 will unbind the previous binding, texture=0 will clear
       the new binding
    */
    SOKOL_ASSERT((gl_tex_slot >= 0) && (gl_tex_slot < _SG_GL_MAX_IMG_SMP_BINDINGS));
    if (gl_tex_slot >= _sg.limits.gl_max_combined_texture_image_units) {
        return;
    }
    _SG_GL_CHECK_ERROR();
    _sg_gl_cache_texture_sampler_bind_slot* slot = &_sg.gl.cache.texture_samplers[gl_tex_slot];
    if ((slot->target != target) || (slot->texture != texture) || (slot->sampler != sampler)) {
        _sg_gl_cache_active_texture((GLenum)(GL_TEXTURE0 + gl_tex_slot));
        // if the target has changed, clear the previous binding on that target
        if ((target != slot->target) && (slot->target != 0)) {
            glBindTexture(slot->target, 0);
            _SG_GL_CHECK_ERROR();
            _sg_stats_add(gl.num_bind_texture, 1);
        }
        // apply new binding (can be 0 to unbind)
        if (target != 0) {
            glBindTexture(target, texture);
            _SG_GL_CHECK_ERROR();
            _sg_stats_add(gl.num_bind_texture, 1);
        }
        // apply new sampler (can be 0 to unbind)
        glBindSampler((GLuint)gl_tex_slot, sampler);
        _SG_GL_CHECK_ERROR();
        _sg_stats_add(gl.num_bind_sampler, 1);

        slot->target = target;
        slot->texture = texture;
        slot->sampler = sampler;
    }
}

_SOKOL_PRIVATE void _sg_gl_cache_store_texture_sampler_binding(int8_t gl_tex_slot) {
    SOKOL_ASSERT((gl_tex_slot >= 0) && (gl_tex_slot < _SG_GL_MAX_IMG_SMP_BINDINGS));
    _sg.gl.cache.stored_texture_sampler = _sg.gl.cache.texture_samplers[gl_tex_slot];
}

_SOKOL_PRIVATE void _sg_gl_cache_restore_texture_sampler_binding(int8_t gl_tex_slot) {
    SOKOL_ASSERT((gl_tex_slot >= 0) && (gl_tex_slot < _SG_GL_MAX_IMG_SMP_BINDINGS));
    _sg_gl_cache_texture_sampler_bind_slot* slot = &_sg.gl.cache.stored_texture_sampler;
    if (slot->texture != 0) {
        // we only care about restoring valid ids
        SOKOL_ASSERT(slot->target != 0);
        _sg_gl_cache_bind_texture_sampler(gl_tex_slot, slot->target, slot->texture, slot->sampler);
        slot->target = 0;
        slot->texture = 0;
        slot->sampler = 0;
    }
}

// called from _sg_gl_discard_texture() and _sg_gl_discard_sampler()
_SOKOL_PRIVATE void _sg_gl_cache_invalidate_texture_sampler(GLuint tex, GLuint smp) {
    _SG_GL_CHECK_ERROR();
    for (size_t i = 0; i < _SG_GL_MAX_IMG_SMP_BINDINGS; i++) {
        _sg_gl_cache_texture_sampler_bind_slot* slot = &_sg.gl.cache.texture_samplers[i];
        if ((0 != slot->target) && ((tex == slot->texture) || (smp == slot->sampler))) {
            _sg_gl_cache_active_texture((GLenum)(GL_TEXTURE0 + i));
            glBindTexture(slot->target, 0);
            _SG_GL_CHECK_ERROR();
            _sg_stats_add(gl.num_bind_texture, 1);
            glBindSampler((GLuint)i, 0);
            _SG_GL_CHECK_ERROR();
            _sg_stats_add(gl.num_bind_sampler, 1);
            slot->target = 0;
            slot->texture = 0;
            slot->sampler = 0;
        }
    }
    if ((tex == _sg.gl.cache.stored_texture_sampler.texture) || (smp == _sg.gl.cache.stored_texture_sampler.sampler)) {
        _sg.gl.cache.stored_texture_sampler.target = 0;
        _sg.gl.cache.stored_texture_sampler.texture = 0;
        _sg.gl.cache.stored_texture_sampler.sampler = 0;
    }
}

// called from _sg_gl_discard_shader()
_SOKOL_PRIVATE void _sg_gl_cache_invalidate_program(GLuint prog) {
    if (prog == _sg.gl.cache.prog) {
        _sg.gl.cache.prog = 0;
        glUseProgram(0);
        _sg_stats_add(gl.num_use_program, 1);
    }
}

// called from _sg_gl_discard_pipeline()
_SOKOL_PRIVATE void _sg_gl_cache_invalidate_pipeline(_sg_pipeline_t* pip) {
    if (pip == _sg.gl.cache.cur_pipeline) {
        _sg.gl.cache.cur_pipeline = 0;
        _sg.gl.cache.cur_pipeline_id.id = SG_INVALID_ID;
    }
}

_SOKOL_PRIVATE void _sg_gl_reset_state_cache(void) {
    _SG_GL_CHECK_ERROR();
    glBindVertexArray(_sg.gl.vao);
    _SG_GL_CHECK_ERROR();
    _sg_clear(&_sg.gl.cache, sizeof(_sg.gl.cache));
    _sg_gl_cache_clear_buffer_bindings(true);
    _SG_GL_CHECK_ERROR();
    _sg_gl_cache_clear_texture_sampler_bindings(true);
    _SG_GL_CHECK_ERROR();
    for (int i = 0; i < _sg.limits.max_vertex_attrs; i++) {
        _sg_gl_attr_t* attr = &_sg.gl.cache.attrs[i].gl_attr;
        attr->vb_index = -1;
        attr->divisor = -1;
        glDisableVertexAttribArray((GLuint)i);
        _SG_GL_CHECK_ERROR();
        _sg_stats_add(gl.num_disable_vertex_attrib_array, 1);
    }
    _sg.gl.cache.cur_primitive_type = GL_TRIANGLES;

    // shader program
    glGetIntegerv(GL_CURRENT_PROGRAM, (GLint*)&_sg.gl.cache.prog);
    _SG_GL_CHECK_ERROR();

    // depth and stencil state
    _sg.gl.cache.depth.compare = SG_COMPAREFUNC_ALWAYS;
    _sg.gl.cache.stencil.front.compare = SG_COMPAREFUNC_ALWAYS;
    _sg.gl.cache.stencil.front.fail_op = SG_STENCILOP_KEEP;
    _sg.gl.cache.stencil.front.depth_fail_op = SG_STENCILOP_KEEP;
    _sg.gl.cache.stencil.front.pass_op = SG_STENCILOP_KEEP;
    _sg.gl.cache.stencil.back.compare = SG_COMPAREFUNC_ALWAYS;
    _sg.gl.cache.stencil.back.fail_op = SG_STENCILOP_KEEP;
    _sg.gl.cache.stencil.back.depth_fail_op = SG_STENCILOP_KEEP;
    _sg.gl.cache.stencil.back.pass_op = SG_STENCILOP_KEEP;
    glEnable(GL_DEPTH_TEST);
    glDepthFunc(GL_ALWAYS);
    glDepthMask(GL_FALSE);
    glDisable(GL_STENCIL_TEST);
    glStencilFunc(GL_ALWAYS, 0, 0);
    glStencilOp(GL_KEEP, GL_KEEP, GL_KEEP);
    glStencilMask(0);
    _sg_stats_add(gl.num_render_state, 7);

    // blend state
    _sg.gl.cache.blend.src_factor_rgb = SG_BLENDFACTOR_ONE;
    _sg.gl.cache.blend.dst_factor_rgb = SG_BLENDFACTOR_ZERO;
    _sg.gl.cache.blend.op_rgb = SG_BLENDOP_ADD;
    _sg.gl.cache.blend.src_factor_alpha = SG_BLENDFACTOR_ONE;
    _sg.gl.cache.blend.dst_factor_alpha = SG_BLENDFACTOR_ZERO;
    _sg.gl.cache.blend.op_alpha = SG_BLENDOP_ADD;
    glDisable(GL_BLEND);
    glBlendFuncSeparate(GL_ONE, GL_ZERO, GL_ONE, GL_ZERO);
    glBlendEquationSeparate(GL_FUNC_ADD, GL_FUNC_ADD);
    glBlendColor(0.0f, 0.0f, 0.0f, 0.0f);
    _sg_stats_add(gl.num_render_state, 4);

    // standalone state
    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        _sg.gl.cache.color_write_mask[i] = SG_COLORMASK_RGBA;
    }
    _sg.gl.cache.cull_mode = SG_CULLMODE_NONE;
    _sg.gl.cache.face_winding = SG_FACEWINDING_CW;
    _sg.gl.cache.sample_count = 1;
    glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE);
    glPolygonOffset(0.0f, 0.0f);
    glDisable(GL_POLYGON_OFFSET_FILL);
    glDisable(GL_CULL_FACE);
    glFrontFace(GL_CW);
    glCullFace(GL_BACK);
    glEnable(GL_SCISSOR_TEST);
    glDisable(GL_SAMPLE_ALPHA_TO_COVERAGE);
    glEnable(GL_DITHER);
    glDisable(GL_POLYGON_OFFSET_FILL);
    _sg_stats_add(gl.num_render_state, 10);
    #if defined(SOKOL_GLCORE)
        glEnable(GL_MULTISAMPLE);
        glEnable(GL_PROGRAM_POINT_SIZE);
        _sg_stats_add(gl.num_render_state, 2);
    #endif
}

_SOKOL_PRIVATE void _sg_gl_setup_backend(const sg_desc* desc) {
    _SOKOL_UNUSED(desc);

    // assumes that _sg.gl is already zero-initialized
    _sg.gl.valid = true;

    #if defined(_SOKOL_USE_WIN32_GL_LOADER)
    _sg_gl_load_opengl();
    #endif

    // clear initial GL error state
    #if defined(SOKOL_DEBUG)
        while (glGetError() != GL_NO_ERROR);
    #endif
    #if defined(SOKOL_GLCORE)
        _sg_gl_init_caps_glcore();
    #elif defined(SOKOL_GLES3)
        _sg_gl_init_caps_gles3();
    #endif

    glGenVertexArrays(1, &_sg.gl.vao);
    glBindVertexArray(_sg.gl.vao);
    _SG_GL_CHECK_ERROR();
    // incoming texture data is generally expected to be packed tightly
    glPixelStorei(GL_UNPACK_ALIGNMENT, 1);
    #if defined(SOKOL_GLCORE)
        // enable seamless cubemap sampling (only desktop GL)
        glEnable(GL_TEXTURE_CUBE_MAP_SEAMLESS);
    #endif
    _sg_gl_reset_state_cache();
}

_SOKOL_PRIVATE void _sg_gl_discard_backend(void) {
    SOKOL_ASSERT(_sg.gl.valid);
    if (_sg.gl.vao) {
        glDeleteVertexArrays(1, &_sg.gl.vao);
    }
    #if defined(_SOKOL_USE_WIN32_GL_LOADER)
    _sg_gl_unload_opengl();
    #endif
    _sg.gl.valid = false;
}

//-- GL backend resource creation and destruction ------------------------------
_SOKOL_PRIVATE sg_resource_state _sg_gl_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(buf && desc);
    _SG_GL_CHECK_ERROR();
    buf->gl.injected = (0 != desc->gl_buffers[0]);
    const GLenum gl_target = _sg_gl_buffer_target(&buf->cmn.usage);
    const GLenum gl_usage  = _sg_gl_buffer_usage(&buf->cmn.usage);
    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {
        GLuint gl_buf = 0;
        if (buf->gl.injected) {
            SOKOL_ASSERT(desc->gl_buffers[slot]);
            gl_buf = desc->gl_buffers[slot];
        } else {
            glGenBuffers(1, &gl_buf);
            SOKOL_ASSERT(gl_buf);
            _sg_gl_cache_store_buffer_binding(gl_target);
            _sg_gl_cache_bind_buffer(gl_target, gl_buf);
            glBufferData(gl_target, buf->cmn.size, 0, gl_usage);
            if (desc->data.ptr) {
                glBufferSubData(gl_target, 0, buf->cmn.size, desc->data.ptr);
            }
            _sg_gl_cache_restore_buffer_binding(gl_target);
        }
        buf->gl.buf[slot] = gl_buf;
    }
    _SG_GL_CHECK_ERROR();
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_gl_discard_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf);
    _SG_GL_CHECK_ERROR();
    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {
        if (buf->gl.buf[slot]) {
            _sg_gl_cache_invalidate_buffer(buf->gl.buf[slot]);
            if (!buf->gl.injected) {
                glDeleteBuffers(1, &buf->gl.buf[slot]);
            }
        }
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE bool _sg_gl_supported_texture_format(sg_pixel_format fmt) {
    const int fmt_index = (int) fmt;
    SOKOL_ASSERT((fmt_index > SG_PIXELFORMAT_NONE) && (fmt_index < _SG_PIXELFORMAT_NUM));
    return _sg.formats[fmt_index].sample;
}

_SOKOL_PRIVATE void _sg_gl_texstorage(const _sg_image_t* img) {
    const GLenum tgt = img->gl.target;
    const int num_mips = img->cmn.num_mipmaps;
    #if defined(_SOKOL_GL_HAS_TEXSTORAGE)
        const GLenum ifmt = _sg_gl_teximage_internal_format(img->cmn.pixel_format);
        const bool msaa = img->cmn.sample_count > 1;
        const int w = img->cmn.width;
        const int h = img->cmn.height;
        if ((SG_IMAGETYPE_2D == img->cmn.type) || (SG_IMAGETYPE_CUBE == img->cmn.type)) {
            #if defined(SOKOL_GLCORE)
                if (msaa) {
                    glTexStorage2DMultisample(tgt, img->cmn.sample_count, ifmt, w, h, GL_TRUE);
                } else {
                    glTexStorage2D(tgt, num_mips, ifmt, w, h);
                }
            #else
                SOKOL_ASSERT(!msaa); _SOKOL_UNUSED(msaa);
                glTexStorage2D(tgt, num_mips, ifmt, w, h);
            #endif
        } else if ((SG_IMAGETYPE_3D == img->cmn.type) || (SG_IMAGETYPE_ARRAY == img->cmn.type)) {
            const int depth = img->cmn.num_slices;
            #if defined(SOKOL_GLCORE)
                if (msaa) {
                    // NOTE: MSAA works only for array textures, not 3D textures
                    glTexStorage3DMultisample(tgt, img->cmn.sample_count, ifmt, w, h, depth, GL_TRUE);
                } else {
                    glTexStorage3D(tgt, num_mips, ifmt, w, h, depth);
                }
            #else
                SOKOL_ASSERT(!msaa); _SOKOL_UNUSED(msaa);
                glTexStorage3D(tgt, num_mips, ifmt, w, h, depth);
            #endif
        }
    #else
        glTexParameteri(tgt, GL_TEXTURE_MAX_LEVEL, num_mips - 1);
    #endif
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_teximage(const _sg_image_t* img, GLenum tgt, int mip_index, int w, int h, int depth, const GLvoid* data_ptr, GLsizei data_size) {
    const bool compressed = _sg_is_compressed_pixel_format(img->cmn.pixel_format);
    #if defined(_SOKOL_GL_HAS_TEXSTORAGE)
        if (data_ptr == 0) {
            return;
        }
        SOKOL_ASSERT(img->cmn.sample_count == 1);
        if ((SG_IMAGETYPE_2D == img->cmn.type) || (SG_IMAGETYPE_CUBE == img->cmn.type)) {
            if (compressed) {
                const GLenum ifmt = _sg_gl_teximage_internal_format(img->cmn.pixel_format);
                glCompressedTexSubImage2D(tgt, mip_index, 0, 0, w, h, ifmt, data_size, data_ptr);
            } else {
                const GLenum type = _sg_gl_teximage_type(img->cmn.pixel_format);
                const GLenum fmt = _sg_gl_teximage_format(img->cmn.pixel_format);
                glTexSubImage2D(tgt, mip_index, 0, 0, w, h, fmt, type, data_ptr);
            }
        } else if ((SG_IMAGETYPE_3D == img->cmn.type) || (SG_IMAGETYPE_ARRAY == img->cmn.type)) {
            if (compressed) {
                const GLenum ifmt = _sg_gl_teximage_internal_format(img->cmn.pixel_format);
                glCompressedTexSubImage3D(tgt, mip_index, 0, 0, 0, w, h, depth, ifmt, data_size, data_ptr);
            } else {
                const GLenum type = _sg_gl_teximage_type(img->cmn.pixel_format);
                const GLenum fmt = _sg_gl_teximage_format(img->cmn.pixel_format);
                glTexSubImage3D(tgt, mip_index, 0, 0, 0, w, h, depth, fmt, type, data_ptr);
            }
        }
    #else
        const GLenum ifmt = _sg_gl_teximage_internal_format(img->cmn.pixel_format);
        const bool msaa = img->cmn.sample_count > 1;
        if ((SG_IMAGETYPE_2D == img->cmn.type) || (SG_IMAGETYPE_CUBE == img->cmn.type)) {
            if (compressed) {
                SOKOL_ASSERT(!msaa); _SOKOL_UNUSED(msaa);
                glCompressedTexImage2D(tgt, mip_index, ifmt, w, h, 0, data_size, data_ptr);
            } else {
                const GLenum type = _sg_gl_teximage_type(img->cmn.pixel_format);
                const GLenum fmt = _sg_gl_teximage_format(img->cmn.pixel_format);
                #if defined(SOKOL_GLCORE)
                    if (msaa) {
                        glTexImage2DMultisample(tgt, img->cmn.sample_count, (GLint)ifmt, w, h, GL_TRUE);
                    } else {
                        glTexImage2D(tgt, mip_index, (GLint)ifmt, w, h, 0, fmt, type, data_ptr);
                    }
                #else
                    SOKOL_ASSERT(!msaa); _SOKOL_UNUSED(msaa);
                    glTexImage2D(tgt, mip_index, (GLint)ifmt, w, h, 0, fmt, type, data_ptr);
                #endif
            }
        } else if ((SG_IMAGETYPE_3D == img->cmn.type) || (SG_IMAGETYPE_ARRAY == img->cmn.type)) {
            if (compressed) {
                SOKOL_ASSERT(!msaa); _SOKOL_UNUSED(msaa);
                glCompressedTexImage3D(tgt, mip_index, ifmt, w, h, depth, 0, data_size, data_ptr);
            } else {
                const GLenum type = _sg_gl_teximage_type(img->cmn.pixel_format);
                const GLenum fmt = _sg_gl_teximage_format(img->cmn.pixel_format);
                #if defined(SOKOL_GLCORE)
                    if (msaa) {
                        // NOTE: MSAA works only for array textures, not 3D textures
                        glTexImage3DMultisample(tgt, img->cmn.sample_count, (GLint)ifmt, w, h, depth, GL_TRUE);
                    } else {
                        glTexImage3D(tgt, mip_index, (GLint)ifmt, w, h, depth, 0, fmt, type, data_ptr);
                    }
                #else
                    SOKOL_ASSERT(!msaa); _SOKOL_UNUSED(msaa);
                    glTexImage3D(tgt, mip_index, (GLint)ifmt, w, h, depth, 0, fmt, type, data_ptr);
                #endif
            }
        }
    #endif
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE sg_resource_state _sg_gl_create_image(_sg_image_t* img, const sg_image_desc* desc) {
    SOKOL_ASSERT(img && desc);
    _SG_GL_CHECK_ERROR();
    img->gl.injected = (0 != desc->gl_textures[0]);

    // check if texture format is support
    if (!_sg_gl_supported_texture_format(img->cmn.pixel_format)) {
        _SG_ERROR(GL_TEXTURE_FORMAT_NOT_SUPPORTED);
        return SG_RESOURCESTATE_FAILED;
    }

    // GLES3/WebGL2/macOS doesn't have support for multisampled textures, so create a render buffer object instead
    const bool msaa = img->cmn.sample_count > 1;
    if (!_sg.features.msaa_image_bindings && img->cmn.usage.render_attachment && msaa) {
        const GLenum gl_internal_format = _sg_gl_teximage_internal_format(img->cmn.pixel_format);
        glGenRenderbuffers(1, &img->gl.msaa_render_buffer);
        glBindRenderbuffer(GL_RENDERBUFFER, img->gl.msaa_render_buffer);
        glRenderbufferStorageMultisample(GL_RENDERBUFFER, img->cmn.sample_count, gl_internal_format, img->cmn.width, img->cmn.height);
    } else if (img->gl.injected) {
        img->gl.target = _sg_gl_texture_target(img->cmn.type, img->cmn.sample_count);
        // inject externally GL textures
        for (int slot = 0; slot < img->cmn.num_slots; slot++) {
            SOKOL_ASSERT(desc->gl_textures[slot]);
            img->gl.tex[slot] = desc->gl_textures[slot];
        }
        if (desc->gl_texture_target) {
            img->gl.target = (GLenum)desc->gl_texture_target;
        }
    } else {
        // create our own GL texture(s)
        img->gl.target = _sg_gl_texture_target(img->cmn.type, img->cmn.sample_count);
        for (int slot = 0; slot < img->cmn.num_slots; slot++) {
            glGenTextures(1, &img->gl.tex[slot]);
            SOKOL_ASSERT(img->gl.tex[slot]);
            _sg_gl_cache_store_texture_sampler_binding(0);
            _sg_gl_cache_bind_texture_sampler(0, img->gl.target, img->gl.tex[slot], 0);
            _sg_gl_texstorage(img);
            const int num_faces = img->cmn.type == SG_IMAGETYPE_CUBE ? 6 : 1;
            for (int face_index = 0; face_index < num_faces; face_index++) {
                for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++) {
                    GLenum gl_img_target = img->gl.target;
                    if (SG_IMAGETYPE_CUBE == img->cmn.type) {
                        gl_img_target = _sg_gl_cubeface_target(face_index);
                    }
                    const GLvoid* data_ptr = desc->data.subimage[face_index][mip_index].ptr;
                    const GLsizei data_size = (GLsizei)desc->data.subimage[face_index][mip_index].size;
                    const int mip_width = _sg_miplevel_dim(img->cmn.width, mip_index);
                    const int mip_height = _sg_miplevel_dim(img->cmn.height, mip_index);
                    const int mip_depth = (SG_IMAGETYPE_3D == img->cmn.type) ? _sg_miplevel_dim(img->cmn.num_slices, mip_index) : img->cmn.num_slices;
                    _sg_gl_teximage(img, gl_img_target, mip_index, mip_width, mip_height, mip_depth, data_ptr, data_size);
                }
            }
            _sg_gl_cache_restore_texture_sampler_binding(0);
        }
    }
    _SG_GL_CHECK_ERROR();
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_gl_discard_image(_sg_image_t* img) {
    SOKOL_ASSERT(img);
    _SG_GL_CHECK_ERROR();
    for (int slot = 0; slot < img->cmn.num_slots; slot++) {
        if (img->gl.tex[slot]) {
            _sg_gl_cache_invalidate_texture_sampler(img->gl.tex[slot], 0);
            if (!img->gl.injected) {
                glDeleteTextures(1, &img->gl.tex[slot]);
            }
        }
    }
    if (img->gl.msaa_render_buffer) {
        glDeleteRenderbuffers(1, &img->gl.msaa_render_buffer);
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE sg_resource_state _sg_gl_create_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(smp && desc);
    _SG_GL_CHECK_ERROR();
    smp->gl.injected = (0 != desc->gl_sampler);
    if (smp->gl.injected) {
        smp->gl.smp = (GLuint) desc->gl_sampler;
    } else {
        glGenSamplers(1, &smp->gl.smp);
        SOKOL_ASSERT(smp->gl.smp);

        const GLenum gl_min_filter = _sg_gl_min_filter(smp->cmn.min_filter, smp->cmn.mipmap_filter);
        const GLenum gl_mag_filter = _sg_gl_mag_filter(smp->cmn.mag_filter);
        glSamplerParameteri(smp->gl.smp, GL_TEXTURE_MIN_FILTER, (GLint)gl_min_filter);
        glSamplerParameteri(smp->gl.smp, GL_TEXTURE_MAG_FILTER, (GLint)gl_mag_filter);
        // GL spec has strange defaults for mipmap min/max lod: -1000 to +1000
        const float min_lod = _sg_clamp(desc->min_lod, 0.0f, 1000.0f);
        const float max_lod = _sg_clamp(desc->max_lod, 0.0f, 1000.0f);
        glSamplerParameterf(smp->gl.smp, GL_TEXTURE_MIN_LOD, min_lod);
        glSamplerParameterf(smp->gl.smp, GL_TEXTURE_MAX_LOD, max_lod);
        glSamplerParameteri(smp->gl.smp, GL_TEXTURE_WRAP_S, (GLint)_sg_gl_wrap(smp->cmn.wrap_u));
        glSamplerParameteri(smp->gl.smp, GL_TEXTURE_WRAP_T, (GLint)_sg_gl_wrap(smp->cmn.wrap_v));
        glSamplerParameteri(smp->gl.smp, GL_TEXTURE_WRAP_R, (GLint)_sg_gl_wrap(smp->cmn.wrap_w));
        #if defined(SOKOL_GLCORE)
        float border[4];
        switch (smp->cmn.border_color) {
            case SG_BORDERCOLOR_TRANSPARENT_BLACK:
                border[0] = 0.0f; border[1] = 0.0f; border[2] = 0.0f; border[3] = 0.0f;
                break;
            case SG_BORDERCOLOR_OPAQUE_WHITE:
                border[0] = 1.0f; border[1] = 1.0f; border[2] = 1.0f; border[3] = 1.0f;
                break;
            default:
                border[0] = 0.0f; border[1] = 0.0f; border[2] = 0.0f; border[3] = 1.0f;
                break;
        }
        glSamplerParameterfv(smp->gl.smp, GL_TEXTURE_BORDER_COLOR, border);
        #endif
        if (smp->cmn.compare != SG_COMPAREFUNC_NEVER) {
            glSamplerParameteri(smp->gl.smp, GL_TEXTURE_COMPARE_MODE, GL_COMPARE_REF_TO_TEXTURE);
            glSamplerParameteri(smp->gl.smp, GL_TEXTURE_COMPARE_FUNC, (GLint)_sg_gl_compare_func(smp->cmn.compare));
        } else {
            glSamplerParameteri(smp->gl.smp, GL_TEXTURE_COMPARE_MODE, GL_NONE);
        }
        if (_sg.gl.ext_anisotropic && (smp->cmn.max_anisotropy > 1)) {
            GLint max_aniso = (GLint) smp->cmn.max_anisotropy;
            if (max_aniso > _sg.gl.max_anisotropy) {
                max_aniso = _sg.gl.max_anisotropy;
            }
            glSamplerParameteri(smp->gl.smp, GL_TEXTURE_MAX_ANISOTROPY_EXT, max_aniso);
        }
    }
    _SG_GL_CHECK_ERROR();
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_gl_discard_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp);
    _SG_GL_CHECK_ERROR();
    _sg_gl_cache_invalidate_texture_sampler(0, smp->gl.smp);
    if (!smp->gl.injected) {
        glDeleteSamplers(1, &smp->gl.smp);
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE GLuint _sg_gl_compile_shader(sg_shader_stage stage, const char* src) {
    SOKOL_ASSERT(src);
    _SG_GL_CHECK_ERROR();
    GLuint gl_shd = glCreateShader(_sg_gl_shader_stage(stage));
    glShaderSource(gl_shd, 1, &src, 0);
    glCompileShader(gl_shd);
    GLint compile_status = 0;
    glGetShaderiv(gl_shd, GL_COMPILE_STATUS, &compile_status);
    if (!compile_status) {
        // compilation failed, log error and delete shader
        GLint log_len = 0;
        glGetShaderiv(gl_shd, GL_INFO_LOG_LENGTH, &log_len);
        if (log_len > 0) {
            GLchar* log_buf = (GLchar*) _sg_malloc((size_t)log_len);
            glGetShaderInfoLog(gl_shd, log_len, &log_len, log_buf);
            _SG_ERROR(GL_SHADER_COMPILATION_FAILED);
            _SG_LOGMSG(GL_SHADER_COMPILATION_FAILED, log_buf);
            _sg_free(log_buf);
        }
        glDeleteShader(gl_shd);
        gl_shd = 0;
    }
    _SG_GL_CHECK_ERROR();
    return gl_shd;
}

// NOTE: this is an out-of-range check for GLSL bindslots that's also active in release mode
_SOKOL_PRIVATE bool _sg_gl_ensure_glsl_bindslot_ranges(const sg_shader_desc* desc) {
    SOKOL_ASSERT(desc);
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (desc->storage_buffers[i].glsl_binding_n >= _SG_GL_MAX_SBUF_BINDINGS) {
            _SG_ERROR(GL_STORAGEBUFFER_GLSL_BINDING_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (desc->storage_images[i].glsl_binding_n >= _SG_GL_MAX_SIMG_BINDINGS) {
            _SG_ERROR(GL_STORAGEIMAGE_GLSL_BINDING_OUT_OF_RANGE);
            return false;
        }
    }
    return true;
}

_SOKOL_PRIVATE sg_resource_state _sg_gl_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    SOKOL_ASSERT(shd && desc);
    SOKOL_ASSERT(!shd->gl.prog);
    _SG_GL_CHECK_ERROR();

    // perform a fatal range-check on GLSL bindslots that's also active
    // in release mode to avoid potential out-of-bounds array accesses
    if (!_sg_gl_ensure_glsl_bindslot_ranges(desc)) {
        return SG_RESOURCESTATE_FAILED;
    }

    // copy the optional vertex attribute names over
    for (int i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {
        _sg_strcpy(&shd->gl.attrs[i].name, desc->attrs[i].glsl_name);
    }

    const bool has_vs = desc->vertex_func.source;
    const bool has_fs = desc->fragment_func.source;
    const bool has_cs = desc->compute_func.source;
    SOKOL_ASSERT((has_vs && has_fs) || has_cs);
    GLuint gl_prog = glCreateProgram();
    if (has_vs && has_fs) {
        GLuint gl_vs = _sg_gl_compile_shader(SG_SHADERSTAGE_VERTEX, desc->vertex_func.source);
        GLuint gl_fs = _sg_gl_compile_shader(SG_SHADERSTAGE_FRAGMENT, desc->fragment_func.source);
        if (!(gl_vs && gl_fs)) {
            glDeleteProgram(gl_prog);
            if (gl_vs) { glDeleteShader(gl_vs); }
            if (gl_fs) { glDeleteShader(gl_fs); }
            return SG_RESOURCESTATE_FAILED;
        }
        glAttachShader(gl_prog, gl_vs);
        glAttachShader(gl_prog, gl_fs);
        glLinkProgram(gl_prog);
        glDeleteShader(gl_vs);
        glDeleteShader(gl_fs);
        _SG_GL_CHECK_ERROR();
    } else if (has_cs) {
        GLuint gl_cs = _sg_gl_compile_shader(SG_SHADERSTAGE_COMPUTE, desc->compute_func.source);
        if (!gl_cs) {
            glDeleteProgram(gl_prog);
            return SG_RESOURCESTATE_FAILED;
        }
        glAttachShader(gl_prog, gl_cs);
        glLinkProgram(gl_prog);
        glDeleteShader(gl_cs);
        _SG_GL_CHECK_ERROR();
    } else {
        SOKOL_UNREACHABLE;
    }
    GLint link_status;
    glGetProgramiv(gl_prog, GL_LINK_STATUS, &link_status);
    if (!link_status) {
        GLint log_len = 0;
        glGetProgramiv(gl_prog, GL_INFO_LOG_LENGTH, &log_len);
        if (log_len > 0) {
            GLchar* log_buf = (GLchar*) _sg_malloc((size_t)log_len);
            glGetProgramInfoLog(gl_prog, log_len, &log_len, log_buf);
            _SG_ERROR(GL_SHADER_LINKING_FAILED);
            _SG_LOGMSG(GL_SHADER_LINKING_FAILED, log_buf);
            _sg_free(log_buf);
        }
        glDeleteProgram(gl_prog);
        return SG_RESOURCESTATE_FAILED;
    }
    shd->gl.prog = gl_prog;

    // resolve uniforms
    _SG_GL_CHECK_ERROR();
    for (size_t ub_index = 0; ub_index < SG_MAX_UNIFORMBLOCK_BINDSLOTS; ub_index++) {
        const sg_shader_uniform_block* ub_desc = &desc->uniform_blocks[ub_index];
        if (ub_desc->stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(ub_desc->size > 0);
        _sg_gl_uniform_block_t* ub = &shd->gl.uniform_blocks[ub_index];
        SOKOL_ASSERT(ub->num_uniforms == 0);
        uint32_t cur_uniform_offset = 0;
        for (int u_index = 0; u_index < SG_MAX_UNIFORMBLOCK_MEMBERS; u_index++) {
            const sg_glsl_shader_uniform* u_desc = &ub_desc->glsl_uniforms[u_index];
            if (u_desc->type == SG_UNIFORMTYPE_INVALID) {
                break;
            }
            const uint32_t u_align = _sg_uniform_alignment(u_desc->type, u_desc->array_count, ub_desc->layout);
            const uint32_t u_size = _sg_uniform_size(u_desc->type, u_desc->array_count, ub_desc->layout);
            cur_uniform_offset = _sg_align_u32(cur_uniform_offset, u_align);
            _sg_gl_uniform_t* u = &ub->uniforms[u_index];
            u->type = u_desc->type;
            u->count = (uint16_t) u_desc->array_count;
            u->offset = (uint16_t) cur_uniform_offset;
            SOKOL_ASSERT(u_desc->glsl_name);
            u->gl_loc = glGetUniformLocation(gl_prog, u_desc->glsl_name);
            if (u->gl_loc == -1) {
                _SG_WARN(GL_UNIFORMBLOCK_NAME_NOT_FOUND_IN_SHADER);
                _SG_LOGMSG(GL_UNIFORMBLOCK_NAME_NOT_FOUND_IN_SHADER, u_desc->glsl_name);
            }
            cur_uniform_offset += u_size;
            ub->num_uniforms++;
        }
        if (ub_desc->layout == SG_UNIFORMLAYOUT_STD140) {
            cur_uniform_offset = _sg_align_u32(cur_uniform_offset, 16);
        }
        SOKOL_ASSERT(ub_desc->size == (size_t)cur_uniform_offset);
        _SOKOL_UNUSED(cur_uniform_offset);
    }

    // copy storage buffer bind slots
    for (size_t sbuf_index = 0; sbuf_index < SG_MAX_STORAGEBUFFER_BINDSLOTS; sbuf_index++) {
        const sg_shader_storage_buffer* sbuf_desc = &desc->storage_buffers[sbuf_index];
        if (sbuf_desc->stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(sbuf_desc->glsl_binding_n < _SG_GL_MAX_SBUF_BINDINGS);
        shd->gl.sbuf_binding[sbuf_index] = sbuf_desc->glsl_binding_n;
    }

    // copy storage image bind slots
    for (size_t simg_index = 0; simg_index < SG_MAX_STORAGE_ATTACHMENTS; simg_index++) {
        const sg_shader_storage_image* simg_desc = &desc->storage_images[simg_index];
        if (simg_desc->stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(simg_desc->glsl_binding_n < _SG_GL_MAX_SIMG_BINDINGS);
        shd->gl.simg_binding[simg_index] = simg_desc->glsl_binding_n;
    }

    // record image sampler location in shader program
    _SG_GL_CHECK_ERROR();
    GLuint cur_prog = 0;
    glGetIntegerv(GL_CURRENT_PROGRAM, (GLint*)&cur_prog);
    glUseProgram(gl_prog);
    GLint gl_tex_slot = 0;
    for (size_t img_smp_index = 0; img_smp_index < SG_MAX_IMAGE_SAMPLER_PAIRS; img_smp_index++) {
        const sg_shader_image_sampler_pair* img_smp_desc = &desc->image_sampler_pairs[img_smp_index];
        if (img_smp_desc->stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(img_smp_desc->glsl_name);
        GLint gl_loc = glGetUniformLocation(gl_prog, img_smp_desc->glsl_name);
        if (gl_loc != -1) {
            glUniform1i(gl_loc, gl_tex_slot);
            shd->gl.tex_slot[img_smp_index] = (int8_t)gl_tex_slot++;
        } else {
            shd->gl.tex_slot[img_smp_index] = -1;
            _SG_WARN(GL_IMAGE_SAMPLER_NAME_NOT_FOUND_IN_SHADER);
            _SG_LOGMSG(GL_IMAGE_SAMPLER_NAME_NOT_FOUND_IN_SHADER, img_smp_desc->glsl_name);
        }
    }

    // it's legal to call glUseProgram with 0
    glUseProgram(cur_prog);
    _SG_GL_CHECK_ERROR();
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_gl_discard_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd);
    _SG_GL_CHECK_ERROR();
    if (shd->gl.prog) {
        _sg_gl_cache_invalidate_program(shd->gl.prog);
        glDeleteProgram(shd->gl.prog);
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE sg_resource_state _sg_gl_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(pip && shd && desc);
    SOKOL_ASSERT((pip->shader == 0) && (pip->cmn.shader_id.id != SG_INVALID_ID));
    SOKOL_ASSERT(desc->shader.id == shd->slot.id);
    SOKOL_ASSERT(shd->gl.prog);
    SOKOL_ASSERT(_sg.limits.max_vertex_attrs <= SG_MAX_VERTEX_ATTRIBUTES);
    pip->shader = shd;
    if (pip->cmn.is_compute) {
        // shortcut for compute pipelines
        return SG_RESOURCESTATE_VALID;
    }
    pip->gl.primitive_type = desc->primitive_type;
    pip->gl.depth = desc->depth;
    pip->gl.stencil = desc->stencil;
    // FIXME: blend color and write mask per draw-buffer-attachment (requires GL4)
    pip->gl.blend = desc->colors[0].blend;
    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        pip->gl.color_write_mask[i] = desc->colors[i].write_mask;
    }
    pip->gl.cull_mode = desc->cull_mode;
    pip->gl.face_winding = desc->face_winding;
    pip->gl.sample_count = desc->sample_count;
    pip->gl.alpha_to_coverage_enabled = desc->alpha_to_coverage_enabled;

    // NOTE: GLSL compilers may remove unused vertex attributes so we can't rely
    // on the 'prepopulated' vertex_buffer_layout_active[] state and need to
    // fill this array from scratch with the actual info after GLSL compilation
    for (int i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
        pip->cmn.vertex_buffer_layout_active[i] = false;
    }

    // resolve vertex attributes
    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
        pip->gl.attrs[attr_index].vb_index = -1;
    }
    for (int attr_index = 0; attr_index < _sg.limits.max_vertex_attrs; attr_index++) {
        const sg_vertex_attr_state* a_state = &desc->layout.attrs[attr_index];
        if (a_state->format == SG_VERTEXFORMAT_INVALID) {
            break;
        }
        SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
        const sg_vertex_buffer_layout_state* l_state = &desc->layout.buffers[a_state->buffer_index];
        const sg_vertex_step step_func = l_state->step_func;
        const int step_rate = l_state->step_rate;
        GLint attr_loc = attr_index;
        if (!_sg_strempty(&shd->gl.attrs[attr_index].name)) {
            attr_loc = glGetAttribLocation(pip->shader->gl.prog, _sg_strptr(&shd->gl.attrs[attr_index].name));
        }
        if (attr_loc != -1) {
            SOKOL_ASSERT(attr_loc < (GLint)_sg.limits.max_vertex_attrs);
            _sg_gl_attr_t* gl_attr = &pip->gl.attrs[attr_loc];
            SOKOL_ASSERT(gl_attr->vb_index == -1);
            gl_attr->vb_index = (int8_t) a_state->buffer_index;
            if (step_func == SG_VERTEXSTEP_PER_VERTEX) {
                gl_attr->divisor = 0;
            } else {
                gl_attr->divisor = (int8_t) step_rate;
                pip->cmn.use_instanced_draw = true;
            }
            SOKOL_ASSERT(l_state->stride > 0);
            gl_attr->stride = (uint8_t) l_state->stride;
            gl_attr->offset = a_state->offset;
            gl_attr->size = (uint8_t) _sg_gl_vertexformat_size(a_state->format);
            gl_attr->type = _sg_gl_vertexformat_type(a_state->format);
            gl_attr->normalized = _sg_gl_vertexformat_normalized(a_state->format);
            gl_attr->base_type = _sg_vertexformat_basetype(a_state->format);
            pip->cmn.vertex_buffer_layout_active[a_state->buffer_index] = true;
        } else {
            _SG_WARN(GL_VERTEX_ATTRIBUTE_NOT_FOUND_IN_SHADER);
            _SG_LOGMSG(GL_VERTEX_ATTRIBUTE_NOT_FOUND_IN_SHADER, _sg_strptr(&shd->gl.attrs[attr_index].name));
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_gl_discard_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    _sg_gl_cache_invalidate_pipeline(pip);
}

_SOKOL_PRIVATE void _sg_gl_fb_attach_texture(const _sg_gl_attachment_t* gl_att, const _sg_attachment_common_t* cmn_att, GLenum gl_att_type) {
    const _sg_image_t* img = gl_att->image;
    SOKOL_ASSERT(img);
    const GLuint gl_tex = img->gl.tex[0];
    SOKOL_ASSERT(gl_tex);
    const GLuint gl_target = img->gl.target;
    SOKOL_ASSERT(gl_target);
    const int mip_level = cmn_att->mip_level;
    const int slice = cmn_att->slice;
    switch (img->cmn.type) {
        case SG_IMAGETYPE_2D:
            glFramebufferTexture2D(GL_FRAMEBUFFER, gl_att_type, gl_target, gl_tex, mip_level);
            break;
        case SG_IMAGETYPE_CUBE:
            glFramebufferTexture2D(GL_FRAMEBUFFER, gl_att_type, _sg_gl_cubeface_target(slice), gl_tex, mip_level);
            break;
        default:
            glFramebufferTextureLayer(GL_FRAMEBUFFER, gl_att_type, gl_tex, mip_level, slice);
            break;
    }
}

_SOKOL_PRIVATE GLenum _sg_gl_depth_stencil_attachment_type(const _sg_gl_attachment_t* ds_att) {
    const _sg_image_t* img = ds_att->image;
    SOKOL_ASSERT(img);
    if (_sg_is_depth_stencil_format(img->cmn.pixel_format)) {
        return GL_DEPTH_STENCIL_ATTACHMENT;
    } else {
        return GL_DEPTH_ATTACHMENT;
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_gl_create_attachments(_sg_attachments_t* atts, const _sg_attachments_ptrs_t* atts_ptrs, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(atts && atts_ptrs && desc);
    _SG_GL_CHECK_ERROR();

    // copy image pointers
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const sg_attachment_desc* color_desc = &desc->colors[i];
        _SOKOL_UNUSED(color_desc);
        SOKOL_ASSERT(color_desc->image.id != SG_INVALID_ID);
        SOKOL_ASSERT(0 == atts->gl.colors[i].image);
        SOKOL_ASSERT(atts_ptrs->color_images[i]);
        _sg_image_t* clr_img = atts_ptrs->color_images[i];
        SOKOL_ASSERT(clr_img->slot.id == color_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_color_format(clr_img->cmn.pixel_format));
        atts->gl.colors[i].image = clr_img;

        const sg_attachment_desc* resolve_desc = &desc->resolves[i];
        if (resolve_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->gl.resolves[i].image);
            SOKOL_ASSERT(atts_ptrs->resolve_images[i]);
            _sg_image_t* rsv_img = atts_ptrs->resolve_images[i];
            SOKOL_ASSERT(rsv_img->slot.id == resolve_desc->image.id);
            SOKOL_ASSERT(clr_img && (clr_img->cmn.pixel_format == rsv_img->cmn.pixel_format));
            atts->gl.resolves[i].image = rsv_img;
        }
    }
    SOKOL_ASSERT(0 == atts->gl.depth_stencil.image);
    const sg_attachment_desc* ds_desc = &desc->depth_stencil;
    if (ds_desc->image.id != SG_INVALID_ID) {
        SOKOL_ASSERT(atts_ptrs->ds_image);
        _sg_image_t* ds_img = atts_ptrs->ds_image;
        SOKOL_ASSERT(ds_img->slot.id == ds_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_depth_format(ds_img->cmn.pixel_format));
        atts->gl.depth_stencil.image = ds_img;
    }
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const sg_attachment_desc* storage_desc = &desc->storages[i];
        if (storage_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->gl.storages[i].image);
            SOKOL_ASSERT(atts_ptrs->storage_images[i]);
            _sg_image_t* stg_img = atts_ptrs->storage_images[i];
            SOKOL_ASSERT(stg_img->slot.id == storage_desc->image.id);
            atts->gl.storages[i].image = stg_img;
        }
    }

    // if this is a compute pass attachment we're done here
    if (atts->cmn.has_storage_attachments) {
        SOKOL_ASSERT(!atts->cmn.has_render_attachments);
        return SG_RESOURCESTATE_VALID;
    }

    // store current framebuffer binding (restored at end of function)
    GLuint gl_orig_fb;
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&gl_orig_fb);

    // create a framebuffer object
    glGenFramebuffers(1, &atts->gl.fb);
    glBindFramebuffer(GL_FRAMEBUFFER, atts->gl.fb);

    // attach color attachments to framebuffer
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const _sg_image_t* color_img = atts->gl.colors[i].image;
        SOKOL_ASSERT(color_img);
        const GLuint gl_msaa_render_buffer = color_img->gl.msaa_render_buffer;
        if (gl_msaa_render_buffer) {
            glFramebufferRenderbuffer(GL_FRAMEBUFFER, (GLenum)(GL_COLOR_ATTACHMENT0+i), GL_RENDERBUFFER, gl_msaa_render_buffer);
        } else {
            const GLenum gl_att_type = (GLenum)(GL_COLOR_ATTACHMENT0 + i);
            _sg_gl_fb_attach_texture(&atts->gl.colors[i], &atts->cmn.colors[i], gl_att_type);
        }
    }
    // attach depth-stencil attachment
    if (atts->gl.depth_stencil.image) {
        const GLenum gl_att = _sg_gl_depth_stencil_attachment_type(&atts->gl.depth_stencil);
        const _sg_image_t* ds_img = atts->gl.depth_stencil.image;
        const GLuint gl_msaa_render_buffer = ds_img->gl.msaa_render_buffer;
        if (gl_msaa_render_buffer) {
            glFramebufferRenderbuffer(GL_FRAMEBUFFER, gl_att, GL_RENDERBUFFER, gl_msaa_render_buffer);
        } else {
            const GLenum gl_att_type = _sg_gl_depth_stencil_attachment_type(&atts->gl.depth_stencil);
            _sg_gl_fb_attach_texture(&atts->gl.depth_stencil, &atts->cmn.depth_stencil, gl_att_type);
        }
    }

    // check if framebuffer is complete
    {
        const GLenum fb_status = glCheckFramebufferStatus(GL_FRAMEBUFFER);
        if (fb_status != GL_FRAMEBUFFER_COMPLETE) {
            switch (fb_status) {
                case GL_FRAMEBUFFER_UNDEFINED:
                    _SG_ERROR(GL_FRAMEBUFFER_STATUS_UNDEFINED);
                    break;
                case GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
                    _SG_ERROR(GL_FRAMEBUFFER_STATUS_INCOMPLETE_ATTACHMENT);
                    break;
                case GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
                    _SG_ERROR(GL_FRAMEBUFFER_STATUS_INCOMPLETE_MISSING_ATTACHMENT);
                    break;
                case GL_FRAMEBUFFER_UNSUPPORTED:
                    _SG_ERROR(GL_FRAMEBUFFER_STATUS_UNSUPPORTED);
                    break;
                case GL_FRAMEBUFFER_INCOMPLETE_MULTISAMPLE:
                    _SG_ERROR(GL_FRAMEBUFFER_STATUS_INCOMPLETE_MULTISAMPLE);
                    break;
                default:
                    _SG_ERROR(GL_FRAMEBUFFER_STATUS_UNKNOWN);
                    break;
            }
            return SG_RESOURCESTATE_FAILED;
        }
    }

    // setup color attachments for the framebuffer
    static const GLenum gl_draw_bufs[SG_MAX_COLOR_ATTACHMENTS] = {
        GL_COLOR_ATTACHMENT0,
        GL_COLOR_ATTACHMENT1,
        GL_COLOR_ATTACHMENT2,
        GL_COLOR_ATTACHMENT3
    };
    glDrawBuffers(atts->cmn.num_colors, gl_draw_bufs);

    // create MSAA resolve framebuffers if necessary
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        _sg_gl_attachment_t* gl_resolve_att = &atts->gl.resolves[i];
        if (gl_resolve_att->image) {
            _sg_attachment_common_t* cmn_resolve_att = &atts->cmn.resolves[i];
            SOKOL_ASSERT(0 == atts->gl.msaa_resolve_framebuffer[i]);
            glGenFramebuffers(1, &atts->gl.msaa_resolve_framebuffer[i]);
            glBindFramebuffer(GL_FRAMEBUFFER, atts->gl.msaa_resolve_framebuffer[i]);
            _sg_gl_fb_attach_texture(gl_resolve_att, cmn_resolve_att, GL_COLOR_ATTACHMENT0);
            // check if framebuffer is complete
            const GLenum fb_status = glCheckFramebufferStatus(GL_FRAMEBUFFER);
            if (fb_status != GL_FRAMEBUFFER_COMPLETE) {
                switch (fb_status) {
                    case GL_FRAMEBUFFER_UNDEFINED:
                        _SG_ERROR(GL_FRAMEBUFFER_STATUS_UNDEFINED);
                        break;
                    case GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
                        _SG_ERROR(GL_FRAMEBUFFER_STATUS_INCOMPLETE_ATTACHMENT);
                        break;
                    case GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
                        _SG_ERROR(GL_FRAMEBUFFER_STATUS_INCOMPLETE_MISSING_ATTACHMENT);
                        break;
                    case GL_FRAMEBUFFER_UNSUPPORTED:
                        _SG_ERROR(GL_FRAMEBUFFER_STATUS_UNSUPPORTED);
                        break;
                    case GL_FRAMEBUFFER_INCOMPLETE_MULTISAMPLE:
                        _SG_ERROR(GL_FRAMEBUFFER_STATUS_INCOMPLETE_MULTISAMPLE);
                        break;
                    default:
                        _SG_ERROR(GL_FRAMEBUFFER_STATUS_UNKNOWN);
                        break;
                }
                return SG_RESOURCESTATE_FAILED;
            }
            // setup color attachments for the framebuffer
            glDrawBuffers(1, &gl_draw_bufs[0]);
        }
    }

    // restore original framebuffer binding
    glBindFramebuffer(GL_FRAMEBUFFER, gl_orig_fb);
    _SG_GL_CHECK_ERROR();
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_gl_discard_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    _SG_GL_CHECK_ERROR();
    if (0 != atts->gl.fb) {
        glDeleteFramebuffers(1, &atts->gl.fb);
    }
    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        if (atts->gl.msaa_resolve_framebuffer[i]) {
            glDeleteFramebuffers(1, &atts->gl.msaa_resolve_framebuffer[i]);
        }
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE _sg_image_t* _sg_gl_attachments_color_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->gl.colors[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_gl_attachments_resolve_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->gl.resolves[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_gl_attachments_ds_image(const _sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    return atts->gl.depth_stencil.image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_gl_attachments_storage_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->gl.storages[index].image;
}

_SOKOL_PRIVATE void _sg_gl_begin_pass(const sg_pass* pass) {
    // FIXME: what if a texture used as render target is still bound, should we
    // unbind all currently bound textures in begin pass?
    SOKOL_ASSERT(pass);
    _SG_GL_CHECK_ERROR();

    // early out if this a compute pass
    if (pass->compute) {
        // first pipeline in pass needs to re-apply storage attachments
        if (_sg.cur_pass.atts && _sg.cur_pass.atts->cmn.has_storage_attachments) {
            _sg.gl.cache.cur_pipeline = 0;
            _sg.gl.cache.cur_pipeline_id.id = SG_INVALID_ID;
        }
        return;
    }

    const _sg_attachments_t* atts = _sg.cur_pass.atts;
    const sg_swapchain* swapchain = &pass->swapchain;
    const sg_pass_action* action = &pass->action;

    // bind the render pass framebuffer
    //
    // FIXME: Disabling SRGB conversion for the default framebuffer is
    // a crude hack to make behaviour for sRGB render target textures
    // identical with the Metal and D3D11 swapchains created by sokol-app.
    //
    // This will need a cleaner solution (e.g. allowing to configure
    // sokol_app.h with an sRGB or RGB framebuffer.
    if (atts) {
        // offscreen pass
        SOKOL_ASSERT(atts->gl.fb);
        #if defined(SOKOL_GLCORE)
        glEnable(GL_FRAMEBUFFER_SRGB);
        #endif
        glBindFramebuffer(GL_FRAMEBUFFER, atts->gl.fb);
    } else {
        // default pass
        #if defined(SOKOL_GLCORE)
        glDisable(GL_FRAMEBUFFER_SRGB);
        #endif
        // NOTE: on some platforms, the default framebuffer of a context
        // is null, so we can't actually assert here that the
        // framebuffer has been provided
        glBindFramebuffer(GL_FRAMEBUFFER, swapchain->gl.framebuffer);
    }
    glViewport(0, 0, _sg.cur_pass.width, _sg.cur_pass.height);
    glScissor(0, 0, _sg.cur_pass.width, _sg.cur_pass.height);

    // number of color attachments
    const int num_color_atts = atts ? atts->cmn.num_colors : 1;

    // clear color and depth-stencil attachments if needed
    bool clear_any_color = false;
    for (int i = 0; i < num_color_atts; i++) {
        if (SG_LOADACTION_CLEAR == action->colors[i].load_action) {
            clear_any_color = true;
            break;
        }
    }
    const bool clear_depth = (action->depth.load_action == SG_LOADACTION_CLEAR);
    const bool clear_stencil = (action->stencil.load_action == SG_LOADACTION_CLEAR);

    bool need_pip_cache_flush = false;
    if (clear_any_color) {
        bool need_color_mask_flush = false;
        // NOTE: not a bug to iterate over all possible color attachments
        for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
            if (SG_COLORMASK_RGBA != _sg.gl.cache.color_write_mask[i]) {
                need_pip_cache_flush = true;
                need_color_mask_flush = true;
                _sg.gl.cache.color_write_mask[i] = SG_COLORMASK_RGBA;
            }
        }
        if (need_color_mask_flush) {
            glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE);
        }
    }
    if (clear_depth) {
        if (!_sg.gl.cache.depth.write_enabled) {
            need_pip_cache_flush = true;
            _sg.gl.cache.depth.write_enabled = true;
            glDepthMask(GL_TRUE);
        }
        if (_sg.gl.cache.depth.compare != SG_COMPAREFUNC_ALWAYS) {
            need_pip_cache_flush = true;
            _sg.gl.cache.depth.compare = SG_COMPAREFUNC_ALWAYS;
            glDepthFunc(GL_ALWAYS);
        }
    }
    if (clear_stencil) {
        if (_sg.gl.cache.stencil.write_mask != 0xFF) {
            need_pip_cache_flush = true;
            _sg.gl.cache.stencil.write_mask = 0xFF;
            glStencilMask(0xFF);
        }
    }
    if (need_pip_cache_flush) {
        // we messed with the state cache directly, need to clear cached
        // pipeline to force re-evaluation in next sg_apply_pipeline()
        _sg.gl.cache.cur_pipeline = 0;
        _sg.gl.cache.cur_pipeline_id.id = SG_INVALID_ID;
    }
    for (int i = 0; i < num_color_atts; i++) {
        if (action->colors[i].load_action == SG_LOADACTION_CLEAR) {
            glClearBufferfv(GL_COLOR, i, &action->colors[i].clear_value.r);
        }
    }
    if ((atts == 0) || (atts->gl.depth_stencil.image)) {
        if (clear_depth && clear_stencil) {
            glClearBufferfi(GL_DEPTH_STENCIL, 0, action->depth.clear_value, action->stencil.clear_value);
        } else if (clear_depth) {
            glClearBufferfv(GL_DEPTH, 0, &action->depth.clear_value);
        } else if (clear_stencil) {
            GLint val = (GLint) action->stencil.clear_value;
            glClearBufferiv(GL_STENCIL, 0, &val);
        }
    }
    // keep store actions for end-pass
    for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        _sg.gl.color_store_actions[i] = action->colors[i].store_action;
    }
    _sg.gl.depth_store_action = action->depth.store_action;
    _sg.gl.stencil_store_action = action->stencil.store_action;

    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_end_render_pass(void) {
    if (_sg.cur_pass.atts) {
        const _sg_attachments_t* atts = _sg.cur_pass.atts;
        SOKOL_ASSERT(atts->slot.id == _sg.cur_pass.atts_id.id);
        bool fb_read_bound = false;
        bool fb_draw_bound = false;
        const int num_color_atts = atts->cmn.num_colors;
        for (int i = 0; i < num_color_atts; i++) {
            // perform MSAA resolve if needed
            if (atts->gl.msaa_resolve_framebuffer[i] != 0) {
                if (!fb_read_bound) {
                    SOKOL_ASSERT(atts->gl.fb);
                    glBindFramebuffer(GL_READ_FRAMEBUFFER, atts->gl.fb);
                    fb_read_bound = true;
                }
                const int w = atts->gl.colors[i].image->cmn.width;
                const int h = atts->gl.colors[i].image->cmn.height;
                glBindFramebuffer(GL_DRAW_FRAMEBUFFER, atts->gl.msaa_resolve_framebuffer[i]);
                glReadBuffer((GLenum)(GL_COLOR_ATTACHMENT0 + i));
                glBlitFramebuffer(0, 0, w, h, 0, 0, w, h, GL_COLOR_BUFFER_BIT, GL_NEAREST);
                fb_draw_bound = true;
            }
        }

        // invalidate framebuffers
        _SOKOL_UNUSED(fb_draw_bound);
        #if defined(SOKOL_GLES3)
        // need to restore framebuffer binding before invalidate if the MSAA resolve had changed the binding
        if (fb_draw_bound) {
            glBindFramebuffer(GL_FRAMEBUFFER, atts->gl.fb);
        }
        GLenum invalidate_atts[SG_MAX_COLOR_ATTACHMENTS + 2] = { 0 };
        int att_index = 0;
        for (int i = 0; i < num_color_atts; i++) {
            if (_sg.gl.color_store_actions[i] == SG_STOREACTION_DONTCARE) {
                invalidate_atts[att_index++] = (GLenum)(GL_COLOR_ATTACHMENT0 + i);
            }
        }
        if ((_sg.gl.depth_store_action == SG_STOREACTION_DONTCARE) && (_sg.cur_pass.atts->cmn.depth_stencil.image_id.id != SG_INVALID_ID)) {
            invalidate_atts[att_index++] = GL_DEPTH_ATTACHMENT;
        }
        if ((_sg.gl.stencil_store_action == SG_STOREACTION_DONTCARE) && (_sg.cur_pass.atts->cmn.depth_stencil.image_id.id != SG_INVALID_ID)) {
            invalidate_atts[att_index++] = GL_STENCIL_ATTACHMENT;
        }
        if (att_index > 0) {
            glInvalidateFramebuffer(GL_DRAW_FRAMEBUFFER, att_index, invalidate_atts);
        }
        #endif
    }
}

_SOKOL_PRIVATE void _sg_gl_end_compute_pass(void) {
    #if defined(_SOKOL_GL_HAS_COMPUTE)
    if (_sg.cur_pass.atts && _sg.cur_pass.atts->cmn.has_storage_attachments) {
        glMemoryBarrier(GL_TEXTURE_FETCH_BARRIER_BIT|GL_SHADER_IMAGE_ACCESS_BARRIER_BIT);
    }
    #endif
}

_SOKOL_PRIVATE void _sg_gl_end_pass(void) {
    _SG_GL_CHECK_ERROR();
    if (_sg.cur_pass.is_compute) {
        _sg_gl_end_compute_pass();
    } else {
        _sg_gl_end_render_pass();
    }
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {
    y = origin_top_left ? (_sg.cur_pass.height - (y+h)) : y;
    glViewport(x, y, w, h);
}

_SOKOL_PRIVATE void _sg_gl_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {
    y = origin_top_left ? (_sg.cur_pass.height - (y+h)) : y;
    glScissor(x, y, w, h);
}

_SOKOL_PRIVATE void _sg_gl_apply_render_pipeline_state(_sg_pipeline_t* pip) {
    // update render pipeline state
    _sg.gl.cache.cur_primitive_type = _sg_gl_primitive_type(pip->gl.primitive_type);
    _sg.gl.cache.cur_index_type = _sg_gl_index_type(pip->cmn.index_type);

    // update depth state
    {
        const sg_depth_state* state_ds = &pip->gl.depth;
        sg_depth_state* cache_ds = &_sg.gl.cache.depth;
        if (state_ds->compare != cache_ds->compare) {
            cache_ds->compare = state_ds->compare;
            glDepthFunc(_sg_gl_compare_func(state_ds->compare));
            _sg_stats_add(gl.num_render_state, 1);
        }
        if (state_ds->write_enabled != cache_ds->write_enabled) {
            cache_ds->write_enabled = state_ds->write_enabled;
            glDepthMask(state_ds->write_enabled);
            _sg_stats_add(gl.num_render_state, 1);
        }
        if (!_sg_fequal(state_ds->bias, cache_ds->bias, 0.000001f) ||
            !_sg_fequal(state_ds->bias_slope_scale, cache_ds->bias_slope_scale, 0.000001f))
        {
            /* according to ANGLE's D3D11 backend:
                D3D11 SlopeScaledDepthBias ==> GL polygonOffsetFactor
                D3D11 DepthBias ==> GL polygonOffsetUnits
                DepthBiasClamp has no meaning on GL
            */
            cache_ds->bias = state_ds->bias;
            cache_ds->bias_slope_scale = state_ds->bias_slope_scale;
            glPolygonOffset(state_ds->bias_slope_scale, state_ds->bias);
            _sg_stats_add(gl.num_render_state, 1);
            bool po_enabled = true;
            if (_sg_fequal(state_ds->bias, 0.0f, 0.000001f) &&
                _sg_fequal(state_ds->bias_slope_scale, 0.0f, 0.000001f))
            {
                po_enabled = false;
            }
            if (po_enabled != _sg.gl.cache.polygon_offset_enabled) {
                _sg.gl.cache.polygon_offset_enabled = po_enabled;
                if (po_enabled) {
                    glEnable(GL_POLYGON_OFFSET_FILL);
                } else {
                    glDisable(GL_POLYGON_OFFSET_FILL);
                }
                _sg_stats_add(gl.num_render_state, 1);
            }
        }
    }

    // update stencil state
    {
        const sg_stencil_state* state_ss = &pip->gl.stencil;
        sg_stencil_state* cache_ss = &_sg.gl.cache.stencil;
        if (state_ss->enabled != cache_ss->enabled) {
            cache_ss->enabled = state_ss->enabled;
            if (state_ss->enabled) {
                glEnable(GL_STENCIL_TEST);
            } else {
                glDisable(GL_STENCIL_TEST);
            }
            _sg_stats_add(gl.num_render_state, 1);
        }
        if (state_ss->write_mask != cache_ss->write_mask) {
            cache_ss->write_mask = state_ss->write_mask;
            glStencilMask(state_ss->write_mask);
            _sg_stats_add(gl.num_render_state, 1);
        }
        for (int i = 0; i < 2; i++) {
            const sg_stencil_face_state* state_sfs = (i==0)? &state_ss->front : &state_ss->back;
            sg_stencil_face_state* cache_sfs = (i==0)? &cache_ss->front : &cache_ss->back;
            GLenum gl_face = (i==0)? GL_FRONT : GL_BACK;
            if ((state_sfs->compare != cache_sfs->compare) ||
                (state_ss->read_mask != cache_ss->read_mask) ||
                (state_ss->ref != cache_ss->ref))
            {
                cache_sfs->compare = state_sfs->compare;
                glStencilFuncSeparate(gl_face,
                    _sg_gl_compare_func(state_sfs->compare),
                    state_ss->ref,
                    state_ss->read_mask);
                _sg_stats_add(gl.num_render_state, 1);
            }
            if ((state_sfs->fail_op != cache_sfs->fail_op) ||
                (state_sfs->depth_fail_op != cache_sfs->depth_fail_op) ||
                (state_sfs->pass_op != cache_sfs->pass_op))
            {
                cache_sfs->fail_op = state_sfs->fail_op;
                cache_sfs->depth_fail_op = state_sfs->depth_fail_op;
                cache_sfs->pass_op = state_sfs->pass_op;
                glStencilOpSeparate(gl_face,
                    _sg_gl_stencil_op(state_sfs->fail_op),
                    _sg_gl_stencil_op(state_sfs->depth_fail_op),
                    _sg_gl_stencil_op(state_sfs->pass_op));
                _sg_stats_add(gl.num_render_state, 1);
            }
        }
        cache_ss->read_mask = state_ss->read_mask;
        cache_ss->ref = state_ss->ref;
    }

    if (pip->cmn.color_count > 0) {
        // update blend state
        // FIXME: separate blend state per color attachment
        const sg_blend_state* state_bs = &pip->gl.blend;
        sg_blend_state* cache_bs = &_sg.gl.cache.blend;
        if (state_bs->enabled != cache_bs->enabled) {
            cache_bs->enabled = state_bs->enabled;
            if (state_bs->enabled) {
                glEnable(GL_BLEND);
            } else {
                glDisable(GL_BLEND);
            }
            _sg_stats_add(gl.num_render_state, 1);
        }
        if ((state_bs->src_factor_rgb != cache_bs->src_factor_rgb) ||
            (state_bs->dst_factor_rgb != cache_bs->dst_factor_rgb) ||
            (state_bs->src_factor_alpha != cache_bs->src_factor_alpha) ||
            (state_bs->dst_factor_alpha != cache_bs->dst_factor_alpha))
        {
            cache_bs->src_factor_rgb = state_bs->src_factor_rgb;
            cache_bs->dst_factor_rgb = state_bs->dst_factor_rgb;
            cache_bs->src_factor_alpha = state_bs->src_factor_alpha;
            cache_bs->dst_factor_alpha = state_bs->dst_factor_alpha;
            glBlendFuncSeparate(_sg_gl_blend_factor(state_bs->src_factor_rgb),
                _sg_gl_blend_factor(state_bs->dst_factor_rgb),
                _sg_gl_blend_factor(state_bs->src_factor_alpha),
                _sg_gl_blend_factor(state_bs->dst_factor_alpha));
            _sg_stats_add(gl.num_render_state, 1);
        }
        if ((state_bs->op_rgb != cache_bs->op_rgb) || (state_bs->op_alpha != cache_bs->op_alpha)) {
            cache_bs->op_rgb = state_bs->op_rgb;
            cache_bs->op_alpha = state_bs->op_alpha;
            glBlendEquationSeparate(_sg_gl_blend_op(state_bs->op_rgb), _sg_gl_blend_op(state_bs->op_alpha));
            _sg_stats_add(gl.num_render_state, 1);
        }

        // standalone color target state
        for (GLuint i = 0; i < (GLuint)pip->cmn.color_count; i++) {
            if (pip->gl.color_write_mask[i] != _sg.gl.cache.color_write_mask[i]) {
                const sg_color_mask cm = pip->gl.color_write_mask[i];
                _sg.gl.cache.color_write_mask[i] = cm;
                #ifdef SOKOL_GLCORE
                    glColorMaski(i,
                                (cm & SG_COLORMASK_R) != 0,
                                (cm & SG_COLORMASK_G) != 0,
                                (cm & SG_COLORMASK_B) != 0,
                                (cm & SG_COLORMASK_A) != 0);
                #else
                    if (0 == i) {
                        glColorMask((cm & SG_COLORMASK_R) != 0,
                                    (cm & SG_COLORMASK_G) != 0,
                                    (cm & SG_COLORMASK_B) != 0,
                                    (cm & SG_COLORMASK_A) != 0);
                    }
                #endif
                _sg_stats_add(gl.num_render_state, 1);
            }
        }

        if (!_sg_fequal(pip->cmn.blend_color.r, _sg.gl.cache.blend_color.r, 0.0001f) ||
            !_sg_fequal(pip->cmn.blend_color.g, _sg.gl.cache.blend_color.g, 0.0001f) ||
            !_sg_fequal(pip->cmn.blend_color.b, _sg.gl.cache.blend_color.b, 0.0001f) ||
            !_sg_fequal(pip->cmn.blend_color.a, _sg.gl.cache.blend_color.a, 0.0001f))
        {
            sg_color c = pip->cmn.blend_color;
            _sg.gl.cache.blend_color = c;
            glBlendColor(c.r, c.g, c.b, c.a);
            _sg_stats_add(gl.num_render_state, 1);
        }
    } // pip->cmn.color_count > 0

    if (pip->gl.cull_mode != _sg.gl.cache.cull_mode) {
        _sg.gl.cache.cull_mode = pip->gl.cull_mode;
        if (SG_CULLMODE_NONE == pip->gl.cull_mode) {
            glDisable(GL_CULL_FACE);
            _sg_stats_add(gl.num_render_state, 1);
        } else {
            glEnable(GL_CULL_FACE);
            GLenum gl_mode = (SG_CULLMODE_FRONT == pip->gl.cull_mode) ? GL_FRONT : GL_BACK;
            glCullFace(gl_mode);
            _sg_stats_add(gl.num_render_state, 2);
        }
    }
    if (pip->gl.face_winding != _sg.gl.cache.face_winding) {
        _sg.gl.cache.face_winding = pip->gl.face_winding;
        GLenum gl_winding = (SG_FACEWINDING_CW == pip->gl.face_winding) ? GL_CW : GL_CCW;
        glFrontFace(gl_winding);
        _sg_stats_add(gl.num_render_state, 1);
    }
    if (pip->gl.alpha_to_coverage_enabled != _sg.gl.cache.alpha_to_coverage_enabled) {
        _sg.gl.cache.alpha_to_coverage_enabled = pip->gl.alpha_to_coverage_enabled;
        if (pip->gl.alpha_to_coverage_enabled) {
            glEnable(GL_SAMPLE_ALPHA_TO_COVERAGE);
        } else {
            glDisable(GL_SAMPLE_ALPHA_TO_COVERAGE);
        }
        _sg_stats_add(gl.num_render_state, 1);
    }
    #ifdef SOKOL_GLCORE
    if (pip->gl.sample_count != _sg.gl.cache.sample_count) {
        _sg.gl.cache.sample_count = pip->gl.sample_count;
        if (pip->gl.sample_count > 1) {
            glEnable(GL_MULTISAMPLE);
        } else {
            glDisable(GL_MULTISAMPLE);
        }
        _sg_stats_add(gl.num_render_state, 1);
    }
    #endif
}

_SOKOL_PRIVATE void _sg_gl_apply_compute_pipeline_state(_sg_pipeline_t* pip) {
    #if defined(_SOKOL_GL_HAS_COMPUTE)
    // apply storage attachment images (if any)
    if (_sg.cur_pass.atts) {
        const _sg_attachments_t* atts = _sg.cur_pass.atts;
        const _sg_shader_t* shd = pip->shader;
        for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
            if (shd->cmn.storage_images[i].stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            SOKOL_ASSERT(shd->cmn.storage_images[i].stage == SG_SHADERSTAGE_COMPUTE);
            SOKOL_ASSERT(shd->gl.simg_binding[i] < _SG_GL_MAX_SIMG_BINDINGS);
            SOKOL_ASSERT(atts->gl.storages[i].image);
            _sg_image_t* img = atts->gl.storages[i].image;
            GLuint gl_unit = shd->gl.simg_binding[i];
            GLuint gl_tex = img->gl.tex[img->cmn.active_slot];
            GLint level = atts->cmn.storages[i].mip_level;
            GLint layer = atts->cmn.storages[i].slice;
            GLboolean layered = shd->cmn.storage_images[i].image_type != SG_IMAGETYPE_2D;
            GLenum access = shd->cmn.storage_images[i].writeonly ? GL_WRITE_ONLY : GL_READ_WRITE;
            GLenum format = _sg_gl_teximage_internal_format(shd->cmn.storage_images[i].access_format);
            // FIXME: go through state cache, use attachment id as key
            glBindImageTexture(gl_unit, gl_tex, level, layered, layer, access, format);
            _SG_GL_CHECK_ERROR();
        }
    }
    #else
    _SOKOL_UNUSED(pip);
    #endif
}

_SOKOL_PRIVATE void _sg_gl_apply_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));
    _SG_GL_CHECK_ERROR();
    if ((_sg.gl.cache.cur_pipeline != pip) || (_sg.gl.cache.cur_pipeline_id.id != pip->slot.id)) {
        _sg.gl.cache.cur_pipeline = pip;
        _sg.gl.cache.cur_pipeline_id.id = pip->slot.id;

        // bind shader program
        if (pip->shader->gl.prog != _sg.gl.cache.prog) {
            _sg.gl.cache.prog = pip->shader->gl.prog;
            glUseProgram(pip->shader->gl.prog);
            _sg_stats_add(gl.num_use_program, 1);
        }

        if (pip->cmn.is_compute) {
            _sg_gl_apply_compute_pipeline_state(pip);
        } else {
            _sg_gl_apply_render_pipeline_state(pip);
        }
    }
    _SG_GL_CHECK_ERROR();
}

#if defined(_SOKOL_GL_HAS_COMPUTE)
_SOKOL_PRIVATE void _sg_gl_handle_memory_barriers(const _sg_shader_t* shd, const _sg_bindings_ptrs_t* bnd) {
    if (!_sg.features.compute) {
        return;
    }
    GLbitfield gl_barrier_bits = 0;

    // if vertex-, index- or storage-buffer bindings have been written
    // by a compute shader before, a barrier must be issued
    for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
        _sg_buffer_t* buf = bnd->vbs[i];
        if (!buf) {
            continue;
        }
        if (buf->gl.gpu_dirty_flags & _SG_GL_GPUDIRTY_VERTEXBUFFER) {
            gl_barrier_bits |= GL_VERTEX_ATTRIB_ARRAY_BARRIER_BIT;
            buf->gl.gpu_dirty_flags &= (uint8_t)~_SG_GL_GPUDIRTY_VERTEXBUFFER;
        }
    }
    if (bnd->ib) {
        _sg_buffer_t* buf = bnd->ib;
        if (buf->gl.gpu_dirty_flags & _SG_GL_GPUDIRTY_INDEXBUFFER) {
            gl_barrier_bits |= GL_ELEMENT_ARRAY_BARRIER_BIT;
            buf->gl.gpu_dirty_flags &= (uint8_t)~_SG_GL_GPUDIRTY_INDEXBUFFER;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        _sg_buffer_t* buf = bnd->sbufs[i];
        if (!buf) {
            continue;
        }
        SOKOL_ASSERT(shd->cmn.storage_buffers[i].stage != SG_SHADERSTAGE_NONE);
        if (buf->gl.gpu_dirty_flags & _SG_GL_GPUDIRTY_STORAGEBUFFER) {
            gl_barrier_bits |= GL_SHADER_STORAGE_BARRIER_BIT;
            buf->gl.gpu_dirty_flags &= (uint8_t)~_SG_GL_GPUDIRTY_STORAGEBUFFER;
        }
    }

    // mark storage buffers as dirty which will be written by compute shaders
    // (don't merge this into the above loop, this would mess up the dirty
    // dirty flags if the same buffer is bound multiple times)
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        _sg_buffer_t* buf = bnd->sbufs[i];
        if (!buf) {
            continue;
        }
        if (!shd->cmn.storage_buffers[i].readonly) {
            buf->gl.gpu_dirty_flags = _SG_GL_GPUDIRTY_BUFFER_ALL;
        }
    }
    if (0 != gl_barrier_bits) {
        glMemoryBarrier(gl_barrier_bits);
        _sg_stats_add(gl.num_memory_barriers, 1);
    }
}
#endif

_SOKOL_PRIVATE bool _sg_gl_apply_bindings(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(bnd);
    SOKOL_ASSERT(bnd->pip && bnd->pip->shader);
    SOKOL_ASSERT(bnd->pip->shader->slot.id == bnd->pip->cmn.shader_id.id);
    _SG_GL_CHECK_ERROR();
    const _sg_shader_t* shd = bnd->pip->shader;

    // bind combined image-samplers
    _SG_GL_CHECK_ERROR();
    for (size_t img_smp_index = 0; img_smp_index < SG_MAX_IMAGE_SAMPLER_PAIRS; img_smp_index++) {
        const _sg_shader_image_sampler_t* img_smp = &shd->cmn.image_samplers[img_smp_index];
        if (img_smp->stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        const int8_t gl_tex_slot = (GLint)shd->gl.tex_slot[img_smp_index];
        if (gl_tex_slot != -1) {
            SOKOL_ASSERT(img_smp->image_slot < SG_MAX_IMAGE_BINDSLOTS);
            SOKOL_ASSERT(img_smp->sampler_slot < SG_MAX_SAMPLER_BINDSLOTS);
            const _sg_image_t* img = bnd->imgs[img_smp->image_slot];
            const _sg_sampler_t* smp = bnd->smps[img_smp->sampler_slot];
            SOKOL_ASSERT(img);
            SOKOL_ASSERT(smp);
            const GLenum gl_tgt = img->gl.target;
            const GLuint gl_tex = img->gl.tex[img->cmn.active_slot];
            const GLuint gl_smp = smp->gl.smp;
            _sg_gl_cache_bind_texture_sampler(gl_tex_slot, gl_tgt, gl_tex, gl_smp);
        }
    }
    _SG_GL_CHECK_ERROR();

    // bind storage buffers
    for (size_t sbuf_index = 0; sbuf_index < SG_MAX_STORAGEBUFFER_BINDSLOTS; sbuf_index++) {
        if (shd->cmn.storage_buffers[sbuf_index].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        const _sg_buffer_t* sbuf = bnd->sbufs[sbuf_index];
        const uint8_t binding = shd->gl.sbuf_binding[sbuf_index];
        GLuint gl_sbuf = sbuf->gl.buf[sbuf->cmn.active_slot];
        _sg_gl_cache_bind_storage_buffer(binding, gl_sbuf);
    }
    _SG_GL_CHECK_ERROR();

    if (!bnd->pip->cmn.is_compute) {
        // index buffer (can be 0)
        const GLuint gl_ib = bnd->ib ? bnd->ib->gl.buf[bnd->ib->cmn.active_slot] : 0;
        _sg_gl_cache_bind_buffer(GL_ELEMENT_ARRAY_BUFFER, gl_ib);
        _sg.gl.cache.cur_ib_offset = bnd->ib_offset;

        // vertex attributes
        for (GLuint attr_index = 0; attr_index < (GLuint)_sg.limits.max_vertex_attrs; attr_index++) {
            _sg_gl_attr_t* attr = &bnd->pip->gl.attrs[attr_index];
            _sg_gl_cache_attr_t* cache_attr = &_sg.gl.cache.attrs[attr_index];
            bool cache_attr_dirty = false;
            int vb_offset = 0;
            GLuint gl_vb = 0;
            if (attr->vb_index >= 0) {
                // attribute is enabled
                SOKOL_ASSERT(attr->vb_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
                _sg_buffer_t* vb = bnd->vbs[attr->vb_index];
                SOKOL_ASSERT(vb);
                gl_vb = vb->gl.buf[vb->cmn.active_slot];
                vb_offset = bnd->vb_offsets[attr->vb_index] + attr->offset;
                if ((gl_vb != cache_attr->gl_vbuf) ||
                    (attr->size != cache_attr->gl_attr.size) ||
                    (attr->type != cache_attr->gl_attr.type) ||
                    (attr->normalized != cache_attr->gl_attr.normalized) ||
                    (attr->base_type != cache_attr->gl_attr.base_type) ||
                    (attr->stride != cache_attr->gl_attr.stride) ||
                    (vb_offset != cache_attr->gl_attr.offset) ||
                    (cache_attr->gl_attr.divisor != attr->divisor))
                {
                    _sg_gl_cache_bind_buffer(GL_ARRAY_BUFFER, gl_vb);
                    if (attr->base_type == SG_SHADERATTRBASETYPE_FLOAT) {
                        glVertexAttribPointer(attr_index, attr->size, attr->type, attr->normalized, attr->stride, (const GLvoid*)(GLintptr)vb_offset);
                    } else {
                        glVertexAttribIPointer(attr_index, attr->size, attr->type, attr->stride, (const GLvoid*)(GLintptr)vb_offset);
                    }
                    _sg_stats_add(gl.num_vertex_attrib_pointer, 1);
                    glVertexAttribDivisor(attr_index, (GLuint)attr->divisor);
                    _sg_stats_add(gl.num_vertex_attrib_divisor, 1);
                    cache_attr_dirty = true;
                }
                if (cache_attr->gl_attr.vb_index == -1) {
                    glEnableVertexAttribArray(attr_index);
                    _sg_stats_add(gl.num_enable_vertex_attrib_array, 1);
                    cache_attr_dirty = true;
                }
            } else {
                // attribute is disabled
                if (cache_attr->gl_attr.vb_index != -1) {
                    glDisableVertexAttribArray(attr_index);
                    _sg_stats_add(gl.num_disable_vertex_attrib_array, 1);
                    cache_attr_dirty = true;
                }
            }
            if (cache_attr_dirty) {
                cache_attr->gl_attr = *attr;
                cache_attr->gl_attr.offset = vb_offset;
                cache_attr->gl_vbuf = gl_vb;
            }
        }
        _SG_GL_CHECK_ERROR();
    }

    // take care of storage buffer memory barriers (this needs to happen after the bindings are set)
    #if defined(_SOKOL_GL_HAS_COMPUTE)
    _sg_gl_handle_memory_barriers(shd, bnd);
    _SG_GL_CHECK_ERROR();
    #endif

    return true;
}

_SOKOL_PRIVATE void _sg_gl_apply_uniforms(int ub_slot, const sg_range* data) {
    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline);
    SOKOL_ASSERT((ub_slot >= 0) && (ub_slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS));
    const _sg_pipeline_t* pip = _sg.gl.cache.cur_pipeline;
    SOKOL_ASSERT(pip && pip->shader);
    SOKOL_ASSERT(pip->slot.id == _sg.gl.cache.cur_pipeline_id.id);
    const _sg_shader_t* shd = pip->shader;
    SOKOL_ASSERT(shd->slot.id == pip->cmn.shader_id.id);
    SOKOL_ASSERT(SG_SHADERSTAGE_NONE != shd->cmn.uniform_blocks[ub_slot].stage);
    SOKOL_ASSERT(data->size == shd->cmn.uniform_blocks[ub_slot].size);
    const _sg_gl_uniform_block_t* gl_ub = &shd->gl.uniform_blocks[ub_slot];
    for (int u_index = 0; u_index < gl_ub->num_uniforms; u_index++) {
        const _sg_gl_uniform_t* u = &gl_ub->uniforms[u_index];
        SOKOL_ASSERT(u->type != SG_UNIFORMTYPE_INVALID);
        if (u->gl_loc == -1) {
            continue;
        }
        _sg_stats_add(gl.num_uniform, 1);
        GLfloat* fptr = (GLfloat*) (((uint8_t*)data->ptr) + u->offset);
        GLint* iptr = (GLint*) (((uint8_t*)data->ptr) + u->offset);
        switch (u->type) {
            case SG_UNIFORMTYPE_INVALID:
                break;
            case SG_UNIFORMTYPE_FLOAT:
                glUniform1fv(u->gl_loc, u->count, fptr);
                break;
            case SG_UNIFORMTYPE_FLOAT2:
                glUniform2fv(u->gl_loc, u->count, fptr);
                break;
            case SG_UNIFORMTYPE_FLOAT3:
                glUniform3fv(u->gl_loc, u->count, fptr);
                break;
            case SG_UNIFORMTYPE_FLOAT4:
                glUniform4fv(u->gl_loc, u->count, fptr);
                break;
            case SG_UNIFORMTYPE_INT:
                glUniform1iv(u->gl_loc, u->count, iptr);
                break;
            case SG_UNIFORMTYPE_INT2:
                glUniform2iv(u->gl_loc, u->count, iptr);
                break;
            case SG_UNIFORMTYPE_INT3:
                glUniform3iv(u->gl_loc, u->count, iptr);
                break;
            case SG_UNIFORMTYPE_INT4:
                glUniform4iv(u->gl_loc, u->count, iptr);
                break;
            case SG_UNIFORMTYPE_MAT4:
                glUniformMatrix4fv(u->gl_loc, u->count, GL_FALSE, fptr);
                break;
            default:
                SOKOL_UNREACHABLE;
                break;
        }
    }
}

_SOKOL_PRIVATE void _sg_gl_draw(int base_element, int num_elements, int num_instances) {
    SOKOL_ASSERT(_sg.gl.cache.cur_pipeline);
    const GLenum i_type = _sg.gl.cache.cur_index_type;
    const GLenum p_type = _sg.gl.cache.cur_primitive_type;
    const bool use_instanced_draw = (num_instances > 1) || (_sg.gl.cache.cur_pipeline->cmn.use_instanced_draw);
    if (0 != i_type) {
        // indexed rendering
        const int i_size = (i_type == GL_UNSIGNED_SHORT) ? 2 : 4;
        const int ib_offset = _sg.gl.cache.cur_ib_offset;
        const GLvoid* indices = (const GLvoid*)(GLintptr)(base_element*i_size+ib_offset);
        if (use_instanced_draw) {
            glDrawElementsInstanced(p_type, num_elements, i_type, indices, num_instances);
        } else {
            glDrawElements(p_type, num_elements, i_type, indices);
        }
    } else {
        // non-indexed rendering
        if (use_instanced_draw) {
            glDrawArraysInstanced(p_type, base_element, num_elements, num_instances);
        } else {
            glDrawArrays(p_type, base_element, num_elements);
        }
    }
}

_SOKOL_PRIVATE void _sg_gl_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    #if defined(_SOKOL_GL_HAS_COMPUTE)
    if (!_sg.features.compute) {
        return;
    }
    glDispatchCompute((GLuint)num_groups_x, (GLuint)num_groups_y, (GLuint)num_groups_z);
    #else
    (void)num_groups_x; (void)num_groups_y; (void)num_groups_z;
    #endif
}

_SOKOL_PRIVATE void _sg_gl_commit(void) {
    // "soft" clear bindings (only those that are actually bound)
    _sg_gl_cache_clear_buffer_bindings(false);
    _sg_gl_cache_clear_texture_sampler_bindings(false);
}

_SOKOL_PRIVATE void _sg_gl_update_buffer(_sg_buffer_t* buf, const sg_range* data) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    // only one update per buffer per frame allowed
    if (++buf->cmn.active_slot >= buf->cmn.num_slots) {
        buf->cmn.active_slot = 0;
    }
    GLenum gl_tgt = _sg_gl_buffer_target(&buf->cmn.usage);
    SOKOL_ASSERT(buf->cmn.active_slot < SG_NUM_INFLIGHT_FRAMES);
    GLuint gl_buf = buf->gl.buf[buf->cmn.active_slot];
    SOKOL_ASSERT(gl_buf);
    _SG_GL_CHECK_ERROR();
    _sg_gl_cache_store_buffer_binding(gl_tgt);
    _sg_gl_cache_bind_buffer(gl_tgt, gl_buf);
    glBufferSubData(gl_tgt, 0, (GLsizeiptr)data->size, data->ptr);
    _sg_gl_cache_restore_buffer_binding(gl_tgt);
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_append_buffer(_sg_buffer_t* buf, const sg_range* data, bool new_frame) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    if (new_frame) {
        if (++buf->cmn.active_slot >= buf->cmn.num_slots) {
            buf->cmn.active_slot = 0;
        }
    }
    GLenum gl_tgt = _sg_gl_buffer_target(&buf->cmn.usage);
    SOKOL_ASSERT(buf->cmn.active_slot < SG_NUM_INFLIGHT_FRAMES);
    GLuint gl_buf = buf->gl.buf[buf->cmn.active_slot];
    SOKOL_ASSERT(gl_buf);
    _SG_GL_CHECK_ERROR();
    _sg_gl_cache_store_buffer_binding(gl_tgt);
    _sg_gl_cache_bind_buffer(gl_tgt, gl_buf);
    glBufferSubData(gl_tgt, buf->cmn.append_pos, (GLsizeiptr)data->size, data->ptr);
    _sg_gl_cache_restore_buffer_binding(gl_tgt);
    _SG_GL_CHECK_ERROR();
}

_SOKOL_PRIVATE void _sg_gl_update_image(_sg_image_t* img, const sg_image_data* data) {
    SOKOL_ASSERT(img && data);
    // only one update per image per frame allowed
    if (++img->cmn.active_slot >= img->cmn.num_slots) {
        img->cmn.active_slot = 0;
    }
    SOKOL_ASSERT(img->cmn.active_slot < SG_NUM_INFLIGHT_FRAMES);
    SOKOL_ASSERT(0 != img->gl.tex[img->cmn.active_slot]);
    _sg_gl_cache_store_texture_sampler_binding(0);
    _sg_gl_cache_bind_texture_sampler(0, img->gl.target, img->gl.tex[img->cmn.active_slot], 0);
    const GLenum gl_img_format = _sg_gl_teximage_format(img->cmn.pixel_format);
    const GLenum gl_img_type = _sg_gl_teximage_type(img->cmn.pixel_format);
    const int num_faces = img->cmn.type == SG_IMAGETYPE_CUBE ? 6 : 1;
    const int num_mips = img->cmn.num_mipmaps;
    for (int face_index = 0; face_index < num_faces; face_index++) {
        for (int mip_index = 0; mip_index < num_mips; mip_index++) {
            GLenum gl_img_target = img->gl.target;
            if (SG_IMAGETYPE_CUBE == img->cmn.type) {
                gl_img_target = _sg_gl_cubeface_target(face_index);
            }
            const GLvoid* data_ptr = data->subimage[face_index][mip_index].ptr;
            int mip_width = _sg_miplevel_dim(img->cmn.width, mip_index);
            int mip_height = _sg_miplevel_dim(img->cmn.height, mip_index);
            if ((SG_IMAGETYPE_2D == img->cmn.type) || (SG_IMAGETYPE_CUBE == img->cmn.type)) {
                glTexSubImage2D(gl_img_target, mip_index,
                    0, 0,
                    mip_width, mip_height,
                    gl_img_format, gl_img_type,
                    data_ptr);
            } else if ((SG_IMAGETYPE_3D == img->cmn.type) || (SG_IMAGETYPE_ARRAY == img->cmn.type)) {
                int mip_depth = img->cmn.num_slices;
                if (SG_IMAGETYPE_3D == img->cmn.type) {
                    mip_depth = _sg_miplevel_dim(img->cmn.num_slices, mip_index);
                }
                glTexSubImage3D(gl_img_target, mip_index,
                    0, 0, 0,
                    mip_width, mip_height, mip_depth,
                    gl_img_format, gl_img_type,
                    data_ptr);

            }
        }
    }
    _sg_gl_cache_restore_texture_sampler_binding(0);
}

// ██████  ██████  ██████   ██  ██     ██████   █████   ██████ ██   ██ ███████ ███    ██ ██████
// ██   ██      ██ ██   ██ ███ ███     ██   ██ ██   ██ ██      ██  ██  ██      ████   ██ ██   ██
// ██   ██  █████  ██   ██  ██  ██     ██████  ███████ ██      █████   █████   ██ ██  ██ ██   ██
// ██   ██      ██ ██   ██  ██  ██     ██   ██ ██   ██ ██      ██  ██  ██      ██  ██ ██ ██   ██
// ██████  ██████  ██████   ██  ██     ██████  ██   ██  ██████ ██   ██ ███████ ██   ████ ██████
//
// >>d3d11 backend
#elif defined(SOKOL_D3D11)

#if defined(__cplusplus)
#define _sg_d3d11_AddRef(self) (self)->AddRef()
#else
#define _sg_d3d11_AddRef(self) (self)->lpVtbl->AddRef(self)
#endif

#if defined(__cplusplus)
#define _sg_d3d11_Release(self) (self)->Release()
#else
#define _sg_d3d11_Release(self) (self)->lpVtbl->Release(self)
#endif

// NOTE: This needs to be a macro since we can't use the polymorphism in C. It's called on many kinds of resources.
// NOTE: Based on microsoft docs, it's fine to call this with pData=NULL if DataSize is also zero.
#if defined(__cplusplus)
#define _sg_d3d11_SetPrivateData(self, guid, DataSize, pData) (self)->SetPrivateData(guid, DataSize, pData)
#else
#define _sg_d3d11_SetPrivateData(self, guid, DataSize, pData) (self)->lpVtbl->SetPrivateData(self, guid, DataSize, pData)
#endif

#if defined(__cplusplus)
#define _sg_win32_refguid(guid) guid
#else
#define _sg_win32_refguid(guid) &guid
#endif

static const GUID _sg_d3d11_WKPDID_D3DDebugObjectName = { 0x429b8c22,0x9188,0x4b0c, {0x87,0x42,0xac,0xb0,0xbf,0x85,0xc2,0x00} };

#if defined(SOKOL_DEBUG)
#define _sg_d3d11_setlabel(self, label) _sg_d3d11_SetPrivateData(self, _sg_win32_refguid(_sg_d3d11_WKPDID_D3DDebugObjectName), label ? (UINT)strlen(label) : 0, label)
#else
#define _sg_d3d11_setlabel(self, label)
#endif


//-- D3D11 C/C++ wrappers ------------------------------------------------------
static inline HRESULT _sg_d3d11_CheckFormatSupport(ID3D11Device* self, DXGI_FORMAT Format, UINT* pFormatSupport) {
    #if defined(__cplusplus)
        return self->CheckFormatSupport(Format, pFormatSupport);
    #else
        return self->lpVtbl->CheckFormatSupport(self, Format, pFormatSupport);
    #endif
}

static inline void _sg_d3d11_OMSetRenderTargets(ID3D11DeviceContext* self, UINT NumViews, ID3D11RenderTargetView* const* ppRenderTargetViews, ID3D11DepthStencilView *pDepthStencilView) {
    #if defined(__cplusplus)
        self->OMSetRenderTargets(NumViews, ppRenderTargetViews, pDepthStencilView);
    #else
        self->lpVtbl->OMSetRenderTargets(self, NumViews, ppRenderTargetViews, pDepthStencilView);
    #endif
}

static inline void _sg_d3d11_RSSetState(ID3D11DeviceContext* self, ID3D11RasterizerState* pRasterizerState) {
    #if defined(__cplusplus)
        self->RSSetState(pRasterizerState);
    #else
        self->lpVtbl->RSSetState(self, pRasterizerState);
    #endif
}

static inline void _sg_d3d11_OMSetDepthStencilState(ID3D11DeviceContext* self, ID3D11DepthStencilState* pDepthStencilState, UINT StencilRef) {
    #if defined(__cplusplus)
        self->OMSetDepthStencilState(pDepthStencilState, StencilRef);
    #else
        self->lpVtbl->OMSetDepthStencilState(self, pDepthStencilState, StencilRef);
    #endif
}

static inline void _sg_d3d11_OMSetBlendState(ID3D11DeviceContext* self, ID3D11BlendState* pBlendState, const FLOAT BlendFactor[4], UINT SampleMask) {
    #if defined(__cplusplus)
        self->OMSetBlendState(pBlendState, BlendFactor, SampleMask);
    #else
        self->lpVtbl->OMSetBlendState(self, pBlendState, BlendFactor, SampleMask);
    #endif
}

static inline void _sg_d3d11_IASetVertexBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppVertexBuffers, const UINT* pStrides, const UINT* pOffsets) {
    #if defined(__cplusplus)
        self->IASetVertexBuffers(StartSlot, NumBuffers, ppVertexBuffers, pStrides, pOffsets);
    #else
        self->lpVtbl->IASetVertexBuffers(self, StartSlot, NumBuffers, ppVertexBuffers, pStrides, pOffsets);
    #endif
}

static inline void _sg_d3d11_IASetIndexBuffer(ID3D11DeviceContext* self, ID3D11Buffer* pIndexBuffer, DXGI_FORMAT Format, UINT Offset) {
    #if defined(__cplusplus)
        self->IASetIndexBuffer(pIndexBuffer, Format, Offset);
    #else
        self->lpVtbl->IASetIndexBuffer(self, pIndexBuffer, Format, Offset);
    #endif
}

static inline void _sg_d3d11_IASetInputLayout(ID3D11DeviceContext* self, ID3D11InputLayout* pInputLayout) {
    #if defined(__cplusplus)
        self->IASetInputLayout(pInputLayout);
    #else
        self->lpVtbl->IASetInputLayout(self, pInputLayout);
    #endif
}

static inline void _sg_d3d11_VSSetShader(ID3D11DeviceContext* self, ID3D11VertexShader* pVertexShader, ID3D11ClassInstance* const* ppClassInstances, UINT NumClassInstances) {
    #if defined(__cplusplus)
        self->VSSetShader(pVertexShader, ppClassInstances, NumClassInstances);
    #else
        self->lpVtbl->VSSetShader(self, pVertexShader, ppClassInstances, NumClassInstances);
    #endif
}

static inline void _sg_d3d11_PSSetShader(ID3D11DeviceContext* self, ID3D11PixelShader* pPixelShader, ID3D11ClassInstance* const* ppClassInstances, UINT NumClassInstances) {
    #if defined(__cplusplus)
        self->PSSetShader(pPixelShader, ppClassInstances, NumClassInstances);
    #else
        self->lpVtbl->PSSetShader(self, pPixelShader, ppClassInstances, NumClassInstances);
    #endif
}

static inline void _sg_d3d11_CSSetShader(ID3D11DeviceContext* self, ID3D11ComputeShader* pComputeShader, ID3D11ClassInstance* const* ppClassInstances, UINT NumClassInstances) {
    #if defined(__cplusplus)
        self->CSSetShader(pComputeShader, ppClassInstances, NumClassInstances);
    #else
        self->lpVtbl->CSSetShader(self, pComputeShader, ppClassInstances, NumClassInstances);
    #endif
}

static inline void _sg_d3d11_VSSetConstantBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppConstantBuffers) {
    #if defined(__cplusplus)
        self->VSSetConstantBuffers(StartSlot, NumBuffers, ppConstantBuffers);
    #else
        self->lpVtbl->VSSetConstantBuffers(self, StartSlot, NumBuffers, ppConstantBuffers);
    #endif
}

static inline void _sg_d3d11_PSSetConstantBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppConstantBuffers) {
    #if defined(__cplusplus)
        self->PSSetConstantBuffers(StartSlot, NumBuffers, ppConstantBuffers);
    #else
        self->lpVtbl->PSSetConstantBuffers(self, StartSlot, NumBuffers, ppConstantBuffers);
    #endif
}

static inline void _sg_d3d11_CSSetConstantBuffers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumBuffers, ID3D11Buffer* const* ppConstantBuffers) {
    #if defined(__cplusplus)
        self->CSSetConstantBuffers(StartSlot, NumBuffers, ppConstantBuffers);
    #else
        self->lpVtbl->CSSetConstantBuffers(self, StartSlot, NumBuffers, ppConstantBuffers);
    #endif
}

static inline void _sg_d3d11_VSSetShaderResources(ID3D11DeviceContext* self, UINT StartSlot, UINT NumViews, ID3D11ShaderResourceView* const* ppShaderResourceViews) {
    #if defined(__cplusplus)
        self->VSSetShaderResources(StartSlot, NumViews, ppShaderResourceViews);
    #else
        self->lpVtbl->VSSetShaderResources(self, StartSlot, NumViews, ppShaderResourceViews);
    #endif
}

static inline void _sg_d3d11_PSSetShaderResources(ID3D11DeviceContext* self, UINT StartSlot, UINT NumViews, ID3D11ShaderResourceView* const* ppShaderResourceViews) {
    #if defined(__cplusplus)
        self->PSSetShaderResources(StartSlot, NumViews, ppShaderResourceViews);
    #else
        self->lpVtbl->PSSetShaderResources(self, StartSlot, NumViews, ppShaderResourceViews);
    #endif
}

static inline void _sg_d3d11_CSSetShaderResources(ID3D11DeviceContext* self, UINT StartSlot, UINT NumViews, ID3D11ShaderResourceView* const* ppShaderResourceViews) {
    #if defined(__cplusplus)
        self->CSSetShaderResources(StartSlot, NumViews, ppShaderResourceViews);
    #else
        self->lpVtbl->CSSetShaderResources(self, StartSlot, NumViews, ppShaderResourceViews);
    #endif
}

static inline void _sg_d3d11_VSSetSamplers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumSamplers, ID3D11SamplerState* const* ppSamplers) {
    #if defined(__cplusplus)
        self->VSSetSamplers(StartSlot, NumSamplers, ppSamplers);
    #else
        self->lpVtbl->VSSetSamplers(self, StartSlot, NumSamplers, ppSamplers);
    #endif
}

static inline void _sg_d3d11_PSSetSamplers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumSamplers, ID3D11SamplerState* const* ppSamplers) {
    #if defined(__cplusplus)
        self->PSSetSamplers(StartSlot, NumSamplers, ppSamplers);
    #else
        self->lpVtbl->PSSetSamplers(self, StartSlot, NumSamplers, ppSamplers);
    #endif
}

static inline void _sg_d3d11_CSSetSamplers(ID3D11DeviceContext* self, UINT StartSlot, UINT NumSamplers, ID3D11SamplerState* const* ppSamplers) {
    #if defined(__cplusplus)
        self->CSSetSamplers(StartSlot, NumSamplers, ppSamplers);
    #else
        self->lpVtbl->CSSetSamplers(self, StartSlot, NumSamplers, ppSamplers);
    #endif
}

static inline void _sg_d3d11_CSSetUnorderedAccessViews(ID3D11DeviceContext* self, UINT StartSlot, UINT NumUAVs, ID3D11UnorderedAccessView* const* ppUnorderedAccessViews, const UINT* pUAVInitialCounts) {
    #if defined(__cplusplus)
        self->CSSetUnorderedAccessViews(StartSlot, NumUAVs, ppUnorderedAccessViews, pUAVInitialCounts);
    #else
        self->lpVtbl->CSSetUnorderedAccessViews(self, StartSlot, NumUAVs, ppUnorderedAccessViews, pUAVInitialCounts);
    #endif
}

static inline HRESULT _sg_d3d11_CreateBuffer(ID3D11Device* self, const D3D11_BUFFER_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Buffer** ppBuffer) {
    #if defined(__cplusplus)
        return self->CreateBuffer(pDesc, pInitialData, ppBuffer);
    #else
        return self->lpVtbl->CreateBuffer(self, pDesc, pInitialData, ppBuffer);
    #endif
}

static inline HRESULT _sg_d3d11_CreateTexture2D(ID3D11Device* self, const D3D11_TEXTURE2D_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Texture2D** ppTexture2D) {
    #if defined(__cplusplus)
        return self->CreateTexture2D(pDesc, pInitialData, ppTexture2D);
    #else
        return self->lpVtbl->CreateTexture2D(self, pDesc, pInitialData, ppTexture2D);
    #endif
}

static inline HRESULT _sg_d3d11_CreateShaderResourceView(ID3D11Device* self, ID3D11Resource* pResource, const D3D11_SHADER_RESOURCE_VIEW_DESC* pDesc, ID3D11ShaderResourceView** ppSRView) {
    #if defined(__cplusplus)
        return self->CreateShaderResourceView(pResource, pDesc, ppSRView);
    #else
        return self->lpVtbl->CreateShaderResourceView(self, pResource, pDesc, ppSRView);
    #endif
}

static inline HRESULT _sg_d3d11_CreateUnorderedAccessView(ID3D11Device* self, ID3D11Resource* pResource, const D3D11_UNORDERED_ACCESS_VIEW_DESC* pDesc, ID3D11UnorderedAccessView** ppUAVView) {
    #if defined(__cplusplus)
        return self->CreateUnorderedAccessView(pResource, pDesc, ppUAVView);
    #else
        return self->lpVtbl->CreateUnorderedAccessView(self, pResource, pDesc, ppUAVView);
    #endif
}

static inline void _sg_d3d11_GetResource(ID3D11View* self, ID3D11Resource** ppResource) {
    #if defined(__cplusplus)
        self->GetResource(ppResource);
    #else
        self->lpVtbl->GetResource(self, ppResource);
    #endif
}

static inline HRESULT _sg_d3d11_CreateTexture3D(ID3D11Device* self, const D3D11_TEXTURE3D_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Texture3D** ppTexture3D) {
    #if defined(__cplusplus)
        return self->CreateTexture3D(pDesc, pInitialData, ppTexture3D);
    #else
        return self->lpVtbl->CreateTexture3D(self, pDesc, pInitialData, ppTexture3D);
    #endif
}

static inline HRESULT _sg_d3d11_CreateSamplerState(ID3D11Device* self, const D3D11_SAMPLER_DESC* pSamplerDesc, ID3D11SamplerState** ppSamplerState) {
    #if defined(__cplusplus)
        return self->CreateSamplerState(pSamplerDesc, ppSamplerState);
    #else
        return self->lpVtbl->CreateSamplerState(self, pSamplerDesc, ppSamplerState);
    #endif
}

static inline LPVOID _sg_d3d11_GetBufferPointer(ID3D10Blob* self) {
    #if defined(__cplusplus)
        return self->GetBufferPointer();
    #else
        return self->lpVtbl->GetBufferPointer(self);
    #endif
}

static inline SIZE_T _sg_d3d11_GetBufferSize(ID3D10Blob* self) {
    #if defined(__cplusplus)
        return self->GetBufferSize();
    #else
        return self->lpVtbl->GetBufferSize(self);
    #endif
}

static inline HRESULT _sg_d3d11_CreateVertexShader(ID3D11Device* self, const void* pShaderBytecode, SIZE_T BytecodeLength, ID3D11ClassLinkage* pClassLinkage, ID3D11VertexShader** ppVertexShader) {
    #if defined(__cplusplus)
        return self->CreateVertexShader(pShaderBytecode, BytecodeLength, pClassLinkage, ppVertexShader);
    #else
        return self->lpVtbl->CreateVertexShader(self, pShaderBytecode, BytecodeLength, pClassLinkage, ppVertexShader);
    #endif
}

static inline HRESULT _sg_d3d11_CreatePixelShader(ID3D11Device* self, const void* pShaderBytecode, SIZE_T BytecodeLength, ID3D11ClassLinkage* pClassLinkage, ID3D11PixelShader** ppPixelShader) {
    #if defined(__cplusplus)
        return self->CreatePixelShader(pShaderBytecode, BytecodeLength, pClassLinkage, ppPixelShader);
    #else
        return self->lpVtbl->CreatePixelShader(self, pShaderBytecode, BytecodeLength, pClassLinkage, ppPixelShader);
    #endif
}

static inline HRESULT _sg_d3d11_CreateComputeShader(ID3D11Device* self, const void* pShaderBytecode, SIZE_T BytecodeLength, ID3D11ClassLinkage* pClassLinkage, ID3D11ComputeShader** ppComputeShader) {
    #if defined(__cplusplus)
        return self->CreateComputeShader(pShaderBytecode, BytecodeLength, pClassLinkage, ppComputeShader);
    #else
        return self->lpVtbl->CreateComputeShader(self, pShaderBytecode, BytecodeLength, pClassLinkage, ppComputeShader);
    #endif
}

static inline HRESULT _sg_d3d11_CreateInputLayout(ID3D11Device* self, const D3D11_INPUT_ELEMENT_DESC* pInputElementDescs, UINT NumElements, const void* pShaderBytecodeWithInputSignature, SIZE_T BytecodeLength, ID3D11InputLayout **ppInputLayout) {
    #if defined(__cplusplus)
        return self->CreateInputLayout(pInputElementDescs, NumElements, pShaderBytecodeWithInputSignature, BytecodeLength, ppInputLayout);
    #else
        return self->lpVtbl->CreateInputLayout(self, pInputElementDescs, NumElements, pShaderBytecodeWithInputSignature, BytecodeLength, ppInputLayout);
    #endif
}

static inline HRESULT _sg_d3d11_CreateRasterizerState(ID3D11Device* self, const D3D11_RASTERIZER_DESC* pRasterizerDesc, ID3D11RasterizerState** ppRasterizerState) {
    #if defined(__cplusplus)
        return self->CreateRasterizerState(pRasterizerDesc, ppRasterizerState);
    #else
        return self->lpVtbl->CreateRasterizerState(self, pRasterizerDesc, ppRasterizerState);
    #endif
}

static inline HRESULT _sg_d3d11_CreateDepthStencilState(ID3D11Device* self, const D3D11_DEPTH_STENCIL_DESC* pDepthStencilDesc, ID3D11DepthStencilState** ppDepthStencilState) {
    #if defined(__cplusplus)
        return self->CreateDepthStencilState(pDepthStencilDesc, ppDepthStencilState);
    #else
        return self->lpVtbl->CreateDepthStencilState(self, pDepthStencilDesc, ppDepthStencilState);
    #endif
}

static inline HRESULT _sg_d3d11_CreateBlendState(ID3D11Device* self, const D3D11_BLEND_DESC* pBlendStateDesc, ID3D11BlendState** ppBlendState) {
    #if defined(__cplusplus)
        return self->CreateBlendState(pBlendStateDesc, ppBlendState);
    #else
        return self->lpVtbl->CreateBlendState(self, pBlendStateDesc, ppBlendState);
    #endif
}

static inline HRESULT _sg_d3d11_CreateRenderTargetView(ID3D11Device* self, ID3D11Resource *pResource, const D3D11_RENDER_TARGET_VIEW_DESC* pDesc, ID3D11RenderTargetView** ppRTView) {
    #if defined(__cplusplus)
        return self->CreateRenderTargetView(pResource, pDesc, ppRTView);
    #else
        return self->lpVtbl->CreateRenderTargetView(self, pResource, pDesc, ppRTView);
    #endif
}

static inline HRESULT _sg_d3d11_CreateDepthStencilView(ID3D11Device* self, ID3D11Resource* pResource, const D3D11_DEPTH_STENCIL_VIEW_DESC* pDesc, ID3D11DepthStencilView** ppDepthStencilView) {
    #if defined(__cplusplus)
        return self->CreateDepthStencilView(pResource, pDesc, ppDepthStencilView);
    #else
        return self->lpVtbl->CreateDepthStencilView(self, pResource, pDesc, ppDepthStencilView);
    #endif
}

static inline void _sg_d3d11_RSSetViewports(ID3D11DeviceContext* self, UINT NumViewports, const D3D11_VIEWPORT* pViewports) {
    #if defined(__cplusplus)
        self->RSSetViewports(NumViewports, pViewports);
    #else
        self->lpVtbl->RSSetViewports(self, NumViewports, pViewports);
    #endif
}

static inline void _sg_d3d11_RSSetScissorRects(ID3D11DeviceContext* self, UINT NumRects, const D3D11_RECT* pRects) {
    #if defined(__cplusplus)
        self->RSSetScissorRects(NumRects, pRects);
    #else
        self->lpVtbl->RSSetScissorRects(self, NumRects, pRects);
    #endif
}

static inline void _sg_d3d11_ClearRenderTargetView(ID3D11DeviceContext* self, ID3D11RenderTargetView* pRenderTargetView, const FLOAT ColorRGBA[4]) {
    #if defined(__cplusplus)
        self->ClearRenderTargetView(pRenderTargetView, ColorRGBA);
    #else
        self->lpVtbl->ClearRenderTargetView(self, pRenderTargetView, ColorRGBA);
    #endif
}

static inline void _sg_d3d11_ClearDepthStencilView(ID3D11DeviceContext* self, ID3D11DepthStencilView* pDepthStencilView, UINT ClearFlags, FLOAT Depth, UINT8 Stencil) {
    #if defined(__cplusplus)
        self->ClearDepthStencilView(pDepthStencilView, ClearFlags, Depth, Stencil);
    #else
        self->lpVtbl->ClearDepthStencilView(self, pDepthStencilView, ClearFlags, Depth, Stencil);
    #endif
}

static inline void _sg_d3d11_ResolveSubresource(ID3D11DeviceContext* self, ID3D11Resource* pDstResource, UINT DstSubresource, ID3D11Resource* pSrcResource, UINT SrcSubresource, DXGI_FORMAT Format) {
    #if defined(__cplusplus)
        self->ResolveSubresource(pDstResource, DstSubresource, pSrcResource, SrcSubresource, Format);
    #else
        self->lpVtbl->ResolveSubresource(self, pDstResource, DstSubresource, pSrcResource, SrcSubresource, Format);
    #endif
}

static inline void _sg_d3d11_IASetPrimitiveTopology(ID3D11DeviceContext* self, D3D11_PRIMITIVE_TOPOLOGY Topology) {
    #if defined(__cplusplus)
        self->IASetPrimitiveTopology(Topology);
    #else
        self->lpVtbl->IASetPrimitiveTopology(self, Topology);
    #endif
}

static inline void _sg_d3d11_UpdateSubresource(ID3D11DeviceContext* self, ID3D11Resource* pDstResource, UINT DstSubresource, const D3D11_BOX* pDstBox, const void* pSrcData, UINT SrcRowPitch, UINT SrcDepthPitch) {
    #if defined(__cplusplus)
        self->UpdateSubresource(pDstResource, DstSubresource, pDstBox, pSrcData, SrcRowPitch, SrcDepthPitch);
    #else
        self->lpVtbl->UpdateSubresource(self, pDstResource, DstSubresource, pDstBox, pSrcData, SrcRowPitch, SrcDepthPitch);
    #endif
}

static inline void _sg_d3d11_DrawIndexed(ID3D11DeviceContext* self, UINT IndexCount, UINT StartIndexLocation, INT  BaseVertexLocation) {
    #if defined(__cplusplus)
        self->DrawIndexed(IndexCount, StartIndexLocation, BaseVertexLocation);
    #else
        self->lpVtbl->DrawIndexed(self, IndexCount, StartIndexLocation, BaseVertexLocation);
    #endif
}

static inline void _sg_d3d11_DrawIndexedInstanced(ID3D11DeviceContext* self, UINT IndexCountPerInstance, UINT InstanceCount, UINT StartIndexLocation, INT BaseVertexLocation, UINT StartInstanceLocation) {
    #if defined(__cplusplus)
        self->DrawIndexedInstanced(IndexCountPerInstance, InstanceCount, StartIndexLocation, BaseVertexLocation, StartInstanceLocation);
    #else
        self->lpVtbl->DrawIndexedInstanced(self, IndexCountPerInstance, InstanceCount, StartIndexLocation, BaseVertexLocation, StartInstanceLocation);
    #endif
}

static inline void _sg_d3d11_Draw(ID3D11DeviceContext* self, UINT VertexCount, UINT StartVertexLocation) {
    #if defined(__cplusplus)
        self->Draw(VertexCount, StartVertexLocation);
    #else
        self->lpVtbl->Draw(self, VertexCount, StartVertexLocation);
    #endif
}

static inline void _sg_d3d11_DrawInstanced(ID3D11DeviceContext* self, UINT VertexCountPerInstance, UINT InstanceCount, UINT StartVertexLocation, UINT StartInstanceLocation) {
    #if defined(__cplusplus)
        self->DrawInstanced(VertexCountPerInstance, InstanceCount, StartVertexLocation, StartInstanceLocation);
    #else
        self->lpVtbl->DrawInstanced(self, VertexCountPerInstance, InstanceCount, StartVertexLocation, StartInstanceLocation);
    #endif
}

static inline void _sg_d3d11_Dispatch(ID3D11DeviceContext* self, UINT ThreadGroupCountX, UINT ThreadGroupCountY, UINT ThreadGroupCountZ) {
    #if defined(__cplusplus)
        self->Dispatch(ThreadGroupCountX, ThreadGroupCountY, ThreadGroupCountZ);
    #else
        self->lpVtbl->Dispatch(self, ThreadGroupCountX, ThreadGroupCountY, ThreadGroupCountZ);
    #endif
}

static inline HRESULT _sg_d3d11_Map(ID3D11DeviceContext* self, ID3D11Resource* pResource, UINT Subresource, D3D11_MAP MapType, UINT MapFlags, D3D11_MAPPED_SUBRESOURCE* pMappedResource) {
    #if defined(__cplusplus)
        return self->Map(pResource, Subresource, MapType, MapFlags, pMappedResource);
    #else
        return self->lpVtbl->Map(self, pResource, Subresource, MapType, MapFlags, pMappedResource);
    #endif
}

static inline void _sg_d3d11_Unmap(ID3D11DeviceContext* self, ID3D11Resource* pResource, UINT Subresource) {
    #if defined(__cplusplus)
        self->Unmap(pResource, Subresource);
    #else
        self->lpVtbl->Unmap(self, pResource, Subresource);
    #endif
}

static inline void _sg_d3d11_ClearState(ID3D11DeviceContext* self) {
    #if defined(__cplusplus)
        self->ClearState();
    #else
        self->lpVtbl->ClearState(self);
    #endif
}

//-- enum translation functions ------------------------------------------------
_SOKOL_PRIVATE D3D11_USAGE _sg_d3d11_image_usage(const sg_image_usage* usg) {
    if (usg->immutable) {
        if (usg->render_attachment || usg->storage_attachment) {
            return D3D11_USAGE_DEFAULT;
        } else {
            return D3D11_USAGE_IMMUTABLE;
        }
    } else {
        return D3D11_USAGE_DYNAMIC;
    }
}

_SOKOL_PRIVATE UINT _sg_d3d11_image_bind_flags(const sg_image_usage* usg, sg_pixel_format fmt) {
    UINT res = D3D11_BIND_SHADER_RESOURCE;
    if (usg->render_attachment) {
        if (_sg_is_depth_or_depth_stencil_format(fmt)) {
            res |= D3D11_BIND_DEPTH_STENCIL;
        } else {
            res |= D3D11_BIND_RENDER_TARGET;
        }
    } else if (usg->storage_attachment) {
        res |= D3D11_BIND_UNORDERED_ACCESS;
    }
    return res;
}

_SOKOL_PRIVATE UINT _sg_d3d11_image_cpu_access_flags(const sg_image_usage* usg) {
    if (usg->render_attachment || usg->storage_attachment || usg->immutable) {
        return 0;
    } else {
        return D3D11_CPU_ACCESS_WRITE;
    }
}

_SOKOL_PRIVATE D3D11_USAGE _sg_d3d11_buffer_usage(const sg_buffer_usage* usg) {
    if (usg->immutable) {
        return usg->storage_buffer ? D3D11_USAGE_DEFAULT : D3D11_USAGE_IMMUTABLE;
    } else {
        return D3D11_USAGE_DYNAMIC;
    }
}

_SOKOL_PRIVATE UINT _sg_d3d11_buffer_bind_flags(const sg_buffer_usage* usg) {
    UINT res = 0;
    if (usg->vertex_buffer) {
        res |= D3D11_BIND_VERTEX_BUFFER;
    }
    if (usg->index_buffer) {
        res |= D3D11_BIND_INDEX_BUFFER;
    }
    if (usg->storage_buffer) {
        if (usg->immutable) {
            res |= D3D11_BIND_SHADER_RESOURCE | D3D11_BIND_UNORDERED_ACCESS;
        } else {
            res |= D3D11_BIND_SHADER_RESOURCE;
        }
    }
    return res;
}

_SOKOL_PRIVATE UINT _sg_d3d11_buffer_misc_flags(const sg_buffer_usage* usg) {
    return usg->storage_buffer ? D3D11_RESOURCE_MISC_BUFFER_ALLOW_RAW_VIEWS : 0;
}

_SOKOL_PRIVATE UINT _sg_d3d11_buffer_cpu_access_flags(const sg_buffer_usage* usg) {
    return usg->immutable ? 0 : D3D11_CPU_ACCESS_WRITE;
}

_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_texture_pixel_format(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_R8:             return DXGI_FORMAT_R8_UNORM;
        case SG_PIXELFORMAT_R8SN:           return DXGI_FORMAT_R8_SNORM;
        case SG_PIXELFORMAT_R8UI:           return DXGI_FORMAT_R8_UINT;
        case SG_PIXELFORMAT_R8SI:           return DXGI_FORMAT_R8_SINT;
        case SG_PIXELFORMAT_R16:            return DXGI_FORMAT_R16_UNORM;
        case SG_PIXELFORMAT_R16SN:          return DXGI_FORMAT_R16_SNORM;
        case SG_PIXELFORMAT_R16UI:          return DXGI_FORMAT_R16_UINT;
        case SG_PIXELFORMAT_R16SI:          return DXGI_FORMAT_R16_SINT;
        case SG_PIXELFORMAT_R16F:           return DXGI_FORMAT_R16_FLOAT;
        case SG_PIXELFORMAT_RG8:            return DXGI_FORMAT_R8G8_UNORM;
        case SG_PIXELFORMAT_RG8SN:          return DXGI_FORMAT_R8G8_SNORM;
        case SG_PIXELFORMAT_RG8UI:          return DXGI_FORMAT_R8G8_UINT;
        case SG_PIXELFORMAT_RG8SI:          return DXGI_FORMAT_R8G8_SINT;
        case SG_PIXELFORMAT_R32UI:          return DXGI_FORMAT_R32_UINT;
        case SG_PIXELFORMAT_R32SI:          return DXGI_FORMAT_R32_SINT;
        case SG_PIXELFORMAT_R32F:           return DXGI_FORMAT_R32_FLOAT;
        case SG_PIXELFORMAT_RG16:           return DXGI_FORMAT_R16G16_UNORM;
        case SG_PIXELFORMAT_RG16SN:         return DXGI_FORMAT_R16G16_SNORM;
        case SG_PIXELFORMAT_RG16UI:         return DXGI_FORMAT_R16G16_UINT;
        case SG_PIXELFORMAT_RG16SI:         return DXGI_FORMAT_R16G16_SINT;
        case SG_PIXELFORMAT_RG16F:          return DXGI_FORMAT_R16G16_FLOAT;
        case SG_PIXELFORMAT_RGBA8:          return DXGI_FORMAT_R8G8B8A8_UNORM;
        case SG_PIXELFORMAT_SRGB8A8:        return DXGI_FORMAT_R8G8B8A8_UNORM_SRGB;
        case SG_PIXELFORMAT_RGBA8SN:        return DXGI_FORMAT_R8G8B8A8_SNORM;
        case SG_PIXELFORMAT_RGBA8UI:        return DXGI_FORMAT_R8G8B8A8_UINT;
        case SG_PIXELFORMAT_RGBA8SI:        return DXGI_FORMAT_R8G8B8A8_SINT;
        case SG_PIXELFORMAT_BGRA8:          return DXGI_FORMAT_B8G8R8A8_UNORM;
        case SG_PIXELFORMAT_RGB10A2:        return DXGI_FORMAT_R10G10B10A2_UNORM;
        case SG_PIXELFORMAT_RG11B10F:       return DXGI_FORMAT_R11G11B10_FLOAT;
        case SG_PIXELFORMAT_RGB9E5:         return DXGI_FORMAT_R9G9B9E5_SHAREDEXP;
        case SG_PIXELFORMAT_RG32UI:         return DXGI_FORMAT_R32G32_UINT;
        case SG_PIXELFORMAT_RG32SI:         return DXGI_FORMAT_R32G32_SINT;
        case SG_PIXELFORMAT_RG32F:          return DXGI_FORMAT_R32G32_FLOAT;
        case SG_PIXELFORMAT_RGBA16:         return DXGI_FORMAT_R16G16B16A16_UNORM;
        case SG_PIXELFORMAT_RGBA16SN:       return DXGI_FORMAT_R16G16B16A16_SNORM;
        case SG_PIXELFORMAT_RGBA16UI:       return DXGI_FORMAT_R16G16B16A16_UINT;
        case SG_PIXELFORMAT_RGBA16SI:       return DXGI_FORMAT_R16G16B16A16_SINT;
        case SG_PIXELFORMAT_RGBA16F:        return DXGI_FORMAT_R16G16B16A16_FLOAT;
        case SG_PIXELFORMAT_RGBA32UI:       return DXGI_FORMAT_R32G32B32A32_UINT;
        case SG_PIXELFORMAT_RGBA32SI:       return DXGI_FORMAT_R32G32B32A32_SINT;
        case SG_PIXELFORMAT_RGBA32F:        return DXGI_FORMAT_R32G32B32A32_FLOAT;
        case SG_PIXELFORMAT_DEPTH:          return DXGI_FORMAT_R32_TYPELESS;
        case SG_PIXELFORMAT_DEPTH_STENCIL:  return DXGI_FORMAT_R24G8_TYPELESS;
        case SG_PIXELFORMAT_BC1_RGBA:       return DXGI_FORMAT_BC1_UNORM;
        case SG_PIXELFORMAT_BC2_RGBA:       return DXGI_FORMAT_BC2_UNORM;
        case SG_PIXELFORMAT_BC3_RGBA:       return DXGI_FORMAT_BC3_UNORM;
        case SG_PIXELFORMAT_BC3_SRGBA:      return DXGI_FORMAT_BC3_UNORM_SRGB;
        case SG_PIXELFORMAT_BC4_R:          return DXGI_FORMAT_BC4_UNORM;
        case SG_PIXELFORMAT_BC4_RSN:        return DXGI_FORMAT_BC4_SNORM;
        case SG_PIXELFORMAT_BC5_RG:         return DXGI_FORMAT_BC5_UNORM;
        case SG_PIXELFORMAT_BC5_RGSN:       return DXGI_FORMAT_BC5_SNORM;
        case SG_PIXELFORMAT_BC6H_RGBF:      return DXGI_FORMAT_BC6H_SF16;
        case SG_PIXELFORMAT_BC6H_RGBUF:     return DXGI_FORMAT_BC6H_UF16;
        case SG_PIXELFORMAT_BC7_RGBA:       return DXGI_FORMAT_BC7_UNORM;
        case SG_PIXELFORMAT_BC7_SRGBA:      return DXGI_FORMAT_BC7_UNORM_SRGB;
        default:                            return DXGI_FORMAT_UNKNOWN;
    };
}

_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_srv_pixel_format(sg_pixel_format fmt) {
    if (fmt == SG_PIXELFORMAT_DEPTH) {
        return DXGI_FORMAT_R32_FLOAT;
    } else if (fmt == SG_PIXELFORMAT_DEPTH_STENCIL) {
        return DXGI_FORMAT_R24_UNORM_X8_TYPELESS;
    } else {
        return _sg_d3d11_texture_pixel_format(fmt);
    }
}

_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_dsv_pixel_format(sg_pixel_format fmt) {
    if (fmt == SG_PIXELFORMAT_DEPTH) {
        return DXGI_FORMAT_D32_FLOAT;
    } else if (fmt == SG_PIXELFORMAT_DEPTH_STENCIL) {
        return DXGI_FORMAT_D24_UNORM_S8_UINT;
    } else {
        return _sg_d3d11_texture_pixel_format(fmt);
    }
}

_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_rtv_uav_pixel_format(sg_pixel_format fmt) {
    if (fmt == SG_PIXELFORMAT_DEPTH) {
        return DXGI_FORMAT_R32_FLOAT;
    } else if (fmt == SG_PIXELFORMAT_DEPTH_STENCIL) {
        return DXGI_FORMAT_R24_UNORM_X8_TYPELESS;
    } else {
        return _sg_d3d11_texture_pixel_format(fmt);
    }
}

_SOKOL_PRIVATE D3D11_PRIMITIVE_TOPOLOGY _sg_d3d11_primitive_topology(sg_primitive_type prim_type) {
    switch (prim_type) {
        case SG_PRIMITIVETYPE_POINTS:           return D3D11_PRIMITIVE_TOPOLOGY_POINTLIST;
        case SG_PRIMITIVETYPE_LINES:            return D3D11_PRIMITIVE_TOPOLOGY_LINELIST;
        case SG_PRIMITIVETYPE_LINE_STRIP:       return D3D11_PRIMITIVE_TOPOLOGY_LINESTRIP;
        case SG_PRIMITIVETYPE_TRIANGLES:        return D3D11_PRIMITIVE_TOPOLOGY_TRIANGLELIST;
        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return D3D11_PRIMITIVE_TOPOLOGY_TRIANGLESTRIP;
        default: SOKOL_UNREACHABLE; return (D3D11_PRIMITIVE_TOPOLOGY) 0;
    }
}

_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_index_format(sg_index_type index_type) {
    switch (index_type) {
        case SG_INDEXTYPE_NONE:     return DXGI_FORMAT_UNKNOWN;
        case SG_INDEXTYPE_UINT16:   return DXGI_FORMAT_R16_UINT;
        case SG_INDEXTYPE_UINT32:   return DXGI_FORMAT_R32_UINT;
        default: SOKOL_UNREACHABLE; return (DXGI_FORMAT) 0;
    }
}

_SOKOL_PRIVATE D3D11_FILTER _sg_d3d11_filter(sg_filter min_f, sg_filter mag_f, sg_filter mipmap_f, bool comparison, uint32_t max_anisotropy) {
    uint32_t d3d11_filter = 0;
    if (max_anisotropy > 1) {
        // D3D11_FILTER_ANISOTROPIC = 0x55,
        d3d11_filter |= 0x55;
    } else {
        // D3D11_FILTER_MIN_MAG_MIP_POINT = 0,
        // D3D11_FILTER_MIN_MAG_POINT_MIP_LINEAR = 0x1,
        // D3D11_FILTER_MIN_POINT_MAG_LINEAR_MIP_POINT = 0x4,
        // D3D11_FILTER_MIN_POINT_MAG_MIP_LINEAR = 0x5,
        // D3D11_FILTER_MIN_LINEAR_MAG_MIP_POINT = 0x10,
        // D3D11_FILTER_MIN_LINEAR_MAG_POINT_MIP_LINEAR = 0x11,
        // D3D11_FILTER_MIN_MAG_LINEAR_MIP_POINT = 0x14,
        // D3D11_FILTER_MIN_MAG_MIP_LINEAR = 0x15,
        if (mipmap_f == SG_FILTER_LINEAR) {
            d3d11_filter |= 0x01;
        }
        if (mag_f == SG_FILTER_LINEAR) {
            d3d11_filter |= 0x04;
        }
        if (min_f == SG_FILTER_LINEAR) {
            d3d11_filter |= 0x10;
        }
    }
    // D3D11_FILTER_COMPARISON_MIN_MAG_MIP_POINT = 0x80,
    // D3D11_FILTER_COMPARISON_MIN_MAG_POINT_MIP_LINEAR = 0x81,
    // D3D11_FILTER_COMPARISON_MIN_POINT_MAG_LINEAR_MIP_POINT = 0x84,
    // D3D11_FILTER_COMPARISON_MIN_POINT_MAG_MIP_LINEAR = 0x85,
    // D3D11_FILTER_COMPARISON_MIN_LINEAR_MAG_MIP_POINT = 0x90,
    // D3D11_FILTER_COMPARISON_MIN_LINEAR_MAG_POINT_MIP_LINEAR = 0x91,
    // D3D11_FILTER_COMPARISON_MIN_MAG_LINEAR_MIP_POINT = 0x94,
    // D3D11_FILTER_COMPARISON_MIN_MAG_MIP_LINEAR = 0x95,
    // D3D11_FILTER_COMPARISON_ANISOTROPIC = 0xd5,
    if (comparison) {
        d3d11_filter |= 0x80;
    }
    return (D3D11_FILTER)d3d11_filter;
}

_SOKOL_PRIVATE D3D11_TEXTURE_ADDRESS_MODE _sg_d3d11_address_mode(sg_wrap m) {
    switch (m) {
        case SG_WRAP_REPEAT:            return D3D11_TEXTURE_ADDRESS_WRAP;
        case SG_WRAP_CLAMP_TO_EDGE:     return D3D11_TEXTURE_ADDRESS_CLAMP;
        case SG_WRAP_CLAMP_TO_BORDER:   return D3D11_TEXTURE_ADDRESS_BORDER;
        case SG_WRAP_MIRRORED_REPEAT:   return D3D11_TEXTURE_ADDRESS_MIRROR;
        default: SOKOL_UNREACHABLE; return (D3D11_TEXTURE_ADDRESS_MODE) 0;
    }
}

_SOKOL_PRIVATE DXGI_FORMAT _sg_d3d11_vertex_format(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:     return DXGI_FORMAT_R32_FLOAT;
        case SG_VERTEXFORMAT_FLOAT2:    return DXGI_FORMAT_R32G32_FLOAT;
        case SG_VERTEXFORMAT_FLOAT3:    return DXGI_FORMAT_R32G32B32_FLOAT;
        case SG_VERTEXFORMAT_FLOAT4:    return DXGI_FORMAT_R32G32B32A32_FLOAT;
        case SG_VERTEXFORMAT_INT:       return DXGI_FORMAT_R32_SINT;
        case SG_VERTEXFORMAT_INT2:      return DXGI_FORMAT_R32G32_SINT;
        case SG_VERTEXFORMAT_INT3:      return DXGI_FORMAT_R32G32B32_SINT;
        case SG_VERTEXFORMAT_INT4:      return DXGI_FORMAT_R32G32B32A32_SINT;
        case SG_VERTEXFORMAT_UINT:      return DXGI_FORMAT_R32_UINT;
        case SG_VERTEXFORMAT_UINT2:     return DXGI_FORMAT_R32G32_UINT;
        case SG_VERTEXFORMAT_UINT3:     return DXGI_FORMAT_R32G32B32_UINT;
        case SG_VERTEXFORMAT_UINT4:     return DXGI_FORMAT_R32G32B32A32_UINT;
        case SG_VERTEXFORMAT_BYTE4:     return DXGI_FORMAT_R8G8B8A8_SINT;
        case SG_VERTEXFORMAT_BYTE4N:    return DXGI_FORMAT_R8G8B8A8_SNORM;
        case SG_VERTEXFORMAT_UBYTE4:    return DXGI_FORMAT_R8G8B8A8_UINT;
        case SG_VERTEXFORMAT_UBYTE4N:   return DXGI_FORMAT_R8G8B8A8_UNORM;
        case SG_VERTEXFORMAT_SHORT2:    return DXGI_FORMAT_R16G16_SINT;
        case SG_VERTEXFORMAT_SHORT2N:   return DXGI_FORMAT_R16G16_SNORM;
        case SG_VERTEXFORMAT_USHORT2:   return DXGI_FORMAT_R16G16_UINT;
        case SG_VERTEXFORMAT_USHORT2N:  return DXGI_FORMAT_R16G16_UNORM;
        case SG_VERTEXFORMAT_SHORT4:    return DXGI_FORMAT_R16G16B16A16_SINT;
        case SG_VERTEXFORMAT_SHORT4N:   return DXGI_FORMAT_R16G16B16A16_SNORM;
        case SG_VERTEXFORMAT_USHORT4:   return DXGI_FORMAT_R16G16B16A16_UINT;
        case SG_VERTEXFORMAT_USHORT4N:  return DXGI_FORMAT_R16G16B16A16_UNORM;
        case SG_VERTEXFORMAT_UINT10_N2: return DXGI_FORMAT_R10G10B10A2_UNORM;
        case SG_VERTEXFORMAT_HALF2:     return DXGI_FORMAT_R16G16_FLOAT;
        case SG_VERTEXFORMAT_HALF4:     return DXGI_FORMAT_R16G16B16A16_FLOAT;
        default: SOKOL_UNREACHABLE; return (DXGI_FORMAT) 0;
    }
}

_SOKOL_PRIVATE D3D11_INPUT_CLASSIFICATION _sg_d3d11_input_classification(sg_vertex_step step) {
    switch (step) {
        case SG_VERTEXSTEP_PER_VERTEX:      return D3D11_INPUT_PER_VERTEX_DATA;
        case SG_VERTEXSTEP_PER_INSTANCE:    return D3D11_INPUT_PER_INSTANCE_DATA;
        default: SOKOL_UNREACHABLE; return (D3D11_INPUT_CLASSIFICATION) 0;
    }
}

_SOKOL_PRIVATE D3D11_CULL_MODE _sg_d3d11_cull_mode(sg_cull_mode m) {
    switch (m) {
        case SG_CULLMODE_NONE:      return D3D11_CULL_NONE;
        case SG_CULLMODE_FRONT:     return D3D11_CULL_FRONT;
        case SG_CULLMODE_BACK:      return D3D11_CULL_BACK;
        default: SOKOL_UNREACHABLE; return (D3D11_CULL_MODE) 0;
    }
}

_SOKOL_PRIVATE D3D11_COMPARISON_FUNC _sg_d3d11_compare_func(sg_compare_func f) {
    switch (f) {
        case SG_COMPAREFUNC_NEVER:          return D3D11_COMPARISON_NEVER;
        case SG_COMPAREFUNC_LESS:           return D3D11_COMPARISON_LESS;
        case SG_COMPAREFUNC_EQUAL:          return D3D11_COMPARISON_EQUAL;
        case SG_COMPAREFUNC_LESS_EQUAL:     return D3D11_COMPARISON_LESS_EQUAL;
        case SG_COMPAREFUNC_GREATER:        return D3D11_COMPARISON_GREATER;
        case SG_COMPAREFUNC_NOT_EQUAL:      return D3D11_COMPARISON_NOT_EQUAL;
        case SG_COMPAREFUNC_GREATER_EQUAL:  return D3D11_COMPARISON_GREATER_EQUAL;
        case SG_COMPAREFUNC_ALWAYS:         return D3D11_COMPARISON_ALWAYS;
        default: SOKOL_UNREACHABLE; return (D3D11_COMPARISON_FUNC) 0;
    }
}

_SOKOL_PRIVATE D3D11_STENCIL_OP _sg_d3d11_stencil_op(sg_stencil_op op) {
    switch (op) {
        case SG_STENCILOP_KEEP:         return D3D11_STENCIL_OP_KEEP;
        case SG_STENCILOP_ZERO:         return D3D11_STENCIL_OP_ZERO;
        case SG_STENCILOP_REPLACE:      return D3D11_STENCIL_OP_REPLACE;
        case SG_STENCILOP_INCR_CLAMP:   return D3D11_STENCIL_OP_INCR_SAT;
        case SG_STENCILOP_DECR_CLAMP:   return D3D11_STENCIL_OP_DECR_SAT;
        case SG_STENCILOP_INVERT:       return D3D11_STENCIL_OP_INVERT;
        case SG_STENCILOP_INCR_WRAP:    return D3D11_STENCIL_OP_INCR;
        case SG_STENCILOP_DECR_WRAP:    return D3D11_STENCIL_OP_DECR;
        default: SOKOL_UNREACHABLE; return (D3D11_STENCIL_OP) 0;
    }
}

_SOKOL_PRIVATE D3D11_BLEND _sg_d3d11_blend_factor(sg_blend_factor f) {
    switch (f) {
        case SG_BLENDFACTOR_ZERO:                   return D3D11_BLEND_ZERO;
        case SG_BLENDFACTOR_ONE:                    return D3D11_BLEND_ONE;
        case SG_BLENDFACTOR_SRC_COLOR:              return D3D11_BLEND_SRC_COLOR;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return D3D11_BLEND_INV_SRC_COLOR;
        case SG_BLENDFACTOR_SRC_ALPHA:              return D3D11_BLEND_SRC_ALPHA;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return D3D11_BLEND_INV_SRC_ALPHA;
        case SG_BLENDFACTOR_DST_COLOR:              return D3D11_BLEND_DEST_COLOR;
        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return D3D11_BLEND_INV_DEST_COLOR;
        case SG_BLENDFACTOR_DST_ALPHA:              return D3D11_BLEND_DEST_ALPHA;
        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return D3D11_BLEND_INV_DEST_ALPHA;
        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return D3D11_BLEND_SRC_ALPHA_SAT;
        case SG_BLENDFACTOR_BLEND_COLOR:            return D3D11_BLEND_BLEND_FACTOR;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return D3D11_BLEND_INV_BLEND_FACTOR;
        case SG_BLENDFACTOR_BLEND_ALPHA:            return D3D11_BLEND_BLEND_FACTOR;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return D3D11_BLEND_INV_BLEND_FACTOR;
        default: SOKOL_UNREACHABLE; return (D3D11_BLEND) 0;
    }
}

_SOKOL_PRIVATE D3D11_BLEND_OP _sg_d3d11_blend_op(sg_blend_op op) {
    switch (op) {
        case SG_BLENDOP_ADD:                return D3D11_BLEND_OP_ADD;
        case SG_BLENDOP_SUBTRACT:           return D3D11_BLEND_OP_SUBTRACT;
        case SG_BLENDOP_REVERSE_SUBTRACT:   return D3D11_BLEND_OP_REV_SUBTRACT;
        case SG_BLENDOP_MIN:                return D3D11_BLEND_OP_MIN;
        case SG_BLENDOP_MAX:                return D3D11_BLEND_OP_MAX;
        default: SOKOL_UNREACHABLE; return (D3D11_BLEND_OP) 0;
    }
}

_SOKOL_PRIVATE UINT8 _sg_d3d11_color_write_mask(sg_color_mask m) {
    UINT8 res = 0;
    if (m & SG_COLORMASK_R) {
        res |= D3D11_COLOR_WRITE_ENABLE_RED;
    }
    if (m & SG_COLORMASK_G) {
        res |= D3D11_COLOR_WRITE_ENABLE_GREEN;
    }
    if (m & SG_COLORMASK_B) {
        res |= D3D11_COLOR_WRITE_ENABLE_BLUE;
    }
    if (m & SG_COLORMASK_A) {
        res |= D3D11_COLOR_WRITE_ENABLE_ALPHA;
    }
    return res;
}

_SOKOL_PRIVATE UINT _sg_d3d11_dxgi_fmt_caps(DXGI_FORMAT dxgi_fmt) {
    UINT dxgi_fmt_caps = 0;
    if (dxgi_fmt != DXGI_FORMAT_UNKNOWN) {
        HRESULT hr = _sg_d3d11_CheckFormatSupport(_sg.d3d11.dev, dxgi_fmt, &dxgi_fmt_caps);
        SOKOL_ASSERT(SUCCEEDED(hr) || (E_FAIL == hr));
        if (!SUCCEEDED(hr)) {
            dxgi_fmt_caps = 0;
        }
    }
    return dxgi_fmt_caps;
}

// see: https://docs.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-resources-limits#resource-limits-for-feature-level-11-hardware
_SOKOL_PRIVATE void _sg_d3d11_init_caps(void) {
    _sg.backend = SG_BACKEND_D3D11;

    _sg.features.origin_top_left = true;
    _sg.features.image_clamp_to_border = true;
    _sg.features.mrt_independent_blend_state = true;
    _sg.features.mrt_independent_write_mask = true;
    _sg.features.compute = true;
    _sg.features.msaa_image_bindings = true;

    _sg.limits.max_image_size_2d = 16 * 1024;
    _sg.limits.max_image_size_cube = 16 * 1024;
    _sg.limits.max_image_size_3d = 2 * 1024;
    _sg.limits.max_image_size_array = 16 * 1024;
    _sg.limits.max_image_array_layers = 2 * 1024;
    _sg.limits.max_vertex_attrs = SG_MAX_VERTEX_ATTRIBUTES;

    // see: https://docs.microsoft.com/en-us/windows/win32/api/d3d11/ne-d3d11-d3d11_format_support
    for (int fmt = (SG_PIXELFORMAT_NONE+1); fmt < _SG_PIXELFORMAT_NUM; fmt++) {
        const UINT srv_dxgi_fmt_caps = _sg_d3d11_dxgi_fmt_caps(_sg_d3d11_srv_pixel_format((sg_pixel_format)fmt));
        const UINT rtv_uav_dxgi_fmt_caps = _sg_d3d11_dxgi_fmt_caps(_sg_d3d11_rtv_uav_pixel_format((sg_pixel_format)fmt));
        const UINT dsv_dxgi_fmt_caps = _sg_d3d11_dxgi_fmt_caps(_sg_d3d11_dsv_pixel_format((sg_pixel_format)fmt));
        _sg_pixelformat_info_t* info = &_sg.formats[fmt];
        const bool render = 0 != (rtv_uav_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_RENDER_TARGET);
        const bool depth  = 0 != (dsv_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_DEPTH_STENCIL);
        info->sample = 0 != (srv_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_TEXTURE2D);
        info->filter = 0 != (srv_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_SHADER_SAMPLE);
        info->render = render || depth;
        if (depth) {
            info->blend = 0 != (dsv_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_BLENDABLE);
            info->msaa  = 0 != (dsv_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_MULTISAMPLE_RENDERTARGET);
        } else {
            info->blend = 0 != (rtv_uav_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_BLENDABLE);
            info->msaa  = 0 != (rtv_uav_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_MULTISAMPLE_RENDERTARGET);
        }
        info->depth = depth;
        info->read = info->write = 0 != (rtv_uav_dxgi_fmt_caps & D3D11_FORMAT_SUPPORT_TYPED_UNORDERED_ACCESS_VIEW);
    }
}

_SOKOL_PRIVATE void _sg_d3d11_setup_backend(const sg_desc* desc) {
    // assume _sg.d3d11 already is zero-initialized
    SOKOL_ASSERT(desc);
    SOKOL_ASSERT(desc->environment.d3d11.device);
    SOKOL_ASSERT(desc->environment.d3d11.device_context);
    _sg.d3d11.valid = true;
    _sg.d3d11.dev = (ID3D11Device*) desc->environment.d3d11.device;
    _sg.d3d11.ctx = (ID3D11DeviceContext*) desc->environment.d3d11.device_context;
    _sg_d3d11_init_caps();
}

_SOKOL_PRIVATE void _sg_d3d11_discard_backend(void) {
    SOKOL_ASSERT(_sg.d3d11.valid);
    _sg.d3d11.valid = false;
}

_SOKOL_PRIVATE void _sg_d3d11_clear_state(void) {
    // clear all the device context state, so that resource refs don't keep stuck in the d3d device context
    _sg_d3d11_ClearState(_sg.d3d11.ctx);
}

_SOKOL_PRIVATE void _sg_d3d11_reset_state_cache(void) {
    // there's currently no state cache in the D3D11 backend, so this is a no-op
}

_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(buf && desc);
    SOKOL_ASSERT(!buf->d3d11.buf);
    const bool injected = (0 != desc->d3d11_buffer);
    if (injected) {
        buf->d3d11.buf = (ID3D11Buffer*) desc->d3d11_buffer;
        _sg_d3d11_AddRef(buf->d3d11.buf);
    } else {
        D3D11_BUFFER_DESC d3d11_buf_desc;
        _sg_clear(&d3d11_buf_desc, sizeof(d3d11_buf_desc));
        d3d11_buf_desc.ByteWidth = (UINT)buf->cmn.size;
        d3d11_buf_desc.Usage = _sg_d3d11_buffer_usage(&buf->cmn.usage);
        d3d11_buf_desc.BindFlags = _sg_d3d11_buffer_bind_flags(&buf->cmn.usage);
        d3d11_buf_desc.CPUAccessFlags = _sg_d3d11_buffer_cpu_access_flags(&buf->cmn.usage);
        d3d11_buf_desc.MiscFlags = _sg_d3d11_buffer_misc_flags(&buf->cmn.usage);
        D3D11_SUBRESOURCE_DATA* init_data_ptr = 0;
        D3D11_SUBRESOURCE_DATA init_data;
        _sg_clear(&init_data, sizeof(init_data));
        if (desc->data.ptr) {
            init_data.pSysMem = desc->data.ptr;
            init_data_ptr = &init_data;
        }
        HRESULT hr = _sg_d3d11_CreateBuffer(_sg.d3d11.dev, &d3d11_buf_desc, init_data_ptr, &buf->d3d11.buf);
        if (!(SUCCEEDED(hr) && buf->d3d11.buf)) {
            _SG_ERROR(D3D11_CREATE_BUFFER_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }

        // for storage buffers need to create a shader-resource-view
        // for read-only access, and an unordered-access-view for
        // read-write access
        if (buf->cmn.usage.storage_buffer) {
            SOKOL_ASSERT(_sg_multiple_u64((uint64_t)buf->cmn.size, 4));
            D3D11_SHADER_RESOURCE_VIEW_DESC d3d11_srv_desc;
            _sg_clear(&d3d11_srv_desc, sizeof(d3d11_srv_desc));
            d3d11_srv_desc.Format = DXGI_FORMAT_R32_TYPELESS;
            d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_BUFFEREX;
            d3d11_srv_desc.BufferEx.FirstElement = 0;
            d3d11_srv_desc.BufferEx.NumElements = ((UINT)buf->cmn.size) / 4;
            d3d11_srv_desc.BufferEx.Flags = D3D11_BUFFEREX_SRV_FLAG_RAW;
            hr = _sg_d3d11_CreateShaderResourceView(_sg.d3d11.dev, (ID3D11Resource*)buf->d3d11.buf, &d3d11_srv_desc, &buf->d3d11.srv);
            if (!(SUCCEEDED(hr) && buf->d3d11.srv)) {
                _SG_ERROR(D3D11_CREATE_BUFFER_SRV_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
            if (buf->cmn.usage.immutable) {
                D3D11_UNORDERED_ACCESS_VIEW_DESC d3d11_uav_desc;
                _sg_clear(&d3d11_uav_desc, sizeof(d3d11_uav_desc));
                d3d11_uav_desc.Format = DXGI_FORMAT_R32_TYPELESS;
                d3d11_uav_desc.ViewDimension = D3D11_UAV_DIMENSION_BUFFER;
                d3d11_uav_desc.buffer_t.FirstElement = 0;
                d3d11_uav_desc.buffer_t.NumElements = ((UINT)buf->cmn.size) / 4;
                d3d11_uav_desc.buffer_t.Flags = D3D11_BUFFER_UAV_FLAG_RAW;
                hr = _sg_d3d11_CreateUnorderedAccessView(_sg.d3d11.dev, (ID3D11Resource*)buf->d3d11.buf, &d3d11_uav_desc, &buf->d3d11.uav);
                if (!(SUCCEEDED(hr) && buf->d3d11.uav)) {
                    _SG_ERROR(D3D11_CREATE_BUFFER_UAV_FAILED);
                    return SG_RESOURCESTATE_FAILED;
                }
            }
        }
        _sg_d3d11_setlabel(buf->d3d11.buf, desc->label);
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_d3d11_discard_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf);
    if (buf->d3d11.buf) {
        _sg_d3d11_Release(buf->d3d11.buf);
    }
    if (buf->d3d11.srv) {
        _sg_d3d11_Release(buf->d3d11.srv);
    }
    if (buf->d3d11.uav) {
        _sg_d3d11_Release(buf->d3d11.uav);
    }
}

_SOKOL_PRIVATE void _sg_d3d11_fill_subres_data(const _sg_image_t* img, const sg_image_data* data) {
    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;
    const int num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.num_slices:1;
    int subres_index = 0;
    for (int face_index = 0; face_index < num_faces; face_index++) {
        for (int slice_index = 0; slice_index < num_slices; slice_index++) {
            for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++, subres_index++) {
                SOKOL_ASSERT(subres_index < (SG_MAX_MIPMAPS * SG_MAX_TEXTUREARRAY_LAYERS));
                D3D11_SUBRESOURCE_DATA* subres_data = &_sg.d3d11.subres_data[subres_index];
                const int mip_width = _sg_miplevel_dim(img->cmn.width, mip_index);
                const int mip_height = _sg_miplevel_dim(img->cmn.height, mip_index);
                const sg_range* subimg_data = &(data->subimage[face_index][mip_index]);
                const size_t slice_size = subimg_data->size / (size_t)num_slices;
                const size_t slice_offset = slice_size * (size_t)slice_index;
                const uint8_t* ptr = (const uint8_t*) subimg_data->ptr;
                subres_data->pSysMem = ptr + slice_offset;
                subres_data->SysMemPitch = (UINT)_sg_row_pitch(img->cmn.pixel_format, mip_width, 1);
                if (img->cmn.type == SG_IMAGETYPE_3D) {
                    // FIXME? const int mip_depth = _sg_miplevel_dim(img->depth, mip_index);
                    subres_data->SysMemSlicePitch = (UINT)_sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, 1);
                } else {
                    subres_data->SysMemSlicePitch = 0;
                }
            }
        }
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_image(_sg_image_t* img, const sg_image_desc* desc) {
    SOKOL_ASSERT(img && desc);
    SOKOL_ASSERT((0 == img->d3d11.tex2d) && (0 == img->d3d11.tex3d) && (0 == img->d3d11.res) && (0 == img->d3d11.srv));
    HRESULT hr;

    const bool injected = (0 != desc->d3d11_texture);
    const bool msaa = (img->cmn.sample_count > 1);
    SOKOL_ASSERT(!(msaa && (img->cmn.type == SG_IMAGETYPE_CUBE)));
    img->d3d11.format = _sg_d3d11_texture_pixel_format(img->cmn.pixel_format);
    if (img->d3d11.format == DXGI_FORMAT_UNKNOWN) {
        _SG_ERROR(D3D11_CREATE_2D_TEXTURE_UNSUPPORTED_PIXEL_FORMAT);
        return SG_RESOURCESTATE_FAILED;
    }

    // prepare initial content pointers
    D3D11_SUBRESOURCE_DATA* init_data = 0;
    if (!injected && desc->data.subimage[0][0].ptr) {
        _sg_d3d11_fill_subres_data(img, &desc->data);
        init_data = _sg.d3d11.subres_data;
    }
    if (img->cmn.type != SG_IMAGETYPE_3D) {
        // 2D-, cube- or array-texture
        // first check for injected texture and/or resource view
        if (injected) {
            img->d3d11.tex2d = (ID3D11Texture2D*) desc->d3d11_texture;
            _sg_d3d11_AddRef(img->d3d11.tex2d);
            img->d3d11.srv = (ID3D11ShaderResourceView*) desc->d3d11_shader_resource_view;
            if (img->d3d11.srv) {
                _sg_d3d11_AddRef(img->d3d11.srv);
            }
        } else {
            // if not injected, create 2D texture
            D3D11_TEXTURE2D_DESC d3d11_tex_desc;
            _sg_clear(&d3d11_tex_desc, sizeof(d3d11_tex_desc));
            d3d11_tex_desc.Width = (UINT)img->cmn.width;
            d3d11_tex_desc.Height = (UINT)img->cmn.height;
            d3d11_tex_desc.MipLevels = (UINT)img->cmn.num_mipmaps;
            switch (img->cmn.type) {
                case SG_IMAGETYPE_ARRAY:    d3d11_tex_desc.ArraySize = (UINT)img->cmn.num_slices; break;
                case SG_IMAGETYPE_CUBE:     d3d11_tex_desc.ArraySize = 6; break;
                default:                    d3d11_tex_desc.ArraySize = 1; break;
            }
            d3d11_tex_desc.Format = img->d3d11.format;
            d3d11_tex_desc.BindFlags = _sg_d3d11_image_bind_flags(&img->cmn.usage, img->cmn.pixel_format);
            d3d11_tex_desc.Usage = _sg_d3d11_image_usage(&img->cmn.usage);
            d3d11_tex_desc.CPUAccessFlags = _sg_d3d11_image_cpu_access_flags(&img->cmn.usage);
            d3d11_tex_desc.SampleDesc.Count = (UINT)img->cmn.sample_count;
            d3d11_tex_desc.SampleDesc.Quality = (UINT) (msaa ? D3D11_STANDARD_MULTISAMPLE_PATTERN : 0);
            d3d11_tex_desc.MiscFlags = (img->cmn.type == SG_IMAGETYPE_CUBE) ? D3D11_RESOURCE_MISC_TEXTURECUBE : 0;
            hr = _sg_d3d11_CreateTexture2D(_sg.d3d11.dev, &d3d11_tex_desc, init_data, &img->d3d11.tex2d);
            if (!(SUCCEEDED(hr) && img->d3d11.tex2d)) {
                _SG_ERROR(D3D11_CREATE_2D_TEXTURE_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
            _sg_d3d11_setlabel(img->d3d11.tex2d, desc->label);

            // create shader-resource-view for 2D texture
            D3D11_SHADER_RESOURCE_VIEW_DESC d3d11_srv_desc;
            _sg_clear(&d3d11_srv_desc, sizeof(d3d11_srv_desc));
            d3d11_srv_desc.Format = _sg_d3d11_srv_pixel_format(img->cmn.pixel_format);
            switch (img->cmn.type) {
                case SG_IMAGETYPE_2D:
                    d3d11_srv_desc.ViewDimension = msaa ? D3D11_SRV_DIMENSION_TEXTURE2DMS : D3D11_SRV_DIMENSION_TEXTURE2D;
                    d3d11_srv_desc.Texture2D.MipLevels = (UINT)img->cmn.num_mipmaps;
                    break;
                case SG_IMAGETYPE_CUBE:
                    d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_TEXTURECUBE;
                    d3d11_srv_desc.TextureCube.MipLevels = (UINT)img->cmn.num_mipmaps;
                    break;
                case SG_IMAGETYPE_ARRAY:
                    d3d11_srv_desc.ViewDimension = msaa ? D3D11_SRV_DIMENSION_TEXTURE2DMSARRAY : D3D11_SRV_DIMENSION_TEXTURE2DARRAY;
                    d3d11_srv_desc.Texture2DArray.MipLevels = (UINT)img->cmn.num_mipmaps;
                    d3d11_srv_desc.Texture2DArray.ArraySize = (UINT)img->cmn.num_slices;
                    break;
                default:
                    SOKOL_UNREACHABLE; break;
            }
            hr = _sg_d3d11_CreateShaderResourceView(_sg.d3d11.dev, (ID3D11Resource*)img->d3d11.tex2d, &d3d11_srv_desc, &img->d3d11.srv);
            if (!(SUCCEEDED(hr) && img->d3d11.srv)) {
                _SG_ERROR(D3D11_CREATE_2D_SRV_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
            _sg_d3d11_setlabel(img->d3d11.srv, desc->label);
        }
        SOKOL_ASSERT(img->d3d11.tex2d);
        img->d3d11.res = (ID3D11Resource*)img->d3d11.tex2d;
        _sg_d3d11_AddRef(img->d3d11.res);
    } else {
        // 3D texture - same procedure, first check if injected, than create non-injected
        if (injected) {
            img->d3d11.tex3d = (ID3D11Texture3D*) desc->d3d11_texture;
            _sg_d3d11_AddRef(img->d3d11.tex3d);
            img->d3d11.srv = (ID3D11ShaderResourceView*) desc->d3d11_shader_resource_view;
            if (img->d3d11.srv) {
                _sg_d3d11_AddRef(img->d3d11.srv);
            }
        } else {
            // not injected, create 3d texture
            D3D11_TEXTURE3D_DESC d3d11_tex_desc;
            _sg_clear(&d3d11_tex_desc, sizeof(d3d11_tex_desc));
            d3d11_tex_desc.Width = (UINT)img->cmn.width;
            d3d11_tex_desc.Height = (UINT)img->cmn.height;
            d3d11_tex_desc.Depth = (UINT)img->cmn.num_slices;
            d3d11_tex_desc.MipLevels = (UINT)img->cmn.num_mipmaps;
            d3d11_tex_desc.Format = img->d3d11.format;
            d3d11_tex_desc.BindFlags = _sg_d3d11_image_bind_flags(&img->cmn.usage, img->cmn.pixel_format);
            d3d11_tex_desc.Usage = _sg_d3d11_image_usage(&img->cmn.usage);
            d3d11_tex_desc.CPUAccessFlags = _sg_d3d11_image_cpu_access_flags(&img->cmn.usage);
            if (img->d3d11.format == DXGI_FORMAT_UNKNOWN) {
                _SG_ERROR(D3D11_CREATE_3D_TEXTURE_UNSUPPORTED_PIXEL_FORMAT);
                return SG_RESOURCESTATE_FAILED;
            }
            hr = _sg_d3d11_CreateTexture3D(_sg.d3d11.dev, &d3d11_tex_desc, init_data, &img->d3d11.tex3d);
            if (!(SUCCEEDED(hr) && img->d3d11.tex3d)) {
                _SG_ERROR(D3D11_CREATE_3D_TEXTURE_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
            _sg_d3d11_setlabel(img->d3d11.tex3d, desc->label);

            // create shader-resource-view for 3D texture
            if (!msaa) {
                D3D11_SHADER_RESOURCE_VIEW_DESC d3d11_srv_desc;
                _sg_clear(&d3d11_srv_desc, sizeof(d3d11_srv_desc));
                d3d11_srv_desc.Format = _sg_d3d11_srv_pixel_format(img->cmn.pixel_format);
                d3d11_srv_desc.ViewDimension = D3D11_SRV_DIMENSION_TEXTURE3D;
                d3d11_srv_desc.Texture3D.MipLevels = (UINT)img->cmn.num_mipmaps;
                hr = _sg_d3d11_CreateShaderResourceView(_sg.d3d11.dev, (ID3D11Resource*)img->d3d11.tex3d, &d3d11_srv_desc, &img->d3d11.srv);
                if (!(SUCCEEDED(hr) && img->d3d11.srv)) {
                    _SG_ERROR(D3D11_CREATE_3D_SRV_FAILED);
                    return SG_RESOURCESTATE_FAILED;
                }
                _sg_d3d11_setlabel(img->d3d11.srv, desc->label);
            }
        }
        SOKOL_ASSERT(img->d3d11.tex3d);
        img->d3d11.res = (ID3D11Resource*)img->d3d11.tex3d;
        _sg_d3d11_AddRef(img->d3d11.res);
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_d3d11_discard_image(_sg_image_t* img) {
    SOKOL_ASSERT(img);
    if (img->d3d11.tex2d) {
        _sg_d3d11_Release(img->d3d11.tex2d);
    }
    if (img->d3d11.tex3d) {
        _sg_d3d11_Release(img->d3d11.tex3d);
    }
    if (img->d3d11.res) {
        _sg_d3d11_Release(img->d3d11.res);
    }
    if (img->d3d11.srv) {
        _sg_d3d11_Release(img->d3d11.srv);
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(smp && desc);
    SOKOL_ASSERT(0 == smp->d3d11.smp);
    const bool injected = (0 != desc->d3d11_sampler);
    if (injected) {
        smp->d3d11.smp = (ID3D11SamplerState*)desc->d3d11_sampler;
        _sg_d3d11_AddRef(smp->d3d11.smp);
    } else {
        D3D11_SAMPLER_DESC d3d11_smp_desc;
        _sg_clear(&d3d11_smp_desc, sizeof(d3d11_smp_desc));
        d3d11_smp_desc.Filter = _sg_d3d11_filter(desc->min_filter, desc->mag_filter, desc->mipmap_filter, desc->compare != SG_COMPAREFUNC_NEVER, desc->max_anisotropy);
        d3d11_smp_desc.AddressU = _sg_d3d11_address_mode(desc->wrap_u);
        d3d11_smp_desc.AddressV = _sg_d3d11_address_mode(desc->wrap_v);
        d3d11_smp_desc.AddressW = _sg_d3d11_address_mode(desc->wrap_w);
        d3d11_smp_desc.MipLODBias = 0.0f; // FIXME?
        switch (desc->border_color) {
            case SG_BORDERCOLOR_TRANSPARENT_BLACK:
                // all 0.0f
                break;
            case SG_BORDERCOLOR_OPAQUE_WHITE:
                for (int i = 0; i < 4; i++) {
                    d3d11_smp_desc.BorderColor[i] = 1.0f;
                }
                break;
            default:
                // opaque black
                d3d11_smp_desc.BorderColor[3] = 1.0f;
                break;
        }
        d3d11_smp_desc.MaxAnisotropy = desc->max_anisotropy;
        d3d11_smp_desc.ComparisonFunc = _sg_d3d11_compare_func(desc->compare);
        d3d11_smp_desc.MinLOD = desc->min_lod;
        d3d11_smp_desc.MaxLOD = desc->max_lod;
        HRESULT hr = _sg_d3d11_CreateSamplerState(_sg.d3d11.dev, &d3d11_smp_desc, &smp->d3d11.smp);
        if (!(SUCCEEDED(hr) && smp->d3d11.smp)) {
            _SG_ERROR(D3D11_CREATE_SAMPLER_STATE_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        _sg_d3d11_setlabel(smp->d3d11.smp, desc->label);
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_d3d11_discard_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp);
    if (smp->d3d11.smp) {
        _sg_d3d11_Release(smp->d3d11.smp);
    }
}

_SOKOL_PRIVATE bool _sg_d3d11_load_d3dcompiler_dll(void) {
    if ((0 == _sg.d3d11.d3dcompiler_dll) && !_sg.d3d11.d3dcompiler_dll_load_failed) {
        _sg.d3d11.d3dcompiler_dll = LoadLibraryA("d3dcompiler_47.dll");
        if (0 == _sg.d3d11.d3dcompiler_dll) {
            // don't attempt to load missing DLL in the future
            _SG_ERROR(D3D11_LOAD_D3DCOMPILER_47_DLL_FAILED);
            _sg.d3d11.d3dcompiler_dll_load_failed = true;
            return false;
        }
        // look up function pointers
        _sg.d3d11.D3DCompile_func = (pD3DCompile)(void*) GetProcAddress(_sg.d3d11.d3dcompiler_dll, "D3DCompile");
        SOKOL_ASSERT(_sg.d3d11.D3DCompile_func);
    }
    return 0 != _sg.d3d11.d3dcompiler_dll;
}

_SOKOL_PRIVATE ID3DBlob* _sg_d3d11_compile_shader(const sg_shader_function* shd_func) {
    if (!_sg_d3d11_load_d3dcompiler_dll()) {
        return NULL;
    }
    SOKOL_ASSERT(shd_func->d3d11_target);
    UINT flags1 = D3DCOMPILE_PACK_MATRIX_COLUMN_MAJOR;
    if (_sg.desc.d3d11_shader_debugging) {
        flags1 |= D3DCOMPILE_DEBUG | D3DCOMPILE_SKIP_OPTIMIZATION;
    } else {
        flags1 |= D3DCOMPILE_OPTIMIZATION_LEVEL3;
    }
    ID3DBlob* output = NULL;
    ID3DBlob* errors_or_warnings = NULL;
    HRESULT hr = _sg.d3d11.D3DCompile_func(
        shd_func->source,               // pSrcData
        strlen(shd_func->source),       // SrcDataSize
        NULL,                           // pSourceName
        NULL,                           // pDefines
        NULL,                           // pInclude
        shd_func->entry ? shd_func->entry : "main", // pEntryPoint
        shd_func->d3d11_target,         // pTarget
        flags1,     // Flags1
        0,          // Flags2
        &output,    // ppCode
        &errors_or_warnings);   // ppErrorMsgs
    if (FAILED(hr)) {
        _SG_ERROR(D3D11_SHADER_COMPILATION_FAILED);
    }
    if (errors_or_warnings) {
        _SG_WARN(D3D11_SHADER_COMPILATION_OUTPUT);
        _SG_LOGMSG(D3D11_SHADER_COMPILATION_OUTPUT, (LPCSTR)_sg_d3d11_GetBufferPointer(errors_or_warnings));
        _sg_d3d11_Release(errors_or_warnings); errors_or_warnings = NULL;
    }
    if (FAILED(hr)) {
        // just in case, usually output is NULL here
        if (output) {
            _sg_d3d11_Release(output);
            output = NULL;
        }
    }
    return output;
}

// NOTE: this is an out-of-range check for HLSL bindslots that's also active in release mode
_SOKOL_PRIVATE bool _sg_d3d11_ensure_hlsl_bindslot_ranges(const sg_shader_desc* desc) {
    SOKOL_ASSERT(desc);
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        if (desc->uniform_blocks[i].hlsl_register_b_n >= _SG_D3D11_MAX_STAGE_UB_BINDINGS) {
            _SG_ERROR(D3D11_UNIFORMBLOCK_HLSL_REGISTER_B_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (desc->storage_buffers[i].hlsl_register_t_n >= _SG_D3D11_MAX_STAGE_SRV_BINDINGS) {
            _SG_ERROR(D3D11_STORAGEBUFFER_HLSL_REGISTER_T_OUT_OF_RANGE);
            return false;
        }
        if (desc->storage_buffers[i].hlsl_register_u_n >= _SG_D3D11_MAX_STAGE_UAV_BINDINGS) {
            _SG_ERROR(D3D11_STORAGEBUFFER_HLSL_REGISTER_U_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (desc->images[i].hlsl_register_t_n >= _SG_D3D11_MAX_STAGE_SRV_BINDINGS) {
            _SG_ERROR(D3D11_IMAGE_HLSL_REGISTER_T_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (desc->samplers[i].hlsl_register_s_n >= _SG_D3D11_MAX_STAGE_SMP_BINDINGS) {
            _SG_ERROR(D3D11_SAMPLER_HLSL_REGISTER_S_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (desc->storage_images[i].hlsl_register_u_n >= _SG_D3D11_MAX_STAGE_UAV_BINDINGS) {
            _SG_ERROR(D3D11_STORAGEIMAGE_HLSL_REGISTER_U_OUT_OF_RANGE);
            return false;
        }
    }
    return true;
}

_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    SOKOL_ASSERT(shd && desc);
    SOKOL_ASSERT(!shd->d3d11.vs && !shd->d3d11.fs && !shd->d3d11.cs && !shd->d3d11.vs_blob);
    HRESULT hr;

    // perform a range-check on HLSL bindslots that's also active in release
    // mode to avoid potential out-of-bounds array accesses
    if (!_sg_d3d11_ensure_hlsl_bindslot_ranges(desc)) {
        return SG_RESOURCESTATE_FAILED;
    }

    // copy vertex attribute semantic names and indices
    for (size_t i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {
        _sg_strcpy(&shd->d3d11.attrs[i].sem_name, desc->attrs[i].hlsl_sem_name);
        shd->d3d11.attrs[i].sem_index = desc->attrs[i].hlsl_sem_index;
    }

    // copy HLSL bind slots
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        shd->d3d11.ub_register_b_n[i] = desc->uniform_blocks[i].hlsl_register_b_n;
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        shd->d3d11.sbuf_register_t_n[i] = desc->storage_buffers[i].hlsl_register_t_n;
        shd->d3d11.sbuf_register_u_n[i] = desc->storage_buffers[i].hlsl_register_u_n;
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        shd->d3d11.img_register_t_n[i] = desc->images[i].hlsl_register_t_n;
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        shd->d3d11.smp_register_s_n[i] = desc->samplers[i].hlsl_register_s_n;
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        shd->d3d11.simg_register_u_n[i] = desc->storage_images[i].hlsl_register_u_n;
    }

    // create a D3D constant buffer for each uniform block
    for (size_t ub_index = 0; ub_index < SG_MAX_UNIFORMBLOCK_BINDSLOTS; ub_index++) {
        const sg_shader_stage stage = desc->uniform_blocks[ub_index].stage;
        if (stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        const _sg_shader_uniform_block_t* ub = &shd->cmn.uniform_blocks[ub_index];
        ID3D11Buffer* cbuf = 0;
        D3D11_BUFFER_DESC cb_desc;
        _sg_clear(&cb_desc, sizeof(cb_desc));
        cb_desc.ByteWidth = (UINT)_sg_roundup((int)ub->size, 16);
        cb_desc.Usage = D3D11_USAGE_DEFAULT;
        cb_desc.BindFlags = D3D11_BIND_CONSTANT_BUFFER;
        hr = _sg_d3d11_CreateBuffer(_sg.d3d11.dev, &cb_desc, NULL, &cbuf);
        if (!(SUCCEEDED(hr) && cbuf)) {
            _SG_ERROR(D3D11_CREATE_CONSTANT_BUFFER_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        _sg_d3d11_setlabel(cbuf, desc->label);
        shd->d3d11.all_cbufs[ub_index] = cbuf;

        const uint8_t d3d11_slot = shd->d3d11.ub_register_b_n[ub_index];
        SOKOL_ASSERT(d3d11_slot < _SG_D3D11_MAX_STAGE_UB_BINDINGS);
        if (stage == SG_SHADERSTAGE_VERTEX) {
            SOKOL_ASSERT(0 == shd->d3d11.vs_cbufs[d3d11_slot]);
            shd->d3d11.vs_cbufs[d3d11_slot] = cbuf;
        } else if (stage == SG_SHADERSTAGE_FRAGMENT) {
            SOKOL_ASSERT(0 == shd->d3d11.fs_cbufs[d3d11_slot]);
            shd->d3d11.fs_cbufs[d3d11_slot] = cbuf;
        } else if (stage == SG_SHADERSTAGE_COMPUTE) {
            SOKOL_ASSERT(0 == shd->d3d11.cs_cbufs[d3d11_slot]);
            shd->d3d11.cs_cbufs[d3d11_slot] = cbuf;
        } else {
            SOKOL_UNREACHABLE;
        }
    }

    // create shader functions
    const bool has_vs = desc->vertex_func.bytecode.ptr || desc->vertex_func.source;
    const bool has_fs = desc->fragment_func.bytecode.ptr || desc->fragment_func.source;
    const bool has_cs = desc->compute_func.bytecode.ptr || desc->compute_func.source;
    bool vs_valid = false; bool fs_valid = false; bool cs_valid = false;
    if (has_vs) {
        const void* vs_ptr = 0; SIZE_T vs_length = 0;
        ID3DBlob* vs_blob = 0;
        if (desc->vertex_func.bytecode.ptr) {
            SOKOL_ASSERT(desc->vertex_func.bytecode.size > 0);
            vs_ptr = desc->vertex_func.bytecode.ptr;
            vs_length = desc->vertex_func.bytecode.size;
        } else {
            SOKOL_ASSERT(desc->vertex_func.source);
            vs_blob = _sg_d3d11_compile_shader(&desc->vertex_func);
            if (vs_blob) {
                vs_ptr = _sg_d3d11_GetBufferPointer(vs_blob);
                vs_length = _sg_d3d11_GetBufferSize(vs_blob);
            }
        }
        if (vs_ptr && (vs_length > 0)) {
            hr = _sg_d3d11_CreateVertexShader(_sg.d3d11.dev, vs_ptr, vs_length, NULL, &shd->d3d11.vs);
            vs_valid = SUCCEEDED(hr) && shd->d3d11.vs;
        }
        // set label, and need to store a copy of the vertex shader blob for the pipeline creation
        if (vs_valid) {
            _sg_d3d11_setlabel(shd->d3d11.vs, desc->label);
            shd->d3d11.vs_blob_length = vs_length;
            shd->d3d11.vs_blob = _sg_malloc((size_t)vs_length);
            SOKOL_ASSERT(shd->d3d11.vs_blob);
            memcpy(shd->d3d11.vs_blob, vs_ptr, vs_length);
        }
        if (vs_blob) {
            _sg_d3d11_Release(vs_blob);
        }
    }
    if (has_fs) {
        const void* fs_ptr = 0; SIZE_T fs_length = 0;
        ID3DBlob* fs_blob = 0;
        if (desc->fragment_func.bytecode.ptr) {
            SOKOL_ASSERT(desc->fragment_func.bytecode.size > 0);
            fs_ptr = desc->fragment_func.bytecode.ptr;
            fs_length = desc->fragment_func.bytecode.size;
        } else {
            SOKOL_ASSERT(desc->fragment_func.source);
            fs_blob = _sg_d3d11_compile_shader(&desc->fragment_func);
            if (fs_blob) {
                fs_ptr = _sg_d3d11_GetBufferPointer(fs_blob);
                fs_length = _sg_d3d11_GetBufferSize(fs_blob);
            }
        }
        if (fs_ptr && (fs_length > 0)) {
            hr = _sg_d3d11_CreatePixelShader(_sg.d3d11.dev, fs_ptr, fs_length, NULL, &shd->d3d11.fs);
            fs_valid = SUCCEEDED(hr) && shd->d3d11.fs;
        }
        if (fs_valid) {
            _sg_d3d11_setlabel(shd->d3d11.fs, desc->label);
        }
        if (fs_blob) {
            _sg_d3d11_Release(fs_blob);
        }
    }
    if (has_cs) {
        const void* cs_ptr = 0; SIZE_T cs_length = 0;
        ID3DBlob* cs_blob = 0;
        if (desc->compute_func.bytecode.ptr) {
            SOKOL_ASSERT(desc->compute_func.bytecode.size > 0);
            cs_ptr = desc->compute_func.bytecode.ptr;
            cs_length = desc->compute_func.bytecode.size;
        } else {
            SOKOL_ASSERT(desc->compute_func.source);
            cs_blob = _sg_d3d11_compile_shader(&desc->compute_func);
            if (cs_blob) {
                cs_ptr = _sg_d3d11_GetBufferPointer(cs_blob);
                cs_length = _sg_d3d11_GetBufferSize(cs_blob);
            }
        }
        if (cs_ptr && (cs_length > 0)) {
            hr = _sg_d3d11_CreateComputeShader(_sg.d3d11.dev, cs_ptr, cs_length, NULL, &shd->d3d11.cs);
            cs_valid = SUCCEEDED(hr) && shd->d3d11.cs;
        }
        if (cs_blob) {
            _sg_d3d11_Release(cs_blob);
        }
    }
    if ((vs_valid && fs_valid) || cs_valid) {
        return SG_RESOURCESTATE_VALID;
    } else {
        return SG_RESOURCESTATE_FAILED;
    }
}

_SOKOL_PRIVATE void _sg_d3d11_discard_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd);
    if (shd->d3d11.vs) {
        _sg_d3d11_Release(shd->d3d11.vs);
    }
    if (shd->d3d11.fs) {
        _sg_d3d11_Release(shd->d3d11.fs);
    }
    if (shd->d3d11.cs) {
        _sg_d3d11_Release(shd->d3d11.cs);
    }
    if (shd->d3d11.vs_blob) {
        _sg_free(shd->d3d11.vs_blob);
    }
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        if (shd->d3d11.all_cbufs[i]) {
            _sg_d3d11_Release(shd->d3d11.all_cbufs[i]);
        }
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(pip && shd && desc);
    SOKOL_ASSERT(desc->shader.id == shd->slot.id);
    SOKOL_ASSERT(shd->slot.state == SG_RESOURCESTATE_VALID);

    pip->shader = shd;

    // if this is a compute pipeline, we're done here
    if (pip->cmn.is_compute) {
        return SG_RESOURCESTATE_VALID;
    }

    // a render pipeline...
    SOKOL_ASSERT(shd->d3d11.vs_blob && shd->d3d11.vs_blob_length > 0);
    SOKOL_ASSERT(!pip->d3d11.il && !pip->d3d11.rs && !pip->d3d11.dss && !pip->d3d11.bs);

    pip->d3d11.index_format = _sg_d3d11_index_format(pip->cmn.index_type);
    pip->d3d11.topology = _sg_d3d11_primitive_topology(desc->primitive_type);
    pip->d3d11.stencil_ref = desc->stencil.ref;

    // create input layout object
    HRESULT hr;
    D3D11_INPUT_ELEMENT_DESC d3d11_comps[SG_MAX_VERTEX_ATTRIBUTES];
    _sg_clear(d3d11_comps, sizeof(d3d11_comps));
    size_t attr_index = 0;
    for (; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
        const sg_vertex_attr_state* a_state = &desc->layout.attrs[attr_index];
        if (a_state->format == SG_VERTEXFORMAT_INVALID) {
            break;
        }
        SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
        SOKOL_ASSERT(pip->cmn.vertex_buffer_layout_active[a_state->buffer_index]);
        const sg_vertex_buffer_layout_state* l_state = &desc->layout.buffers[a_state->buffer_index];
        const sg_vertex_step step_func = l_state->step_func;
        const int step_rate = l_state->step_rate;
        D3D11_INPUT_ELEMENT_DESC* d3d11_comp = &d3d11_comps[attr_index];
        d3d11_comp->SemanticName = _sg_strptr(&shd->d3d11.attrs[attr_index].sem_name);
        d3d11_comp->SemanticIndex = (UINT)shd->d3d11.attrs[attr_index].sem_index;
        d3d11_comp->Format = _sg_d3d11_vertex_format(a_state->format);
        d3d11_comp->InputSlot = (UINT)a_state->buffer_index;
        d3d11_comp->AlignedByteOffset = (UINT)a_state->offset;
        d3d11_comp->InputSlotClass = _sg_d3d11_input_classification(step_func);
        if (SG_VERTEXSTEP_PER_INSTANCE == step_func) {
            d3d11_comp->InstanceDataStepRate = (UINT)step_rate;
            pip->cmn.use_instanced_draw = true;
        }
    }
    for (size_t layout_index = 0; layout_index < SG_MAX_VERTEXBUFFER_BINDSLOTS; layout_index++) {
        if (pip->cmn.vertex_buffer_layout_active[layout_index]) {
            const sg_vertex_buffer_layout_state* l_state = &desc->layout.buffers[layout_index];
            SOKOL_ASSERT(l_state->stride > 0);
            pip->d3d11.vb_strides[layout_index] = (UINT)l_state->stride;
        } else {
            pip->d3d11.vb_strides[layout_index] = 0;
        }
    }
    if (attr_index > 0) {
        hr = _sg_d3d11_CreateInputLayout(_sg.d3d11.dev,
            d3d11_comps,                // pInputElementDesc
            (UINT)attr_index,           // NumElements
            shd->d3d11.vs_blob,         // pShaderByteCodeWithInputSignature
            shd->d3d11.vs_blob_length,  // BytecodeLength
            &pip->d3d11.il);
        if (!(SUCCEEDED(hr) && pip->d3d11.il)) {
            _SG_ERROR(D3D11_CREATE_INPUT_LAYOUT_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        _sg_d3d11_setlabel(pip->d3d11.il, desc->label);
    }

    // create rasterizer state
    D3D11_RASTERIZER_DESC rs_desc;
    _sg_clear(&rs_desc, sizeof(rs_desc));
    rs_desc.FillMode = D3D11_FILL_SOLID;
    rs_desc.CullMode = _sg_d3d11_cull_mode(desc->cull_mode);
    rs_desc.FrontCounterClockwise = desc->face_winding == SG_FACEWINDING_CCW;
    rs_desc.DepthBias = (INT) pip->cmn.depth.bias;
    rs_desc.DepthBiasClamp = pip->cmn.depth.bias_clamp;
    rs_desc.SlopeScaledDepthBias = pip->cmn.depth.bias_slope_scale;
    rs_desc.DepthClipEnable = TRUE;
    rs_desc.ScissorEnable = TRUE;
    rs_desc.MultisampleEnable = desc->sample_count > 1;
    rs_desc.AntialiasedLineEnable = FALSE;
    hr = _sg_d3d11_CreateRasterizerState(_sg.d3d11.dev, &rs_desc, &pip->d3d11.rs);
    if (!(SUCCEEDED(hr) && pip->d3d11.rs)) {
        _SG_ERROR(D3D11_CREATE_RASTERIZER_STATE_FAILED);
        return SG_RESOURCESTATE_FAILED;
    }
    _sg_d3d11_setlabel(pip->d3d11.rs, desc->label);

    // create depth-stencil state
    D3D11_DEPTH_STENCIL_DESC dss_desc;
    _sg_clear(&dss_desc, sizeof(dss_desc));
    dss_desc.DepthEnable = TRUE;
    dss_desc.DepthWriteMask = desc->depth.write_enabled ? D3D11_DEPTH_WRITE_MASK_ALL : D3D11_DEPTH_WRITE_MASK_ZERO;
    dss_desc.DepthFunc = _sg_d3d11_compare_func(desc->depth.compare);
    dss_desc.StencilEnable = desc->stencil.enabled;
    dss_desc.StencilReadMask = desc->stencil.read_mask;
    dss_desc.StencilWriteMask = desc->stencil.write_mask;
    const sg_stencil_face_state* sf = &desc->stencil.front;
    dss_desc.FrontFace.StencilFailOp = _sg_d3d11_stencil_op(sf->fail_op);
    dss_desc.FrontFace.StencilDepthFailOp = _sg_d3d11_stencil_op(sf->depth_fail_op);
    dss_desc.FrontFace.StencilPassOp = _sg_d3d11_stencil_op(sf->pass_op);
    dss_desc.FrontFace.StencilFunc = _sg_d3d11_compare_func(sf->compare);
    const sg_stencil_face_state* sb = &desc->stencil.back;
    dss_desc.BackFace.StencilFailOp = _sg_d3d11_stencil_op(sb->fail_op);
    dss_desc.BackFace.StencilDepthFailOp = _sg_d3d11_stencil_op(sb->depth_fail_op);
    dss_desc.BackFace.StencilPassOp = _sg_d3d11_stencil_op(sb->pass_op);
    dss_desc.BackFace.StencilFunc = _sg_d3d11_compare_func(sb->compare);
    hr = _sg_d3d11_CreateDepthStencilState(_sg.d3d11.dev, &dss_desc, &pip->d3d11.dss);
    if (!(SUCCEEDED(hr) && pip->d3d11.dss)) {
        _SG_ERROR(D3D11_CREATE_DEPTH_STENCIL_STATE_FAILED);
        return SG_RESOURCESTATE_FAILED;
    }
    _sg_d3d11_setlabel(pip->d3d11.dss, desc->label);

    // create blend state
    D3D11_BLEND_DESC bs_desc;
    _sg_clear(&bs_desc, sizeof(bs_desc));
    bs_desc.AlphaToCoverageEnable = desc->alpha_to_coverage_enabled;
    bs_desc.IndependentBlendEnable = TRUE;
    {
        size_t i = 0;
        for (i = 0; i < (size_t)desc->color_count; i++) {
            const sg_blend_state* src = &desc->colors[i].blend;
            D3D11_RENDER_TARGET_BLEND_DESC* dst = &bs_desc.RenderTarget[i];
            dst->BlendEnable = src->enabled;
            dst->SrcBlend = _sg_d3d11_blend_factor(src->src_factor_rgb);
            dst->DestBlend = _sg_d3d11_blend_factor(src->dst_factor_rgb);
            dst->BlendOp = _sg_d3d11_blend_op(src->op_rgb);
            dst->SrcBlendAlpha = _sg_d3d11_blend_factor(src->src_factor_alpha);
            dst->DestBlendAlpha = _sg_d3d11_blend_factor(src->dst_factor_alpha);
            dst->BlendOpAlpha = _sg_d3d11_blend_op(src->op_alpha);
            dst->RenderTargetWriteMask = _sg_d3d11_color_write_mask(desc->colors[i].write_mask);
        }
        for (; i < 8; i++) {
            D3D11_RENDER_TARGET_BLEND_DESC* dst = &bs_desc.RenderTarget[i];
            dst->BlendEnable = FALSE;
            dst->SrcBlend = dst->SrcBlendAlpha = D3D11_BLEND_ONE;
            dst->DestBlend = dst->DestBlendAlpha = D3D11_BLEND_ZERO;
            dst->BlendOp = dst->BlendOpAlpha = D3D11_BLEND_OP_ADD;
            dst->RenderTargetWriteMask = D3D11_COLOR_WRITE_ENABLE_ALL;
        }
    }
    hr = _sg_d3d11_CreateBlendState(_sg.d3d11.dev, &bs_desc, &pip->d3d11.bs);
    if (!(SUCCEEDED(hr) && pip->d3d11.bs)) {
        _SG_ERROR(D3D11_CREATE_BLEND_STATE_FAILED);
        return SG_RESOURCESTATE_FAILED;
    }
    _sg_d3d11_setlabel(pip->d3d11.bs, desc->label);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_d3d11_discard_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    if (pip == _sg.d3d11.cur_pipeline) {
        _sg.d3d11.cur_pipeline = 0;
        _sg.d3d11.cur_pipeline_id.id = SG_INVALID_ID;
    }
    if (pip->d3d11.il) {
        _sg_d3d11_Release(pip->d3d11.il);
    }
    if (pip->d3d11.rs) {
        _sg_d3d11_Release(pip->d3d11.rs);
    }
    if (pip->d3d11.dss) {
        _sg_d3d11_Release(pip->d3d11.dss);
    }
    if (pip->d3d11.bs) {
        _sg_d3d11_Release(pip->d3d11.bs);
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_d3d11_create_attachments(_sg_attachments_t* atts, const _sg_attachments_ptrs_t* atts_ptrs, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(atts && atts_ptrs && desc);
    SOKOL_ASSERT(_sg.d3d11.dev);

    // copy image pointers
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const sg_attachment_desc* color_desc = &desc->colors[i];
        _SOKOL_UNUSED(color_desc);
        SOKOL_ASSERT(color_desc->image.id != SG_INVALID_ID);
        SOKOL_ASSERT(0 == atts->d3d11.colors[i].image);
        SOKOL_ASSERT(atts_ptrs->color_images[i]);
        _sg_image_t* clr_img = atts_ptrs->color_images[i];
        SOKOL_ASSERT(clr_img->slot.id == color_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_color_format(clr_img->cmn.pixel_format));
        atts->d3d11.colors[i].image = clr_img;

        const sg_attachment_desc* resolve_desc = &desc->resolves[i];
        if (resolve_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->d3d11.resolves[i].image);
            SOKOL_ASSERT(atts_ptrs->resolve_images[i]);
            _sg_image_t* rsv_img = atts_ptrs->resolve_images[i];
            SOKOL_ASSERT(rsv_img->slot.id == resolve_desc->image.id);
            SOKOL_ASSERT(clr_img->cmn.pixel_format == rsv_img->cmn.pixel_format);
            atts->d3d11.resolves[i].image = rsv_img;
        }
    }
    SOKOL_ASSERT(0 == atts->d3d11.depth_stencil.image);
    const sg_attachment_desc* ds_desc = &desc->depth_stencil;
    if (ds_desc->image.id != SG_INVALID_ID) {
        SOKOL_ASSERT(atts_ptrs->ds_image);
        _sg_image_t* ds_img = atts_ptrs->ds_image;
        SOKOL_ASSERT(ds_img->slot.id == ds_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_depth_format(ds_img->cmn.pixel_format));
        atts->d3d11.depth_stencil.image = ds_img;
    }
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const sg_attachment_desc* storage_desc = &desc->storages[i];
        if (storage_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->d3d11.storages[i].image);
            SOKOL_ASSERT(atts_ptrs->storage_images[i]);
            _sg_image_t* stg_img = atts_ptrs->storage_images[i];
            SOKOL_ASSERT(stg_img->slot.id == storage_desc->image.id);
            atts->d3d11.storages[i].image = stg_img;
        }
    }

    // create render-target views
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const _sg_attachment_common_t* cmn_color_att = &atts->cmn.colors[i];
        const _sg_image_t* clr_img = atts_ptrs->color_images[i];
        SOKOL_ASSERT(0 == atts->d3d11.colors[i].view.rtv);
        const bool msaa = clr_img->cmn.sample_count > 1;
        D3D11_RENDER_TARGET_VIEW_DESC d3d11_rtv_desc;
        _sg_clear(&d3d11_rtv_desc, sizeof(d3d11_rtv_desc));
        d3d11_rtv_desc.Format = _sg_d3d11_rtv_uav_pixel_format(clr_img->cmn.pixel_format);
        switch (clr_img->cmn.type) {
            case SG_IMAGETYPE_2D:
                if (msaa) {
                    d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2DMS;
                } else {
                    d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2D;
                    d3d11_rtv_desc.Texture2D.MipSlice = (UINT)cmn_color_att->mip_level;
                }
                break;
            case SG_IMAGETYPE_CUBE:
            case SG_IMAGETYPE_ARRAY:
                if (msaa) {
                    d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2DMSARRAY;
                    d3d11_rtv_desc.Texture2DMSArray.FirstArraySlice = (UINT)cmn_color_att->slice;
                    d3d11_rtv_desc.Texture2DMSArray.ArraySize = 1;
                } else {
                    d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE2DARRAY;
                    d3d11_rtv_desc.Texture2DArray.MipSlice = (UINT)cmn_color_att->mip_level;
                    d3d11_rtv_desc.Texture2DArray.FirstArraySlice = (UINT)cmn_color_att->slice;
                    d3d11_rtv_desc.Texture2DArray.ArraySize = 1;
                }
                break;
            case SG_IMAGETYPE_3D:
                SOKOL_ASSERT(!msaa);
                d3d11_rtv_desc.ViewDimension = D3D11_RTV_DIMENSION_TEXTURE3D;
                d3d11_rtv_desc.Texture3D.MipSlice = (UINT)cmn_color_att->mip_level;
                d3d11_rtv_desc.Texture3D.FirstWSlice = (UINT)cmn_color_att->slice;
                d3d11_rtv_desc.Texture3D.WSize = 1;
                break;
            default: SOKOL_UNREACHABLE; break;
        }
        SOKOL_ASSERT(clr_img->d3d11.res);
        HRESULT hr = _sg_d3d11_CreateRenderTargetView(_sg.d3d11.dev, clr_img->d3d11.res, &d3d11_rtv_desc, &atts->d3d11.colors[i].view.rtv);
        if (!(SUCCEEDED(hr) && atts->d3d11.colors[i].view.rtv)) {
            _SG_ERROR(D3D11_CREATE_RTV_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        _sg_d3d11_setlabel(atts->d3d11.colors[i].view.rtv, desc->label);
    }
    SOKOL_ASSERT(0 == atts->d3d11.depth_stencil.view.dsv);
    if (ds_desc->image.id != SG_INVALID_ID) {
        const _sg_attachment_common_t* cmn_ds_att = &atts->cmn.depth_stencil;
        _sg_image_t* ds_img = atts_ptrs->ds_image;
        const bool msaa = ds_img->cmn.sample_count > 1;
        D3D11_DEPTH_STENCIL_VIEW_DESC d3d11_dsv_desc;
        _sg_clear(&d3d11_dsv_desc, sizeof(d3d11_dsv_desc));
        d3d11_dsv_desc.Format = _sg_d3d11_dsv_pixel_format(ds_img->cmn.pixel_format);
        SOKOL_ASSERT(ds_img && ds_img->cmn.type != SG_IMAGETYPE_3D);
        switch(ds_img->cmn.type) {
            case SG_IMAGETYPE_2D:
                if (msaa) {
                    d3d11_dsv_desc.ViewDimension = D3D11_DSV_DIMENSION_TEXTURE2DMS;
                } else {
                    d3d11_dsv_desc.ViewDimension = D3D11_DSV_DIMENSION_TEXTURE2D;
                    d3d11_dsv_desc.Texture2D.MipSlice = (UINT)cmn_ds_att->mip_level;
                }
                break;
            case SG_IMAGETYPE_CUBE:
            case SG_IMAGETYPE_ARRAY:
                if (msaa) {
                    d3d11_dsv_desc.ViewDimension = D3D11_DSV_DIMENSION_TEXTURE2DMSARRAY;
                    d3d11_dsv_desc.Texture2DMSArray.FirstArraySlice = (UINT)cmn_ds_att->slice;
                    d3d11_dsv_desc.Texture2DMSArray.ArraySize = 1;
                } else {
                    d3d11_dsv_desc.ViewDimension = D3D11_DSV_DIMENSION_TEXTURE2DARRAY;
                    d3d11_dsv_desc.Texture2DArray.MipSlice = (UINT)cmn_ds_att->mip_level;
                    d3d11_dsv_desc.Texture2DArray.FirstArraySlice = (UINT)cmn_ds_att->slice;
                    d3d11_dsv_desc.Texture2DArray.ArraySize = 1;
                }
                break;
            default: SOKOL_UNREACHABLE; break;
        }
        SOKOL_ASSERT(ds_img->d3d11.res);
        HRESULT hr = _sg_d3d11_CreateDepthStencilView(_sg.d3d11.dev, ds_img->d3d11.res, &d3d11_dsv_desc, &atts->d3d11.depth_stencil.view.dsv);
        if (!(SUCCEEDED(hr) && atts->d3d11.depth_stencil.view.dsv)) {
            _SG_ERROR(D3D11_CREATE_DSV_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        _sg_d3d11_setlabel(atts->d3d11.depth_stencil.view.dsv, desc->label);
    }

    // create storage attachments unordered access views
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const _sg_attachment_common_t* cmn_stg_att = &atts->cmn.storages[i];
        const _sg_image_t* stg_img = atts_ptrs->storage_images[i];
        if (!stg_img) {
            continue;
        }
        SOKOL_ASSERT(stg_img->cmn.sample_count == 1);
        SOKOL_ASSERT(0 == atts->d3d11.storages[i].view.uav);
        D3D11_UNORDERED_ACCESS_VIEW_DESC d3d11_uav_desc;
        _sg_clear(&d3d11_uav_desc, sizeof(d3d11_uav_desc));
        d3d11_uav_desc.Format = _sg_d3d11_rtv_uav_pixel_format(stg_img->cmn.pixel_format);
        switch (stg_img->cmn.type) {
            case SG_IMAGETYPE_2D:
                d3d11_uav_desc.ViewDimension = D3D11_UAV_DIMENSION_TEXTURE2D;
                d3d11_uav_desc.Texture2D.MipSlice = (UINT)cmn_stg_att->mip_level;
                break;
            case SG_IMAGETYPE_CUBE:
            case SG_IMAGETYPE_ARRAY:
                d3d11_uav_desc.ViewDimension = D3D11_UAV_DIMENSION_TEXTURE2DARRAY;
                d3d11_uav_desc.Texture2DArray.MipSlice = (UINT)cmn_stg_att->mip_level;
                d3d11_uav_desc.Texture2DArray.FirstArraySlice = (UINT)cmn_stg_att->slice;
                d3d11_uav_desc.Texture2DArray.ArraySize = 1;
                break;
            case SG_IMAGETYPE_3D:
                d3d11_uav_desc.ViewDimension = D3D11_UAV_DIMENSION_TEXTURE3D;
                d3d11_uav_desc.Texture3D.MipSlice = (UINT)cmn_stg_att->mip_level;
                d3d11_uav_desc.Texture3D.FirstWSlice = (UINT)cmn_stg_att->slice;
                d3d11_uav_desc.Texture3D.WSize = 1;
                break;
            default: SOKOL_UNREACHABLE; break;
        }
        SOKOL_ASSERT(stg_img->d3d11.res);
        HRESULT hr = _sg_d3d11_CreateUnorderedAccessView(_sg.d3d11.dev, stg_img->d3d11.res, &d3d11_uav_desc, &atts->d3d11.storages[i].view.uav);
        if (!(SUCCEEDED(hr) && atts->d3d11.storages[i].view.uav)) {
            _SG_ERROR(D3D11_CREATE_UAV_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        _sg_d3d11_setlabel(atts->d3d11.storages[i].view.uav, desc->label);
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_d3d11_discard_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    for (size_t i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
        if (atts->d3d11.colors[i].view.rtv) {
            _sg_d3d11_Release(atts->d3d11.colors[i].view.rtv);
        }
        if (atts->d3d11.resolves[i].view.rtv) {
            _sg_d3d11_Release(atts->d3d11.resolves[i].view.rtv);
        }
    }
    if (atts->d3d11.depth_stencil.view.dsv) {
        _sg_d3d11_Release(atts->d3d11.depth_stencil.view.dsv);
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (atts->d3d11.storages[i].view.uav) {
            _sg_d3d11_Release(atts->d3d11.storages[i].view.uav);
        }
    }
}

_SOKOL_PRIVATE _sg_image_t* _sg_d3d11_attachments_color_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->d3d11.colors[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_d3d11_attachments_resolve_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->d3d11.resolves[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_d3d11_attachments_ds_image(const _sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    return atts->d3d11.depth_stencil.image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_d3d11_attachments_storage_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_STORAGE_ATTACHMENTS));
    return atts->d3d11.storages[index].image;
}

_SOKOL_PRIVATE void _sg_d3d11_begin_pass(const sg_pass* pass) {
    SOKOL_ASSERT(pass);
    if (_sg.cur_pass.is_compute) {
        // nothing to do in compute passes
        return;
    }
    const _sg_attachments_t* atts = _sg.cur_pass.atts;
    const sg_swapchain* swapchain = &pass->swapchain;
    const sg_pass_action* action = &pass->action;

    int num_rtvs = 0;
    ID3D11RenderTargetView* rtvs[SG_MAX_COLOR_ATTACHMENTS] = { 0 };
    ID3D11DepthStencilView* dsv = 0;
    _sg.d3d11.cur_pass.render_view = 0;
    _sg.d3d11.cur_pass.resolve_view = 0;
    if (atts) {
        num_rtvs = atts->cmn.num_colors;
        for (size_t i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
            rtvs[i] = atts->d3d11.colors[i].view.rtv;
        }
        dsv = atts->d3d11.depth_stencil.view.dsv;
    } else {
        // NOTE: depth-stencil-view is optional
        SOKOL_ASSERT(swapchain->d3d11.render_view);
        num_rtvs = 1;
        rtvs[0] = (ID3D11RenderTargetView*) swapchain->d3d11.render_view;
        dsv = (ID3D11DepthStencilView*) swapchain->d3d11.depth_stencil_view;
        _sg.d3d11.cur_pass.render_view = (ID3D11RenderTargetView*) swapchain->d3d11.render_view;
        _sg.d3d11.cur_pass.resolve_view = (ID3D11RenderTargetView*) swapchain->d3d11.resolve_view;
    }
    // apply the render-target- and depth-stencil-views
    _sg_d3d11_OMSetRenderTargets(_sg.d3d11.ctx, SG_MAX_COLOR_ATTACHMENTS, rtvs, dsv);
    _sg_stats_add(d3d11.pass.num_om_set_render_targets, 1);

    // set viewport and scissor rect to cover whole screen
    D3D11_VIEWPORT vp;
    _sg_clear(&vp, sizeof(vp));
    vp.Width = (FLOAT) _sg.cur_pass.width;
    vp.Height = (FLOAT) _sg.cur_pass.height;
    vp.MaxDepth = 1.0f;
    _sg_d3d11_RSSetViewports(_sg.d3d11.ctx, 1, &vp);
    D3D11_RECT rect;
    rect.left = 0;
    rect.top = 0;
    rect.right = _sg.cur_pass.width;
    rect.bottom = _sg.cur_pass.height;
    _sg_d3d11_RSSetScissorRects(_sg.d3d11.ctx, 1, &rect);

    // perform clear action
    for (size_t i = 0; i < (size_t)num_rtvs; i++) {
        if (action->colors[i].load_action == SG_LOADACTION_CLEAR) {
            _sg_d3d11_ClearRenderTargetView(_sg.d3d11.ctx, rtvs[i], (float*)&action->colors[i].clear_value);
            _sg_stats_add(d3d11.pass.num_clear_render_target_view, 1);
        }
    }
    UINT ds_flags = 0;
    if (action->depth.load_action == SG_LOADACTION_CLEAR) {
        ds_flags |= D3D11_CLEAR_DEPTH;
    }
    if (action->stencil.load_action == SG_LOADACTION_CLEAR) {
        ds_flags |= D3D11_CLEAR_STENCIL;
    }
    if ((0 != ds_flags) && dsv) {
        _sg_d3d11_ClearDepthStencilView(_sg.d3d11.ctx, dsv, ds_flags, action->depth.clear_value, action->stencil.clear_value);
        _sg_stats_add(d3d11.pass.num_clear_depth_stencil_view, 1);
    }
}

// D3D11CalcSubresource only exists for C++
_SOKOL_PRIVATE UINT _sg_d3d11_calcsubresource(UINT mip_slice, UINT array_slice, UINT mip_levels) {
    return mip_slice + array_slice * mip_levels;
}

_SOKOL_PRIVATE void _sg_d3d11_end_pass(void) {
    SOKOL_ASSERT(_sg.d3d11.ctx);

    if (!_sg.cur_pass.is_compute) {
        // need to resolve MSAA render attachments into texture?
        if (_sg.cur_pass.atts_id.id != SG_INVALID_ID) {
            // ...for offscreen pass...
            SOKOL_ASSERT(_sg.cur_pass.atts && _sg.cur_pass.atts->slot.id == _sg.cur_pass.atts_id.id);
            for (size_t i = 0; i < (size_t)_sg.cur_pass.atts->cmn.num_colors; i++) {
                const _sg_image_t* resolve_img = _sg.cur_pass.atts->d3d11.resolves[i].image;
                if (resolve_img) {
                    const _sg_image_t* color_img = _sg.cur_pass.atts->d3d11.colors[i].image;
                    const _sg_attachment_common_t* cmn_color_att = &_sg.cur_pass.atts->cmn.colors[i];
                    const _sg_attachment_common_t* cmn_resolve_att = &_sg.cur_pass.atts->cmn.resolves[i];
                    SOKOL_ASSERT(resolve_img->slot.id == cmn_resolve_att->image_id.id);
                    SOKOL_ASSERT(color_img && (color_img->slot.id == cmn_color_att->image_id.id));
                    SOKOL_ASSERT(color_img->cmn.sample_count > 1);
                    SOKOL_ASSERT(resolve_img->cmn.sample_count == 1);
                    const UINT src_subres = _sg_d3d11_calcsubresource(
                        (UINT)cmn_color_att->mip_level,
                        (UINT)cmn_color_att->slice,
                        (UINT)color_img->cmn.num_mipmaps);
                    const UINT dst_subres = _sg_d3d11_calcsubresource(
                        (UINT)cmn_resolve_att->mip_level,
                        (UINT)cmn_resolve_att->slice,
                        (UINT)resolve_img->cmn.num_mipmaps);
                    _sg_d3d11_ResolveSubresource(_sg.d3d11.ctx,
                        resolve_img->d3d11.res,
                        dst_subres,
                        color_img->d3d11.res,
                        src_subres,
                        color_img->d3d11.format);
                    _sg_stats_add(d3d11.pass.num_resolve_subresource, 1);
                }
            }
        } else {
            // ...for swapchain pass...
            if (_sg.d3d11.cur_pass.resolve_view) {
                SOKOL_ASSERT(_sg.d3d11.cur_pass.render_view);
                SOKOL_ASSERT(_sg.cur_pass.swapchain.sample_count > 1);
                SOKOL_ASSERT(_sg.cur_pass.swapchain.color_fmt > SG_PIXELFORMAT_NONE);
                ID3D11Resource* d3d11_render_res = 0;
                ID3D11Resource* d3d11_resolve_res = 0;
                _sg_d3d11_GetResource((ID3D11View*)_sg.d3d11.cur_pass.render_view, &d3d11_render_res);
                _sg_d3d11_GetResource((ID3D11View*)_sg.d3d11.cur_pass.resolve_view, &d3d11_resolve_res);
                SOKOL_ASSERT(d3d11_render_res);
                SOKOL_ASSERT(d3d11_resolve_res);
                const sg_pixel_format color_fmt = _sg.cur_pass.swapchain.color_fmt;
                _sg_d3d11_ResolveSubresource(_sg.d3d11.ctx, d3d11_resolve_res, 0, d3d11_render_res, 0, _sg_d3d11_rtv_uav_pixel_format(color_fmt));
                _sg_d3d11_Release(d3d11_render_res);
                _sg_d3d11_Release(d3d11_resolve_res);
                _sg_stats_add(d3d11.pass.num_resolve_subresource, 1);
            }
        }
    }
    _sg.d3d11.cur_pass.render_view = 0;
    _sg.d3d11.cur_pass.resolve_view = 0;
    _sg.d3d11.cur_pipeline = 0;
    _sg.d3d11.cur_pipeline_id.id = SG_INVALID_ID;
    _sg_d3d11_clear_state();
}

_SOKOL_PRIVATE void _sg_d3d11_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {
    SOKOL_ASSERT(_sg.d3d11.ctx);
    D3D11_VIEWPORT vp;
    vp.TopLeftX = (FLOAT) x;
    vp.TopLeftY = (FLOAT) (origin_top_left ? y : (_sg.cur_pass.height - (y + h)));
    vp.Width = (FLOAT) w;
    vp.Height = (FLOAT) h;
    vp.MinDepth = 0.0f;
    vp.MaxDepth = 1.0f;
    _sg_d3d11_RSSetViewports(_sg.d3d11.ctx, 1, &vp);
}

_SOKOL_PRIVATE void _sg_d3d11_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {
    SOKOL_ASSERT(_sg.d3d11.ctx);
    D3D11_RECT rect;
    rect.left = x;
    rect.top = (origin_top_left ? y : (_sg.cur_pass.height - (y + h)));
    rect.right = x + w;
    rect.bottom = origin_top_left ? (y + h) : (_sg.cur_pass.height - y);
    _sg_d3d11_RSSetScissorRects(_sg.d3d11.ctx, 1, &rect);
}

_SOKOL_PRIVATE void _sg_d3d11_populate_storage_attachment_uavs(_sg_pipeline_t* pip, ID3D11UnorderedAccessView** d3d11_cs_uavs) {
    const _sg_attachments_t* atts = _sg.cur_pass.atts;
    SOKOL_ASSERT(atts);
    const _sg_shader_t* shd = pip->shader;
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (shd->cmn.storage_images[i].stage != SG_SHADERSTAGE_COMPUTE) {
            continue;
        }
        SOKOL_ASSERT(shd->d3d11.simg_register_u_n[i] < _SG_D3D11_MAX_STAGE_UAV_BINDINGS);
        SOKOL_ASSERT(atts->d3d11.storages[i].view.uav);
        SOKOL_ASSERT(0 == d3d11_cs_uavs[i]);
        d3d11_cs_uavs[shd->d3d11.simg_register_u_n[i]] = atts->d3d11.storages[i].view.uav;
    }
}

_SOKOL_PRIVATE void _sg_d3d11_apply_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));
    SOKOL_ASSERT(_sg.d3d11.ctx);

    _sg.d3d11.cur_pipeline = pip;
    _sg.d3d11.cur_pipeline_id.id = pip->slot.id;

    if (pip->cmn.is_compute) {
        // a compute pipeline
        SOKOL_ASSERT(pip->shader->d3d11.cs);
        _sg_d3d11_CSSetShader(_sg.d3d11.ctx, pip->shader->d3d11.cs, NULL, 0);
        _sg_d3d11_CSSetConstantBuffers(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_UB_BINDINGS, pip->shader->d3d11.cs_cbufs);
        _sg_stats_add(d3d11.pipeline.num_cs_set_shader, 1);
        _sg_stats_add(d3d11.pipeline.num_cs_set_constant_buffers, 1);

        // bind storage attachment UAVs
        if (_sg.cur_pass.atts) {
            ID3D11UnorderedAccessView* d3d11_cs_uavs[_SG_D3D11_MAX_STAGE_UAV_BINDINGS] = {0};
            _sg_d3d11_populate_storage_attachment_uavs(pip, d3d11_cs_uavs);
            _sg_d3d11_CSSetUnorderedAccessViews(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_UAV_BINDINGS, d3d11_cs_uavs, NULL);
            _sg_stats_add(d3d11.bindings.num_cs_set_unordered_access_views, 1);
        }
    } else {
        // a render pipeline
        SOKOL_ASSERT(pip->d3d11.rs && pip->d3d11.bs && pip->d3d11.dss);
        SOKOL_ASSERT(pip->shader->d3d11.vs);
        SOKOL_ASSERT(pip->shader->d3d11.fs);

        _sg.d3d11.use_indexed_draw = (pip->d3d11.index_format != DXGI_FORMAT_UNKNOWN);
        _sg.d3d11.use_instanced_draw = pip->cmn.use_instanced_draw;

        _sg_d3d11_RSSetState(_sg.d3d11.ctx, pip->d3d11.rs);
        _sg_d3d11_OMSetDepthStencilState(_sg.d3d11.ctx, pip->d3d11.dss, pip->d3d11.stencil_ref);
        _sg_d3d11_OMSetBlendState(_sg.d3d11.ctx, pip->d3d11.bs, (float*)&pip->cmn.blend_color, 0xFFFFFFFF);
        _sg_d3d11_IASetPrimitiveTopology(_sg.d3d11.ctx, pip->d3d11.topology);
        _sg_d3d11_IASetInputLayout(_sg.d3d11.ctx, pip->d3d11.il);
        _sg_d3d11_VSSetShader(_sg.d3d11.ctx, pip->shader->d3d11.vs, NULL, 0);
        _sg_d3d11_VSSetConstantBuffers(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_UB_BINDINGS, pip->shader->d3d11.vs_cbufs);
        _sg_d3d11_PSSetShader(_sg.d3d11.ctx, pip->shader->d3d11.fs, NULL, 0);
        _sg_d3d11_PSSetConstantBuffers(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_UB_BINDINGS, pip->shader->d3d11.fs_cbufs);
        _sg_stats_add(d3d11.pipeline.num_rs_set_state, 1);
        _sg_stats_add(d3d11.pipeline.num_om_set_depth_stencil_state, 1);
        _sg_stats_add(d3d11.pipeline.num_om_set_blend_state, 1);
        _sg_stats_add(d3d11.pipeline.num_ia_set_primitive_topology, 1);
        _sg_stats_add(d3d11.pipeline.num_ia_set_input_layout, 1);
        _sg_stats_add(d3d11.pipeline.num_vs_set_shader, 1);
        _sg_stats_add(d3d11.pipeline.num_vs_set_constant_buffers, 1);
        _sg_stats_add(d3d11.pipeline.num_ps_set_shader, 1);
        _sg_stats_add(d3d11.pipeline.num_ps_set_constant_buffers, 1);
    }
}

_SOKOL_PRIVATE bool _sg_d3d11_apply_bindings(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(bnd);
    SOKOL_ASSERT(bnd->pip && bnd->pip->shader);
    SOKOL_ASSERT(bnd->pip->shader->slot.id == bnd->pip->cmn.shader_id.id);
    SOKOL_ASSERT(_sg.d3d11.ctx);
    const _sg_shader_t* shd = bnd->pip->shader;
    const bool is_compute = bnd->pip->cmn.is_compute;

    // gather all the D3D11 resources into arrays
    ID3D11Buffer* d3d11_ib = bnd->ib ? bnd->ib->d3d11.buf : 0;
    ID3D11Buffer* d3d11_vbs[SG_MAX_VERTEXBUFFER_BINDSLOTS] = {0};
    UINT d3d11_vb_offsets[SG_MAX_VERTEXBUFFER_BINDSLOTS] = {0};
    ID3D11ShaderResourceView* d3d11_vs_srvs[_SG_D3D11_MAX_STAGE_SRV_BINDINGS] = {0};
    ID3D11ShaderResourceView* d3d11_fs_srvs[_SG_D3D11_MAX_STAGE_SRV_BINDINGS] = {0};
    ID3D11ShaderResourceView* d3d11_cs_srvs[_SG_D3D11_MAX_STAGE_SRV_BINDINGS] = {0};
    ID3D11SamplerState* d3d11_vs_smps[_SG_D3D11_MAX_STAGE_SMP_BINDINGS] = {0};
    ID3D11SamplerState* d3d11_fs_smps[_SG_D3D11_MAX_STAGE_SMP_BINDINGS] = {0};
    ID3D11SamplerState* d3d11_cs_smps[_SG_D3D11_MAX_STAGE_SMP_BINDINGS] = {0};
    ID3D11UnorderedAccessView* d3d11_cs_uavs[_SG_D3D11_MAX_STAGE_UAV_BINDINGS] = {0};

    if (!is_compute) {
        for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
            const _sg_buffer_t* vb = bnd->vbs[i];
            if (vb == 0) {
                continue;
            }
            SOKOL_ASSERT(vb->d3d11.buf);
            d3d11_vbs[i] = vb->d3d11.buf;
            d3d11_vb_offsets[i] = (UINT)bnd->vb_offsets[i];
        }
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        const _sg_image_t* img = bnd->imgs[i];
        if (img == 0) {
            continue;
        }
        const sg_shader_stage stage = shd->cmn.images[i].stage;
        SOKOL_ASSERT(stage != SG_SHADERSTAGE_NONE);
        const uint8_t d3d11_slot = shd->d3d11.img_register_t_n[i];
        SOKOL_ASSERT(d3d11_slot < _SG_D3D11_MAX_STAGE_SRV_BINDINGS);
        SOKOL_ASSERT(img->d3d11.srv);
        ID3D11ShaderResourceView* d3d11_srv = img->d3d11.srv;
        switch (stage) {
            case SG_SHADERSTAGE_VERTEX: d3d11_vs_srvs[d3d11_slot] = d3d11_srv; break;
            case SG_SHADERSTAGE_FRAGMENT: d3d11_fs_srvs[d3d11_slot] = d3d11_srv; break;
            case SG_SHADERSTAGE_COMPUTE: d3d11_cs_srvs[d3d11_slot] = d3d11_srv; break;
            default: SOKOL_UNREACHABLE;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        const _sg_buffer_t* sbuf = bnd->sbufs[i];
        if (sbuf == 0) {
            continue;
        }
        const sg_shader_stage stage = shd->cmn.storage_buffers[i].stage;
        SOKOL_ASSERT(stage != SG_SHADERSTAGE_NONE);
        if (shd->cmn.storage_buffers[i].readonly) {
            SOKOL_ASSERT(sbuf->d3d11.srv);
            const uint8_t d3d11_slot = shd->d3d11.sbuf_register_t_n[i];
            SOKOL_ASSERT(d3d11_slot < _SG_D3D11_MAX_STAGE_SRV_BINDINGS);
            ID3D11ShaderResourceView* d3d11_srv = sbuf->d3d11.srv;
            switch (stage) {
                case SG_SHADERSTAGE_VERTEX: d3d11_vs_srvs[d3d11_slot] = d3d11_srv; break;
                case SG_SHADERSTAGE_FRAGMENT: d3d11_fs_srvs[d3d11_slot] = d3d11_srv; break;
                case SG_SHADERSTAGE_COMPUTE: d3d11_cs_srvs[d3d11_slot] = d3d11_srv; break;
                default: SOKOL_UNREACHABLE;
            }
        } else {
            SOKOL_ASSERT(sbuf->d3d11.uav);
            SOKOL_ASSERT(stage == SG_SHADERSTAGE_COMPUTE);
            const uint8_t d3d11_slot = shd->d3d11.sbuf_register_u_n[i];
            SOKOL_ASSERT(d3d11_slot < _SG_D3D11_MAX_STAGE_UAV_BINDINGS);
            d3d11_cs_uavs[d3d11_slot] = sbuf->d3d11.uav;
        }
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        const _sg_sampler_t* smp = bnd->smps[i];
        if (smp == 0) {
            continue;
        }
        const sg_shader_stage stage = shd->cmn.samplers[i].stage;
        SOKOL_ASSERT(stage != SG_SHADERSTAGE_NONE);
        const uint8_t d3d11_slot = shd->d3d11.smp_register_s_n[i];
        SOKOL_ASSERT(d3d11_slot < _SG_D3D11_MAX_STAGE_SMP_BINDINGS);
        SOKOL_ASSERT(smp->d3d11.smp);
        ID3D11SamplerState* d3d11_smp = smp->d3d11.smp;
        switch (stage) {
            case SG_SHADERSTAGE_VERTEX: d3d11_vs_smps[d3d11_slot] = d3d11_smp; break;
            case SG_SHADERSTAGE_FRAGMENT: d3d11_fs_smps[d3d11_slot] = d3d11_smp; break;
            case SG_SHADERSTAGE_COMPUTE: d3d11_cs_smps[d3d11_slot] = d3d11_smp; break;
            default: SOKOL_UNREACHABLE;
        }
    }
    if (is_compute) {
        // in a compute pass with storage attachments, also need to rebind the storage attachments
        if (_sg.cur_pass.atts) {
            _sg_d3d11_populate_storage_attachment_uavs(bnd->pip, d3d11_cs_uavs);
        }
        _sg_d3d11_CSSetShaderResources(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_SRV_BINDINGS, d3d11_cs_srvs);
        _sg_d3d11_CSSetSamplers(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_SMP_BINDINGS, d3d11_cs_smps);
        _sg_d3d11_CSSetUnorderedAccessViews(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_UAV_BINDINGS, d3d11_cs_uavs, NULL);
        _sg_stats_add(d3d11.bindings.num_cs_set_shader_resources, 1);
        _sg_stats_add(d3d11.bindings.num_cs_set_samplers, 1);
        _sg_stats_add(d3d11.bindings.num_cs_set_unordered_access_views, 1);
    } else {
        _sg_d3d11_IASetVertexBuffers(_sg.d3d11.ctx, 0, SG_MAX_VERTEXBUFFER_BINDSLOTS, d3d11_vbs, bnd->pip->d3d11.vb_strides, d3d11_vb_offsets);
        _sg_d3d11_IASetIndexBuffer(_sg.d3d11.ctx, d3d11_ib, bnd->pip->d3d11.index_format, (UINT)bnd->ib_offset);
        _sg_d3d11_VSSetShaderResources(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_SRV_BINDINGS, d3d11_vs_srvs);
        _sg_d3d11_PSSetShaderResources(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_SRV_BINDINGS, d3d11_fs_srvs);
        _sg_d3d11_VSSetSamplers(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_SMP_BINDINGS, d3d11_vs_smps);
        _sg_d3d11_PSSetSamplers(_sg.d3d11.ctx, 0, _SG_D3D11_MAX_STAGE_SMP_BINDINGS, d3d11_fs_smps);
        _sg_stats_add(d3d11.bindings.num_ia_set_vertex_buffers, 1);
        _sg_stats_add(d3d11.bindings.num_ia_set_index_buffer, 1);
        _sg_stats_add(d3d11.bindings.num_vs_set_shader_resources, 1);
        _sg_stats_add(d3d11.bindings.num_ps_set_shader_resources, 1);
        _sg_stats_add(d3d11.bindings.num_vs_set_samplers, 1);
        _sg_stats_add(d3d11.bindings.num_ps_set_samplers, 1);
    }
    return true;
}

_SOKOL_PRIVATE void _sg_d3d11_apply_uniforms(int ub_slot, const sg_range* data) {
    SOKOL_ASSERT(_sg.d3d11.ctx);
    SOKOL_ASSERT((ub_slot >= 0) && (ub_slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS));
    SOKOL_ASSERT(_sg.d3d11.cur_pipeline && _sg.d3d11.cur_pipeline->slot.id == _sg.d3d11.cur_pipeline_id.id);
    const _sg_shader_t* shd = _sg.d3d11.cur_pipeline->shader;
    SOKOL_ASSERT(shd && (shd->slot.id == _sg.d3d11.cur_pipeline->cmn.shader_id.id));
    SOKOL_ASSERT(data->size == shd->cmn.uniform_blocks[ub_slot].size);

    ID3D11Buffer* cbuf = shd->d3d11.all_cbufs[ub_slot];
    SOKOL_ASSERT(cbuf);
    _sg_d3d11_UpdateSubresource(_sg.d3d11.ctx, (ID3D11Resource*)cbuf, 0, NULL, data->ptr, 0, 0);
    _sg_stats_add(d3d11.uniforms.num_update_subresource, 1);
}

_SOKOL_PRIVATE void _sg_d3d11_draw(int base_element, int num_elements, int num_instances) {
    const bool use_instanced_draw = (num_instances > 1) || (_sg.d3d11.use_instanced_draw);
    if (_sg.d3d11.use_indexed_draw) {
        if (use_instanced_draw) {
            _sg_d3d11_DrawIndexedInstanced(_sg.d3d11.ctx, (UINT)num_elements, (UINT)num_instances, (UINT)base_element, 0, 0);
            _sg_stats_add(d3d11.draw.num_draw_indexed_instanced, 1);
        } else {
            _sg_d3d11_DrawIndexed(_sg.d3d11.ctx, (UINT)num_elements, (UINT)base_element, 0);
            _sg_stats_add(d3d11.draw.num_draw_indexed, 1);
        }
    } else {
        if (use_instanced_draw) {
            _sg_d3d11_DrawInstanced(_sg.d3d11.ctx, (UINT)num_elements, (UINT)num_instances, (UINT)base_element, 0);
            _sg_stats_add(d3d11.draw.num_draw_instanced, 1);
        } else {
            _sg_d3d11_Draw(_sg.d3d11.ctx, (UINT)num_elements, (UINT)base_element);
            _sg_stats_add(d3d11.draw.num_draw, 1);
        }
    }
}

_SOKOL_PRIVATE void _sg_d3d11_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    _sg_d3d11_Dispatch(_sg.d3d11.ctx, (UINT)num_groups_x, (UINT)num_groups_y, (UINT)num_groups_z);
}

_SOKOL_PRIVATE void _sg_d3d11_commit(void) {
    // empty
}

_SOKOL_PRIVATE void _sg_d3d11_update_buffer(_sg_buffer_t* buf, const sg_range* data) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    SOKOL_ASSERT(_sg.d3d11.ctx);
    SOKOL_ASSERT(buf->d3d11.buf);
    D3D11_MAPPED_SUBRESOURCE d3d11_msr;
    HRESULT hr = _sg_d3d11_Map(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0, D3D11_MAP_WRITE_DISCARD, 0, &d3d11_msr);
    _sg_stats_add(d3d11.num_map, 1);
    if (SUCCEEDED(hr)) {
        memcpy(d3d11_msr.pData, data->ptr, data->size);
        _sg_d3d11_Unmap(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0);
        _sg_stats_add(d3d11.num_unmap, 1);
    } else {
        _SG_ERROR(D3D11_MAP_FOR_UPDATE_BUFFER_FAILED);
    }
}

_SOKOL_PRIVATE void _sg_d3d11_append_buffer(_sg_buffer_t* buf, const sg_range* data, bool new_frame) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    SOKOL_ASSERT(_sg.d3d11.ctx);
    SOKOL_ASSERT(buf->d3d11.buf);
    D3D11_MAP map_type = new_frame ? D3D11_MAP_WRITE_DISCARD : D3D11_MAP_WRITE_NO_OVERWRITE;
    D3D11_MAPPED_SUBRESOURCE d3d11_msr;
    HRESULT hr = _sg_d3d11_Map(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0, map_type, 0, &d3d11_msr);
    _sg_stats_add(d3d11.num_map, 1);
    if (SUCCEEDED(hr)) {
        uint8_t* dst_ptr = (uint8_t*)d3d11_msr.pData + buf->cmn.append_pos;
        memcpy(dst_ptr, data->ptr, data->size);
        _sg_d3d11_Unmap(_sg.d3d11.ctx, (ID3D11Resource*)buf->d3d11.buf, 0);
        _sg_stats_add(d3d11.num_unmap, 1);
    } else {
        _SG_ERROR(D3D11_MAP_FOR_APPEND_BUFFER_FAILED);
    }
}

// see: https://learn.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-resources-subresources
// also see: https://learn.microsoft.com/en-us/windows/win32/api/d3d11/nf-d3d11-d3d11calcsubresource
_SOKOL_PRIVATE void _sg_d3d11_update_image(_sg_image_t* img, const sg_image_data* data) {
    SOKOL_ASSERT(img && data);
    SOKOL_ASSERT(_sg.d3d11.ctx);
    SOKOL_ASSERT(img->d3d11.res);
    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;
    const int num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.num_slices:1;
    const int num_depth_slices = (img->cmn.type == SG_IMAGETYPE_3D) ? img->cmn.num_slices:1;
    UINT subres_index = 0;
    HRESULT hr;
    D3D11_MAPPED_SUBRESOURCE d3d11_msr;
    for (int face_index = 0; face_index < num_faces; face_index++) {
        for (int slice_index = 0; slice_index < num_slices; slice_index++) {
            for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++, subres_index++) {
                SOKOL_ASSERT(subres_index < (SG_MAX_MIPMAPS * SG_MAX_TEXTUREARRAY_LAYERS));
                const int mip_width = _sg_miplevel_dim(img->cmn.width, mip_index);
                const int mip_height = _sg_miplevel_dim(img->cmn.height, mip_index);
                const int src_row_pitch = _sg_row_pitch(img->cmn.pixel_format, mip_width, 1);
                const int src_depth_pitch = _sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, 1);
                const sg_range* subimg_data = &(data->subimage[face_index][mip_index]);
                const size_t slice_size = subimg_data->size / (size_t)num_slices;
                SOKOL_ASSERT(slice_size == (size_t)(src_depth_pitch * num_depth_slices));
                const size_t slice_offset = slice_size * (size_t)slice_index;
                const uint8_t* slice_ptr = ((const uint8_t*)subimg_data->ptr) + slice_offset;
                hr = _sg_d3d11_Map(_sg.d3d11.ctx, img->d3d11.res, subres_index, D3D11_MAP_WRITE_DISCARD, 0, &d3d11_msr);
                _sg_stats_add(d3d11.num_map, 1);
                if (SUCCEEDED(hr)) {
                    const uint8_t* src_ptr = slice_ptr;
                    uint8_t* dst_ptr = (uint8_t*)d3d11_msr.pData;
                    for (int depth_index = 0; depth_index < num_depth_slices; depth_index++) {
                        if (src_row_pitch == (int)d3d11_msr.RowPitch) {
                            const size_t copy_size = slice_size / (size_t)num_depth_slices;
                            SOKOL_ASSERT((copy_size * (size_t)num_depth_slices) == slice_size);
                            memcpy(dst_ptr, src_ptr, copy_size);
                        } else {
                            SOKOL_ASSERT(src_row_pitch < (int)d3d11_msr.RowPitch);
                            const uint8_t* src_row_ptr = src_ptr;
                            uint8_t* dst_row_ptr = dst_ptr;
                            for (int row_index = 0; row_index < mip_height; row_index++) {
                                memcpy(dst_row_ptr, src_row_ptr, (size_t)src_row_pitch);
                                src_row_ptr += src_row_pitch;
                                dst_row_ptr += d3d11_msr.RowPitch;
                            }
                        }
                        src_ptr += src_depth_pitch;
                        dst_ptr += d3d11_msr.DepthPitch;
                    }
                    _sg_d3d11_Unmap(_sg.d3d11.ctx, img->d3d11.res, subres_index);
                    _sg_stats_add(d3d11.num_unmap, 1);
                } else {
                    _SG_ERROR(D3D11_MAP_FOR_UPDATE_IMAGE_FAILED);
                }
            }
        }
    }
}

// ███    ███ ███████ ████████  █████  ██          ██████   █████   ██████ ██   ██ ███████ ███    ██ ██████
// ████  ████ ██         ██    ██   ██ ██          ██   ██ ██   ██ ██      ██  ██  ██      ████   ██ ██   ██
// ██ ████ ██ █████      ██    ███████ ██          ██████  ███████ ██      █████   █████   ██ ██  ██ ██   ██
// ██  ██  ██ ██         ██    ██   ██ ██          ██   ██ ██   ██ ██      ██  ██  ██      ██  ██ ██ ██   ██
// ██      ██ ███████    ██    ██   ██ ███████     ██████  ██   ██  ██████ ██   ██ ███████ ██   ████ ██████
//
// >>metal backend
#elif defined(SOKOL_METAL)

#if __has_feature(objc_arc)
#define _SG_OBJC_RETAIN(obj) { }
#define _SG_OBJC_RELEASE(obj) { obj = nil; }
#else
#define _SG_OBJC_RETAIN(obj) { [obj retain]; }
#define _SG_OBJC_RELEASE(obj) { [obj release]; obj = nil; }
#endif

//-- enum translation functions ------------------------------------------------
_SOKOL_PRIVATE MTLLoadAction _sg_mtl_load_action(sg_load_action a) {
    switch (a) {
        case SG_LOADACTION_CLEAR:       return MTLLoadActionClear;
        case SG_LOADACTION_LOAD:        return MTLLoadActionLoad;
        case SG_LOADACTION_DONTCARE:    return MTLLoadActionDontCare;
        default: SOKOL_UNREACHABLE;     return (MTLLoadAction)0;
    }
}

_SOKOL_PRIVATE MTLStoreAction _sg_mtl_store_action(sg_store_action a, bool resolve) {
    switch (a) {
        case SG_STOREACTION_STORE:
            if (resolve) {
                return MTLStoreActionStoreAndMultisampleResolve;
            } else {
                return MTLStoreActionStore;
            }
            break;
        case SG_STOREACTION_DONTCARE:
            if (resolve) {
                return MTLStoreActionMultisampleResolve;
            } else {
                return MTLStoreActionDontCare;
            }
            break;
        default: SOKOL_UNREACHABLE; return (MTLStoreAction)0;
    }
}

_SOKOL_PRIVATE MTLResourceOptions _sg_mtl_resource_options_storage_mode_managed_or_shared(void) {
    #if defined(_SG_TARGET_MACOS)
    if (_sg.mtl.use_shared_storage_mode) {
        return MTLResourceStorageModeShared;
    } else {
        return MTLResourceStorageModeManaged;
    }
    #else
        // MTLResourceStorageModeManaged is not even defined on iOS SDK
        return MTLResourceStorageModeShared;
    #endif
}

_SOKOL_PRIVATE MTLResourceOptions _sg_mtl_buffer_resource_options(const sg_buffer_usage* usage) {
    if (usage->immutable) {
        return _sg_mtl_resource_options_storage_mode_managed_or_shared();
    } else {
        return MTLResourceCPUCacheModeWriteCombined | _sg_mtl_resource_options_storage_mode_managed_or_shared();
    }
}

_SOKOL_PRIVATE MTLVertexStepFunction _sg_mtl_step_function(sg_vertex_step step) {
    switch (step) {
        case SG_VERTEXSTEP_PER_VERTEX:      return MTLVertexStepFunctionPerVertex;
        case SG_VERTEXSTEP_PER_INSTANCE:    return MTLVertexStepFunctionPerInstance;
        default: SOKOL_UNREACHABLE; return (MTLVertexStepFunction)0;
    }
}

_SOKOL_PRIVATE MTLVertexFormat _sg_mtl_vertex_format(sg_vertex_format fmt) {
    switch (fmt) {
        case SG_VERTEXFORMAT_FLOAT:     return MTLVertexFormatFloat;
        case SG_VERTEXFORMAT_FLOAT2:    return MTLVertexFormatFloat2;
        case SG_VERTEXFORMAT_FLOAT3:    return MTLVertexFormatFloat3;
        case SG_VERTEXFORMAT_FLOAT4:    return MTLVertexFormatFloat4;
        case SG_VERTEXFORMAT_INT:       return MTLVertexFormatInt;
        case SG_VERTEXFORMAT_INT2:      return MTLVertexFormatInt2;
        case SG_VERTEXFORMAT_INT3:      return MTLVertexFormatInt3;
        case SG_VERTEXFORMAT_INT4:      return MTLVertexFormatInt4;
        case SG_VERTEXFORMAT_UINT:      return MTLVertexFormatUInt;
        case SG_VERTEXFORMAT_UINT2:     return MTLVertexFormatUInt2;
        case SG_VERTEXFORMAT_UINT3:     return MTLVertexFormatUInt3;
        case SG_VERTEXFORMAT_UINT4:     return MTLVertexFormatUInt4;
        case SG_VERTEXFORMAT_BYTE4:     return MTLVertexFormatChar4;
        case SG_VERTEXFORMAT_BYTE4N:    return MTLVertexFormatChar4Normalized;
        case SG_VERTEXFORMAT_UBYTE4:    return MTLVertexFormatUChar4;
        case SG_VERTEXFORMAT_UBYTE4N:   return MTLVertexFormatUChar4Normalized;
        case SG_VERTEXFORMAT_SHORT2:    return MTLVertexFormatShort2;
        case SG_VERTEXFORMAT_SHORT2N:   return MTLVertexFormatShort2Normalized;
        case SG_VERTEXFORMAT_USHORT2:   return MTLVertexFormatUShort2;
        case SG_VERTEXFORMAT_USHORT2N:  return MTLVertexFormatUShort2Normalized;
        case SG_VERTEXFORMAT_SHORT4:    return MTLVertexFormatShort4;
        case SG_VERTEXFORMAT_SHORT4N:   return MTLVertexFormatShort4Normalized;
        case SG_VERTEXFORMAT_USHORT4:   return MTLVertexFormatUShort4;
        case SG_VERTEXFORMAT_USHORT4N:  return MTLVertexFormatUShort4Normalized;
        case SG_VERTEXFORMAT_UINT10_N2: return MTLVertexFormatUInt1010102Normalized;
        case SG_VERTEXFORMAT_HALF2:     return MTLVertexFormatHalf2;
        case SG_VERTEXFORMAT_HALF4:     return MTLVertexFormatHalf4;
        default: SOKOL_UNREACHABLE; return (MTLVertexFormat)0;
    }
}

_SOKOL_PRIVATE MTLPrimitiveType _sg_mtl_primitive_type(sg_primitive_type t) {
    switch (t) {
        case SG_PRIMITIVETYPE_POINTS:           return MTLPrimitiveTypePoint;
        case SG_PRIMITIVETYPE_LINES:            return MTLPrimitiveTypeLine;
        case SG_PRIMITIVETYPE_LINE_STRIP:       return MTLPrimitiveTypeLineStrip;
        case SG_PRIMITIVETYPE_TRIANGLES:        return MTLPrimitiveTypeTriangle;
        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return MTLPrimitiveTypeTriangleStrip;
        default: SOKOL_UNREACHABLE; return (MTLPrimitiveType)0;
    }
}

_SOKOL_PRIVATE MTLPixelFormat _sg_mtl_pixel_format(sg_pixel_format fmt) {
    switch (fmt) {
        case SG_PIXELFORMAT_R8:                     return MTLPixelFormatR8Unorm;
        case SG_PIXELFORMAT_R8SN:                   return MTLPixelFormatR8Snorm;
        case SG_PIXELFORMAT_R8UI:                   return MTLPixelFormatR8Uint;
        case SG_PIXELFORMAT_R8SI:                   return MTLPixelFormatR8Sint;
        case SG_PIXELFORMAT_R16:                    return MTLPixelFormatR16Unorm;
        case SG_PIXELFORMAT_R16SN:                  return MTLPixelFormatR16Snorm;
        case SG_PIXELFORMAT_R16UI:                  return MTLPixelFormatR16Uint;
        case SG_PIXELFORMAT_R16SI:                  return MTLPixelFormatR16Sint;
        case SG_PIXELFORMAT_R16F:                   return MTLPixelFormatR16Float;
        case SG_PIXELFORMAT_RG8:                    return MTLPixelFormatRG8Unorm;
        case SG_PIXELFORMAT_RG8SN:                  return MTLPixelFormatRG8Snorm;
        case SG_PIXELFORMAT_RG8UI:                  return MTLPixelFormatRG8Uint;
        case SG_PIXELFORMAT_RG8SI:                  return MTLPixelFormatRG8Sint;
        case SG_PIXELFORMAT_R32UI:                  return MTLPixelFormatR32Uint;
        case SG_PIXELFORMAT_R32SI:                  return MTLPixelFormatR32Sint;
        case SG_PIXELFORMAT_R32F:                   return MTLPixelFormatR32Float;
        case SG_PIXELFORMAT_RG16:                   return MTLPixelFormatRG16Unorm;
        case SG_PIXELFORMAT_RG16SN:                 return MTLPixelFormatRG16Snorm;
        case SG_PIXELFORMAT_RG16UI:                 return MTLPixelFormatRG16Uint;
        case SG_PIXELFORMAT_RG16SI:                 return MTLPixelFormatRG16Sint;
        case SG_PIXELFORMAT_RG16F:                  return MTLPixelFormatRG16Float;
        case SG_PIXELFORMAT_RGBA8:                  return MTLPixelFormatRGBA8Unorm;
        case SG_PIXELFORMAT_SRGB8A8:                return MTLPixelFormatRGBA8Unorm_sRGB;
        case SG_PIXELFORMAT_RGBA8SN:                return MTLPixelFormatRGBA8Snorm;
        case SG_PIXELFORMAT_RGBA8UI:                return MTLPixelFormatRGBA8Uint;
        case SG_PIXELFORMAT_RGBA8SI:                return MTLPixelFormatRGBA8Sint;
        case SG_PIXELFORMAT_BGRA8:                  return MTLPixelFormatBGRA8Unorm;
        case SG_PIXELFORMAT_RGB10A2:                return MTLPixelFormatRGB10A2Unorm;
        case SG_PIXELFORMAT_RG11B10F:               return MTLPixelFormatRG11B10Float;
        case SG_PIXELFORMAT_RGB9E5:                 return MTLPixelFormatRGB9E5Float;
        case SG_PIXELFORMAT_RG32UI:                 return MTLPixelFormatRG32Uint;
        case SG_PIXELFORMAT_RG32SI:                 return MTLPixelFormatRG32Sint;
        case SG_PIXELFORMAT_RG32F:                  return MTLPixelFormatRG32Float;
        case SG_PIXELFORMAT_RGBA16:                 return MTLPixelFormatRGBA16Unorm;
        case SG_PIXELFORMAT_RGBA16SN:               return MTLPixelFormatRGBA16Snorm;
        case SG_PIXELFORMAT_RGBA16UI:               return MTLPixelFormatRGBA16Uint;
        case SG_PIXELFORMAT_RGBA16SI:               return MTLPixelFormatRGBA16Sint;
        case SG_PIXELFORMAT_RGBA16F:                return MTLPixelFormatRGBA16Float;
        case SG_PIXELFORMAT_RGBA32UI:               return MTLPixelFormatRGBA32Uint;
        case SG_PIXELFORMAT_RGBA32SI:               return MTLPixelFormatRGBA32Sint;
        case SG_PIXELFORMAT_RGBA32F:                return MTLPixelFormatRGBA32Float;
        case SG_PIXELFORMAT_DEPTH:                  return MTLPixelFormatDepth32Float;
        case SG_PIXELFORMAT_DEPTH_STENCIL:          return MTLPixelFormatDepth32Float_Stencil8;
        #if defined(_SG_TARGET_MACOS)
        case SG_PIXELFORMAT_BC1_RGBA:               return MTLPixelFormatBC1_RGBA;
        case SG_PIXELFORMAT_BC2_RGBA:               return MTLPixelFormatBC2_RGBA;
        case SG_PIXELFORMAT_BC3_RGBA:               return MTLPixelFormatBC3_RGBA;
        case SG_PIXELFORMAT_BC3_SRGBA:              return MTLPixelFormatBC3_RGBA_sRGB;
        case SG_PIXELFORMAT_BC4_R:                  return MTLPixelFormatBC4_RUnorm;
        case SG_PIXELFORMAT_BC4_RSN:                return MTLPixelFormatBC4_RSnorm;
        case SG_PIXELFORMAT_BC5_RG:                 return MTLPixelFormatBC5_RGUnorm;
        case SG_PIXELFORMAT_BC5_RGSN:               return MTLPixelFormatBC5_RGSnorm;
        case SG_PIXELFORMAT_BC6H_RGBF:              return MTLPixelFormatBC6H_RGBFloat;
        case SG_PIXELFORMAT_BC6H_RGBUF:             return MTLPixelFormatBC6H_RGBUfloat;
        case SG_PIXELFORMAT_BC7_RGBA:               return MTLPixelFormatBC7_RGBAUnorm;
        case SG_PIXELFORMAT_BC7_SRGBA:              return MTLPixelFormatBC7_RGBAUnorm_sRGB;
        #else
        case SG_PIXELFORMAT_ETC2_RGB8:              return MTLPixelFormatETC2_RGB8;
        case SG_PIXELFORMAT_ETC2_SRGB8:             return MTLPixelFormatETC2_RGB8_sRGB;
        case SG_PIXELFORMAT_ETC2_RGB8A1:            return MTLPixelFormatETC2_RGB8A1;
        case SG_PIXELFORMAT_ETC2_RGBA8:             return MTLPixelFormatEAC_RGBA8;
        case SG_PIXELFORMAT_ETC2_SRGB8A8:           return MTLPixelFormatEAC_RGBA8_sRGB;
        case SG_PIXELFORMAT_EAC_R11:                return MTLPixelFormatEAC_R11Unorm;
        case SG_PIXELFORMAT_EAC_R11SN:              return MTLPixelFormatEAC_R11Snorm;
        case SG_PIXELFORMAT_EAC_RG11:               return MTLPixelFormatEAC_RG11Unorm;
        case SG_PIXELFORMAT_EAC_RG11SN:             return MTLPixelFormatEAC_RG11Snorm;
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:          return MTLPixelFormatASTC_4x4_LDR;
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA:         return MTLPixelFormatASTC_4x4_sRGB;
        #endif
        default: return MTLPixelFormatInvalid;
    }
}

_SOKOL_PRIVATE MTLColorWriteMask _sg_mtl_color_write_mask(sg_color_mask m) {
    MTLColorWriteMask mtl_mask = MTLColorWriteMaskNone;
    if (m & SG_COLORMASK_R) {
        mtl_mask |= MTLColorWriteMaskRed;
    }
    if (m & SG_COLORMASK_G) {
        mtl_mask |= MTLColorWriteMaskGreen;
    }
    if (m & SG_COLORMASK_B) {
        mtl_mask |= MTLColorWriteMaskBlue;
    }
    if (m & SG_COLORMASK_A) {
        mtl_mask |= MTLColorWriteMaskAlpha;
    }
    return mtl_mask;
}

_SOKOL_PRIVATE MTLBlendOperation _sg_mtl_blend_op(sg_blend_op op) {
    switch (op) {
        case SG_BLENDOP_ADD:                return MTLBlendOperationAdd;
        case SG_BLENDOP_SUBTRACT:           return MTLBlendOperationSubtract;
        case SG_BLENDOP_REVERSE_SUBTRACT:   return MTLBlendOperationReverseSubtract;
        case SG_BLENDOP_MIN:                return MTLBlendOperationMin;
        case SG_BLENDOP_MAX:                return MTLBlendOperationMax;
        default: SOKOL_UNREACHABLE; return (MTLBlendOperation)0;
    }
}

_SOKOL_PRIVATE MTLBlendFactor _sg_mtl_blend_factor(sg_blend_factor f) {
    switch (f) {
        case SG_BLENDFACTOR_ZERO:                   return MTLBlendFactorZero;
        case SG_BLENDFACTOR_ONE:                    return MTLBlendFactorOne;
        case SG_BLENDFACTOR_SRC_COLOR:              return MTLBlendFactorSourceColor;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return MTLBlendFactorOneMinusSourceColor;
        case SG_BLENDFACTOR_SRC_ALPHA:              return MTLBlendFactorSourceAlpha;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return MTLBlendFactorOneMinusSourceAlpha;
        case SG_BLENDFACTOR_DST_COLOR:              return MTLBlendFactorDestinationColor;
        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return MTLBlendFactorOneMinusDestinationColor;
        case SG_BLENDFACTOR_DST_ALPHA:              return MTLBlendFactorDestinationAlpha;
        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return MTLBlendFactorOneMinusDestinationAlpha;
        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return MTLBlendFactorSourceAlphaSaturated;
        case SG_BLENDFACTOR_BLEND_COLOR:            return MTLBlendFactorBlendColor;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return MTLBlendFactorOneMinusBlendColor;
        case SG_BLENDFACTOR_BLEND_ALPHA:            return MTLBlendFactorBlendAlpha;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return MTLBlendFactorOneMinusBlendAlpha;
        default: SOKOL_UNREACHABLE; return (MTLBlendFactor)0;
    }
}

_SOKOL_PRIVATE MTLCompareFunction _sg_mtl_compare_func(sg_compare_func f) {
    switch (f) {
        case SG_COMPAREFUNC_NEVER:          return MTLCompareFunctionNever;
        case SG_COMPAREFUNC_LESS:           return MTLCompareFunctionLess;
        case SG_COMPAREFUNC_EQUAL:          return MTLCompareFunctionEqual;
        case SG_COMPAREFUNC_LESS_EQUAL:     return MTLCompareFunctionLessEqual;
        case SG_COMPAREFUNC_GREATER:        return MTLCompareFunctionGreater;
        case SG_COMPAREFUNC_NOT_EQUAL:      return MTLCompareFunctionNotEqual;
        case SG_COMPAREFUNC_GREATER_EQUAL:  return MTLCompareFunctionGreaterEqual;
        case SG_COMPAREFUNC_ALWAYS:         return MTLCompareFunctionAlways;
        default: SOKOL_UNREACHABLE; return (MTLCompareFunction)0;
    }
}

_SOKOL_PRIVATE MTLStencilOperation _sg_mtl_stencil_op(sg_stencil_op op) {
    switch (op) {
        case SG_STENCILOP_KEEP:         return MTLStencilOperationKeep;
        case SG_STENCILOP_ZERO:         return MTLStencilOperationZero;
        case SG_STENCILOP_REPLACE:      return MTLStencilOperationReplace;
        case SG_STENCILOP_INCR_CLAMP:   return MTLStencilOperationIncrementClamp;
        case SG_STENCILOP_DECR_CLAMP:   return MTLStencilOperationDecrementClamp;
        case SG_STENCILOP_INVERT:       return MTLStencilOperationInvert;
        case SG_STENCILOP_INCR_WRAP:    return MTLStencilOperationIncrementWrap;
        case SG_STENCILOP_DECR_WRAP:    return MTLStencilOperationDecrementWrap;
        default: SOKOL_UNREACHABLE; return (MTLStencilOperation)0;
    }
}

_SOKOL_PRIVATE MTLCullMode _sg_mtl_cull_mode(sg_cull_mode m) {
    switch (m) {
        case SG_CULLMODE_NONE:  return MTLCullModeNone;
        case SG_CULLMODE_FRONT: return MTLCullModeFront;
        case SG_CULLMODE_BACK:  return MTLCullModeBack;
        default: SOKOL_UNREACHABLE; return (MTLCullMode)0;
    }
}

_SOKOL_PRIVATE MTLWinding _sg_mtl_winding(sg_face_winding w) {
    switch (w) {
        case SG_FACEWINDING_CW:     return MTLWindingClockwise;
        case SG_FACEWINDING_CCW:    return MTLWindingCounterClockwise;
        default: SOKOL_UNREACHABLE; return (MTLWinding)0;
    }
}

_SOKOL_PRIVATE MTLIndexType _sg_mtl_index_type(sg_index_type t) {
    switch (t) {
        case SG_INDEXTYPE_UINT16:   return MTLIndexTypeUInt16;
        case SG_INDEXTYPE_UINT32:   return MTLIndexTypeUInt32;
        default: SOKOL_UNREACHABLE; return (MTLIndexType)0;
    }
}

_SOKOL_PRIVATE int _sg_mtl_index_size(sg_index_type t) {
    switch (t) {
        case SG_INDEXTYPE_NONE:     return 0;
        case SG_INDEXTYPE_UINT16:   return 2;
        case SG_INDEXTYPE_UINT32:   return 4;
        default: SOKOL_UNREACHABLE; return 0;
    }
}

_SOKOL_PRIVATE MTLTextureType _sg_mtl_texture_type(sg_image_type t, bool msaa) {
    switch (t) {
        case SG_IMAGETYPE_2D:       return msaa ? MTLTextureType2DMultisample : MTLTextureType2D;
        case SG_IMAGETYPE_CUBE:     return MTLTextureTypeCube;
        case SG_IMAGETYPE_3D:       return MTLTextureType3D;
        // NOTE: MTLTextureType2DMultisampleArray requires macOS 10.14+, iOS 14.0+
        case SG_IMAGETYPE_ARRAY:    return MTLTextureType2DArray;
        default: SOKOL_UNREACHABLE; return (MTLTextureType)0;
    }
}

_SOKOL_PRIVATE MTLSamplerAddressMode _sg_mtl_address_mode(sg_wrap w) {
    if (_sg.features.image_clamp_to_border) {
        if (@available(macOS 12.0, iOS 14.0, *)) {
            // border color feature available
            switch (w) {
                case SG_WRAP_REPEAT:            return MTLSamplerAddressModeRepeat;
                case SG_WRAP_CLAMP_TO_EDGE:     return MTLSamplerAddressModeClampToEdge;
                case SG_WRAP_CLAMP_TO_BORDER:   return MTLSamplerAddressModeClampToBorderColor;
                case SG_WRAP_MIRRORED_REPEAT:   return MTLSamplerAddressModeMirrorRepeat;
                default: SOKOL_UNREACHABLE; return (MTLSamplerAddressMode)0;
            }
        }
    }
    // fallthrough: clamp to border no supported
    switch (w) {
        case SG_WRAP_REPEAT:            return MTLSamplerAddressModeRepeat;
        case SG_WRAP_CLAMP_TO_EDGE:     return MTLSamplerAddressModeClampToEdge;
        case SG_WRAP_CLAMP_TO_BORDER:   return MTLSamplerAddressModeClampToEdge;
        case SG_WRAP_MIRRORED_REPEAT:   return MTLSamplerAddressModeMirrorRepeat;
        default: SOKOL_UNREACHABLE; return (MTLSamplerAddressMode)0;
    }
}

_SOKOL_PRIVATE API_AVAILABLE(ios(14.0), macos(12.0)) MTLSamplerBorderColor _sg_mtl_border_color(sg_border_color c) {
    switch (c) {
        case SG_BORDERCOLOR_TRANSPARENT_BLACK: return MTLSamplerBorderColorTransparentBlack;
        case SG_BORDERCOLOR_OPAQUE_BLACK: return MTLSamplerBorderColorOpaqueBlack;
        case SG_BORDERCOLOR_OPAQUE_WHITE: return MTLSamplerBorderColorOpaqueWhite;
        default: SOKOL_UNREACHABLE; return (MTLSamplerBorderColor)0;
    }
}

_SOKOL_PRIVATE MTLSamplerMinMagFilter _sg_mtl_minmag_filter(sg_filter f) {
    switch (f) {
        case SG_FILTER_NEAREST:
            return MTLSamplerMinMagFilterNearest;
        case SG_FILTER_LINEAR:
            return MTLSamplerMinMagFilterLinear;
        default:
            SOKOL_UNREACHABLE; return (MTLSamplerMinMagFilter)0;
    }
}

_SOKOL_PRIVATE MTLSamplerMipFilter _sg_mtl_mipmap_filter(sg_filter f) {
    switch (f) {
        case SG_FILTER_NEAREST:
            return MTLSamplerMipFilterNearest;
        case SG_FILTER_LINEAR:
            return MTLSamplerMipFilterLinear;
        default:
            SOKOL_UNREACHABLE; return (MTLSamplerMipFilter)0;
    }
}

_SOKOL_PRIVATE size_t _sg_mtl_vertexbuffer_bindslot(size_t sokol_bindslot) {
    return sokol_bindslot + _SG_MTL_MAX_STAGE_UB_SBUF_BINDINGS;
}

//-- a pool for all Metal resource objects, with deferred release queue ---------
_SOKOL_PRIVATE void _sg_mtl_init_pool(const sg_desc* desc) {
    _sg.mtl.idpool.num_slots = 2 *
        (
            2 * desc->buffer_pool_size +
            4 * desc->image_pool_size +
            1 * desc->sampler_pool_size +
            4 * desc->shader_pool_size +
            2 * desc->pipeline_pool_size +
            desc->attachments_pool_size +
            128
        );
    _sg.mtl.idpool.pool = [NSMutableArray arrayWithCapacity:(NSUInteger)_sg.mtl.idpool.num_slots];
    _SG_OBJC_RETAIN(_sg.mtl.idpool.pool);
    NSNull* null = [NSNull null];
    for (int i = 0; i < _sg.mtl.idpool.num_slots; i++) {
        [_sg.mtl.idpool.pool addObject:null];
    }
    SOKOL_ASSERT([_sg.mtl.idpool.pool count] == (NSUInteger)_sg.mtl.idpool.num_slots);
    // a queue of currently free slot indices
    _sg.mtl.idpool.free_queue_top = 0;
    _sg.mtl.idpool.free_queue = (int*)_sg_malloc_clear((size_t)_sg.mtl.idpool.num_slots * sizeof(int));
    // pool slot 0 is reserved!
    for (int i = _sg.mtl.idpool.num_slots-1; i >= 1; i--) {
        _sg.mtl.idpool.free_queue[_sg.mtl.idpool.free_queue_top++] = i;
    }
    // a circular queue which holds release items (frame index when a resource is to be released, and the resource's pool index
    _sg.mtl.idpool.release_queue_front = 0;
    _sg.mtl.idpool.release_queue_back = 0;
    _sg.mtl.idpool.release_queue = (_sg_mtl_release_item_t*)_sg_malloc_clear((size_t)_sg.mtl.idpool.num_slots * sizeof(_sg_mtl_release_item_t));
    for (int i = 0; i < _sg.mtl.idpool.num_slots; i++) {
        _sg.mtl.idpool.release_queue[i].frame_index = 0;
        _sg.mtl.idpool.release_queue[i].slot_index = _SG_MTL_INVALID_SLOT_INDEX;
    }
}

_SOKOL_PRIVATE void _sg_mtl_destroy_pool(void) {
    _sg_free(_sg.mtl.idpool.release_queue);  _sg.mtl.idpool.release_queue = 0;
    _sg_free(_sg.mtl.idpool.free_queue);     _sg.mtl.idpool.free_queue = 0;
    _SG_OBJC_RELEASE(_sg.mtl.idpool.pool);
}

// get a new free resource pool slot
_SOKOL_PRIVATE int _sg_mtl_alloc_pool_slot(void) {
    SOKOL_ASSERT(_sg.mtl.idpool.free_queue_top > 0);
    const int slot_index = _sg.mtl.idpool.free_queue[--_sg.mtl.idpool.free_queue_top];
    SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));
    return slot_index;
}

// put a free resource pool slot back into the free-queue
_SOKOL_PRIVATE void _sg_mtl_free_pool_slot(int slot_index) {
    SOKOL_ASSERT(_sg.mtl.idpool.free_queue_top < _sg.mtl.idpool.num_slots);
    SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));
    _sg.mtl.idpool.free_queue[_sg.mtl.idpool.free_queue_top++] = slot_index;
}

// add an MTLResource to the pool, return pool index or 0 if input was 'nil'
_SOKOL_PRIVATE int _sg_mtl_add_resource(id res) {
    if (nil == res) {
        return _SG_MTL_INVALID_SLOT_INDEX;
    }
    _sg_stats_add(metal.idpool.num_added, 1);
    const int slot_index = _sg_mtl_alloc_pool_slot();
    // NOTE: the NSMutableArray will take ownership of its items
    SOKOL_ASSERT([NSNull null] == _sg.mtl.idpool.pool[(NSUInteger)slot_index]);
    _sg.mtl.idpool.pool[(NSUInteger)slot_index] = res;
    return slot_index;
}

/*  mark an MTLResource for release, this will put the resource into the
    deferred-release queue, and the resource will then be released N frames later,
    the special pool index 0 will be ignored (this means that a nil
    value was provided to _sg_mtl_add_resource()
*/
_SOKOL_PRIVATE void _sg_mtl_release_resource(uint32_t frame_index, int slot_index) {
    if (slot_index == _SG_MTL_INVALID_SLOT_INDEX) {
        return;
    }
    _sg_stats_add(metal.idpool.num_released, 1);
    SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));
    SOKOL_ASSERT([NSNull null] != _sg.mtl.idpool.pool[(NSUInteger)slot_index]);
    int release_index = _sg.mtl.idpool.release_queue_front++;
    if (_sg.mtl.idpool.release_queue_front >= _sg.mtl.idpool.num_slots) {
        // wrap-around
        _sg.mtl.idpool.release_queue_front = 0;
    }
    // release queue full?
    SOKOL_ASSERT(_sg.mtl.idpool.release_queue_front != _sg.mtl.idpool.release_queue_back);
    SOKOL_ASSERT(0 == _sg.mtl.idpool.release_queue[release_index].frame_index);
    const uint32_t safe_to_release_frame_index = frame_index + SG_NUM_INFLIGHT_FRAMES + 1;
    _sg.mtl.idpool.release_queue[release_index].frame_index = safe_to_release_frame_index;
    _sg.mtl.idpool.release_queue[release_index].slot_index = slot_index;
}

// run garbage-collection pass on all resources in the release-queue
_SOKOL_PRIVATE void _sg_mtl_garbage_collect(uint32_t frame_index) {
    while (_sg.mtl.idpool.release_queue_back != _sg.mtl.idpool.release_queue_front) {
        if (frame_index < _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].frame_index) {
            // don't need to check further, release-items past this are too young
            break;
        }
        _sg_stats_add(metal.idpool.num_garbage_collected, 1);
        // safe to release this resource
        const int slot_index = _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].slot_index;
        SOKOL_ASSERT((slot_index > 0) && (slot_index < _sg.mtl.idpool.num_slots));
        // note: the NSMutableArray takes ownership of its items, assigning an NSNull object will
        // release the object, no matter if using ARC or not
        SOKOL_ASSERT(_sg.mtl.idpool.pool[(NSUInteger)slot_index] != [NSNull null]);
        _sg.mtl.idpool.pool[(NSUInteger)slot_index] = [NSNull null];
        // put the now free pool index back on the free queue
        _sg_mtl_free_pool_slot(slot_index);
        // reset the release queue slot and advance the back index
        _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].frame_index = 0;
        _sg.mtl.idpool.release_queue[_sg.mtl.idpool.release_queue_back].slot_index = _SG_MTL_INVALID_SLOT_INDEX;
        _sg.mtl.idpool.release_queue_back++;
        if (_sg.mtl.idpool.release_queue_back >= _sg.mtl.idpool.num_slots) {
            // wrap-around
            _sg.mtl.idpool.release_queue_back = 0;
        }
    }
}

_SOKOL_PRIVATE id _sg_mtl_id(int slot_index) {
    return _sg.mtl.idpool.pool[(NSUInteger)slot_index];
}

_SOKOL_PRIVATE void _sg_mtl_clear_state_cache(void) {
    _sg_clear(&_sg.mtl.state_cache, sizeof(_sg.mtl.state_cache));
}

// https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf
_SOKOL_PRIVATE void _sg_mtl_init_caps(void) {
    #if defined(_SG_TARGET_MACOS)
        _sg.backend = SG_BACKEND_METAL_MACOS;
    #elif defined(_SG_TARGET_IOS)
        #if defined(_SG_TARGET_IOS_SIMULATOR)
            _sg.backend = SG_BACKEND_METAL_SIMULATOR;
        #else
            _sg.backend = SG_BACKEND_METAL_IOS;
        #endif
    #endif
    _sg.features.origin_top_left = true;
    _sg.features.mrt_independent_blend_state = true;
    _sg.features.mrt_independent_write_mask = true;
    _sg.features.compute = true;
    _sg.features.msaa_image_bindings = true;

    _sg.features.image_clamp_to_border = false;
    #if (MAC_OS_X_VERSION_MAX_ALLOWED >= 120000) || (__IPHONE_OS_VERSION_MAX_ALLOWED >= 140000)
    if (@available(macOS 12.0, iOS 14.0, *)) {
        _sg.features.image_clamp_to_border = [_sg.mtl.device supportsFamily:MTLGPUFamilyApple7]
                                             || [_sg.mtl.device supportsFamily:MTLGPUFamilyMac2];
        #if (MAC_OS_X_VERSION_MAX_ALLOWED >= 130000) || (__IPHONE_OS_VERSION_MAX_ALLOWED >= 160000)
        if (!_sg.features.image_clamp_to_border) {
            if (@available(macOS 13.0, iOS 16.0, *)) {
                _sg.features.image_clamp_to_border = [_sg.mtl.device supportsFamily:MTLGPUFamilyMetal3];
            }
        }
        #endif
    }
    #endif

    #if defined(_SG_TARGET_MACOS)
        _sg.limits.max_image_size_2d = 16 * 1024;
        _sg.limits.max_image_size_cube = 16 * 1024;
        _sg.limits.max_image_size_3d = 2 * 1024;
        _sg.limits.max_image_size_array = 16 * 1024;
        _sg.limits.max_image_array_layers = 2 * 1024;
    #else
        // FIXME: newer iOS devices support 16k textures
        _sg.limits.max_image_size_2d = 8 * 1024;
        _sg.limits.max_image_size_cube = 8 * 1024;
        _sg.limits.max_image_size_3d = 2 * 1024;
        _sg.limits.max_image_size_array = 8 * 1024;
        _sg.limits.max_image_array_layers = 2 * 1024;
    #endif
    _sg.limits.max_vertex_attrs = SG_MAX_VERTEX_ATTRIBUTES;

    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8SN]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R8SI]);
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16SN]);
    #else
        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_R16]);
        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_R16SN]);
    #endif
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_R16SI]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16F]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8SN]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG8SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32SI]);
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R32F]);
    #else
        _sg_pixelformat_sbr(&_sg.formats[SG_PIXELFORMAT_R32F]);
    #endif
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16SN]);
    #else
        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RG16]);
        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RG16SN]);
    #endif
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG16SI]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16F]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_SRGB8A8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_BGRA8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB10A2]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGB9E5]);
        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    #else
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB9E5]);
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    #endif
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);
    #else
        _sg_pixelformat_sbr(&_sg.formats[SG_PIXELFORMAT_RG32F]);
    #endif
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SN]);
    #else
        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RGBA16]);
        _sg_pixelformat_sfbr(&_sg.formats[SG_PIXELFORMAT_RGBA16SN]);
    #endif
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);
    _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
        _sg_pixelformat_srm(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);
        _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
    #else
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
    #endif
    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH]);
    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL]);
    #if defined(_SG_TARGET_MACOS)
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC1_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC2_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_SRGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_R]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_RSN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RG]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RGSN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBF]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBUF]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_SRGBA]);
    #else
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_SRGB8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8A1]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGBA8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_SRGB8A8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_R11]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_R11SN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_RG11]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_RG11SN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ASTC_4x4_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ASTC_4x4_SRGBA]);
    #endif

    // compute shader access (see: https://github.com/gpuweb/gpuweb/issues/513)
    // for now let's use the same conservative set on all backends even though
    // some backends are less restrictive
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
}

//-- main Metal backend state and functions ------------------------------------
_SOKOL_PRIVATE void _sg_mtl_setup_backend(const sg_desc* desc) {
    // assume already zero-initialized
    SOKOL_ASSERT(desc);
    SOKOL_ASSERT(desc->environment.metal.device);
    SOKOL_ASSERT(desc->uniform_buffer_size > 0);
    _sg_mtl_init_pool(desc);
    _sg_mtl_clear_state_cache();
    _sg.mtl.valid = true;
    _sg.mtl.ub_size = desc->uniform_buffer_size;
    _sg.mtl.sem = dispatch_semaphore_create(SG_NUM_INFLIGHT_FRAMES);
    _sg.mtl.device = (__bridge id<MTLDevice>) desc->environment.metal.device;
    _sg.mtl.cmd_queue = [_sg.mtl.device newCommandQueue];

    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
        _sg.mtl.uniform_buffers[i] = [_sg.mtl.device
            newBufferWithLength:(NSUInteger)_sg.mtl.ub_size
            options:MTLResourceCPUCacheModeWriteCombined|MTLResourceStorageModeShared
        ];
        #if defined(SOKOL_DEBUG)
            _sg.mtl.uniform_buffers[i].label = [NSString stringWithFormat:@"sg-uniform-buffer.%d", i];
        #endif
    }

    if (desc->mtl_force_managed_storage_mode) {
        _sg.mtl.use_shared_storage_mode = false;
    } else if (@available(macOS 10.15, iOS 13.0, *)) {
        // on Intel Macs, always use managed resources even though the
        // device says it supports unified memory (because of texture restrictions)
        const bool is_apple_gpu = [_sg.mtl.device supportsFamily:MTLGPUFamilyApple1];
        if (!is_apple_gpu) {
            _sg.mtl.use_shared_storage_mode = false;
        } else {
            _sg.mtl.use_shared_storage_mode = true;
        }
    } else {
        #if defined(_SG_TARGET_MACOS)
            _sg.mtl.use_shared_storage_mode = false;
        #else
            _sg.mtl.use_shared_storage_mode = true;
        #endif
    }
    _sg_mtl_init_caps();
}

_SOKOL_PRIVATE void _sg_mtl_discard_backend(void) {
    SOKOL_ASSERT(_sg.mtl.valid);
    // wait for the last frame to finish
    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
        dispatch_semaphore_wait(_sg.mtl.sem, DISPATCH_TIME_FOREVER);
    }
    // semaphore must be "relinquished" before destruction
    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
        dispatch_semaphore_signal(_sg.mtl.sem);
    }
    _sg_mtl_garbage_collect(_sg.frame_index + SG_NUM_INFLIGHT_FRAMES + 2);
    _sg_mtl_destroy_pool();
    _sg.mtl.valid = false;

    _SG_OBJC_RELEASE(_sg.mtl.sem);
    _SG_OBJC_RELEASE(_sg.mtl.device);
    _SG_OBJC_RELEASE(_sg.mtl.cmd_queue);
    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
        _SG_OBJC_RELEASE(_sg.mtl.uniform_buffers[i]);
    }
    // NOTE: MTLCommandBuffer, MTLRenderCommandEncoder and MTLComputeCommandEncoder are auto-released
    _sg.mtl.cmd_buffer = nil;
    _sg.mtl.render_cmd_encoder = nil;
    _sg.mtl.compute_cmd_encoder = nil;
}

_SOKOL_PRIVATE void _sg_mtl_reset_state_cache(void) {
    _sg_mtl_clear_state_cache();
}

_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(buf && desc);
    SOKOL_ASSERT(buf->cmn.size > 0);
    const bool injected = (0 != desc->mtl_buffers[0]);
    MTLResourceOptions mtl_options = _sg_mtl_buffer_resource_options(&buf->cmn.usage);
    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {
        id<MTLBuffer> mtl_buf;
        if (injected) {
            SOKOL_ASSERT(desc->mtl_buffers[slot]);
            mtl_buf = (__bridge id<MTLBuffer>) desc->mtl_buffers[slot];
        } else {
            if (desc->data.ptr) {
                SOKOL_ASSERT(desc->data.size > 0);
                mtl_buf = [_sg.mtl.device newBufferWithBytes:desc->data.ptr length:(NSUInteger)buf->cmn.size options:mtl_options];
            } else {
                mtl_buf = [_sg.mtl.device newBufferWithLength:(NSUInteger)buf->cmn.size options:mtl_options];
            }
            if (nil == mtl_buf) {
                _SG_ERROR(METAL_CREATE_BUFFER_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
        }
        #if defined(SOKOL_DEBUG)
            if (desc->label) {
                mtl_buf.label = [NSString stringWithFormat:@"%s.%d", desc->label, slot];
            }
        #endif
        buf->mtl.buf[slot] = _sg_mtl_add_resource(mtl_buf);
        _SG_OBJC_RELEASE(mtl_buf);
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_mtl_discard_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf);
    for (int slot = 0; slot < buf->cmn.num_slots; slot++) {
        // it's valid to call release resource with '0'
        _sg_mtl_release_resource(_sg.frame_index, buf->mtl.buf[slot]);
    }
}

_SOKOL_PRIVATE void _sg_mtl_copy_image_data(const _sg_image_t* img, __unsafe_unretained id<MTLTexture> mtl_tex, const sg_image_data* data) {
    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6:1;
    const int num_slices = (img->cmn.type == SG_IMAGETYPE_ARRAY) ? img->cmn.num_slices : 1;
    for (int face_index = 0; face_index < num_faces; face_index++) {
        for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++) {
            SOKOL_ASSERT(data->subimage[face_index][mip_index].ptr);
            SOKOL_ASSERT(data->subimage[face_index][mip_index].size > 0);
            const uint8_t* data_ptr = (const uint8_t*)data->subimage[face_index][mip_index].ptr;
            const int mip_width = _sg_miplevel_dim(img->cmn.width, mip_index);
            const int mip_height = _sg_miplevel_dim(img->cmn.height, mip_index);
            int bytes_per_row = _sg_row_pitch(img->cmn.pixel_format, mip_width, 1);
            int bytes_per_slice = _sg_surface_pitch(img->cmn.pixel_format, mip_width, mip_height, 1);
            /* bytesPerImage special case: https://developer.apple.com/documentation/metal/mtltexture/1515679-replaceregion

                "Supply a nonzero value only when you copy data to a MTLTextureType3D type texture"
            */
            MTLRegion region;
            int bytes_per_image;
            if (img->cmn.type == SG_IMAGETYPE_3D) {
                const int mip_depth = _sg_miplevel_dim(img->cmn.num_slices, mip_index);
                region = MTLRegionMake3D(0, 0, 0, (NSUInteger)mip_width, (NSUInteger)mip_height, (NSUInteger)mip_depth);
                bytes_per_image = bytes_per_slice;
                // FIXME: apparently the minimal bytes_per_image size for 3D texture is 4 KByte... somehow need to handle this
            } else {
                region = MTLRegionMake2D(0, 0, (NSUInteger)mip_width, (NSUInteger)mip_height);
                bytes_per_image = 0;
            }

            for (int slice_index = 0; slice_index < num_slices; slice_index++) {
                const int mtl_slice_index = (img->cmn.type == SG_IMAGETYPE_CUBE) ? face_index : slice_index;
                const int slice_offset = slice_index * bytes_per_slice;
                SOKOL_ASSERT((slice_offset + bytes_per_slice) <= (int)data->subimage[face_index][mip_index].size);
                [mtl_tex replaceRegion:region
                    mipmapLevel:(NSUInteger)mip_index
                    slice:(NSUInteger)mtl_slice_index
                    withBytes:data_ptr + slice_offset
                    bytesPerRow:(NSUInteger)bytes_per_row
                    bytesPerImage:(NSUInteger)bytes_per_image];
            }
        }
    }
}

_SOKOL_PRIVATE bool _sg_mtl_init_texdesc(MTLTextureDescriptor* mtl_desc, _sg_image_t* img) {
    mtl_desc.textureType = _sg_mtl_texture_type(img->cmn.type, img->cmn.sample_count > 1);
    mtl_desc.pixelFormat = _sg_mtl_pixel_format(img->cmn.pixel_format);
    if (MTLPixelFormatInvalid == mtl_desc.pixelFormat) {
        _SG_ERROR(METAL_TEXTURE_FORMAT_NOT_SUPPORTED);
        return false;
    }
    mtl_desc.width = (NSUInteger)img->cmn.width;
    mtl_desc.height = (NSUInteger)img->cmn.height;
    if (SG_IMAGETYPE_3D == img->cmn.type) {
        mtl_desc.depth = (NSUInteger)img->cmn.num_slices;
    } else {
        mtl_desc.depth = 1;
    }
    mtl_desc.mipmapLevelCount = (NSUInteger)img->cmn.num_mipmaps;
    if (SG_IMAGETYPE_ARRAY == img->cmn.type) {
        mtl_desc.arrayLength = (NSUInteger)img->cmn.num_slices;
    } else {
        mtl_desc.arrayLength = 1;
    }
    mtl_desc.sampleCount = (NSUInteger)img->cmn.sample_count;

    MTLTextureUsage mtl_tex_usage = MTLTextureUsageShaderRead;
    if (img->cmn.usage.render_attachment) {
        mtl_tex_usage |= MTLTextureUsageRenderTarget;
    } else if (img->cmn.usage.storage_attachment) {
        mtl_tex_usage |= MTLTextureUsageShaderWrite;
    }
    mtl_desc.usage = mtl_tex_usage;

    MTLResourceOptions mtl_res_options = 0;
    if (img->cmn.usage.render_attachment || img->cmn.usage.storage_attachment) {
        mtl_res_options |= MTLResourceStorageModePrivate;
    } else {
        mtl_res_options |= _sg_mtl_resource_options_storage_mode_managed_or_shared();
        if (!img->cmn.usage.immutable) {
            mtl_res_options |= MTLResourceCPUCacheModeWriteCombined;
        }
    }
    mtl_desc.resourceOptions = mtl_res_options;

    return true;
}

_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_image(_sg_image_t* img, const sg_image_desc* desc) {
    SOKOL_ASSERT(img && desc);
    const bool injected = (0 != desc->mtl_textures[0]);

    // first initialize all Metal resource pool slots to 'empty'
    for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
        img->mtl.tex[i] = _sg_mtl_add_resource(nil);
    }

    // initialize a Metal texture descriptor
    MTLTextureDescriptor* mtl_desc = [[MTLTextureDescriptor alloc] init];
    if (!_sg_mtl_init_texdesc(mtl_desc, img)) {
        _SG_OBJC_RELEASE(mtl_desc);
        return SG_RESOURCESTATE_FAILED;
    }
    for (int slot = 0; slot < img->cmn.num_slots; slot++) {
        id<MTLTexture> mtl_tex;
        if (injected) {
            SOKOL_ASSERT(desc->mtl_textures[slot]);
            mtl_tex = (__bridge id<MTLTexture>) desc->mtl_textures[slot];
        } else {
            mtl_tex = [_sg.mtl.device newTextureWithDescriptor:mtl_desc];
            if (nil == mtl_tex) {
                _SG_OBJC_RELEASE(mtl_desc);
                _SG_ERROR(METAL_CREATE_TEXTURE_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
            if (desc->data.subimage[0][0].ptr) {
                _sg_mtl_copy_image_data(img, mtl_tex, &desc->data);
            }
        }
        #if defined(SOKOL_DEBUG)
            if (desc->label) {
                mtl_tex.label = [NSString stringWithFormat:@"%s.%d", desc->label, slot];
            }
        #endif
        img->mtl.tex[slot] = _sg_mtl_add_resource(mtl_tex);
        _SG_OBJC_RELEASE(mtl_tex);
    }
    _SG_OBJC_RELEASE(mtl_desc);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_mtl_discard_image(_sg_image_t* img) {
    SOKOL_ASSERT(img);
    // it's valid to call release resource with a 'null resource'
    for (int slot = 0; slot < img->cmn.num_slots; slot++) {
        _sg_mtl_release_resource(_sg.frame_index, img->mtl.tex[slot]);
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(smp && desc);
    id<MTLSamplerState> mtl_smp;
    const bool injected = (0 != desc->mtl_sampler);
    if (injected) {
        SOKOL_ASSERT(desc->mtl_sampler);
        mtl_smp = (__bridge id<MTLSamplerState>) desc->mtl_sampler;
    } else {
        MTLSamplerDescriptor* mtl_desc = [[MTLSamplerDescriptor alloc] init];
        mtl_desc.sAddressMode = _sg_mtl_address_mode(desc->wrap_u);
        mtl_desc.tAddressMode = _sg_mtl_address_mode(desc->wrap_v);
        mtl_desc.rAddressMode = _sg_mtl_address_mode(desc->wrap_w);
        if (_sg.features.image_clamp_to_border) {
            if (@available(macOS 12.0, iOS 14.0, *)) {
                mtl_desc.borderColor  = _sg_mtl_border_color(desc->border_color);
            }
        }
        mtl_desc.minFilter = _sg_mtl_minmag_filter(desc->min_filter);
        mtl_desc.magFilter = _sg_mtl_minmag_filter(desc->mag_filter);
        mtl_desc.mipFilter = _sg_mtl_mipmap_filter(desc->mipmap_filter);
        mtl_desc.lodMinClamp = desc->min_lod;
        mtl_desc.lodMaxClamp = desc->max_lod;
        // FIXME: lodAverage?
        mtl_desc.maxAnisotropy = desc->max_anisotropy;
        mtl_desc.normalizedCoordinates = YES;
        mtl_desc.compareFunction = _sg_mtl_compare_func(desc->compare);
        #if defined(SOKOL_DEBUG)
            if (desc->label) {
                mtl_desc.label = [NSString stringWithUTF8String:desc->label];
            }
        #endif
        mtl_smp = [_sg.mtl.device newSamplerStateWithDescriptor:mtl_desc];
        _SG_OBJC_RELEASE(mtl_desc);
        if (nil == mtl_smp) {
            _SG_ERROR(METAL_CREATE_SAMPLER_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    }
    smp->mtl.sampler_state = _sg_mtl_add_resource(mtl_smp);
    _SG_OBJC_RELEASE(mtl_smp);
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_mtl_discard_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp);
    // it's valid to call release resource with a 'null resource'
    _sg_mtl_release_resource(_sg.frame_index, smp->mtl.sampler_state);
}

_SOKOL_PRIVATE id<MTLLibrary> _sg_mtl_compile_library(const char* src) {
    NSError* err = NULL;
    id<MTLLibrary> lib = [_sg.mtl.device
        newLibraryWithSource:[NSString stringWithUTF8String:src]
        options:nil
        error:&err
    ];
    if (err) {
        _SG_ERROR(METAL_SHADER_COMPILATION_FAILED);
        _SG_LOGMSG(METAL_SHADER_COMPILATION_OUTPUT, [err.localizedDescription UTF8String]);
    }
    return lib;
}

_SOKOL_PRIVATE id<MTLLibrary> _sg_mtl_library_from_bytecode(const void* ptr, size_t num_bytes) {
    NSError* err = NULL;
    dispatch_data_t lib_data = dispatch_data_create(ptr, num_bytes, NULL, DISPATCH_DATA_DESTRUCTOR_DEFAULT);
    id<MTLLibrary> lib = [_sg.mtl.device newLibraryWithData:lib_data error:&err];
    if (err) {
        _SG_ERROR(METAL_SHADER_CREATION_FAILED);
        _SG_LOGMSG(METAL_SHADER_COMPILATION_OUTPUT, [err.localizedDescription UTF8String]);
    }
    _SG_OBJC_RELEASE(lib_data);
    return lib;
}

_SOKOL_PRIVATE bool _sg_mtl_create_shader_func(const sg_shader_function* func, const char* label, const char* label_ext, _sg_mtl_shader_func_t* res) {
    SOKOL_ASSERT(res->mtl_lib == _SG_MTL_INVALID_SLOT_INDEX);
    SOKOL_ASSERT(res->mtl_func == _SG_MTL_INVALID_SLOT_INDEX);
    id<MTLLibrary> mtl_lib = nil;
    if (func->bytecode.ptr) {
        SOKOL_ASSERT(func->bytecode.size > 0);
        mtl_lib = _sg_mtl_library_from_bytecode(func->bytecode.ptr, func->bytecode.size);
    } else if (func->source) {
        mtl_lib = _sg_mtl_compile_library(func->source);
    }
    if (mtl_lib == nil) {
        return false;
    }
    #if defined(SOKOL_DEBUG)
    if (label) {
        SOKOL_ASSERT(label_ext);
        mtl_lib.label = [NSString stringWithFormat:@"%s.%s", label, label_ext];
    }
    #else
    _SOKOL_UNUSED(label);
    _SOKOL_UNUSED(label_ext);
    #endif
    SOKOL_ASSERT(func->entry);
    id<MTLFunction> mtl_func = [mtl_lib newFunctionWithName:[NSString stringWithUTF8String:func->entry]];
    if (mtl_func == nil) {
        _SG_ERROR(METAL_SHADER_ENTRY_NOT_FOUND);
        _SG_OBJC_RELEASE(mtl_lib);
        return false;
    }
    res->mtl_lib = _sg_mtl_add_resource(mtl_lib);
    res->mtl_func = _sg_mtl_add_resource(mtl_func);
    _SG_OBJC_RELEASE(mtl_lib);
    _SG_OBJC_RELEASE(mtl_func);
    return true;
}

_SOKOL_PRIVATE void _sg_mtl_discard_shader_func(const _sg_mtl_shader_func_t* func) {
    // it is valid to call _sg_mtl_release_resource with a 'null resource'
    _sg_mtl_release_resource(_sg.frame_index, func->mtl_func);
    _sg_mtl_release_resource(_sg.frame_index, func->mtl_lib);
}

// NOTE: this is an out-of-range check for MSL bindslots that's also active in release mode
_SOKOL_PRIVATE bool _sg_mtl_ensure_msl_bindslot_ranges(const sg_shader_desc* desc) {
    SOKOL_ASSERT(desc);
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        if (desc->uniform_blocks[i].msl_buffer_n >= _SG_MTL_MAX_STAGE_UB_BINDINGS) {
            _SG_ERROR(METAL_UNIFORMBLOCK_MSL_BUFFER_SLOT_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (desc->images[i].msl_texture_n >= _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS) {
            _SG_ERROR(METAL_IMAGE_MSL_TEXTURE_SLOT_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (desc->samplers[i].msl_sampler_n >= _SG_MTL_MAX_STAGE_SAMPLER_BINDINGS) {
            _SG_ERROR(METAL_SAMPLER_MSL_SAMPLER_SLOT_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (desc->storage_buffers[i].msl_buffer_n >= _SG_MTL_MAX_STAGE_UB_SBUF_BINDINGS) {
            _SG_ERROR(METAL_STORAGEBUFFER_MSL_BUFFER_SLOT_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (desc->storage_images[i].msl_texture_n >= _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS) {
            _SG_ERROR(METAL_STORAGEIMAGE_MSL_TEXTURE_SLOT_OUT_OF_RANGE);
            return false;
        }
    }
    return true;
}

_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    SOKOL_ASSERT(shd && desc);

    // do a MSL bindslot range check also in release mode, and if that fails,
    // also fail shader creation
    if (!_sg_mtl_ensure_msl_bindslot_ranges(desc)) {
        return SG_RESOURCESTATE_FAILED;
    }

    shd->mtl.threads_per_threadgroup = MTLSizeMake(
        (NSUInteger)desc->mtl_threads_per_threadgroup.x,
        (NSUInteger)desc->mtl_threads_per_threadgroup.y,
        (NSUInteger)desc->mtl_threads_per_threadgroup.z);

    // copy resource bindslot mappings
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        shd->mtl.ub_buffer_n[i] = desc->uniform_blocks[i].msl_buffer_n;
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        shd->mtl.img_texture_n[i] = desc->images[i].msl_texture_n;
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        shd->mtl.smp_sampler_n[i] = desc->samplers[i].msl_sampler_n;
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        shd->mtl.sbuf_buffer_n[i] = desc->storage_buffers[i].msl_buffer_n;
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        shd->mtl.simg_texture_n[i] = desc->storage_images[i].msl_texture_n;
    }

    // create metal library and function objects
    bool shd_valid = true;
    if (desc->vertex_func.source || desc->vertex_func.bytecode.ptr) {
        shd_valid &= _sg_mtl_create_shader_func(&desc->vertex_func, desc->label, "vs", &shd->mtl.vertex_func);
    }
    if (desc->fragment_func.source || desc->fragment_func.bytecode.ptr) {
        shd_valid &= _sg_mtl_create_shader_func(&desc->fragment_func, desc->label, "fs", &shd->mtl.fragment_func);
    }
    if (desc->compute_func.source || desc->compute_func.bytecode.ptr) {
        shd_valid &= _sg_mtl_create_shader_func(&desc->compute_func, desc->label, "cs", &shd->mtl.compute_func);
    }
    if (!shd_valid) {
        _sg_mtl_discard_shader_func(&shd->mtl.vertex_func);
        _sg_mtl_discard_shader_func(&shd->mtl.fragment_func);
        _sg_mtl_discard_shader_func(&shd->mtl.compute_func);
    }
    return shd_valid ? SG_RESOURCESTATE_VALID : SG_RESOURCESTATE_FAILED;
}

_SOKOL_PRIVATE void _sg_mtl_discard_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd);
    _sg_mtl_discard_shader_func(&shd->mtl.vertex_func);
    _sg_mtl_discard_shader_func(&shd->mtl.fragment_func);
    _sg_mtl_discard_shader_func(&shd->mtl.compute_func);
}

_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(pip && shd && desc);
    SOKOL_ASSERT(desc->shader.id == shd->slot.id);

    pip->shader = shd;

    if (pip->cmn.is_compute) {
        NSError* err = NULL;
        MTLComputePipelineDescriptor* cp_desc = [[MTLComputePipelineDescriptor alloc] init];
        cp_desc.computeFunction = _sg_mtl_id(shd->mtl.compute_func.mtl_func);
        cp_desc.threadGroupSizeIsMultipleOfThreadExecutionWidth = true;
        for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
            const sg_shader_stage stage = shd->cmn.storage_buffers[i].stage;
            SOKOL_ASSERT((stage != SG_SHADERSTAGE_VERTEX) && (stage != SG_SHADERSTAGE_FRAGMENT));
            if ((stage == SG_SHADERSTAGE_COMPUTE) && shd->cmn.storage_buffers[i].readonly) {
                const NSUInteger mtl_slot = shd->mtl.sbuf_buffer_n[i];
                cp_desc.buffers[mtl_slot].mutability = MTLMutabilityImmutable;
            }
        }
        #if defined(SOKOL_DEBUG)
            if (desc->label) {
                cp_desc.label = [NSString stringWithFormat:@"%s", desc->label];
            }
        #endif
        id<MTLComputePipelineState> mtl_cps = [_sg.mtl.device
            newComputePipelineStateWithDescriptor:cp_desc
            options:MTLPipelineOptionNone
            reflection:nil
            error:&err];
        _SG_OBJC_RELEASE(cp_desc);
        if (nil == mtl_cps) {
            SOKOL_ASSERT(err);
            _SG_ERROR(METAL_CREATE_CPS_FAILED);
            _SG_LOGMSG(METAL_CREATE_CPS_OUTPUT, [err.localizedDescription UTF8String]);
            return SG_RESOURCESTATE_FAILED;
        }
        pip->mtl.cps = _sg_mtl_add_resource(mtl_cps);
        _SG_OBJC_RELEASE(mtl_cps);
        pip->mtl.threads_per_threadgroup = shd->mtl.threads_per_threadgroup;
    } else {
        sg_primitive_type prim_type = desc->primitive_type;
        pip->mtl.prim_type = _sg_mtl_primitive_type(prim_type);
        pip->mtl.index_size = _sg_mtl_index_size(pip->cmn.index_type);
        if (SG_INDEXTYPE_NONE != pip->cmn.index_type) {
            pip->mtl.index_type = _sg_mtl_index_type(pip->cmn.index_type);
        }
        pip->mtl.cull_mode = _sg_mtl_cull_mode(desc->cull_mode);
        pip->mtl.winding = _sg_mtl_winding(desc->face_winding);
        pip->mtl.stencil_ref = desc->stencil.ref;

        // create vertex-descriptor
        MTLVertexDescriptor* vtx_desc = [MTLVertexDescriptor vertexDescriptor];
        for (NSUInteger attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
            const sg_vertex_attr_state* a_state = &desc->layout.attrs[attr_index];
            if (a_state->format == SG_VERTEXFORMAT_INVALID) {
                break;
            }
            SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
            SOKOL_ASSERT(pip->cmn.vertex_buffer_layout_active[a_state->buffer_index]);
            vtx_desc.attributes[attr_index].format = _sg_mtl_vertex_format(a_state->format);
            vtx_desc.attributes[attr_index].offset = (NSUInteger)a_state->offset;
            vtx_desc.attributes[attr_index].bufferIndex = _sg_mtl_vertexbuffer_bindslot((size_t)a_state->buffer_index);
        }
        for (NSUInteger layout_index = 0; layout_index < SG_MAX_VERTEXBUFFER_BINDSLOTS; layout_index++) {
            if (pip->cmn.vertex_buffer_layout_active[layout_index]) {
                const sg_vertex_buffer_layout_state* l_state = &desc->layout.buffers[layout_index];
                const NSUInteger mtl_vb_slot = _sg_mtl_vertexbuffer_bindslot(layout_index);
                SOKOL_ASSERT(l_state->stride > 0);
                vtx_desc.layouts[mtl_vb_slot].stride = (NSUInteger)l_state->stride;
                vtx_desc.layouts[mtl_vb_slot].stepFunction = _sg_mtl_step_function(l_state->step_func);
                vtx_desc.layouts[mtl_vb_slot].stepRate = (NSUInteger)l_state->step_rate;
                if (SG_VERTEXSTEP_PER_INSTANCE == l_state->step_func) {
                    // NOTE: not actually used in _sg_mtl_draw()
                    pip->cmn.use_instanced_draw = true;
                }
            }
        }

        // render-pipeline descriptor
        MTLRenderPipelineDescriptor* rp_desc = [[MTLRenderPipelineDescriptor alloc] init];
        rp_desc.vertexDescriptor = vtx_desc;
        SOKOL_ASSERT(shd->mtl.vertex_func.mtl_func != _SG_MTL_INVALID_SLOT_INDEX);
        rp_desc.vertexFunction = _sg_mtl_id(shd->mtl.vertex_func.mtl_func);
        SOKOL_ASSERT(shd->mtl.fragment_func.mtl_func != _SG_MTL_INVALID_SLOT_INDEX);
        rp_desc.fragmentFunction = _sg_mtl_id(shd->mtl.fragment_func.mtl_func);
        rp_desc.rasterSampleCount = (NSUInteger)desc->sample_count;
        rp_desc.alphaToCoverageEnabled = desc->alpha_to_coverage_enabled;
        rp_desc.alphaToOneEnabled = NO;
        rp_desc.rasterizationEnabled = YES;
        rp_desc.depthAttachmentPixelFormat = _sg_mtl_pixel_format(desc->depth.pixel_format);
        if (desc->depth.pixel_format == SG_PIXELFORMAT_DEPTH_STENCIL) {
            rp_desc.stencilAttachmentPixelFormat = _sg_mtl_pixel_format(desc->depth.pixel_format);
        }
        for (NSUInteger i = 0; i < (NSUInteger)desc->color_count; i++) {
            SOKOL_ASSERT(i < SG_MAX_COLOR_ATTACHMENTS);
            const sg_color_target_state* cs = &desc->colors[i];
            rp_desc.colorAttachments[i].pixelFormat = _sg_mtl_pixel_format(cs->pixel_format);
            rp_desc.colorAttachments[i].writeMask = _sg_mtl_color_write_mask(cs->write_mask);
            rp_desc.colorAttachments[i].blendingEnabled = cs->blend.enabled;
            rp_desc.colorAttachments[i].alphaBlendOperation = _sg_mtl_blend_op(cs->blend.op_alpha);
            rp_desc.colorAttachments[i].rgbBlendOperation = _sg_mtl_blend_op(cs->blend.op_rgb);
            rp_desc.colorAttachments[i].destinationAlphaBlendFactor = _sg_mtl_blend_factor(cs->blend.dst_factor_alpha);
            rp_desc.colorAttachments[i].destinationRGBBlendFactor = _sg_mtl_blend_factor(cs->blend.dst_factor_rgb);
            rp_desc.colorAttachments[i].sourceAlphaBlendFactor = _sg_mtl_blend_factor(cs->blend.src_factor_alpha);
            rp_desc.colorAttachments[i].sourceRGBBlendFactor = _sg_mtl_blend_factor(cs->blend.src_factor_rgb);
        }
        // set buffer mutability for all read-only buffers (vertex buffers and read-only storage buffers)
        for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
            if (pip->cmn.vertex_buffer_layout_active[i]) {
                const NSUInteger mtl_slot = _sg_mtl_vertexbuffer_bindslot(i);
                rp_desc.vertexBuffers[mtl_slot].mutability = MTLMutabilityImmutable;
            }
        }
        for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
            const NSUInteger mtl_slot = shd->mtl.sbuf_buffer_n[i];
            const sg_shader_stage stage = shd->cmn.storage_buffers[i].stage;
            SOKOL_ASSERT(stage != SG_SHADERSTAGE_COMPUTE);
            if (stage == SG_SHADERSTAGE_VERTEX) {
                SOKOL_ASSERT(shd->cmn.storage_buffers[i].readonly);
                rp_desc.vertexBuffers[mtl_slot].mutability = MTLMutabilityImmutable;
            } else if (stage == SG_SHADERSTAGE_FRAGMENT) {
                SOKOL_ASSERT(shd->cmn.storage_buffers[i].readonly);
                rp_desc.fragmentBuffers[mtl_slot].mutability = MTLMutabilityImmutable;
            }
        }
        #if defined(SOKOL_DEBUG)
            if (desc->label) {
                rp_desc.label = [NSString stringWithFormat:@"%s", desc->label];
            }
        #endif
        NSError* err = NULL;
        id<MTLRenderPipelineState> mtl_rps = [_sg.mtl.device newRenderPipelineStateWithDescriptor:rp_desc error:&err];
        _SG_OBJC_RELEASE(rp_desc);
        if (nil == mtl_rps) {
            SOKOL_ASSERT(err);
            _SG_ERROR(METAL_CREATE_RPS_FAILED);
            _SG_LOGMSG(METAL_CREATE_RPS_OUTPUT, [err.localizedDescription UTF8String]);
            return SG_RESOURCESTATE_FAILED;
        }
        pip->mtl.rps = _sg_mtl_add_resource(mtl_rps);
        _SG_OBJC_RELEASE(mtl_rps);

        // depth-stencil-state
        MTLDepthStencilDescriptor* ds_desc = [[MTLDepthStencilDescriptor alloc] init];
        ds_desc.depthCompareFunction = _sg_mtl_compare_func(desc->depth.compare);
        ds_desc.depthWriteEnabled = desc->depth.write_enabled;
        if (desc->stencil.enabled) {
            const sg_stencil_face_state* sb = &desc->stencil.back;
            ds_desc.backFaceStencil = [[MTLStencilDescriptor alloc] init];
            ds_desc.backFaceStencil.stencilFailureOperation = _sg_mtl_stencil_op(sb->fail_op);
            ds_desc.backFaceStencil.depthFailureOperation = _sg_mtl_stencil_op(sb->depth_fail_op);
            ds_desc.backFaceStencil.depthStencilPassOperation = _sg_mtl_stencil_op(sb->pass_op);
            ds_desc.backFaceStencil.stencilCompareFunction = _sg_mtl_compare_func(sb->compare);
            ds_desc.backFaceStencil.readMask = desc->stencil.read_mask;
            ds_desc.backFaceStencil.writeMask = desc->stencil.write_mask;
            const sg_stencil_face_state* sf = &desc->stencil.front;
            ds_desc.frontFaceStencil = [[MTLStencilDescriptor alloc] init];
            ds_desc.frontFaceStencil.stencilFailureOperation = _sg_mtl_stencil_op(sf->fail_op);
            ds_desc.frontFaceStencil.depthFailureOperation = _sg_mtl_stencil_op(sf->depth_fail_op);
            ds_desc.frontFaceStencil.depthStencilPassOperation = _sg_mtl_stencil_op(sf->pass_op);
            ds_desc.frontFaceStencil.stencilCompareFunction = _sg_mtl_compare_func(sf->compare);
            ds_desc.frontFaceStencil.readMask = desc->stencil.read_mask;
            ds_desc.frontFaceStencil.writeMask = desc->stencil.write_mask;
        }
        #if defined(SOKOL_DEBUG)
            if (desc->label) {
                ds_desc.label = [NSString stringWithFormat:@"%s.dss", desc->label];
            }
        #endif
        id<MTLDepthStencilState> mtl_dss = [_sg.mtl.device newDepthStencilStateWithDescriptor:ds_desc];
        _SG_OBJC_RELEASE(ds_desc);
        if (nil == mtl_dss) {
            _SG_ERROR(METAL_CREATE_DSS_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        pip->mtl.dss = _sg_mtl_add_resource(mtl_dss);
        _SG_OBJC_RELEASE(mtl_dss);
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_mtl_discard_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    // it's valid to call release resource with a 'null resource'
    _sg_mtl_release_resource(_sg.frame_index, pip->mtl.cps);
    _sg_mtl_release_resource(_sg.frame_index, pip->mtl.rps);
    _sg_mtl_release_resource(_sg.frame_index, pip->mtl.dss);
}

_SOKOL_PRIVATE sg_resource_state _sg_mtl_create_attachments(_sg_attachments_t* atts, const _sg_attachments_ptrs_t* atts_ptrs, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(atts && atts_ptrs && desc);

    // copy image pointers
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const sg_attachment_desc* color_desc = &desc->colors[i];
        _SOKOL_UNUSED(color_desc);
        SOKOL_ASSERT(color_desc->image.id != SG_INVALID_ID);
        SOKOL_ASSERT(0 == atts->mtl.colors[i].image);
        SOKOL_ASSERT(atts_ptrs->color_images[i]);
        _sg_image_t* clr_img = atts_ptrs->color_images[i];
        SOKOL_ASSERT(clr_img->slot.id == color_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_color_format(clr_img->cmn.pixel_format));
        atts->mtl.colors[i].image = clr_img;
        const sg_attachment_desc* resolve_desc = &desc->resolves[i];
        if (resolve_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->mtl.resolves[i].image);
            SOKOL_ASSERT(atts_ptrs->resolve_images[i]);
            _sg_image_t* rsv_img = atts_ptrs->resolve_images[i];
            SOKOL_ASSERT(rsv_img->slot.id == resolve_desc->image.id);
            SOKOL_ASSERT(clr_img->cmn.pixel_format == rsv_img->cmn.pixel_format);
            atts->mtl.resolves[i].image = rsv_img;
        }
    }
    SOKOL_ASSERT(0 == atts->mtl.depth_stencil.image);
    const sg_attachment_desc* ds_desc = &desc->depth_stencil;
    if (ds_desc->image.id != SG_INVALID_ID) {
        SOKOL_ASSERT(atts_ptrs->ds_image);
        _sg_image_t* ds_img = atts_ptrs->ds_image;
        SOKOL_ASSERT(ds_img->slot.id == ds_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_depth_format(ds_img->cmn.pixel_format));
        atts->mtl.depth_stencil.image = ds_img;
    }
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const sg_attachment_desc* storage_desc = &desc->storages[i];
        if (storage_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->mtl.storages[i].image);
            SOKOL_ASSERT(atts_ptrs->storage_images[i]);
            _sg_image_t* stg_img = atts_ptrs->storage_images[i];
            SOKOL_ASSERT(stg_img->slot.id == storage_desc->image.id);
            SOKOL_ASSERT(_sg_is_valid_attachment_storage_format(stg_img->cmn.pixel_format));
            atts->mtl.storages[i].image = stg_img;
        }
    }

    // create texture views for storage attachments
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const _sg_image_t* stg_img = atts->mtl.storages[i].image;
        if (stg_img) {
            id<MTLTexture> mtl_tex_view = [_sg_mtl_id(stg_img->mtl.tex[0])
                newTextureViewWithPixelFormat: _sg_mtl_pixel_format(stg_img->cmn.pixel_format)
                textureType: _sg_mtl_texture_type(stg_img->cmn.type, false)
                levels: NSMakeRange((NSUInteger)atts->cmn.storages[i].mip_level, 1)
                slices: NSMakeRange((NSUInteger)atts->cmn.storages[i].slice, 1)];
            atts->mtl.storage_views[i] = _sg_mtl_add_resource(mtl_tex_view);
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_mtl_discard_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    _SOKOL_UNUSED(atts);
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        // it's valid to call _sg_mtl_release_resource with a null handle
        _sg_mtl_release_resource(_sg.frame_index, atts->mtl.storage_views[i]);
    }
}

_SOKOL_PRIVATE _sg_image_t* _sg_mtl_attachments_color_image(const _sg_attachments_t* atts, int index) {
    // NOTE: may return null
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->mtl.colors[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_mtl_attachments_resolve_image(const _sg_attachments_t* atts, int index) {
    // NOTE: may return null
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    return atts->mtl.resolves[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_mtl_attachments_ds_image(const _sg_attachments_t* atts) {
    // NOTE: may return null
    SOKOL_ASSERT(atts);
    return atts->mtl.depth_stencil.image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_mtl_attachments_storage_image(const _sg_attachments_t* atts, int index) {
    // NOTE: may return null
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_STORAGE_ATTACHMENTS));
    return atts->mtl.storages[index].image;
}

_SOKOL_PRIVATE void _sg_mtl_bind_uniform_buffers(void) {
    // In the Metal backend, uniform buffer bindings happen once in sg_begin_pass() and
    // remain valid for the entire pass. Only binding offsets will be updated
    // in sg_apply_uniforms()
    if (_sg.cur_pass.is_compute) {
        SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
        for (size_t slot = 0; slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS; slot++) {
            [_sg.mtl.compute_cmd_encoder
                setBuffer:_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index]
                offset:0
                atIndex:slot];
        }
    } else {
        SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
        for (size_t slot = 0; slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS; slot++) {
            [_sg.mtl.render_cmd_encoder
                setVertexBuffer:_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index]
                offset:0
                atIndex:slot];
            [_sg.mtl.render_cmd_encoder
                setFragmentBuffer:_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index]
                offset:0
                atIndex:slot];
        }
    }
}

_SOKOL_PRIVATE void _sg_mtl_begin_compute_pass(const sg_pass* pass) {
    SOKOL_ASSERT(pass); (void)pass;
    SOKOL_ASSERT(nil != _sg.mtl.cmd_buffer);
    SOKOL_ASSERT(nil == _sg.mtl.compute_cmd_encoder);
    SOKOL_ASSERT(nil == _sg.mtl.render_cmd_encoder);

    _sg.mtl.compute_cmd_encoder = [_sg.mtl.cmd_buffer computeCommandEncoder];
    if (nil == _sg.mtl.compute_cmd_encoder) {
        _sg.cur_pass.valid = false;
        return;
    }

    #if defined(SOKOL_DEBUG)
    if (pass->label) {
        _sg.mtl.compute_cmd_encoder.label = [NSString stringWithUTF8String:pass->label];
    }
    #endif
}

_SOKOL_PRIVATE void _sg_mtl_begin_render_pass(const sg_pass* pass) {
    SOKOL_ASSERT(pass);
    SOKOL_ASSERT(nil != _sg.mtl.cmd_buffer);
    SOKOL_ASSERT(nil == _sg.mtl.render_cmd_encoder);
    SOKOL_ASSERT(nil == _sg.mtl.compute_cmd_encoder);

    const _sg_attachments_t* atts = _sg.cur_pass.atts;
    const sg_swapchain* swapchain = &pass->swapchain;
    const sg_pass_action* action = &pass->action;

    MTLRenderPassDescriptor* pass_desc = [MTLRenderPassDescriptor renderPassDescriptor];
    SOKOL_ASSERT(pass_desc);
    if (atts) {
        // setup pass descriptor for offscreen rendering
        SOKOL_ASSERT(atts->slot.state == SG_RESOURCESTATE_VALID);
        for (NSUInteger i = 0; i < (NSUInteger)atts->cmn.num_colors; i++) {
            const _sg_attachment_common_t* cmn_color_att = &atts->cmn.colors[i];
            const _sg_mtl_attachment_t* mtl_color_att = &atts->mtl.colors[i];
            const _sg_image_t* color_att_img = mtl_color_att->image;
            const _sg_attachment_common_t* cmn_resolve_att = &atts->cmn.resolves[i];
            const _sg_mtl_attachment_t* mtl_resolve_att = &atts->mtl.resolves[i];
            const _sg_image_t* resolve_att_img = mtl_resolve_att->image;
            SOKOL_ASSERT(color_att_img->slot.state == SG_RESOURCESTATE_VALID);
            SOKOL_ASSERT(color_att_img->slot.id == cmn_color_att->image_id.id);
            SOKOL_ASSERT(color_att_img->mtl.tex[color_att_img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
            pass_desc.colorAttachments[i].loadAction = _sg_mtl_load_action(action->colors[i].load_action);
            pass_desc.colorAttachments[i].storeAction = _sg_mtl_store_action(action->colors[i].store_action, resolve_att_img != 0);
            sg_color c = action->colors[i].clear_value;
            pass_desc.colorAttachments[i].clearColor = MTLClearColorMake(c.r, c.g, c.b, c.a);
            pass_desc.colorAttachments[i].texture = _sg_mtl_id(color_att_img->mtl.tex[color_att_img->cmn.active_slot]);
            pass_desc.colorAttachments[i].level = (NSUInteger)cmn_color_att->mip_level;
            switch (color_att_img->cmn.type) {
                case SG_IMAGETYPE_CUBE:
                case SG_IMAGETYPE_ARRAY:
                    pass_desc.colorAttachments[i].slice = (NSUInteger)cmn_color_att->slice;
                    break;
                case SG_IMAGETYPE_3D:
                    pass_desc.colorAttachments[i].depthPlane = (NSUInteger)cmn_color_att->slice;
                    break;
                default: break;
            }
            if (resolve_att_img) {
                SOKOL_ASSERT(resolve_att_img->slot.state == SG_RESOURCESTATE_VALID);
                SOKOL_ASSERT(resolve_att_img->slot.id == cmn_resolve_att->image_id.id);
                SOKOL_ASSERT(resolve_att_img->mtl.tex[resolve_att_img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
                pass_desc.colorAttachments[i].resolveTexture = _sg_mtl_id(resolve_att_img->mtl.tex[resolve_att_img->cmn.active_slot]);
                pass_desc.colorAttachments[i].resolveLevel = (NSUInteger)cmn_resolve_att->mip_level;
                switch (resolve_att_img->cmn.type) {
                    case SG_IMAGETYPE_CUBE:
                    case SG_IMAGETYPE_ARRAY:
                        pass_desc.colorAttachments[i].resolveSlice = (NSUInteger)cmn_resolve_att->slice;
                        break;
                    case SG_IMAGETYPE_3D:
                        pass_desc.colorAttachments[i].resolveDepthPlane = (NSUInteger)cmn_resolve_att->slice;
                        break;
                    default: break;
                }
            }
        }
        const _sg_image_t* ds_att_img = atts->mtl.depth_stencil.image;
        if (0 != ds_att_img) {
            SOKOL_ASSERT(ds_att_img->slot.state == SG_RESOURCESTATE_VALID);
            SOKOL_ASSERT(ds_att_img->slot.id == atts->cmn.depth_stencil.image_id.id);
            SOKOL_ASSERT(ds_att_img->mtl.tex[ds_att_img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
            pass_desc.depthAttachment.texture = _sg_mtl_id(ds_att_img->mtl.tex[ds_att_img->cmn.active_slot]);
            pass_desc.depthAttachment.loadAction = _sg_mtl_load_action(action->depth.load_action);
            pass_desc.depthAttachment.storeAction = _sg_mtl_store_action(action->depth.store_action, false);
            pass_desc.depthAttachment.clearDepth = action->depth.clear_value;
            const _sg_attachment_common_t* cmn_ds_att = &atts->cmn.depth_stencil;
            switch (ds_att_img->cmn.type) {
                case SG_IMAGETYPE_CUBE:
                case SG_IMAGETYPE_ARRAY:
                    pass_desc.depthAttachment.slice = (NSUInteger)cmn_ds_att->slice;
                    break;
                case SG_IMAGETYPE_3D:
                    pass_desc.depthAttachment.resolveDepthPlane = (NSUInteger)cmn_ds_att->slice;
                    break;
                default: break;
            }
            if (_sg_is_depth_stencil_format(ds_att_img->cmn.pixel_format)) {
                pass_desc.stencilAttachment.texture = _sg_mtl_id(ds_att_img->mtl.tex[ds_att_img->cmn.active_slot]);
                pass_desc.stencilAttachment.loadAction = _sg_mtl_load_action(action->stencil.load_action);
                pass_desc.stencilAttachment.storeAction = _sg_mtl_store_action(action->depth.store_action, false);
                pass_desc.stencilAttachment.clearStencil = action->stencil.clear_value;
                switch (ds_att_img->cmn.type) {
                    case SG_IMAGETYPE_CUBE:
                    case SG_IMAGETYPE_ARRAY:
                        pass_desc.stencilAttachment.slice = (NSUInteger)cmn_ds_att->slice;
                        break;
                    case SG_IMAGETYPE_3D:
                        pass_desc.stencilAttachment.resolveDepthPlane = (NSUInteger)cmn_ds_att->slice;
                        break;
                    default: break;
                }
            }
        }
    } else {
        // setup pass descriptor for swapchain rendering
        //
        // NOTE: at least in macOS Sonoma this no longer seems to be the case, the
        // current drawable is also valid in a minimized window
        // ===
        // an MTKView current_drawable will not be valid if window is minimized, don't do any rendering in this case
        if (0 == swapchain->metal.current_drawable) {
            _sg.cur_pass.valid = false;
            return;
        }
        // pin the swapchain resources into memory so that they outlive their command buffer
        // (this is necessary because the command buffer doesn't retain references)
        int pass_desc_ref = _sg_mtl_add_resource(pass_desc);
        _sg_mtl_release_resource(_sg.frame_index, pass_desc_ref);

        _sg.mtl.cur_drawable = (__bridge id<CAMetalDrawable>) swapchain->metal.current_drawable;
        if (swapchain->sample_count > 1) {
            // multi-sampling: render into msaa texture, resolve into drawable texture
            id<MTLTexture> msaa_tex = (__bridge id<MTLTexture>) swapchain->metal.msaa_color_texture;
            SOKOL_ASSERT(msaa_tex != nil);
            pass_desc.colorAttachments[0].texture = msaa_tex;
            pass_desc.colorAttachments[0].resolveTexture = _sg.mtl.cur_drawable.texture;
            pass_desc.colorAttachments[0].storeAction = MTLStoreActionMultisampleResolve;
        } else {
            // non-msaa: render into current_drawable
            pass_desc.colorAttachments[0].texture = _sg.mtl.cur_drawable.texture;
            pass_desc.colorAttachments[0].storeAction = MTLStoreActionStore;
        }
        pass_desc.colorAttachments[0].loadAction = _sg_mtl_load_action(action->colors[0].load_action);
        const sg_color c = action->colors[0].clear_value;
        pass_desc.colorAttachments[0].clearColor = MTLClearColorMake(c.r, c.g, c.b, c.a);

        // optional depth-stencil texture
        if (swapchain->metal.depth_stencil_texture) {
            id<MTLTexture> ds_tex = (__bridge id<MTLTexture>) swapchain->metal.depth_stencil_texture;
            SOKOL_ASSERT(ds_tex != nil);
            pass_desc.depthAttachment.texture = ds_tex;
            pass_desc.depthAttachment.storeAction = MTLStoreActionDontCare;
            pass_desc.depthAttachment.loadAction = _sg_mtl_load_action(action->depth.load_action);
            pass_desc.depthAttachment.clearDepth = action->depth.clear_value;
            if (_sg_is_depth_stencil_format(swapchain->depth_format)) {
                pass_desc.stencilAttachment.texture = ds_tex;
                pass_desc.stencilAttachment.storeAction = MTLStoreActionDontCare;
                pass_desc.stencilAttachment.loadAction = _sg_mtl_load_action(action->stencil.load_action);
                pass_desc.stencilAttachment.clearStencil = action->stencil.clear_value;
            }
        }
    }

    // NOTE: at least in macOS Sonoma, the following is no longer the case, a valid
    // render command encoder is also returned in a minimized window
    // ===
    // create a render command encoder, this might return nil if window is minimized
    _sg.mtl.render_cmd_encoder = [_sg.mtl.cmd_buffer renderCommandEncoderWithDescriptor:pass_desc];
    if (nil == _sg.mtl.render_cmd_encoder) {
        _sg.cur_pass.valid = false;
        return;
    }

    #if defined(SOKOL_DEBUG)
    if (pass->label) {
        _sg.mtl.render_cmd_encoder.label = [NSString stringWithUTF8String:pass->label];
    }
    #endif
}

_SOKOL_PRIVATE void _sg_mtl_begin_pass(const sg_pass* pass) {
    SOKOL_ASSERT(pass);
    SOKOL_ASSERT(_sg.mtl.cmd_queue);
    SOKOL_ASSERT(nil == _sg.mtl.compute_cmd_encoder);
    SOKOL_ASSERT(nil == _sg.mtl.render_cmd_encoder);
    SOKOL_ASSERT(nil == _sg.mtl.cur_drawable);
    _sg_mtl_clear_state_cache();

    // if this is the first pass in the frame, create one command buffer and blit-cmd-encoder for the entire frame
    if (nil == _sg.mtl.cmd_buffer) {
        // block until the oldest frame in flight has finished
        dispatch_semaphore_wait(_sg.mtl.sem, DISPATCH_TIME_FOREVER);
        if (_sg.desc.mtl_use_command_buffer_with_retained_references) {
            _sg.mtl.cmd_buffer = [_sg.mtl.cmd_queue commandBuffer];
        } else {
            _sg.mtl.cmd_buffer = [_sg.mtl.cmd_queue commandBufferWithUnretainedReferences];
        }
        [_sg.mtl.cmd_buffer enqueue];
        [_sg.mtl.cmd_buffer addCompletedHandler:^(id<MTLCommandBuffer> cmd_buf) {
            // NOTE: this code is called on a different thread!
            _SOKOL_UNUSED(cmd_buf);
            dispatch_semaphore_signal(_sg.mtl.sem);
        }];
    }

    // if this is first pass in frame, get uniform buffer base pointer
    if (0 == _sg.mtl.cur_ub_base_ptr) {
        _sg.mtl.cur_ub_base_ptr = (uint8_t*)[_sg.mtl.uniform_buffers[_sg.mtl.cur_frame_rotate_index] contents];
    }

    if (pass->compute) {
        _sg_mtl_begin_compute_pass(pass);
    } else {
        _sg_mtl_begin_render_pass(pass);
    }

    // bind uniform buffers, those bindings remain valid for the entire pass
    if (_sg.cur_pass.valid) {
        _sg_mtl_bind_uniform_buffers();
    }
}

_SOKOL_PRIVATE void _sg_mtl_end_pass(void) {
    if (nil != _sg.mtl.render_cmd_encoder) {
        [_sg.mtl.render_cmd_encoder endEncoding];
        // NOTE: MTLRenderCommandEncoder is autoreleased
        _sg.mtl.render_cmd_encoder = nil;
    }
    if (nil != _sg.mtl.compute_cmd_encoder) {
        [_sg.mtl.compute_cmd_encoder endEncoding];
        // NOTE: MTLComputeCommandEncoder is autoreleased
        _sg.mtl.compute_cmd_encoder = nil;

        // synchronize any managed resources written by the GPU
        // NOTE: storage attachment images are currently not managed and are not eligible for syncing
        #if defined(_SG_TARGET_MACOS)
        if (_sg_mtl_resource_options_storage_mode_managed_or_shared() == MTLResourceStorageModeManaged) {
            const bool needs_sync = _sg.compute.readwrite_sbufs.cur > 0;
            if (needs_sync) {
                id<MTLBlitCommandEncoder> blit_cmd_encoder = [_sg.mtl.cmd_buffer blitCommandEncoder];
                for (uint32_t i = 0; i < _sg.compute.readwrite_sbufs.cur; i++) {
                    _sg_buffer_t* sbuf = _sg_lookup_buffer(&_sg.pools, _sg.compute.readwrite_sbufs.items[i]);
                    if (sbuf) {
                        [blit_cmd_encoder synchronizeResource:_sg_mtl_id(sbuf->mtl.buf[sbuf->cmn.active_slot])];
                    }
                }
                [blit_cmd_encoder endEncoding];
            }
        }
        #endif
    }
    // if this is a swapchain pass, present the drawable
    if (nil != _sg.mtl.cur_drawable) {
        [_sg.mtl.cmd_buffer presentDrawable:_sg.mtl.cur_drawable];
        _sg.mtl.cur_drawable = nil;
    }
}

_SOKOL_PRIVATE void _sg_mtl_commit(void) {
    SOKOL_ASSERT(nil == _sg.mtl.render_cmd_encoder);
    SOKOL_ASSERT(nil == _sg.mtl.compute_cmd_encoder);
    SOKOL_ASSERT(nil != _sg.mtl.cmd_buffer);

    // commit the frame's command buffer
    [_sg.mtl.cmd_buffer commit];

    // garbage-collect resources pending for release
    _sg_mtl_garbage_collect(_sg.frame_index);

    // rotate uniform buffer slot
    if (++_sg.mtl.cur_frame_rotate_index >= SG_NUM_INFLIGHT_FRAMES) {
        _sg.mtl.cur_frame_rotate_index = 0;
    }
    _sg.mtl.cur_ub_offset = 0;
    _sg.mtl.cur_ub_base_ptr = 0;
    // NOTE: MTLCommandBuffer is autoreleased
    _sg.mtl.cmd_buffer = nil;
}

_SOKOL_PRIVATE void _sg_mtl_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {
    SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
    SOKOL_ASSERT(_sg.cur_pass.height > 0);
    MTLViewport vp;
    vp.originX = (double) x;
    vp.originY = (double) (origin_top_left ? y : (_sg.cur_pass.height - (y + h)));
    vp.width   = (double) w;
    vp.height  = (double) h;
    vp.znear   = 0.0;
    vp.zfar    = 1.0;
    [_sg.mtl.render_cmd_encoder setViewport:vp];
}

_SOKOL_PRIVATE void _sg_mtl_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {
    SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
    SOKOL_ASSERT(_sg.cur_pass.width > 0);
    SOKOL_ASSERT(_sg.cur_pass.height > 0);
    // clip against framebuffer rect
    const _sg_recti_t clip = _sg_clipi(x, y, w, h, _sg.cur_pass.width, _sg.cur_pass.height);
    MTLScissorRect r;
    r.x = (NSUInteger)clip.x;
    r.y = (NSUInteger) (origin_top_left ? clip.y : (_sg.cur_pass.height - (clip.y + clip.h)));
    r.width = (NSUInteger)clip.w;
    r.height = (NSUInteger)clip.h;
    [_sg.mtl.render_cmd_encoder setScissorRect:r];
}

_SOKOL_PRIVATE void _sg_mtl_apply_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));
    if (_sg.mtl.state_cache.cur_pipeline_id.id != pip->slot.id) {
        _sg.mtl.state_cache.cur_pipeline = pip;
        _sg.mtl.state_cache.cur_pipeline_id.id = pip->slot.id;
        if (pip->cmn.is_compute) {
            SOKOL_ASSERT(_sg.cur_pass.is_compute);
            SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
            SOKOL_ASSERT(pip->mtl.cps != _SG_MTL_INVALID_SLOT_INDEX);
            [_sg.mtl.compute_cmd_encoder setComputePipelineState:_sg_mtl_id(pip->mtl.cps)];
            // apply storage image bindings for writing
            if (_sg.cur_pass.atts) {
                const _sg_shader_t* shd = pip->shader;
                const _sg_attachments_t* atts = _sg.cur_pass.atts;
                for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
                    const sg_shader_stage stage = shd->cmn.storage_images[i].stage;
                    if (stage != SG_SHADERSTAGE_COMPUTE) {
                        continue;
                    }
                    const NSUInteger mtl_slot = shd->mtl.simg_texture_n[i];
                    SOKOL_ASSERT(mtl_slot < _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS);
                    const uint64_t cache_key = ((uint64_t)atts->cmn.storages[i].image_id.id) << 32;
                    SOKOL_ASSERT(cache_key != 0);
                    if (_sg.mtl.state_cache.cur_cs_image_ids[mtl_slot] != cache_key) {
                        _sg.mtl.state_cache.cur_cs_image_ids[mtl_slot] = cache_key;
                        [_sg.mtl.compute_cmd_encoder setTexture:_sg_mtl_id(atts->mtl.storage_views[i]) atIndex:mtl_slot];
                        _sg_stats_add(metal.bindings.num_set_compute_texture, 1);
                    }
                }
            }
        } else {
            SOKOL_ASSERT(!_sg.cur_pass.is_compute);
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            sg_color c = pip->cmn.blend_color;
            [_sg.mtl.render_cmd_encoder setBlendColorRed:c.r green:c.g blue:c.b alpha:c.a];
            _sg_stats_add(metal.pipeline.num_set_blend_color, 1);
            [_sg.mtl.render_cmd_encoder setCullMode:pip->mtl.cull_mode];
            _sg_stats_add(metal.pipeline.num_set_cull_mode, 1);
            [_sg.mtl.render_cmd_encoder setFrontFacingWinding:pip->mtl.winding];
            _sg_stats_add(metal.pipeline.num_set_front_facing_winding, 1);
            [_sg.mtl.render_cmd_encoder setStencilReferenceValue:pip->mtl.stencil_ref];
            _sg_stats_add(metal.pipeline.num_set_stencil_reference_value, 1);
            [_sg.mtl.render_cmd_encoder setDepthBias:pip->cmn.depth.bias slopeScale:pip->cmn.depth.bias_slope_scale clamp:pip->cmn.depth.bias_clamp];
            _sg_stats_add(metal.pipeline.num_set_depth_bias, 1);
            SOKOL_ASSERT(pip->mtl.rps != _SG_MTL_INVALID_SLOT_INDEX);
            [_sg.mtl.render_cmd_encoder setRenderPipelineState:_sg_mtl_id(pip->mtl.rps)];
            _sg_stats_add(metal.pipeline.num_set_render_pipeline_state, 1);
            SOKOL_ASSERT(pip->mtl.dss != _SG_MTL_INVALID_SLOT_INDEX);
            [_sg.mtl.render_cmd_encoder setDepthStencilState:_sg_mtl_id(pip->mtl.dss)];
            _sg_stats_add(metal.pipeline.num_set_depth_stencil_state, 1);
        }
    }
}

_SOKOL_PRIVATE bool _sg_mtl_apply_bindings(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(bnd);
    SOKOL_ASSERT(bnd->pip);
    SOKOL_ASSERT(bnd->pip && bnd->pip->shader);
    SOKOL_ASSERT(bnd->pip->shader->slot.id == bnd->pip->cmn.shader_id.id);
    const _sg_shader_t* shd = bnd->pip->shader;

    // don't set vertex- and index-buffers in compute passes
    if (!_sg.cur_pass.is_compute) {
        SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
        // store index buffer binding, this will be needed later in sg_draw()
        _sg.mtl.state_cache.cur_indexbuffer = bnd->ib;
        _sg.mtl.state_cache.cur_indexbuffer_offset = bnd->ib_offset;
        if (bnd->ib) {
            SOKOL_ASSERT(bnd->pip->cmn.index_type != SG_INDEXTYPE_NONE);
            _sg.mtl.state_cache.cur_indexbuffer_id.id = bnd->ib->slot.id;
        } else {
            SOKOL_ASSERT(bnd->pip->cmn.index_type == SG_INDEXTYPE_NONE);
            _sg.mtl.state_cache.cur_indexbuffer_id.id = SG_INVALID_ID;
        }
        // apply vertex buffers
        for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
            const _sg_buffer_t* vb = bnd->vbs[i];
            if (vb == 0) {
                continue;
            }
            const NSUInteger mtl_slot = _sg_mtl_vertexbuffer_bindslot(i);
            SOKOL_ASSERT(mtl_slot < _SG_MTL_MAX_STAGE_BUFFER_BINDINGS);
            const int vb_offset = bnd->vb_offsets[i];
            if ((_sg.mtl.state_cache.cur_vs_buffer_ids[mtl_slot] != vb->slot.id) ||
                (_sg.mtl.state_cache.cur_vs_buffer_offsets[mtl_slot] != vb_offset))
            {
                _sg.mtl.state_cache.cur_vs_buffer_offsets[mtl_slot] = vb_offset;
                if (_sg.mtl.state_cache.cur_vs_buffer_ids[mtl_slot] != vb->slot.id) {
                    // vertex buffer has changed
                    _sg.mtl.state_cache.cur_vs_buffer_ids[mtl_slot] = vb->slot.id;
                    SOKOL_ASSERT(vb->mtl.buf[vb->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
                    [_sg.mtl.render_cmd_encoder setVertexBuffer:_sg_mtl_id(vb->mtl.buf[vb->cmn.active_slot])
                        offset:(NSUInteger)vb_offset
                        atIndex:mtl_slot];
                } else {
                    // only vertex buffer offset has changed
                    [_sg.mtl.render_cmd_encoder setVertexBufferOffset:(NSUInteger)vb_offset atIndex:mtl_slot];
                }
                _sg_stats_add(metal.bindings.num_set_vertex_buffer, 1);
            }
        }
    }

    // apply image bindings
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        const _sg_image_t* img = bnd->imgs[i];
        if (img == 0) {
            continue;
        }
        SOKOL_ASSERT(img->mtl.tex[img->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
        const sg_shader_stage stage = shd->cmn.images[i].stage;
        SOKOL_ASSERT((stage == SG_SHADERSTAGE_VERTEX) || (stage == SG_SHADERSTAGE_FRAGMENT) || (stage == SG_SHADERSTAGE_COMPUTE));
        const NSUInteger mtl_slot = shd->mtl.img_texture_n[i];
        SOKOL_ASSERT(mtl_slot < _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS);
        if (stage == SG_SHADERSTAGE_VERTEX) {
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            if (_sg.mtl.state_cache.cur_vs_image_ids[mtl_slot] != img->slot.id) {
                _sg.mtl.state_cache.cur_vs_image_ids[mtl_slot] = img->slot.id;
                [_sg.mtl.render_cmd_encoder setVertexTexture:_sg_mtl_id(img->mtl.tex[img->cmn.active_slot]) atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_vertex_texture, 1);
            }
        } else if (stage == SG_SHADERSTAGE_FRAGMENT) {
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            if (_sg.mtl.state_cache.cur_fs_image_ids[mtl_slot] != img->slot.id) {
                _sg.mtl.state_cache.cur_fs_image_ids[mtl_slot] = img->slot.id;
                [_sg.mtl.render_cmd_encoder setFragmentTexture:_sg_mtl_id(img->mtl.tex[img->cmn.active_slot]) atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_fragment_texture, 1);
            }
        } else if (stage == SG_SHADERSTAGE_COMPUTE) {
            SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
            if (_sg.mtl.state_cache.cur_cs_image_ids[mtl_slot] != img->slot.id) {
                _sg.mtl.state_cache.cur_cs_image_ids[mtl_slot] = img->slot.id;
                [_sg.mtl.compute_cmd_encoder setTexture:_sg_mtl_id(img->mtl.tex[img->cmn.active_slot]) atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_compute_texture, 1);
            }
        }
    }

    // apply sampler bindings
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        const _sg_sampler_t* smp = bnd->smps[i];
        if (smp == 0) {
            continue;
        }
        SOKOL_ASSERT(smp->mtl.sampler_state != _SG_MTL_INVALID_SLOT_INDEX);
        const sg_shader_stage stage = shd->cmn.samplers[i].stage;
        SOKOL_ASSERT((stage == SG_SHADERSTAGE_VERTEX) || (stage == SG_SHADERSTAGE_FRAGMENT) || (stage == SG_SHADERSTAGE_COMPUTE));
        const NSUInteger mtl_slot = shd->mtl.smp_sampler_n[i];
        SOKOL_ASSERT(mtl_slot < _SG_MTL_MAX_STAGE_SAMPLER_BINDINGS);
        if (stage == SG_SHADERSTAGE_VERTEX) {
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            if (_sg.mtl.state_cache.cur_vs_sampler_ids[mtl_slot] != smp->slot.id) {
                _sg.mtl.state_cache.cur_vs_sampler_ids[mtl_slot] = smp->slot.id;
                [_sg.mtl.render_cmd_encoder setVertexSamplerState:_sg_mtl_id(smp->mtl.sampler_state) atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_vertex_sampler_state, 1);
            }
        } else if (stage == SG_SHADERSTAGE_FRAGMENT) {
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            if (_sg.mtl.state_cache.cur_fs_sampler_ids[mtl_slot] != smp->slot.id) {
                _sg.mtl.state_cache.cur_fs_sampler_ids[mtl_slot] = smp->slot.id;
                [_sg.mtl.render_cmd_encoder setFragmentSamplerState:_sg_mtl_id(smp->mtl.sampler_state) atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_fragment_sampler_state, 1);
            }
        } else if (stage == SG_SHADERSTAGE_COMPUTE) {
            SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
            if (_sg.mtl.state_cache.cur_cs_sampler_ids[mtl_slot] != smp->slot.id) {
                _sg.mtl.state_cache.cur_cs_sampler_ids[mtl_slot] = smp->slot.id;
                [_sg.mtl.compute_cmd_encoder setSamplerState:_sg_mtl_id(smp->mtl.sampler_state) atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_compute_sampler_state, 1);
            }
        }
    }

    // apply storage buffer bindings
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        const _sg_buffer_t* sbuf = bnd->sbufs[i];
        if (sbuf == 0) {
            continue;
        }
        SOKOL_ASSERT(sbuf->mtl.buf[sbuf->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
        const sg_shader_stage stage = shd->cmn.storage_buffers[i].stage;
        SOKOL_ASSERT((stage == SG_SHADERSTAGE_VERTEX) || (stage == SG_SHADERSTAGE_FRAGMENT) || (stage == SG_SHADERSTAGE_COMPUTE));
        const NSUInteger mtl_slot = shd->mtl.sbuf_buffer_n[i];
        SOKOL_ASSERT(mtl_slot < _SG_MTL_MAX_STAGE_UB_SBUF_BINDINGS);
        if (stage == SG_SHADERSTAGE_VERTEX) {
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            if (_sg.mtl.state_cache.cur_vs_buffer_ids[mtl_slot] != sbuf->slot.id) {
                _sg.mtl.state_cache.cur_vs_buffer_ids[mtl_slot] = sbuf->slot.id;
                [_sg.mtl.render_cmd_encoder setVertexBuffer:_sg_mtl_id(sbuf->mtl.buf[sbuf->cmn.active_slot]) offset:0 atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_vertex_buffer, 1);
            }
        } else if (stage == SG_SHADERSTAGE_FRAGMENT) {
            SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
            if (_sg.mtl.state_cache.cur_fs_buffer_ids[mtl_slot] != sbuf->slot.id) {
                _sg.mtl.state_cache.cur_fs_buffer_ids[mtl_slot] = sbuf->slot.id;
                [_sg.mtl.render_cmd_encoder setFragmentBuffer:_sg_mtl_id(sbuf->mtl.buf[sbuf->cmn.active_slot]) offset:0 atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_fragment_buffer, 1);
            }
        } else if (stage == SG_SHADERSTAGE_COMPUTE) {
            SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
            if (_sg.mtl.state_cache.cur_cs_buffer_ids[mtl_slot] != sbuf->slot.id) {
                _sg.mtl.state_cache.cur_cs_buffer_ids[mtl_slot] = sbuf->slot.id;
                [_sg.mtl.compute_cmd_encoder setBuffer:_sg_mtl_id(sbuf->mtl.buf[sbuf->cmn.active_slot]) offset:0 atIndex:mtl_slot];
                _sg_stats_add(metal.bindings.num_set_compute_buffer, 1);
            }
        }
    }
    return true;
}

_SOKOL_PRIVATE void _sg_mtl_apply_uniforms(int ub_slot, const sg_range* data) {
    SOKOL_ASSERT((ub_slot >= 0) && (ub_slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS));
    SOKOL_ASSERT(((size_t)_sg.mtl.cur_ub_offset + data->size) <= (size_t)_sg.mtl.ub_size);
    SOKOL_ASSERT((_sg.mtl.cur_ub_offset & (_SG_MTL_UB_ALIGN-1)) == 0);
    const _sg_pipeline_t* pip = _sg.mtl.state_cache.cur_pipeline;
    SOKOL_ASSERT(pip && pip->shader);
    SOKOL_ASSERT(pip->slot.id == _sg.mtl.state_cache.cur_pipeline_id.id);
    const _sg_shader_t* shd = pip->shader;
    SOKOL_ASSERT(shd->slot.id == pip->cmn.shader_id.id);
    SOKOL_ASSERT(data->size == shd->cmn.uniform_blocks[ub_slot].size);

    const sg_shader_stage stage = shd->cmn.uniform_blocks[ub_slot].stage;
    const NSUInteger mtl_slot = shd->mtl.ub_buffer_n[ub_slot];

    // copy to global uniform buffer, record offset into cmd encoder, and advance offset
    uint8_t* dst = &_sg.mtl.cur_ub_base_ptr[_sg.mtl.cur_ub_offset];
    memcpy(dst, data->ptr, data->size);
    if (stage == SG_SHADERSTAGE_VERTEX) {
        SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
        [_sg.mtl.render_cmd_encoder setVertexBufferOffset:(NSUInteger)_sg.mtl.cur_ub_offset atIndex:mtl_slot];
        _sg_stats_add(metal.uniforms.num_set_vertex_buffer_offset, 1);
    } else if (stage == SG_SHADERSTAGE_FRAGMENT) {
        SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
        [_sg.mtl.render_cmd_encoder setFragmentBufferOffset:(NSUInteger)_sg.mtl.cur_ub_offset atIndex:mtl_slot];
        _sg_stats_add(metal.uniforms.num_set_fragment_buffer_offset, 1);
    } else if (stage == SG_SHADERSTAGE_COMPUTE) {
        SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
        [_sg.mtl.compute_cmd_encoder setBufferOffset:(NSUInteger)_sg.mtl.cur_ub_offset atIndex:mtl_slot];
        _sg_stats_add(metal.uniforms.num_set_compute_buffer_offset, 1);
    } else {
        SOKOL_UNREACHABLE;
    }
    _sg.mtl.cur_ub_offset = _sg_roundup(_sg.mtl.cur_ub_offset + (int)data->size, _SG_MTL_UB_ALIGN);
}

_SOKOL_PRIVATE void _sg_mtl_draw(int base_element, int num_elements, int num_instances) {
    SOKOL_ASSERT(nil != _sg.mtl.render_cmd_encoder);
    SOKOL_ASSERT(_sg.mtl.state_cache.cur_pipeline && (_sg.mtl.state_cache.cur_pipeline->slot.id == _sg.mtl.state_cache.cur_pipeline_id.id));
    if (SG_INDEXTYPE_NONE != _sg.mtl.state_cache.cur_pipeline->cmn.index_type) {
        // indexed rendering
        SOKOL_ASSERT(_sg.mtl.state_cache.cur_indexbuffer && (_sg.mtl.state_cache.cur_indexbuffer->slot.id == _sg.mtl.state_cache.cur_indexbuffer_id.id));
        const _sg_buffer_t* ib = _sg.mtl.state_cache.cur_indexbuffer;
        SOKOL_ASSERT(ib->mtl.buf[ib->cmn.active_slot] != _SG_MTL_INVALID_SLOT_INDEX);
        const NSUInteger index_buffer_offset = (NSUInteger) (_sg.mtl.state_cache.cur_indexbuffer_offset + base_element * _sg.mtl.state_cache.cur_pipeline->mtl.index_size);
        [_sg.mtl.render_cmd_encoder drawIndexedPrimitives:_sg.mtl.state_cache.cur_pipeline->mtl.prim_type
            indexCount:(NSUInteger)num_elements
            indexType:_sg.mtl.state_cache.cur_pipeline->mtl.index_type
            indexBuffer:_sg_mtl_id(ib->mtl.buf[ib->cmn.active_slot])
            indexBufferOffset:index_buffer_offset
            instanceCount:(NSUInteger)num_instances];
    } else {
        // non-indexed rendering
        [_sg.mtl.render_cmd_encoder drawPrimitives:_sg.mtl.state_cache.cur_pipeline->mtl.prim_type
            vertexStart:(NSUInteger)base_element
            vertexCount:(NSUInteger)num_elements
            instanceCount:(NSUInteger)num_instances];
    }
}

_SOKOL_PRIVATE void _sg_mtl_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    SOKOL_ASSERT(nil != _sg.mtl.compute_cmd_encoder);
    SOKOL_ASSERT(_sg.mtl.state_cache.cur_pipeline && (_sg.mtl.state_cache.cur_pipeline->slot.id == _sg.mtl.state_cache.cur_pipeline_id.id));
    const _sg_pipeline_t* cur_pip = _sg.mtl.state_cache.cur_pipeline;
    const MTLSize thread_groups = MTLSizeMake(
        (NSUInteger)num_groups_x,
        (NSUInteger)num_groups_y,
        (NSUInteger)num_groups_z);
    const MTLSize threads_per_threadgroup = cur_pip->mtl.threads_per_threadgroup;
    [_sg.mtl.compute_cmd_encoder dispatchThreadgroups:thread_groups threadsPerThreadgroup:threads_per_threadgroup];
}

_SOKOL_PRIVATE void _sg_mtl_update_buffer(_sg_buffer_t* buf, const sg_range* data) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    if (++buf->cmn.active_slot >= buf->cmn.num_slots) {
        buf->cmn.active_slot = 0;
    }
    __unsafe_unretained id<MTLBuffer> mtl_buf = _sg_mtl_id(buf->mtl.buf[buf->cmn.active_slot]);
    void* dst_ptr = [mtl_buf contents];
    memcpy(dst_ptr, data->ptr, data->size);
    #if defined(_SG_TARGET_MACOS)
    if (_sg_mtl_resource_options_storage_mode_managed_or_shared() == MTLResourceStorageModeManaged) {
        [mtl_buf didModifyRange:NSMakeRange(0, data->size)];
    }
    #endif
}

_SOKOL_PRIVATE void _sg_mtl_append_buffer(_sg_buffer_t* buf, const sg_range* data, bool new_frame) {
    SOKOL_ASSERT(buf && data && data->ptr && (data->size > 0));
    if (new_frame) {
        if (++buf->cmn.active_slot >= buf->cmn.num_slots) {
            buf->cmn.active_slot = 0;
        }
    }
    __unsafe_unretained id<MTLBuffer> mtl_buf = _sg_mtl_id(buf->mtl.buf[buf->cmn.active_slot]);
    uint8_t* dst_ptr = (uint8_t*) [mtl_buf contents];
    dst_ptr += buf->cmn.append_pos;
    memcpy(dst_ptr, data->ptr, data->size);
    #if defined(_SG_TARGET_MACOS)
    if (_sg_mtl_resource_options_storage_mode_managed_or_shared() == MTLResourceStorageModeManaged) {
        [mtl_buf didModifyRange:NSMakeRange((NSUInteger)buf->cmn.append_pos, (NSUInteger)data->size)];
    }
    #endif
}

_SOKOL_PRIVATE void _sg_mtl_update_image(_sg_image_t* img, const sg_image_data* data) {
    SOKOL_ASSERT(img && data);
    if (++img->cmn.active_slot >= img->cmn.num_slots) {
        img->cmn.active_slot = 0;
    }
    __unsafe_unretained id<MTLTexture> mtl_tex = _sg_mtl_id(img->mtl.tex[img->cmn.active_slot]);
    _sg_mtl_copy_image_data(img, mtl_tex, data);
}

_SOKOL_PRIVATE void _sg_mtl_push_debug_group(const char* name) {
    SOKOL_ASSERT(name);
    if (_sg.mtl.render_cmd_encoder) {
        [_sg.mtl.render_cmd_encoder pushDebugGroup:[NSString stringWithUTF8String:name]];
    } else if (_sg.mtl.compute_cmd_encoder) {
        [_sg.mtl.compute_cmd_encoder pushDebugGroup:[NSString stringWithUTF8String:name]];
    }
}

_SOKOL_PRIVATE void _sg_mtl_pop_debug_group(void) {
    if (_sg.mtl.render_cmd_encoder) {
        [_sg.mtl.render_cmd_encoder popDebugGroup];
    } else if (_sg.mtl.compute_cmd_encoder) {
        [_sg.mtl.compute_cmd_encoder popDebugGroup];
    }
}

// ██     ██ ███████ ██████   ██████  ██████  ██    ██     ██████   █████   ██████ ██   ██ ███████ ███    ██ ██████
// ██     ██ ██      ██   ██ ██       ██   ██ ██    ██     ██   ██ ██   ██ ██      ██  ██  ██      ████   ██ ██   ██
// ██  █  ██ █████   ██████  ██   ███ ██████  ██    ██     ██████  ███████ ██      █████   █████   ██ ██  ██ ██   ██
// ██ ███ ██ ██      ██   ██ ██    ██ ██      ██    ██     ██   ██ ██   ██ ██      ██  ██  ██      ██  ██ ██ ██   ██
//  ███ ███  ███████ ██████   ██████  ██       ██████      ██████  ██   ██  ██████ ██   ██ ███████ ██   ████ ██████
//
// >>webgpu
// >>wgpu
#elif defined(SOKOL_WGPU)

#if !defined(__EMSCRIPTEN__)
// FIXME: webgpu.h differences between Dawn and Emscripten webgpu.h
#define wgpuBufferReference wgpuBufferAddRef
#define wgpuTextureReference wgpuTextureAddRef
#define wgpuTextureViewReference wgpuTextureViewAddRef
#define wgpuSamplerReference wgpuSamplerAddRef
#define WGPUSType_ShaderModuleWGSLDescriptor WGPUSType_ShaderSourceWGSL
_SOKOL_PRIVATE WGPUStringView _sg_wgpu_stringview(const char* str) {
    WGPUStringView res;
    if (str) {
        res.data = str;
        res.length = strlen(str);
    } else {
        res.data = 0;
        res.length = 0;
    }
    return res;
}
_SOKOL_PRIVATE WGPUOptionalBool _sg_wgpu_optional_bool(bool b) {
    return b ? WGPUOptionalBool_True : WGPUOptionalBool_False;
}
#else
#define _sg_wgpu_stringview(str) str
#define _sg_wgpu_optional_bool(b) (b)
#endif

_SOKOL_PRIVATE WGPUBufferUsage _sg_wgpu_buffer_usage(const sg_buffer_usage* usg) {
    int res = 0;
    if (usg->vertex_buffer) {
        res |= WGPUBufferUsage_Vertex;
    }
    if (usg->index_buffer) {
        res |= WGPUBufferUsage_Index;
    }
    if (usg->storage_buffer) {
        res |= WGPUBufferUsage_Storage;
    }
    if (!usg->immutable) {
        res |= WGPUBufferUsage_CopyDst;
    }
    return (WGPUBufferUsage)res;
}

_SOKOL_PRIVATE WGPULoadOp _sg_wgpu_load_op(WGPUTextureView view, sg_load_action a) {
    if (0 == view) {
        return WGPULoadOp_Undefined;
    } else switch (a) {
        case SG_LOADACTION_CLEAR:
        case SG_LOADACTION_DONTCARE:
            return WGPULoadOp_Clear;
        case SG_LOADACTION_LOAD:
            return WGPULoadOp_Load;
        default:
            SOKOL_UNREACHABLE;
            return WGPULoadOp_Force32;
    }
}

_SOKOL_PRIVATE WGPUStoreOp _sg_wgpu_store_op(WGPUTextureView view, sg_store_action a) {
    if (0 == view) {
        return WGPUStoreOp_Undefined;
    } else switch (a) {
        case SG_STOREACTION_STORE:
            return WGPUStoreOp_Store;
        case SG_STOREACTION_DONTCARE:
            return WGPUStoreOp_Discard;
        default:
            SOKOL_UNREACHABLE;
            return WGPUStoreOp_Force32;
    }
}

_SOKOL_PRIVATE WGPUTextureViewDimension _sg_wgpu_texture_view_dimension(sg_image_type t) {
    switch (t) {
        case SG_IMAGETYPE_2D:       return WGPUTextureViewDimension_2D;
        case SG_IMAGETYPE_CUBE:     return WGPUTextureViewDimension_Cube;
        case SG_IMAGETYPE_3D:       return WGPUTextureViewDimension_3D;
        case SG_IMAGETYPE_ARRAY:    return WGPUTextureViewDimension_2DArray;
        default: SOKOL_UNREACHABLE; return WGPUTextureViewDimension_Force32;
    }
}

_SOKOL_PRIVATE WGPUTextureDimension _sg_wgpu_texture_dimension(sg_image_type t) {
    if (SG_IMAGETYPE_3D == t) {
        return WGPUTextureDimension_3D;
    } else {
        return WGPUTextureDimension_2D;
    }
}

_SOKOL_PRIVATE WGPUTextureSampleType _sg_wgpu_texture_sample_type(sg_image_sample_type t, bool msaa) {
    switch (t) {
        case SG_IMAGESAMPLETYPE_FLOAT:  return msaa ? WGPUTextureSampleType_UnfilterableFloat : WGPUTextureSampleType_Float;
        case SG_IMAGESAMPLETYPE_DEPTH:  return WGPUTextureSampleType_Depth;
        case SG_IMAGESAMPLETYPE_SINT:   return WGPUTextureSampleType_Sint;
        case SG_IMAGESAMPLETYPE_UINT:   return WGPUTextureSampleType_Uint;
        case SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT: return WGPUTextureSampleType_UnfilterableFloat;
        default: SOKOL_UNREACHABLE;     return WGPUTextureSampleType_Force32;
    }
}

_SOKOL_PRIVATE WGPUSamplerBindingType _sg_wgpu_sampler_binding_type(sg_sampler_type t) {
    switch (t) {
        case SG_SAMPLERTYPE_FILTERING: return WGPUSamplerBindingType_Filtering;
        case SG_SAMPLERTYPE_COMPARISON: return WGPUSamplerBindingType_Comparison;
        case SG_SAMPLERTYPE_NONFILTERING: return WGPUSamplerBindingType_NonFiltering;
        default: SOKOL_UNREACHABLE; return WGPUSamplerBindingType_Force32;
    }
}

_SOKOL_PRIVATE WGPUAddressMode _sg_wgpu_sampler_address_mode(sg_wrap m) {
    switch (m) {
        case SG_WRAP_REPEAT:
            return WGPUAddressMode_Repeat;
        case SG_WRAP_CLAMP_TO_EDGE:
        case SG_WRAP_CLAMP_TO_BORDER:
            return WGPUAddressMode_ClampToEdge;
        case SG_WRAP_MIRRORED_REPEAT:
            return WGPUAddressMode_MirrorRepeat;
        default:
            SOKOL_UNREACHABLE;
            return WGPUAddressMode_Force32;
    }
}

_SOKOL_PRIVATE WGPUFilterMode _sg_wgpu_sampler_minmag_filter(sg_filter f) {
    switch (f) {
        case SG_FILTER_NEAREST:
            return WGPUFilterMode_Nearest;
        case SG_FILTER_LINEAR:
            return WGPUFilterMode_Linear;
        default:
            SOKOL_UNREACHABLE;
            return WGPUFilterMode_Force32;
    }
}

_SOKOL_PRIVATE WGPUMipmapFilterMode _sg_wgpu_sampler_mipmap_filter(sg_filter f) {
    switch (f) {
        case SG_FILTER_NEAREST:
            return WGPUMipmapFilterMode_Nearest;
        case SG_FILTER_LINEAR:
            return WGPUMipmapFilterMode_Linear;
        default:
            SOKOL_UNREACHABLE;
            return WGPUMipmapFilterMode_Force32;
    }
}

_SOKOL_PRIVATE WGPUIndexFormat _sg_wgpu_indexformat(sg_index_type t) {
    // NOTE: there's no WGPUIndexFormat_None
    return (t == SG_INDEXTYPE_UINT16) ? WGPUIndexFormat_Uint16 : WGPUIndexFormat_Uint32;
}

_SOKOL_PRIVATE WGPUIndexFormat _sg_wgpu_stripindexformat(sg_primitive_type prim_type, sg_index_type idx_type) {
    if (idx_type == SG_INDEXTYPE_NONE) {
        return WGPUIndexFormat_Undefined;
    } else if ((prim_type == SG_PRIMITIVETYPE_LINE_STRIP) || (prim_type == SG_PRIMITIVETYPE_TRIANGLE_STRIP)) {
        return _sg_wgpu_indexformat(idx_type);
    } else {
        return WGPUIndexFormat_Undefined;
    }
}

_SOKOL_PRIVATE WGPUVertexStepMode _sg_wgpu_stepmode(sg_vertex_step s) {
    return (s == SG_VERTEXSTEP_PER_VERTEX) ? WGPUVertexStepMode_Vertex : WGPUVertexStepMode_Instance;
}

_SOKOL_PRIVATE WGPUVertexFormat _sg_wgpu_vertexformat(sg_vertex_format f) {
    switch (f) {
        case SG_VERTEXFORMAT_FLOAT:         return WGPUVertexFormat_Float32;
        case SG_VERTEXFORMAT_FLOAT2:        return WGPUVertexFormat_Float32x2;
        case SG_VERTEXFORMAT_FLOAT3:        return WGPUVertexFormat_Float32x3;
        case SG_VERTEXFORMAT_FLOAT4:        return WGPUVertexFormat_Float32x4;
        case SG_VERTEXFORMAT_INT:           return WGPUVertexFormat_Sint32;
        case SG_VERTEXFORMAT_INT2:          return WGPUVertexFormat_Sint32x2;
        case SG_VERTEXFORMAT_INT3:          return WGPUVertexFormat_Sint32x3;
        case SG_VERTEXFORMAT_INT4:          return WGPUVertexFormat_Sint32x4;
        case SG_VERTEXFORMAT_UINT:          return WGPUVertexFormat_Uint32;
        case SG_VERTEXFORMAT_UINT2:         return WGPUVertexFormat_Uint32x2;
        case SG_VERTEXFORMAT_UINT3:         return WGPUVertexFormat_Uint32x3;
        case SG_VERTEXFORMAT_UINT4:         return WGPUVertexFormat_Uint32x4;
        case SG_VERTEXFORMAT_BYTE4:         return WGPUVertexFormat_Sint8x4;
        case SG_VERTEXFORMAT_BYTE4N:        return WGPUVertexFormat_Snorm8x4;
        case SG_VERTEXFORMAT_UBYTE4:        return WGPUVertexFormat_Uint8x4;
        case SG_VERTEXFORMAT_UBYTE4N:       return WGPUVertexFormat_Unorm8x4;
        case SG_VERTEXFORMAT_SHORT2:        return WGPUVertexFormat_Sint16x2;
        case SG_VERTEXFORMAT_SHORT2N:       return WGPUVertexFormat_Snorm16x2;
        case SG_VERTEXFORMAT_USHORT2:       return WGPUVertexFormat_Uint16x2;
        case SG_VERTEXFORMAT_USHORT2N:      return WGPUVertexFormat_Unorm16x2;
        case SG_VERTEXFORMAT_SHORT4:        return WGPUVertexFormat_Sint16x4;
        case SG_VERTEXFORMAT_SHORT4N:       return WGPUVertexFormat_Snorm16x4;
        case SG_VERTEXFORMAT_USHORT4:       return WGPUVertexFormat_Uint16x4;
        case SG_VERTEXFORMAT_USHORT4N:      return WGPUVertexFormat_Unorm16x4;
        case SG_VERTEXFORMAT_UINT10_N2:     return WGPUVertexFormat_Unorm10_10_10_2;
        case SG_VERTEXFORMAT_HALF2:         return WGPUVertexFormat_Float16x2;
        case SG_VERTEXFORMAT_HALF4:         return WGPUVertexFormat_Float16x4;
        default:
            SOKOL_UNREACHABLE;
            return WGPUVertexFormat_Force32;
    }
}

_SOKOL_PRIVATE WGPUPrimitiveTopology _sg_wgpu_topology(sg_primitive_type t) {
    switch (t) {
        case SG_PRIMITIVETYPE_POINTS:           return WGPUPrimitiveTopology_PointList;
        case SG_PRIMITIVETYPE_LINES:            return WGPUPrimitiveTopology_LineList;
        case SG_PRIMITIVETYPE_LINE_STRIP:       return WGPUPrimitiveTopology_LineStrip;
        case SG_PRIMITIVETYPE_TRIANGLES:        return WGPUPrimitiveTopology_TriangleList;
        case SG_PRIMITIVETYPE_TRIANGLE_STRIP:   return WGPUPrimitiveTopology_TriangleStrip;
        default:
            SOKOL_UNREACHABLE;
            return WGPUPrimitiveTopology_Force32;
    }
}

_SOKOL_PRIVATE WGPUFrontFace _sg_wgpu_frontface(sg_face_winding fw) {
    return (fw == SG_FACEWINDING_CCW) ? WGPUFrontFace_CCW : WGPUFrontFace_CW;
}

_SOKOL_PRIVATE WGPUCullMode _sg_wgpu_cullmode(sg_cull_mode cm) {
    switch (cm) {
        case SG_CULLMODE_NONE:      return WGPUCullMode_None;
        case SG_CULLMODE_FRONT:     return WGPUCullMode_Front;
        case SG_CULLMODE_BACK:      return WGPUCullMode_Back;
        default:
            SOKOL_UNREACHABLE;
            return WGPUCullMode_Force32;
    }
}

_SOKOL_PRIVATE WGPUTextureFormat _sg_wgpu_textureformat(sg_pixel_format p) {
    switch (p) {
        case SG_PIXELFORMAT_NONE:           return WGPUTextureFormat_Undefined;
        case SG_PIXELFORMAT_R8:             return WGPUTextureFormat_R8Unorm;
        case SG_PIXELFORMAT_R8SN:           return WGPUTextureFormat_R8Snorm;
        case SG_PIXELFORMAT_R8UI:           return WGPUTextureFormat_R8Uint;
        case SG_PIXELFORMAT_R8SI:           return WGPUTextureFormat_R8Sint;
        case SG_PIXELFORMAT_R16UI:          return WGPUTextureFormat_R16Uint;
        case SG_PIXELFORMAT_R16SI:          return WGPUTextureFormat_R16Sint;
        case SG_PIXELFORMAT_R16F:           return WGPUTextureFormat_R16Float;
        case SG_PIXELFORMAT_RG8:            return WGPUTextureFormat_RG8Unorm;
        case SG_PIXELFORMAT_RG8SN:          return WGPUTextureFormat_RG8Snorm;
        case SG_PIXELFORMAT_RG8UI:          return WGPUTextureFormat_RG8Uint;
        case SG_PIXELFORMAT_RG8SI:          return WGPUTextureFormat_RG8Sint;
        case SG_PIXELFORMAT_R32UI:          return WGPUTextureFormat_R32Uint;
        case SG_PIXELFORMAT_R32SI:          return WGPUTextureFormat_R32Sint;
        case SG_PIXELFORMAT_R32F:           return WGPUTextureFormat_R32Float;
        case SG_PIXELFORMAT_RG16UI:         return WGPUTextureFormat_RG16Uint;
        case SG_PIXELFORMAT_RG16SI:         return WGPUTextureFormat_RG16Sint;
        case SG_PIXELFORMAT_RG16F:          return WGPUTextureFormat_RG16Float;
        case SG_PIXELFORMAT_RGBA8:          return WGPUTextureFormat_RGBA8Unorm;
        case SG_PIXELFORMAT_SRGB8A8:        return WGPUTextureFormat_RGBA8UnormSrgb;
        case SG_PIXELFORMAT_RGBA8SN:        return WGPUTextureFormat_RGBA8Snorm;
        case SG_PIXELFORMAT_RGBA8UI:        return WGPUTextureFormat_RGBA8Uint;
        case SG_PIXELFORMAT_RGBA8SI:        return WGPUTextureFormat_RGBA8Sint;
        case SG_PIXELFORMAT_BGRA8:          return WGPUTextureFormat_BGRA8Unorm;
        case SG_PIXELFORMAT_RGB10A2:        return WGPUTextureFormat_RGB10A2Unorm;
        case SG_PIXELFORMAT_RG11B10F:       return WGPUTextureFormat_RG11B10Ufloat;
        case SG_PIXELFORMAT_RG32UI:         return WGPUTextureFormat_RG32Uint;
        case SG_PIXELFORMAT_RG32SI:         return WGPUTextureFormat_RG32Sint;
        case SG_PIXELFORMAT_RG32F:          return WGPUTextureFormat_RG32Float;
        case SG_PIXELFORMAT_RGBA16UI:       return WGPUTextureFormat_RGBA16Uint;
        case SG_PIXELFORMAT_RGBA16SI:       return WGPUTextureFormat_RGBA16Sint;
        case SG_PIXELFORMAT_RGBA16F:        return WGPUTextureFormat_RGBA16Float;
        case SG_PIXELFORMAT_RGBA32UI:       return WGPUTextureFormat_RGBA32Uint;
        case SG_PIXELFORMAT_RGBA32SI:       return WGPUTextureFormat_RGBA32Sint;
        case SG_PIXELFORMAT_RGBA32F:        return WGPUTextureFormat_RGBA32Float;
        case SG_PIXELFORMAT_DEPTH:          return WGPUTextureFormat_Depth32Float;
        case SG_PIXELFORMAT_DEPTH_STENCIL:  return WGPUTextureFormat_Depth32FloatStencil8;
        case SG_PIXELFORMAT_BC1_RGBA:       return WGPUTextureFormat_BC1RGBAUnorm;
        case SG_PIXELFORMAT_BC2_RGBA:       return WGPUTextureFormat_BC2RGBAUnorm;
        case SG_PIXELFORMAT_BC3_RGBA:       return WGPUTextureFormat_BC3RGBAUnorm;
        case SG_PIXELFORMAT_BC3_SRGBA:      return WGPUTextureFormat_BC3RGBAUnormSrgb;
        case SG_PIXELFORMAT_BC4_R:          return WGPUTextureFormat_BC4RUnorm;
        case SG_PIXELFORMAT_BC4_RSN:        return WGPUTextureFormat_BC4RSnorm;
        case SG_PIXELFORMAT_BC5_RG:         return WGPUTextureFormat_BC5RGUnorm;
        case SG_PIXELFORMAT_BC5_RGSN:       return WGPUTextureFormat_BC5RGSnorm;
        case SG_PIXELFORMAT_BC6H_RGBF:      return WGPUTextureFormat_BC6HRGBFloat;
        case SG_PIXELFORMAT_BC6H_RGBUF:     return WGPUTextureFormat_BC6HRGBUfloat;
        case SG_PIXELFORMAT_BC7_RGBA:       return WGPUTextureFormat_BC7RGBAUnorm;
        case SG_PIXELFORMAT_BC7_SRGBA:      return WGPUTextureFormat_BC7RGBAUnormSrgb;
        case SG_PIXELFORMAT_ETC2_RGB8:      return WGPUTextureFormat_ETC2RGB8Unorm;
        case SG_PIXELFORMAT_ETC2_RGB8A1:    return WGPUTextureFormat_ETC2RGB8A1Unorm;
        case SG_PIXELFORMAT_ETC2_RGBA8:     return WGPUTextureFormat_ETC2RGBA8Unorm;
        case SG_PIXELFORMAT_ETC2_SRGB8:     return WGPUTextureFormat_ETC2RGB8UnormSrgb;
        case SG_PIXELFORMAT_ETC2_SRGB8A8:   return WGPUTextureFormat_ETC2RGBA8UnormSrgb;
        case SG_PIXELFORMAT_EAC_R11:        return WGPUTextureFormat_EACR11Unorm;
        case SG_PIXELFORMAT_EAC_R11SN:      return WGPUTextureFormat_EACR11Snorm;
        case SG_PIXELFORMAT_EAC_RG11:       return WGPUTextureFormat_EACRG11Unorm;
        case SG_PIXELFORMAT_EAC_RG11SN:     return WGPUTextureFormat_EACRG11Snorm;
        case SG_PIXELFORMAT_RGB9E5:         return WGPUTextureFormat_RGB9E5Ufloat;
        case SG_PIXELFORMAT_ASTC_4x4_RGBA:  return WGPUTextureFormat_ASTC4x4Unorm;
        case SG_PIXELFORMAT_ASTC_4x4_SRGBA: return WGPUTextureFormat_ASTC4x4UnormSrgb;
        // NOT SUPPORTED
        case SG_PIXELFORMAT_R16:
        case SG_PIXELFORMAT_R16SN:
        case SG_PIXELFORMAT_RG16:
        case SG_PIXELFORMAT_RG16SN:
        case SG_PIXELFORMAT_RGBA16:
        case SG_PIXELFORMAT_RGBA16SN:
            return WGPUTextureFormat_Undefined;

        default:
            SOKOL_UNREACHABLE;
            return WGPUTextureFormat_Force32;
    }
}

_SOKOL_PRIVATE WGPUCompareFunction _sg_wgpu_comparefunc(sg_compare_func f) {
    switch (f) {
        case SG_COMPAREFUNC_NEVER:          return WGPUCompareFunction_Never;
        case SG_COMPAREFUNC_LESS:           return WGPUCompareFunction_Less;
        case SG_COMPAREFUNC_EQUAL:          return WGPUCompareFunction_Equal;
        case SG_COMPAREFUNC_LESS_EQUAL:     return WGPUCompareFunction_LessEqual;
        case SG_COMPAREFUNC_GREATER:        return WGPUCompareFunction_Greater;
        case SG_COMPAREFUNC_NOT_EQUAL:      return WGPUCompareFunction_NotEqual;
        case SG_COMPAREFUNC_GREATER_EQUAL:  return WGPUCompareFunction_GreaterEqual;
        case SG_COMPAREFUNC_ALWAYS:         return WGPUCompareFunction_Always;
        default:
            SOKOL_UNREACHABLE;
            return WGPUCompareFunction_Force32;
    }
}

_SOKOL_PRIVATE WGPUStencilOperation _sg_wgpu_stencilop(sg_stencil_op op) {
    switch (op) {
        case SG_STENCILOP_KEEP:         return WGPUStencilOperation_Keep;
        case SG_STENCILOP_ZERO:         return WGPUStencilOperation_Zero;
        case SG_STENCILOP_REPLACE:      return WGPUStencilOperation_Replace;
        case SG_STENCILOP_INCR_CLAMP:   return WGPUStencilOperation_IncrementClamp;
        case SG_STENCILOP_DECR_CLAMP:   return WGPUStencilOperation_DecrementClamp;
        case SG_STENCILOP_INVERT:       return WGPUStencilOperation_Invert;
        case SG_STENCILOP_INCR_WRAP:    return WGPUStencilOperation_IncrementWrap;
        case SG_STENCILOP_DECR_WRAP:    return WGPUStencilOperation_DecrementWrap;
        default:
            SOKOL_UNREACHABLE;
            return WGPUStencilOperation_Force32;
    }
}

_SOKOL_PRIVATE WGPUBlendOperation _sg_wgpu_blendop(sg_blend_op op) {
    switch (op) {
        case SG_BLENDOP_ADD:                return WGPUBlendOperation_Add;
        case SG_BLENDOP_SUBTRACT:           return WGPUBlendOperation_Subtract;
        case SG_BLENDOP_REVERSE_SUBTRACT:   return WGPUBlendOperation_ReverseSubtract;
        case SG_BLENDOP_MIN:                return WGPUBlendOperation_Min;
        case SG_BLENDOP_MAX:                return WGPUBlendOperation_Max;
        default:
            SOKOL_UNREACHABLE;
            return WGPUBlendOperation_Force32;
    }
}

_SOKOL_PRIVATE WGPUBlendFactor _sg_wgpu_blendfactor(sg_blend_factor f) {
    switch (f) {
        case SG_BLENDFACTOR_ZERO:                   return WGPUBlendFactor_Zero;
        case SG_BLENDFACTOR_ONE:                    return WGPUBlendFactor_One;
        case SG_BLENDFACTOR_SRC_COLOR:              return WGPUBlendFactor_Src;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_COLOR:    return WGPUBlendFactor_OneMinusSrc;
        case SG_BLENDFACTOR_SRC_ALPHA:              return WGPUBlendFactor_SrcAlpha;
        case SG_BLENDFACTOR_ONE_MINUS_SRC_ALPHA:    return WGPUBlendFactor_OneMinusSrcAlpha;
        case SG_BLENDFACTOR_DST_COLOR:              return WGPUBlendFactor_Dst;
        case SG_BLENDFACTOR_ONE_MINUS_DST_COLOR:    return WGPUBlendFactor_OneMinusDst;
        case SG_BLENDFACTOR_DST_ALPHA:              return WGPUBlendFactor_DstAlpha;
        case SG_BLENDFACTOR_ONE_MINUS_DST_ALPHA:    return WGPUBlendFactor_OneMinusDstAlpha;
        case SG_BLENDFACTOR_SRC_ALPHA_SATURATED:    return WGPUBlendFactor_SrcAlphaSaturated;
        case SG_BLENDFACTOR_BLEND_COLOR:            return WGPUBlendFactor_Constant;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_COLOR:  return WGPUBlendFactor_OneMinusConstant;
        // FIXME: separate blend alpha value not supported?
        case SG_BLENDFACTOR_BLEND_ALPHA:            return WGPUBlendFactor_Constant;
        case SG_BLENDFACTOR_ONE_MINUS_BLEND_ALPHA:  return WGPUBlendFactor_OneMinusConstant;
        default:
            SOKOL_UNREACHABLE;
            return WGPUBlendFactor_Force32;
    }
}

_SOKOL_PRIVATE WGPUColorWriteMask _sg_wgpu_colorwritemask(uint8_t m) {
    // FIXME: change to WGPUColorWriteMask once Emscripten and Dawn webgpu.h agree
    int res = 0;
    if (0 != (m & SG_COLORMASK_R)) {
        res |= WGPUColorWriteMask_Red;
    }
    if (0 != (m & SG_COLORMASK_G)) {
        res |= WGPUColorWriteMask_Green;
    }
    if (0 != (m & SG_COLORMASK_B)) {
        res |= WGPUColorWriteMask_Blue;
    }
    if (0 != (m & SG_COLORMASK_A)) {
        res |= WGPUColorWriteMask_Alpha;
    }
    return (WGPUColorWriteMask)res;
}

_SOKOL_PRIVATE WGPUShaderStage _sg_wgpu_shader_stage(sg_shader_stage stage) {
    switch (stage) {
        case SG_SHADERSTAGE_VERTEX: return WGPUShaderStage_Vertex;
        case SG_SHADERSTAGE_FRAGMENT: return WGPUShaderStage_Fragment;
        case SG_SHADERSTAGE_COMPUTE: return WGPUShaderStage_Compute;
        default: SOKOL_UNREACHABLE; return WGPUShaderStage_None;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_init_caps(void) {
    _sg.backend = SG_BACKEND_WGPU;
    _sg.features.origin_top_left = true;
    _sg.features.image_clamp_to_border = false;
    _sg.features.mrt_independent_blend_state = true;
    _sg.features.mrt_independent_write_mask = true;
    _sg.features.compute = true;
    _sg.features.msaa_image_bindings = true;

    wgpuDeviceGetLimits(_sg.wgpu.dev, &_sg.wgpu.limits);

    const WGPULimits* l = &_sg.wgpu.limits.limits;
    _sg.limits.max_image_size_2d = (int) l->maxTextureDimension2D;
    _sg.limits.max_image_size_cube = (int) l->maxTextureDimension2D; // not a bug, see: https://github.com/gpuweb/gpuweb/issues/1327
    _sg.limits.max_image_size_3d = (int) l->maxTextureDimension3D;
    _sg.limits.max_image_size_array = (int) l->maxTextureDimension2D;
    _sg.limits.max_image_array_layers = (int) l->maxTextureArrayLayers;
    _sg.limits.max_vertex_attrs = SG_MAX_VERTEX_ATTRIBUTES;

    // NOTE: no WGPUTextureFormat_R16Unorm
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_SRGB8A8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_BGRA8]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_R16F]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RG16F]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    _sg_pixelformat_all(&_sg.formats[SG_PIXELFORMAT_RGB10A2]);

    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_R8SN]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG8SN]);
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);

    // FIXME: can be made renderable via extension
    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RG11B10F]);

    // NOTE: msaa rendering is possible in WebGPU, but no resolve
    // which is a combination that's not currently supported in sokol-gfx
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R8UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R8SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG8UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG8SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R16UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R16SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG16UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG16SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
    _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);

    if (wgpuDeviceHasFeature(_sg.wgpu.dev, WGPUFeatureName_Float32Filterable)) {
        _sg_pixelformat_sfr(&_sg.formats[SG_PIXELFORMAT_R32F]);
        _sg_pixelformat_sfr(&_sg.formats[SG_PIXELFORMAT_RG32F]);
        _sg_pixelformat_sfr(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
    } else {
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_R32F]);
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RG32F]);
        _sg_pixelformat_sr(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
    }

    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH]);
    _sg_pixelformat_srmd(&_sg.formats[SG_PIXELFORMAT_DEPTH_STENCIL]);

    _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_RGB9E5]);

    if (wgpuDeviceHasFeature(_sg.wgpu.dev, WGPUFeatureName_TextureCompressionBC)) {
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC1_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC2_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC3_SRGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_R]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC4_RSN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RG]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC5_RGSN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBF]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC6H_RGBUF]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_BC7_SRGBA]);
    }
    if (wgpuDeviceHasFeature(_sg.wgpu.dev, WGPUFeatureName_TextureCompressionETC2)) {
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_SRGB8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGB8A1]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_RGBA8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ETC2_SRGB8A8]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_R11]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_R11SN]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_RG11]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_EAC_RG11SN]);
    }

    if (wgpuDeviceHasFeature(_sg.wgpu.dev, WGPUFeatureName_TextureCompressionASTC)) {
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ASTC_4x4_RGBA]);
        _sg_pixelformat_sf(&_sg.formats[SG_PIXELFORMAT_ASTC_4x4_SRGBA]);
    }

    // see: https://github.com/gpuweb/gpuweb/issues/513
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SN]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA8SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA16F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_R32F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RG32F]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32UI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32SI]);
    _sg_pixelformat_compute_all(&_sg.formats[SG_PIXELFORMAT_RGBA32F]);
}

_SOKOL_PRIVATE void _sg_wgpu_uniform_buffer_init(const sg_desc* desc) {
    SOKOL_ASSERT(0 == _sg.wgpu.uniform.staging);
    SOKOL_ASSERT(0 == _sg.wgpu.uniform.buf);

    // Add the max-uniform-update size (64 KB) to the requested buffer size,
    // this is to prevent validation errors in the WebGPU implementation
    // if the entire buffer size is used per frame. 64 KB is the allowed
    // max uniform update size on NVIDIA
    //
    // FIXME: is this still needed?
    _sg.wgpu.uniform.num_bytes = (uint32_t)(desc->uniform_buffer_size + _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE);
    _sg.wgpu.uniform.staging = (uint8_t*)_sg_malloc(_sg.wgpu.uniform.num_bytes);

    WGPUBufferDescriptor ub_desc;
    _sg_clear(&ub_desc, sizeof(ub_desc));
    ub_desc.size = _sg.wgpu.uniform.num_bytes;
    ub_desc.usage = WGPUBufferUsage_Uniform|WGPUBufferUsage_CopyDst;
    _sg.wgpu.uniform.buf = wgpuDeviceCreateBuffer(_sg.wgpu.dev, &ub_desc);
    SOKOL_ASSERT(_sg.wgpu.uniform.buf);
}

_SOKOL_PRIVATE void _sg_wgpu_uniform_buffer_discard(void) {
    if (_sg.wgpu.uniform.buf) {
        wgpuBufferRelease(_sg.wgpu.uniform.buf);
        _sg.wgpu.uniform.buf = 0;
    }
    if (_sg.wgpu.uniform.staging) {
        _sg_free(_sg.wgpu.uniform.staging);
        _sg.wgpu.uniform.staging = 0;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_uniform_buffer_on_commit(void) {
    wgpuQueueWriteBuffer(_sg.wgpu.queue, _sg.wgpu.uniform.buf, 0, _sg.wgpu.uniform.staging, _sg.wgpu.uniform.offset);
    _sg_stats_add(wgpu.uniforms.size_write_buffer, _sg.wgpu.uniform.offset);
    _sg.wgpu.uniform.offset = 0;
    _sg_clear(_sg.wgpu.uniform.bind_offsets, sizeof(_sg.wgpu.uniform.bind_offsets));
}

_SOKOL_PRIVATE void _sg_wgpu_bindgroups_pool_init(const sg_desc* desc) {
    SOKOL_ASSERT((desc->wgpu_bindgroups_cache_size > 0) && (desc->wgpu_bindgroups_cache_size < _SG_MAX_POOL_SIZE));
    _sg_wgpu_bindgroups_pool_t* p = &_sg.wgpu.bindgroups_pool;
    SOKOL_ASSERT(0 == p->bindgroups);
    const int pool_size = desc->wgpu_bindgroups_cache_size;
    _sg_pool_init(&p->pool, pool_size);
    size_t pool_byte_size = sizeof(_sg_wgpu_bindgroup_t) * (size_t)p->pool.size;
    p->bindgroups = (_sg_wgpu_bindgroup_t*) _sg_malloc_clear(pool_byte_size);
}

_SOKOL_PRIVATE void _sg_wgpu_bindgroups_pool_discard(void) {
    _sg_wgpu_bindgroups_pool_t* p = &_sg.wgpu.bindgroups_pool;
    SOKOL_ASSERT(p->bindgroups);
    _sg_free(p->bindgroups); p->bindgroups = 0;
    _sg_pool_discard(&p->pool);
}

_SOKOL_PRIVATE _sg_wgpu_bindgroup_t* _sg_wgpu_bindgroup_at(uint32_t bg_id) {
    SOKOL_ASSERT(SG_INVALID_ID != bg_id);
    _sg_wgpu_bindgroups_pool_t* p = &_sg.wgpu.bindgroups_pool;
    int slot_index = _sg_slot_index(bg_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->pool.size));
    return &p->bindgroups[slot_index];
}

_SOKOL_PRIVATE _sg_wgpu_bindgroup_t* _sg_wgpu_lookup_bindgroup(uint32_t bg_id) {
    if (SG_INVALID_ID != bg_id) {
        _sg_wgpu_bindgroup_t* bg = _sg_wgpu_bindgroup_at(bg_id);
        if (bg->slot.id == bg_id) {
            return bg;
        }
    }
    return 0;
}

_SOKOL_PRIVATE _sg_wgpu_bindgroup_handle_t _sg_wgpu_alloc_bindgroup(void) {
    _sg_wgpu_bindgroups_pool_t* p = &_sg.wgpu.bindgroups_pool;
    _sg_wgpu_bindgroup_handle_t res;
    int slot_index = _sg_pool_alloc_index(&p->pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id = _sg_slot_alloc(&p->pool, &p->bindgroups[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(WGPU_BINDGROUPS_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE void _sg_wgpu_dealloc_bindgroup(_sg_wgpu_bindgroup_t* bg) {
    SOKOL_ASSERT(bg && (bg->slot.state == SG_RESOURCESTATE_ALLOC) && (bg->slot.id != SG_INVALID_ID));
    _sg_wgpu_bindgroups_pool_t* p = &_sg.wgpu.bindgroups_pool;
    _sg_pool_free_index(&p->pool, _sg_slot_index(bg->slot.id));
    _sg_slot_reset(&bg->slot);
}

_SOKOL_PRIVATE void _sg_wgpu_reset_bindgroup_to_alloc_state(_sg_wgpu_bindgroup_t* bg) {
    SOKOL_ASSERT(bg);
    _sg_slot_t slot = bg->slot;
    _sg_clear(bg, sizeof(_sg_wgpu_bindgroup_t));
    bg->slot = slot;
    bg->slot.state = SG_RESOURCESTATE_ALLOC;
}

// MurmurHash64B (see: https://github.com/aappleby/smhasher/blob/61a0530f28277f2e850bfc39600ce61d02b518de/src/MurmurHash2.cpp#L142)
_SOKOL_PRIVATE uint64_t _sg_wgpu_hash(const void* key, int len, uint64_t seed) {
    const uint32_t m = 0x5bd1e995;
    const int r = 24;
    uint32_t h1 = (uint32_t)seed ^ (uint32_t)len;
    uint32_t h2 = (uint32_t)(seed >> 32);
    const uint32_t * data = (const uint32_t *)key;
    while (len >= 8) {
        uint32_t k1 = *data++;
        k1 *= m; k1 ^= k1 >> r; k1 *= m;
        h1 *= m; h1 ^= k1;
        len -= 4;
        uint32_t k2 = *data++;
        k2 *= m; k2 ^= k2 >> r; k2 *= m;
        h2 *= m; h2 ^= k2;
        len -= 4;
    }
    if (len >= 4) {
        uint32_t k1 = *data++;
        k1 *= m; k1 ^= k1 >> r; k1 *= m;
        h1 *= m; h1 ^= k1;
        len -= 4;
    }
    switch(len) {
        case 3: h2 ^= (uint32_t)(((unsigned char*)data)[2] << 16);
        case 2: h2 ^= (uint32_t)(((unsigned char*)data)[1] << 8);
        case 1: h2 ^= ((unsigned char*)data)[0];
        h2 *= m;
    };
    h1 ^= h2 >> 18; h1 *= m;
    h2 ^= h1 >> 22; h2 *= m;
    h1 ^= h2 >> 17; h1 *= m;
    h2 ^= h1 >> 19; h2 *= m;
    uint64_t h = h1;
    h = (h << 32) | h2;
    return h;
}

_SOKOL_PRIVATE uint64_t _sg_wgpu_bindgroups_cache_item(_sg_wgpu_bindgroups_cache_item_type_t type, uint8_t wgpu_binding, uint32_t id) {
    // key pattern is bbbbttttiiiiiiii
    const uint64_t bb = (uint64_t)wgpu_binding;
    const uint64_t tttt = (uint64_t)type;
    const uint64_t iiiiiiii = (uint64_t)id;
    return (bb << 56) | (bb << 48) | (tttt << 32) | iiiiiiii;
}

_SOKOL_PRIVATE uint64_t _sg_wgpu_bindgroups_cache_pip_item(uint32_t id) {
    return _sg_wgpu_bindgroups_cache_item(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_PIPELINE, 0xFF, id);
}

_SOKOL_PRIVATE uint64_t _sg_wgpu_bindgroups_cache_image_item(uint8_t wgpu_binding, uint32_t id) {
    return _sg_wgpu_bindgroups_cache_item(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_IMAGE, wgpu_binding, id);
}

_SOKOL_PRIVATE uint64_t _sg_wgpu_bindgroups_cache_sampler_item(uint8_t wgpu_binding, uint32_t id) {
    return _sg_wgpu_bindgroups_cache_item(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_SAMPLER, wgpu_binding, id);
}

_SOKOL_PRIVATE uint64_t _sg_wgpu_bindgroups_cache_sbuf_item(uint8_t wgpu_binding, uint32_t id) {
    return _sg_wgpu_bindgroups_cache_item(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_STORAGEBUFFER, wgpu_binding, id);
}

_SOKOL_PRIVATE void _sg_wgpu_init_bindgroups_cache_key(_sg_wgpu_bindgroups_cache_key_t* key, const _sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(bnd);
    SOKOL_ASSERT(bnd->pip);
    const _sg_shader_t* shd = bnd->pip->shader;
    SOKOL_ASSERT(shd && shd->slot.id == bnd->pip->cmn.shader_id.id);

    _sg_clear(key->items, sizeof(key->items));
    key->items[0] = _sg_wgpu_bindgroups_cache_pip_item(bnd->pip->slot.id);
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (shd->cmn.images[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(bnd->imgs[i]);
        const size_t item_idx = i + 1;
        SOKOL_ASSERT(item_idx < _SG_WGPU_BINDGROUPSCACHEKEY_NUM_ITEMS);
        SOKOL_ASSERT(0 == key->items[item_idx]);
        const uint8_t wgpu_binding = shd->wgpu.img_grp1_bnd_n[i];
        const uint32_t id = bnd->imgs[i]->slot.id;
        key->items[item_idx] = _sg_wgpu_bindgroups_cache_image_item(wgpu_binding, id);
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (shd->cmn.samplers[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(bnd->smps[i]);
        const size_t item_idx = i + 1 + SG_MAX_IMAGE_BINDSLOTS;
        SOKOL_ASSERT(item_idx < _SG_WGPU_BINDGROUPSCACHEKEY_NUM_ITEMS);
        SOKOL_ASSERT(0 == key->items[item_idx]);
        const uint8_t wgpu_binding = shd->wgpu.smp_grp1_bnd_n[i];
        const uint32_t id = bnd->smps[i]->slot.id;
        key->items[item_idx] = _sg_wgpu_bindgroups_cache_sampler_item(wgpu_binding, id);
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (shd->cmn.storage_buffers[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(bnd->sbufs[i]);
        const size_t item_idx = i + 1 + SG_MAX_IMAGE_BINDSLOTS + SG_MAX_SAMPLER_BINDSLOTS;
        SOKOL_ASSERT(item_idx < _SG_WGPU_BINDGROUPSCACHEKEY_NUM_ITEMS);
        SOKOL_ASSERT(0 == key->items[item_idx]);
        const uint8_t wgpu_binding = shd->wgpu.sbuf_grp1_bnd_n[i];
        const uint32_t id = bnd->sbufs[i]->slot.id;
        key->items[item_idx] = _sg_wgpu_bindgroups_cache_sbuf_item(wgpu_binding, id);
    }
    key->hash = _sg_wgpu_hash(&key->items, (int)sizeof(key->items), 0x1234567887654321);
}

_SOKOL_PRIVATE bool _sg_wgpu_compare_bindgroups_cache_key(_sg_wgpu_bindgroups_cache_key_t* k0, _sg_wgpu_bindgroups_cache_key_t* k1) {
    SOKOL_ASSERT(k0 && k1);
    if (k0->hash != k1->hash) {
        return false;
    }
    if (memcmp(&k0->items, &k1->items, sizeof(k0->items)) != 0) {
        _sg_stats_add(wgpu.bindings.num_bindgroup_cache_hash_vs_key_mismatch, 1);
        return false;
    }
    return true;
}

_SOKOL_PRIVATE _sg_wgpu_bindgroup_t* _sg_wgpu_create_bindgroup(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(_sg.wgpu.dev);
    SOKOL_ASSERT(bnd->pip);
    const _sg_shader_t* shd = bnd->pip->shader;
    SOKOL_ASSERT(shd && (shd->slot.id == bnd->pip->cmn.shader_id.id));
    _sg_stats_add(wgpu.bindings.num_create_bindgroup, 1);
    _sg_wgpu_bindgroup_handle_t bg_id = _sg_wgpu_alloc_bindgroup();
    if (bg_id.id == SG_INVALID_ID) {
        return 0;
    }
    _sg_wgpu_bindgroup_t* bg = _sg_wgpu_bindgroup_at(bg_id.id);
    SOKOL_ASSERT(bg && (bg->slot.state == SG_RESOURCESTATE_ALLOC));

    // create wgpu bindgroup object (also see _sg_wgpu_create_shader())
    WGPUBindGroupLayout bgl = bnd->pip->shader->wgpu.bgl_img_smp_sbuf;
    SOKOL_ASSERT(bgl);
    WGPUBindGroupEntry bg_entries[_SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES];
    _sg_clear(&bg_entries, sizeof(bg_entries));
    size_t bgl_index = 0;
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (shd->cmn.images[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(bnd->imgs[i]);
        SOKOL_ASSERT(bgl_index < _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES);
        WGPUBindGroupEntry* bg_entry = &bg_entries[bgl_index];
        bg_entry->binding = shd->wgpu.img_grp1_bnd_n[i];
        bg_entry->textureView = bnd->imgs[i]->wgpu.view;
        bgl_index += 1;
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (shd->cmn.samplers[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(bnd->smps[i]);
        SOKOL_ASSERT(bgl_index < _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES);
        WGPUBindGroupEntry* bg_entry = &bg_entries[bgl_index];
        bg_entry->binding = shd->wgpu.smp_grp1_bnd_n[i];
        bg_entry->sampler = bnd->smps[i]->wgpu.smp;
        bgl_index += 1;
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (shd->cmn.storage_buffers[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        SOKOL_ASSERT(bnd->sbufs[i]);
        SOKOL_ASSERT(bgl_index < _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES);
        WGPUBindGroupEntry* bg_entry = &bg_entries[bgl_index];
        bg_entry->binding = shd->wgpu.sbuf_grp1_bnd_n[i];
        bg_entry->buffer = bnd->sbufs[i]->wgpu.buf;
        bg_entry->size = (uint64_t) bnd->sbufs[i]->cmn.size;
        bgl_index += 1;
    }
    WGPUBindGroupDescriptor bg_desc;
    _sg_clear(&bg_desc, sizeof(bg_desc));
    bg_desc.layout = bgl;
    bg_desc.entryCount = bgl_index;
    bg_desc.entries = bg_entries;
    bg->bindgroup = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);
    if (bg->bindgroup == 0) {
        _SG_ERROR(WGPU_CREATEBINDGROUP_FAILED);
        bg->slot.state = SG_RESOURCESTATE_FAILED;
        return bg;
    }
    _sg_wgpu_init_bindgroups_cache_key(&bg->key, bnd);
    bg->slot.state = SG_RESOURCESTATE_VALID;
    return bg;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_bindgroup(_sg_wgpu_bindgroup_t* bg) {
    SOKOL_ASSERT(bg);
    _sg_stats_add(wgpu.bindings.num_discard_bindgroup, 1);
    if (bg->slot.state == SG_RESOURCESTATE_VALID) {
        if (bg->bindgroup) {
            wgpuBindGroupRelease(bg->bindgroup);
            bg->bindgroup = 0;
        }
        _sg_wgpu_reset_bindgroup_to_alloc_state(bg);
        SOKOL_ASSERT(bg->slot.state == SG_RESOURCESTATE_ALLOC);
    }
    if (bg->slot.state == SG_RESOURCESTATE_ALLOC) {
        _sg_wgpu_dealloc_bindgroup(bg);
        SOKOL_ASSERT(bg->slot.state == SG_RESOURCESTATE_INITIAL);
    }
}

_SOKOL_PRIVATE void _sg_wgpu_discard_all_bindgroups(void) {
    _sg_wgpu_bindgroups_pool_t* p = &_sg.wgpu.bindgroups_pool;
    for (int i = 0; i < p->pool.size; i++) {
        sg_resource_state state = p->bindgroups[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_wgpu_discard_bindgroup(&p->bindgroups[i]);
        }
    }
}

_SOKOL_PRIVATE void _sg_wgpu_bindgroups_cache_init(const sg_desc* desc) {
    SOKOL_ASSERT(desc);
    SOKOL_ASSERT(_sg.wgpu.bindgroups_cache.num == 0);
    SOKOL_ASSERT(_sg.wgpu.bindgroups_cache.index_mask == 0);
    SOKOL_ASSERT(_sg.wgpu.bindgroups_cache.items == 0);
    const int num = desc->wgpu_bindgroups_cache_size;
    if (num <= 1) {
        _SG_PANIC(WGPU_BINDGROUPSCACHE_SIZE_GREATER_ONE);
    }
    if (!_sg_ispow2(num)) {
        _SG_PANIC(WGPU_BINDGROUPSCACHE_SIZE_POW2);
    }
    _sg.wgpu.bindgroups_cache.num = (uint32_t)desc->wgpu_bindgroups_cache_size;
    _sg.wgpu.bindgroups_cache.index_mask = _sg.wgpu.bindgroups_cache.num - 1;
    size_t size_in_bytes = sizeof(_sg_wgpu_bindgroup_handle_t) * (size_t)num;
    _sg.wgpu.bindgroups_cache.items = (_sg_wgpu_bindgroup_handle_t*)_sg_malloc_clear(size_in_bytes);
}

_SOKOL_PRIVATE void _sg_wgpu_bindgroups_cache_discard(void) {
    if (_sg.wgpu.bindgroups_cache.items) {
        _sg_free(_sg.wgpu.bindgroups_cache.items);
        _sg.wgpu.bindgroups_cache.items = 0;
    }
    _sg.wgpu.bindgroups_cache.num = 0;
    _sg.wgpu.bindgroups_cache.index_mask = 0;
}

_SOKOL_PRIVATE void _sg_wgpu_bindgroups_cache_set(uint64_t hash, uint32_t bg_id) {
    uint32_t index = hash & _sg.wgpu.bindgroups_cache.index_mask;
    SOKOL_ASSERT(index < _sg.wgpu.bindgroups_cache.num);
    SOKOL_ASSERT(_sg.wgpu.bindgroups_cache.items);
    _sg.wgpu.bindgroups_cache.items[index].id = bg_id;
}

_SOKOL_PRIVATE uint32_t _sg_wgpu_bindgroups_cache_get(uint64_t hash) {
    uint32_t index = hash & _sg.wgpu.bindgroups_cache.index_mask;
    SOKOL_ASSERT(index < _sg.wgpu.bindgroups_cache.num);
    SOKOL_ASSERT(_sg.wgpu.bindgroups_cache.items);
    return _sg.wgpu.bindgroups_cache.items[index].id;
}

// called from wgpu resource destroy functions to also invalidate any
// bindgroups cache slot and bindgroup referencing that resource
_SOKOL_PRIVATE void _sg_wgpu_bindgroups_cache_invalidate(_sg_wgpu_bindgroups_cache_item_type_t type, uint32_t id) {
    const uint64_t key_mask = 0x0000FFFFFFFFFFFF;
    const uint64_t key_item = _sg_wgpu_bindgroups_cache_item(type, 0, id) & key_mask;
    SOKOL_ASSERT(_sg.wgpu.bindgroups_cache.items);
    for (uint32_t cache_item_idx = 0; cache_item_idx < _sg.wgpu.bindgroups_cache.num; cache_item_idx++) {
        const uint32_t bg_id = _sg.wgpu.bindgroups_cache.items[cache_item_idx].id;
        if (bg_id != SG_INVALID_ID) {
            _sg_wgpu_bindgroup_t* bg = _sg_wgpu_lookup_bindgroup(bg_id);
            SOKOL_ASSERT(bg && (bg->slot.state == SG_RESOURCESTATE_VALID));
            // check if resource is in bindgroup, if yes discard bindgroup and invalidate cache slot
            bool invalidate_cache_item = false;
            for (int key_item_idx = 0; key_item_idx < _SG_WGPU_BINDGROUPSCACHEKEY_NUM_ITEMS; key_item_idx++) {
                if ((bg->key.items[key_item_idx] & key_mask) == key_item) {
                    invalidate_cache_item = true;
                    break;
                }
            }
            if (invalidate_cache_item) {
                _sg_wgpu_discard_bindgroup(bg); bg = 0;
                _sg_wgpu_bindgroups_cache_set(cache_item_idx, SG_INVALID_ID);
                _sg_stats_add(wgpu.bindings.num_bindgroup_cache_invalidates, 1);
            }
        }
    }
}

_SOKOL_PRIVATE void _sg_wgpu_bindings_cache_clear(void) {
    memset(&_sg.wgpu.bindings_cache, 0, sizeof(_sg.wgpu.bindings_cache));
}

_SOKOL_PRIVATE bool _sg_wgpu_bindings_cache_vb_dirty(size_t index, const _sg_buffer_t* vb, uint64_t offset) {
    SOKOL_ASSERT((index >= 0) && (index < SG_MAX_VERTEXBUFFER_BINDSLOTS));
    if (vb) {
        return (_sg.wgpu.bindings_cache.vbs[index].buffer.id != vb->slot.id)
            || (_sg.wgpu.bindings_cache.vbs[index].offset != offset);
    } else {
        return _sg.wgpu.bindings_cache.vbs[index].buffer.id != SG_INVALID_ID;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_bindings_cache_vb_update(size_t index, const _sg_buffer_t* vb, uint64_t offset) {
    SOKOL_ASSERT((index >= 0) && (index < SG_MAX_VERTEXBUFFER_BINDSLOTS));
    if (vb) {
        _sg.wgpu.bindings_cache.vbs[index].buffer.id = vb->slot.id;
        _sg.wgpu.bindings_cache.vbs[index].offset = offset;
    } else {
        _sg.wgpu.bindings_cache.vbs[index].buffer.id = SG_INVALID_ID;
        _sg.wgpu.bindings_cache.vbs[index].offset = 0;
    }
}

_SOKOL_PRIVATE bool _sg_wgpu_bindings_cache_ib_dirty(const _sg_buffer_t* ib, uint64_t offset) {
    if (ib) {
        return (_sg.wgpu.bindings_cache.ib.buffer.id != ib->slot.id)
            || (_sg.wgpu.bindings_cache.ib.offset != offset);
    } else {
        return _sg.wgpu.bindings_cache.ib.buffer.id != SG_INVALID_ID;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_bindings_cache_ib_update(const _sg_buffer_t* ib, uint64_t offset) {
    if (ib) {
        _sg.wgpu.bindings_cache.ib.buffer.id = ib->slot.id;
        _sg.wgpu.bindings_cache.ib.offset = offset;
    } else {
        _sg.wgpu.bindings_cache.ib.buffer.id = SG_INVALID_ID;
        _sg.wgpu.bindings_cache.ib.offset = 0;
    }
}

_SOKOL_PRIVATE bool _sg_wgpu_bindings_cache_bg_dirty(const _sg_wgpu_bindgroup_t* bg) {
    if (bg) {
        return _sg.wgpu.bindings_cache.bg.id != bg->slot.id;
    } else {
        return _sg.wgpu.bindings_cache.bg.id != SG_INVALID_ID;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_bindings_cache_bg_update(const _sg_wgpu_bindgroup_t* bg) {
    if (bg) {
        _sg.wgpu.bindings_cache.bg.id = bg->slot.id;
    } else {
        _sg.wgpu.bindings_cache.bg.id = SG_INVALID_ID;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_set_bindgroup(size_t bg_idx, _sg_wgpu_bindgroup_t* bg) {
    if (_sg_wgpu_bindings_cache_bg_dirty(bg)) {
        _sg_wgpu_bindings_cache_bg_update(bg);
        _sg_stats_add(wgpu.bindings.num_set_bindgroup, 1);
        if (_sg.cur_pass.is_compute) {
            SOKOL_ASSERT(_sg.wgpu.cpass_enc);
            if (bg) {
                SOKOL_ASSERT(bg->slot.state == SG_RESOURCESTATE_VALID);
                SOKOL_ASSERT(bg->bindgroup);
                wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, bg_idx, bg->bindgroup, 0, 0);
            } else {
                wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, bg_idx, _sg.wgpu.empty_bind_group, 0, 0);
            }
        } else {
            SOKOL_ASSERT(_sg.wgpu.rpass_enc);
            if (bg) {
                SOKOL_ASSERT(bg->slot.state == SG_RESOURCESTATE_VALID);
                SOKOL_ASSERT(bg->bindgroup);
                wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.rpass_enc, bg_idx, bg->bindgroup, 0, 0);
            } else {
                wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.rpass_enc, bg_idx, _sg.wgpu.empty_bind_group, 0, 0);
            }
        }
    } else {
        _sg_stats_add(wgpu.bindings.num_skip_redundant_bindgroup, 1);
    }
}

_SOKOL_PRIVATE bool _sg_wgpu_apply_bindings_bindgroup(_sg_bindings_ptrs_t* bnd) {
    if (!_sg.desc.wgpu_disable_bindgroups_cache) {
        _sg_wgpu_bindgroup_t* bg = 0;
        _sg_wgpu_bindgroups_cache_key_t key;
        _sg_wgpu_init_bindgroups_cache_key(&key, bnd);
        uint32_t bg_id = _sg_wgpu_bindgroups_cache_get(key.hash);
        if (bg_id != SG_INVALID_ID) {
            // potential cache hit
            bg = _sg_wgpu_lookup_bindgroup(bg_id);
            SOKOL_ASSERT(bg && (bg->slot.state == SG_RESOURCESTATE_VALID));
            if (!_sg_wgpu_compare_bindgroups_cache_key(&key, &bg->key)) {
                // cache collision, need to delete cached bindgroup
                _sg_stats_add(wgpu.bindings.num_bindgroup_cache_collisions, 1);
                _sg_wgpu_discard_bindgroup(bg);
                _sg_wgpu_bindgroups_cache_set(key.hash, SG_INVALID_ID);
                bg = 0;
            } else {
                _sg_stats_add(wgpu.bindings.num_bindgroup_cache_hits, 1);
            }
        } else {
            _sg_stats_add(wgpu.bindings.num_bindgroup_cache_misses, 1);
        }
        if (bg == 0) {
            // either no cache entry yet, or cache collision, create new bindgroup and store in cache
            bg = _sg_wgpu_create_bindgroup(bnd);
            _sg_wgpu_bindgroups_cache_set(key.hash, bg->slot.id);
        }
        if (bg && bg->slot.state == SG_RESOURCESTATE_VALID) {
            _sg_wgpu_set_bindgroup(_SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX, bg);
        } else {
            return false;
        }
    } else {
        // bindgroups cache disabled, create and destroy bindgroup on the fly (expensive!)
        _sg_wgpu_bindgroup_t* bg = _sg_wgpu_create_bindgroup(bnd);
        if (bg) {
            if (bg->slot.state == SG_RESOURCESTATE_VALID) {
                _sg_wgpu_set_bindgroup(_SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX, bg);
            }
            _sg_wgpu_discard_bindgroup(bg);
        } else {
            return false;
        }
    }
    return true;
}

_SOKOL_PRIVATE bool _sg_wgpu_apply_index_buffer(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(_sg.wgpu.rpass_enc);
    const _sg_buffer_t* ib = bnd->ib;
    uint64_t offset = (uint64_t)bnd->ib_offset;
    if (_sg_wgpu_bindings_cache_ib_dirty(ib, offset)) {
        _sg_wgpu_bindings_cache_ib_update(ib, offset);
        if (ib) {
            const WGPUIndexFormat format = _sg_wgpu_indexformat(bnd->pip->cmn.index_type);
            const uint64_t buf_size = (uint64_t)ib->cmn.size;
            SOKOL_ASSERT(buf_size > offset);
            const uint64_t max_bytes = buf_size - offset;
            wgpuRenderPassEncoderSetIndexBuffer(_sg.wgpu.rpass_enc, ib->wgpu.buf, format, offset, max_bytes);
        /* FIXME: the else-pass should actually set a null index buffer, but that doesn't seem to work yet
        } else {
            wgpuRenderPassEncoderSetIndexBuffer(_sg.wgpu.rpass_enc, 0, WGPUIndexFormat_Undefined, 0, 0);
        */
        }
        _sg_stats_add(wgpu.bindings.num_set_index_buffer, 1);
    } else {
        _sg_stats_add(wgpu.bindings.num_skip_redundant_index_buffer, 1);
    }
    return true;
}

_SOKOL_PRIVATE bool _sg_wgpu_apply_vertex_buffers(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(_sg.wgpu.rpass_enc);
    for (uint32_t slot = 0; slot < SG_MAX_VERTEXBUFFER_BINDSLOTS; slot++) {
        const _sg_buffer_t* vb = bnd->vbs[slot];
        const uint64_t offset = (uint64_t)bnd->vb_offsets[slot];
        if (_sg_wgpu_bindings_cache_vb_dirty(slot, vb, offset)) {
            _sg_wgpu_bindings_cache_vb_update(slot, vb, offset);
            if (vb) {
                const uint64_t buf_size = (uint64_t)vb->cmn.size;
                SOKOL_ASSERT(buf_size > offset);
                const uint64_t max_bytes = buf_size - offset;
                wgpuRenderPassEncoderSetVertexBuffer(_sg.wgpu.rpass_enc, slot, vb->wgpu.buf, offset, max_bytes);
            /* FIXME: the else-pass should actually set a null vertex buffer, but that doesn't seem to work yet
            } else {
                wgpuRenderPassEncoderSetVertexBuffer(_sg.wgpu.rpass_enc, slot, 0, 0, 0);
            */
            }
            _sg_stats_add(wgpu.bindings.num_set_vertex_buffer, 1);
        } else {
            _sg_stats_add(wgpu.bindings.num_skip_redundant_vertex_buffer, 1);
        }
    }
    return true;
}

_SOKOL_PRIVATE void _sg_wgpu_setup_backend(const sg_desc* desc) {
    SOKOL_ASSERT(desc);
    SOKOL_ASSERT(desc->environment.wgpu.device);
    SOKOL_ASSERT(desc->uniform_buffer_size > 0);
    _sg.backend = SG_BACKEND_WGPU;
    _sg.wgpu.valid = true;
    _sg.wgpu.dev = (WGPUDevice) desc->environment.wgpu.device;
    _sg.wgpu.queue = wgpuDeviceGetQueue(_sg.wgpu.dev);
    SOKOL_ASSERT(_sg.wgpu.queue);

    _sg_wgpu_init_caps();
    _sg_wgpu_uniform_buffer_init(desc);
    _sg_wgpu_bindgroups_pool_init(desc);
    _sg_wgpu_bindgroups_cache_init(desc);
    _sg_wgpu_bindings_cache_clear();

    // create an empty bind group
    WGPUBindGroupLayoutDescriptor bgl_desc;
    _sg_clear(&bgl_desc, sizeof(bgl_desc));
    WGPUBindGroupLayout empty_bgl = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &bgl_desc);
    SOKOL_ASSERT(empty_bgl);
    WGPUBindGroupDescriptor bg_desc;
    _sg_clear(&bg_desc, sizeof(bg_desc));
    bg_desc.layout = empty_bgl;
    _sg.wgpu.empty_bind_group = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);
    SOKOL_ASSERT(_sg.wgpu.empty_bind_group);
    wgpuBindGroupLayoutRelease(empty_bgl);

    // create initial per-frame command encoder
    WGPUCommandEncoderDescriptor cmd_enc_desc;
    _sg_clear(&cmd_enc_desc, sizeof(cmd_enc_desc));
    _sg.wgpu.cmd_enc = wgpuDeviceCreateCommandEncoder(_sg.wgpu.dev, &cmd_enc_desc);
    SOKOL_ASSERT(_sg.wgpu.cmd_enc);
}

_SOKOL_PRIVATE void _sg_wgpu_discard_backend(void) {
    SOKOL_ASSERT(_sg.wgpu.valid);
    SOKOL_ASSERT(_sg.wgpu.cmd_enc);
    _sg.wgpu.valid = false;
    _sg_wgpu_discard_all_bindgroups();
    _sg_wgpu_bindgroups_cache_discard();
    _sg_wgpu_bindgroups_pool_discard();
    _sg_wgpu_uniform_buffer_discard();
    wgpuBindGroupRelease(_sg.wgpu.empty_bind_group); _sg.wgpu.empty_bind_group = 0;
    wgpuCommandEncoderRelease(_sg.wgpu.cmd_enc); _sg.wgpu.cmd_enc = 0;
    wgpuQueueRelease(_sg.wgpu.queue); _sg.wgpu.queue = 0;
}

_SOKOL_PRIVATE void _sg_wgpu_reset_state_cache(void) {
    _sg_wgpu_bindings_cache_clear();
}

_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(buf && desc);
    SOKOL_ASSERT(buf->cmn.size > 0);
    const bool injected = (0 != desc->wgpu_buffer);
    if (injected) {
        buf->wgpu.buf = (WGPUBuffer) desc->wgpu_buffer;
        wgpuBufferReference(buf->wgpu.buf);
    } else {
        // buffer mapping size must be multiple of 4, so round up buffer size (only a problem
        // with index buffers containing odd number of indices)
        const uint64_t wgpu_buf_size = _sg_roundup_u64((uint64_t)buf->cmn.size, 4);
        const bool map_at_creation = buf->cmn.usage.immutable && (desc->data.ptr);

        WGPUBufferDescriptor wgpu_buf_desc;
        _sg_clear(&wgpu_buf_desc, sizeof(wgpu_buf_desc));
        wgpu_buf_desc.usage = _sg_wgpu_buffer_usage(&buf->cmn.usage);
        wgpu_buf_desc.size = wgpu_buf_size;
        wgpu_buf_desc.mappedAtCreation = map_at_creation;
        wgpu_buf_desc.label = _sg_wgpu_stringview(desc->label);
        buf->wgpu.buf = wgpuDeviceCreateBuffer(_sg.wgpu.dev, &wgpu_buf_desc);
        if (0 == buf->wgpu.buf) {
            _SG_ERROR(WGPU_CREATE_BUFFER_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        // NOTE: assume that WebGPU creates zero-initialized buffers
        if (map_at_creation) {
            SOKOL_ASSERT(desc->data.ptr && (desc->data.size > 0));
            SOKOL_ASSERT(desc->data.size <= (size_t)buf->cmn.size);
            // FIXME: inefficient on WASM
            void* ptr = wgpuBufferGetMappedRange(buf->wgpu.buf, 0, wgpu_buf_size);
            SOKOL_ASSERT(ptr);
            memcpy(ptr, desc->data.ptr, desc->data.size);
            wgpuBufferUnmap(buf->wgpu.buf);
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf);
    if (buf->cmn.usage.storage_buffer) {
        _sg_wgpu_bindgroups_cache_invalidate(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_STORAGEBUFFER, buf->slot.id);
    }
    if (buf->wgpu.buf) {
        wgpuBufferRelease(buf->wgpu.buf);
    }
}

_SOKOL_PRIVATE void _sg_wgpu_copy_buffer_data(const _sg_buffer_t* buf, uint64_t offset, const sg_range* data) {
    SOKOL_ASSERT((offset + data->size) <= (size_t)buf->cmn.size);
    // WebGPU's write-buffer requires the size to be a multiple of four, so we may need to split the copy
    // operation into two writeBuffer calls
    uint64_t clamped_size = data->size & ~3UL;
    uint64_t extra_size = data->size & 3UL;
    SOKOL_ASSERT(extra_size < 4);
    wgpuQueueWriteBuffer(_sg.wgpu.queue, buf->wgpu.buf, offset, data->ptr, clamped_size);
    if (extra_size > 0) {
        const uint64_t extra_src_offset = clamped_size;
        const uint64_t extra_dst_offset = offset + clamped_size;
        uint8_t extra_data[4] = { 0 };
        uint8_t* extra_src_ptr = ((uint8_t*)data->ptr) + extra_src_offset;
        for (size_t i = 0; i < extra_size; i++) {
            extra_data[i] = extra_src_ptr[i];
        }
        wgpuQueueWriteBuffer(_sg.wgpu.queue, buf->wgpu.buf, extra_dst_offset, extra_src_ptr, 4);
    }
}

_SOKOL_PRIVATE void _sg_wgpu_copy_image_data(const _sg_image_t* img, WGPUTexture wgpu_tex, const sg_image_data* data) {
    WGPUTextureDataLayout wgpu_layout;
    _sg_clear(&wgpu_layout, sizeof(wgpu_layout));
    WGPUImageCopyTexture wgpu_copy_tex;
    _sg_clear(&wgpu_copy_tex, sizeof(wgpu_copy_tex));
    wgpu_copy_tex.texture = wgpu_tex;
    wgpu_copy_tex.aspect = WGPUTextureAspect_All;
    WGPUExtent3D wgpu_extent;
    _sg_clear(&wgpu_extent, sizeof(wgpu_extent));
    const int num_faces = (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6 : 1;
    for (int face_index = 0; face_index < num_faces; face_index++) {
        for (int mip_index = 0; mip_index < img->cmn.num_mipmaps; mip_index++) {
            wgpu_copy_tex.mipLevel = (uint32_t)mip_index;
            wgpu_copy_tex.origin.z = (uint32_t)face_index;
            int mip_width = _sg_miplevel_dim(img->cmn.width, mip_index);
            int mip_height = _sg_miplevel_dim(img->cmn.height, mip_index);
            int mip_slices;
            switch (img->cmn.type) {
                case SG_IMAGETYPE_CUBE:
                    mip_slices = 1;
                    break;
                case SG_IMAGETYPE_3D:
                    mip_slices = _sg_miplevel_dim(img->cmn.num_slices, mip_index);
                    break;
                default:
                    mip_slices = img->cmn.num_slices;
                    break;
            }
            const int row_pitch = _sg_row_pitch(img->cmn.pixel_format, mip_width, 1);
            const int num_rows = _sg_num_rows(img->cmn.pixel_format, mip_height);
            if (_sg_is_compressed_pixel_format(img->cmn.pixel_format)) {
                mip_width = _sg_roundup(mip_width, 4);
                mip_height = _sg_roundup(mip_height, 4);
            }
            wgpu_layout.offset = 0;
            wgpu_layout.bytesPerRow = (uint32_t)row_pitch;
            wgpu_layout.rowsPerImage = (uint32_t)num_rows;
            wgpu_extent.width = (uint32_t)mip_width;
            wgpu_extent.height = (uint32_t)mip_height;
            wgpu_extent.depthOrArrayLayers = (uint32_t)mip_slices;
            const sg_range* mip_data = &data->subimage[face_index][mip_index];
            wgpuQueueWriteTexture(_sg.wgpu.queue, &wgpu_copy_tex, mip_data->ptr, mip_data->size, &wgpu_layout, &wgpu_extent);
        }
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_image(_sg_image_t* img, const sg_image_desc* desc) {
    SOKOL_ASSERT(img && desc);
    const bool injected = (0 != desc->wgpu_texture);
    if (injected) {
        img->wgpu.tex = (WGPUTexture)desc->wgpu_texture;
        wgpuTextureReference(img->wgpu.tex);
        img->wgpu.view = (WGPUTextureView)desc->wgpu_texture_view;
        if (img->wgpu.view) {
            wgpuTextureViewReference(img->wgpu.view);
        }
    } else {
        WGPUTextureDescriptor wgpu_tex_desc;
        _sg_clear(&wgpu_tex_desc, sizeof(wgpu_tex_desc));
        wgpu_tex_desc.label = _sg_wgpu_stringview(desc->label);
        wgpu_tex_desc.usage = WGPUTextureUsage_TextureBinding|WGPUTextureUsage_CopyDst;
        if (desc->usage.render_attachment) {
            wgpu_tex_desc.usage |= WGPUTextureUsage_RenderAttachment;
        }
        if (desc->usage.storage_attachment) {
            wgpu_tex_desc.usage |= WGPUTextureUsage_StorageBinding;
        }
        wgpu_tex_desc.dimension = _sg_wgpu_texture_dimension(img->cmn.type);
        wgpu_tex_desc.size.width = (uint32_t) img->cmn.width;
        wgpu_tex_desc.size.height = (uint32_t) img->cmn.height;
        if (desc->type == SG_IMAGETYPE_CUBE) {
            wgpu_tex_desc.size.depthOrArrayLayers = 6;
        } else {
            wgpu_tex_desc.size.depthOrArrayLayers = (uint32_t) img->cmn.num_slices;
        }
        wgpu_tex_desc.format = _sg_wgpu_textureformat(img->cmn.pixel_format);
        wgpu_tex_desc.mipLevelCount = (uint32_t) img->cmn.num_mipmaps;
        wgpu_tex_desc.sampleCount = (uint32_t) img->cmn.sample_count;
        img->wgpu.tex = wgpuDeviceCreateTexture(_sg.wgpu.dev, &wgpu_tex_desc);
        if (0 == img->wgpu.tex) {
            _SG_ERROR(WGPU_CREATE_TEXTURE_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
        if (desc->data.subimage[0][0].ptr) {
            _sg_wgpu_copy_image_data(img, img->wgpu.tex, &desc->data);
        }
        WGPUTextureViewDescriptor wgpu_texview_desc;
        _sg_clear(&wgpu_texview_desc, sizeof(wgpu_texview_desc));
        wgpu_texview_desc.label = _sg_wgpu_stringview(desc->label);
        wgpu_texview_desc.dimension = _sg_wgpu_texture_view_dimension(img->cmn.type);
        wgpu_texview_desc.mipLevelCount = (uint32_t)img->cmn.num_mipmaps;
        if (img->cmn.type == SG_IMAGETYPE_CUBE) {
            wgpu_texview_desc.arrayLayerCount = 6;
        } else if (img->cmn.type == SG_IMAGETYPE_ARRAY) {
            wgpu_texview_desc.arrayLayerCount = (uint32_t)img->cmn.num_slices;
        } else {
            wgpu_texview_desc.arrayLayerCount = 1;
        }
        if (_sg_is_depth_or_depth_stencil_format(img->cmn.pixel_format)) {
            wgpu_texview_desc.aspect = WGPUTextureAspect_DepthOnly;
        } else {
            wgpu_texview_desc.aspect = WGPUTextureAspect_All;
        }
        img->wgpu.view = wgpuTextureCreateView(img->wgpu.tex, &wgpu_texview_desc);
        if (0 == img->wgpu.view) {
            _SG_ERROR(WGPU_CREATE_TEXTURE_VIEW_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_image(_sg_image_t* img) {
    SOKOL_ASSERT(img);
    _sg_wgpu_bindgroups_cache_invalidate(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_IMAGE, img->slot.id);
    if (img->wgpu.view) {
        wgpuTextureViewRelease(img->wgpu.view);
        img->wgpu.view = 0;
    }
    if (img->wgpu.tex) {
        wgpuTextureRelease(img->wgpu.tex);
        img->wgpu.tex = 0;
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(smp && desc);
    SOKOL_ASSERT(_sg.wgpu.dev);
    const bool injected = (0 != desc->wgpu_sampler);
    if (injected) {
        smp->wgpu.smp = (WGPUSampler) desc->wgpu_sampler;
        wgpuSamplerReference(smp->wgpu.smp);
    } else {
        WGPUSamplerDescriptor wgpu_desc;
        _sg_clear(&wgpu_desc, sizeof(wgpu_desc));
        wgpu_desc.label = _sg_wgpu_stringview(desc->label);
        wgpu_desc.addressModeU = _sg_wgpu_sampler_address_mode(desc->wrap_u);
        wgpu_desc.addressModeV = _sg_wgpu_sampler_address_mode(desc->wrap_v);
        wgpu_desc.addressModeW = _sg_wgpu_sampler_address_mode(desc->wrap_w);
        wgpu_desc.magFilter = _sg_wgpu_sampler_minmag_filter(desc->mag_filter);
        wgpu_desc.minFilter = _sg_wgpu_sampler_minmag_filter(desc->min_filter);
        wgpu_desc.mipmapFilter = _sg_wgpu_sampler_mipmap_filter(desc->mipmap_filter);
        wgpu_desc.lodMinClamp = desc->min_lod;
        wgpu_desc.lodMaxClamp = desc->max_lod;
        wgpu_desc.compare = _sg_wgpu_comparefunc(desc->compare);
        if (wgpu_desc.compare == WGPUCompareFunction_Never) {
            wgpu_desc.compare = WGPUCompareFunction_Undefined;
        }
        wgpu_desc.maxAnisotropy = (uint16_t)desc->max_anisotropy;
        smp->wgpu.smp = wgpuDeviceCreateSampler(_sg.wgpu.dev, &wgpu_desc);
        if (0 == smp->wgpu.smp) {
            _SG_ERROR(WGPU_CREATE_SAMPLER_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp);
    _sg_wgpu_bindgroups_cache_invalidate(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_SAMPLER, smp->slot.id);
    if (smp->wgpu.smp) {
        wgpuSamplerRelease(smp->wgpu.smp);
        smp->wgpu.smp = 0;
    }
}

_SOKOL_PRIVATE _sg_wgpu_shader_func_t _sg_wgpu_create_shader_func(const sg_shader_function* func, const char* label) {
    SOKOL_ASSERT(func);
    SOKOL_ASSERT(func->source);
    SOKOL_ASSERT(func->entry);

    _sg_wgpu_shader_func_t res;
    _sg_clear(&res, sizeof(res));
    _sg_strcpy(&res.entry, func->entry);

    WGPUShaderModuleWGSLDescriptor wgpu_shdmod_wgsl_desc;
    _sg_clear(&wgpu_shdmod_wgsl_desc, sizeof(wgpu_shdmod_wgsl_desc));
    wgpu_shdmod_wgsl_desc.chain.sType = WGPUSType_ShaderModuleWGSLDescriptor;
    wgpu_shdmod_wgsl_desc.code = _sg_wgpu_stringview(func->source);

    WGPUShaderModuleDescriptor wgpu_shdmod_desc;
    _sg_clear(&wgpu_shdmod_desc, sizeof(wgpu_shdmod_desc));
    wgpu_shdmod_desc.nextInChain = &wgpu_shdmod_wgsl_desc.chain;
    wgpu_shdmod_desc.label = _sg_wgpu_stringview(label);

    // NOTE: if compilation fails we won't actually find out in this call since
    // it always returns a valid module handle, and the GetCompilationInfo() call
    // is asynchronous
    res.module = wgpuDeviceCreateShaderModule(_sg.wgpu.dev, &wgpu_shdmod_desc);
    if (0 == res.module) {
        _SG_ERROR(WGPU_CREATE_SHADER_MODULE_FAILED);
    }
    return res;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_shader_func(_sg_wgpu_shader_func_t* func) {
    if (func->module) {
        wgpuShaderModuleRelease(func->module);
        func->module = 0;
    }
}

typedef struct { uint8_t sokol_slot, wgpu_slot; } _sg_wgpu_dynoffset_mapping_t;

_SOKOL_PRIVATE int _sg_wgpu_dynoffset_cmp(const void* a, const void* b) {
    const _sg_wgpu_dynoffset_mapping_t* aa = (const _sg_wgpu_dynoffset_mapping_t*)a;
    const _sg_wgpu_dynoffset_mapping_t* bb = (const _sg_wgpu_dynoffset_mapping_t*)b;
    if (aa->wgpu_slot < bb->wgpu_slot) return -1;
    else if (aa->wgpu_slot > bb->wgpu_slot) return 1;
    return 0;
}

// NOTE: this is an out-of-range check for WGSL bindslots that's also active in release mode
_SOKOL_PRIVATE bool _sg_wgpu_ensure_wgsl_bindslot_ranges(const sg_shader_desc* desc) {
    SOKOL_ASSERT(desc);
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        if (desc->uniform_blocks[i].wgsl_group0_binding_n >= _SG_WGPU_MAX_UB_BINDGROUP_BIND_SLOTS) {
            _SG_ERROR(WGPU_UNIFORMBLOCK_WGSL_GROUP0_BINDING_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (desc->storage_buffers[i].wgsl_group1_binding_n >= _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS) {
            _SG_ERROR(WGPU_STORAGEBUFFER_WGSL_GROUP1_BINDING_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (desc->images[i].wgsl_group1_binding_n >= _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS) {
            _SG_ERROR(WGPU_IMAGE_WGSL_GROUP1_BINDING_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (desc->samplers[i].wgsl_group1_binding_n >= _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS) {
            _SG_ERROR(WGPU_SAMPLER_WGSL_GROUP1_BINDING_OUT_OF_RANGE);
            return false;
        }
    }
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (desc->storage_images[i].wgsl_group2_binding_n >= _SG_WGPU_MAX_SIMG_BIND_SLOTS) {
            _SG_ERROR(WGPU_STORAGEIMAGE_WGSL_GROUP2_BINDING_OUT_OF_RANGE);
        }
    }
    return true;
}

_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    SOKOL_ASSERT(shd && desc);
    SOKOL_ASSERT(shd->wgpu.vertex_func.module == 0);
    SOKOL_ASSERT(shd->wgpu.fragment_func.module == 0);
    SOKOL_ASSERT(shd->wgpu.compute_func.module == 0);
    SOKOL_ASSERT(shd->wgpu.bgl_ub == 0);
    SOKOL_ASSERT(shd->wgpu.bg_ub == 0);
    SOKOL_ASSERT(shd->wgpu.bgl_img_smp_sbuf == 0);

    // do a release-mode bounds-check on wgsl bindslots, even though out-of-range
    // bindslots can't cause out-of-bounds accesses in the wgpu backend, this
    // is done to be consistent with the other backends
    if (!_sg_wgpu_ensure_wgsl_bindslot_ranges(desc)) {
        return SG_RESOURCESTATE_FAILED;
    }

    // build shader modules
    bool shd_valid = true;
    if (desc->vertex_func.source) {
        shd->wgpu.vertex_func = _sg_wgpu_create_shader_func(&desc->vertex_func, desc->label);
        shd_valid &= shd->wgpu.vertex_func.module != 0;
    }
    if (desc->fragment_func.source) {
        shd->wgpu.fragment_func = _sg_wgpu_create_shader_func(&desc->fragment_func, desc->label);
        shd_valid &= shd->wgpu.fragment_func.module != 0;
    }
    if (desc->compute_func.source) {
        shd->wgpu.compute_func = _sg_wgpu_create_shader_func(&desc->compute_func, desc->label);
        shd_valid &= shd->wgpu.compute_func.module != 0;
    }
    if (!shd_valid) {
        _sg_wgpu_discard_shader_func(&shd->wgpu.vertex_func);
        _sg_wgpu_discard_shader_func(&shd->wgpu.fragment_func);
        _sg_wgpu_discard_shader_func(&shd->wgpu.compute_func);
        return SG_RESOURCESTATE_FAILED;
    }

    // create bind group layout and bind group for uniform blocks
    // NOTE also need to create a mapping of sokol ub bind slots to array indices
    // for the dynamic offsets array in the setBindGroup call
    SOKOL_ASSERT(_SG_WGPU_MAX_UB_BINDGROUP_ENTRIES <= _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES);
    SOKOL_ASSERT(_SG_WGPU_MAX_SIMG_BINDGROUP_ENTRIES <= _SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES);
    WGPUBindGroupLayoutEntry bgl_entries[_SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES];
    _sg_clear(bgl_entries, sizeof(bgl_entries));
    WGPUBindGroupLayoutDescriptor bgl_desc;
    _sg_clear(&bgl_desc, sizeof(bgl_desc));
    WGPUBindGroupEntry bg_entries[_SG_WGPU_MAX_IMG_SMP_SBUF_BINDGROUP_ENTRIES];
    _sg_clear(&bg_entries, sizeof(bg_entries));
    WGPUBindGroupDescriptor bg_desc;
    _sg_clear(&bg_desc, sizeof(bg_desc));
    _sg_wgpu_dynoffset_mapping_t dynoffset_map[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
    _sg_clear(dynoffset_map, sizeof(dynoffset_map));
    size_t bgl_index = 0;
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        if (shd->cmn.uniform_blocks[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        shd->wgpu.ub_grp0_bnd_n[i] = desc->uniform_blocks[i].wgsl_group0_binding_n;
        WGPUBindGroupEntry* bg_entry = &bg_entries[bgl_index];
        WGPUBindGroupLayoutEntry* bgl_entry = &bgl_entries[bgl_index];
        bgl_entry->binding = shd->wgpu.ub_grp0_bnd_n[i];
        bgl_entry->visibility = _sg_wgpu_shader_stage(shd->cmn.uniform_blocks[i].stage);
        bgl_entry->buffer.type = WGPUBufferBindingType_Uniform;
        bgl_entry->buffer.hasDynamicOffset = true;
        bg_entry->binding = bgl_entry->binding;
        bg_entry->buffer = _sg.wgpu.uniform.buf;
        bg_entry->size = _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE;
        dynoffset_map[i].sokol_slot = i;
        dynoffset_map[i].wgpu_slot = bgl_entry->binding;
        bgl_index += 1;
    }
    bgl_desc.entryCount = bgl_index;
    bgl_desc.entries = bgl_entries;
    shd->wgpu.bgl_ub = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &bgl_desc);
    SOKOL_ASSERT(shd->wgpu.bgl_ub);
    bg_desc.layout = shd->wgpu.bgl_ub;
    bg_desc.entryCount = bgl_index;
    bg_desc.entries = bg_entries;
    shd->wgpu.bg_ub = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);
    SOKOL_ASSERT(shd->wgpu.bg_ub);

    // sort the dynoffset_map by wgpu bindings, this is because the
    // dynamic offsets of the WebGPU setBindGroup call must be in
    // 'binding order', not 'bindgroup entry order'
    qsort(dynoffset_map, bgl_index, sizeof(_sg_wgpu_dynoffset_mapping_t), _sg_wgpu_dynoffset_cmp);
    shd->wgpu.ub_num_dynoffsets = bgl_index;
    for (uint8_t i = 0; i < bgl_index; i++) {
        const uint8_t sokol_slot = dynoffset_map[i].sokol_slot;
        shd->wgpu.ub_dynoffsets[sokol_slot] = i;
    }

    // create bind group layout for images, samplers and storage buffers
    _sg_clear(bgl_entries, sizeof(bgl_entries));
    _sg_clear(&bgl_desc, sizeof(bgl_desc));
    bgl_index = 0;
    for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (shd->cmn.images[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        const bool msaa = shd->cmn.images[i].multisampled;
        shd->wgpu.img_grp1_bnd_n[i] = desc->images[i].wgsl_group1_binding_n;
        WGPUBindGroupLayoutEntry* bgl_entry = &bgl_entries[bgl_index];
        bgl_entry->binding = shd->wgpu.img_grp1_bnd_n[i];
        bgl_entry->visibility = _sg_wgpu_shader_stage(shd->cmn.images[i].stage);
        bgl_entry->texture.viewDimension = _sg_wgpu_texture_view_dimension(shd->cmn.images[i].image_type);
        bgl_entry->texture.sampleType = _sg_wgpu_texture_sample_type(shd->cmn.images[i].sample_type, msaa);
        bgl_entry->texture.multisampled = msaa;
        bgl_index += 1;
    }
    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (shd->cmn.samplers[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        shd->wgpu.smp_grp1_bnd_n[i] = desc->samplers[i].wgsl_group1_binding_n;
        WGPUBindGroupLayoutEntry* bgl_entry = &bgl_entries[bgl_index];
        bgl_entry->binding = shd->wgpu.smp_grp1_bnd_n[i];
        bgl_entry->visibility = _sg_wgpu_shader_stage(shd->cmn.samplers[i].stage);
        bgl_entry->sampler.type = _sg_wgpu_sampler_binding_type(shd->cmn.samplers[i].sampler_type);
        bgl_index += 1;
    }
    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (shd->cmn.storage_buffers[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        shd->wgpu.sbuf_grp1_bnd_n[i] = desc->storage_buffers[i].wgsl_group1_binding_n;
        WGPUBindGroupLayoutEntry* bgl_entry = &bgl_entries[bgl_index];
        bgl_entry->binding = shd->wgpu.sbuf_grp1_bnd_n[i];
        bgl_entry->visibility = _sg_wgpu_shader_stage(shd->cmn.storage_buffers[i].stage);
        if (shd->cmn.storage_buffers[i].readonly) {
            bgl_entry->buffer.type = WGPUBufferBindingType_ReadOnlyStorage;
        } else {
            bgl_entry->buffer.type = WGPUBufferBindingType_Storage;
        }
        bgl_index += 1;
    }
    bgl_desc.entryCount = bgl_index;
    bgl_desc.entries = bgl_entries;
    shd->wgpu.bgl_img_smp_sbuf = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &bgl_desc);
    if (shd->wgpu.bgl_img_smp_sbuf == 0) {
        _SG_ERROR(WGPU_SHADER_CREATE_BINDGROUP_LAYOUT_FAILED);
        return SG_RESOURCESTATE_FAILED;
    }

    // create optional bindgroup layout for storage images (separate bindgroup because
    // those are not applied in sg_apply_bindings() but are defined as pass attachments)
    _sg_clear(bgl_entries, sizeof(bgl_entries));
    _sg_clear(&bgl_desc, sizeof(bgl_desc));
    bgl_index = 0;
    for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (shd->cmn.storage_images[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        shd->wgpu.simg_grp2_bnd_n[i] = desc->storage_images[i].wgsl_group2_binding_n;
        WGPUBindGroupLayoutEntry* bgl_entry = &bgl_entries[bgl_index];
        bgl_entry->binding = shd->wgpu.simg_grp2_bnd_n[i];
        bgl_entry->visibility = _sg_wgpu_shader_stage(shd->cmn.storage_images[i].stage);
        if (shd->cmn.storage_images[i].writeonly) {
            bgl_entry->storageTexture.access = WGPUStorageTextureAccess_WriteOnly;
        } else {
            bgl_entry->storageTexture.access = WGPUStorageTextureAccess_ReadWrite;
        }
        bgl_entry->storageTexture.format = _sg_wgpu_textureformat(desc->storage_images[i].access_format);
        bgl_entry->texture.viewDimension = _sg_wgpu_texture_view_dimension(shd->cmn.storage_images[i].image_type);
        bgl_index += 1;
    }
    if (bgl_index > 0) {
        bgl_desc.entryCount = bgl_index;
        bgl_desc.entries = bgl_entries;
        shd->wgpu.bgl_simg = wgpuDeviceCreateBindGroupLayout(_sg.wgpu.dev, &bgl_desc);
        if (shd->wgpu.bgl_simg == 0) {
            _SG_ERROR(WGPU_SHADER_CREATE_BINDGROUP_LAYOUT_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd);
    _sg_wgpu_discard_shader_func(&shd->wgpu.vertex_func);
    _sg_wgpu_discard_shader_func(&shd->wgpu.fragment_func);
    _sg_wgpu_discard_shader_func(&shd->wgpu.compute_func);
    if (shd->wgpu.bgl_ub) {
        wgpuBindGroupLayoutRelease(shd->wgpu.bgl_ub);
        shd->wgpu.bgl_ub = 0;
    }
    if (shd->wgpu.bg_ub) {
        wgpuBindGroupRelease(shd->wgpu.bg_ub);
        shd->wgpu.bg_ub = 0;
    }
    if (shd->wgpu.bgl_img_smp_sbuf) {
        wgpuBindGroupLayoutRelease(shd->wgpu.bgl_img_smp_sbuf);
        shd->wgpu.bgl_img_smp_sbuf = 0;
    }
    if (shd->wgpu.bgl_simg) {
        wgpuBindGroupLayoutRelease(shd->wgpu.bgl_simg);
        shd->wgpu.bgl_simg = 0;
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(pip && shd && desc);
    SOKOL_ASSERT(desc->shader.id == shd->slot.id);
    SOKOL_ASSERT(shd->wgpu.bgl_ub);
    SOKOL_ASSERT(shd->wgpu.bgl_img_smp_sbuf);
    pip->shader = shd;

    pip->wgpu.blend_color.r = (double) desc->blend_color.r;
    pip->wgpu.blend_color.g = (double) desc->blend_color.g;
    pip->wgpu.blend_color.b = (double) desc->blend_color.b;
    pip->wgpu.blend_color.a = (double) desc->blend_color.a;

    // - @group(0) for uniform blocks
    // - @group(1) for all image, sampler and storagebuffer resources
    // - @group(2) optional: storage image attachments in compute passes
    size_t num_bgls = 2;
    WGPUBindGroupLayout wgpu_bgl[_SG_WGPU_MAX_BINDGROUPS];
    _sg_clear(&wgpu_bgl, sizeof(wgpu_bgl));
    wgpu_bgl[_SG_WGPU_UB_BINDGROUP_INDEX ] = shd->wgpu.bgl_ub;
    wgpu_bgl[_SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX] = shd->wgpu.bgl_img_smp_sbuf;
    if (shd->wgpu.bgl_simg) {
        wgpu_bgl[_SG_WGPU_SIMG_BINDGROUP_INDEX] = shd->wgpu.bgl_simg;
        num_bgls += 1;
    }
    WGPUPipelineLayoutDescriptor wgpu_pl_desc;
    _sg_clear(&wgpu_pl_desc, sizeof(wgpu_pl_desc));
    wgpu_pl_desc.bindGroupLayoutCount = num_bgls;
    wgpu_pl_desc.bindGroupLayouts = &wgpu_bgl[0];
    const WGPUPipelineLayout wgpu_pip_layout = wgpuDeviceCreatePipelineLayout(_sg.wgpu.dev, &wgpu_pl_desc);
    if (0 == wgpu_pip_layout) {
        _SG_ERROR(WGPU_CREATE_PIPELINE_LAYOUT_FAILED);
        return SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT(wgpu_pip_layout);

    if (pip->cmn.is_compute) {
        WGPUComputePipelineDescriptor wgpu_pip_desc;
        _sg_clear(&wgpu_pip_desc, sizeof(wgpu_pip_desc));
        wgpu_pip_desc.label = _sg_wgpu_stringview(desc->label);
        wgpu_pip_desc.layout = wgpu_pip_layout;
        wgpu_pip_desc.compute.module = shd->wgpu.compute_func.module;
        wgpu_pip_desc.compute.entryPoint = shd->wgpu.compute_func.entry.buf;
        pip->wgpu.cpip = wgpuDeviceCreateComputePipeline(_sg.wgpu.dev, &wgpu_pip_desc);
        wgpuPipelineLayoutRelease(wgpu_pip_layout);
        if (0 == pip->wgpu.cpip) {
            _SG_ERROR(WGPU_CREATE_COMPUTE_PIPELINE_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    } else {
        WGPUVertexBufferLayout wgpu_vb_layouts[SG_MAX_VERTEXBUFFER_BINDSLOTS];
        _sg_clear(wgpu_vb_layouts, sizeof(wgpu_vb_layouts));
        WGPUVertexAttribute wgpu_vtx_attrs[SG_MAX_VERTEXBUFFER_BINDSLOTS][SG_MAX_VERTEX_ATTRIBUTES];
        _sg_clear(wgpu_vtx_attrs, sizeof(wgpu_vtx_attrs));
        int wgpu_vb_num = 0;
        for (int vb_idx = 0; vb_idx < SG_MAX_VERTEXBUFFER_BINDSLOTS; vb_idx++, wgpu_vb_num++) {
            const sg_vertex_buffer_layout_state* vbl_state = &desc->layout.buffers[vb_idx];
            if (0 == vbl_state->stride) {
                break;
            }
            wgpu_vb_layouts[vb_idx].arrayStride = (uint64_t)vbl_state->stride;
            wgpu_vb_layouts[vb_idx].stepMode = _sg_wgpu_stepmode(vbl_state->step_func);
            wgpu_vb_layouts[vb_idx].attributes = &wgpu_vtx_attrs[vb_idx][0];
        }
        for (int va_idx = 0; va_idx < SG_MAX_VERTEX_ATTRIBUTES; va_idx++) {
            const sg_vertex_attr_state* va_state = &desc->layout.attrs[va_idx];
            if (SG_VERTEXFORMAT_INVALID == va_state->format) {
                break;
            }
            const int vb_idx = va_state->buffer_index;
            SOKOL_ASSERT(vb_idx < SG_MAX_VERTEXBUFFER_BINDSLOTS);
            SOKOL_ASSERT(pip->cmn.vertex_buffer_layout_active[vb_idx]);
            const size_t wgpu_attr_idx = wgpu_vb_layouts[vb_idx].attributeCount;
            wgpu_vb_layouts[vb_idx].attributeCount += 1;
            wgpu_vtx_attrs[vb_idx][wgpu_attr_idx].format = _sg_wgpu_vertexformat(va_state->format);
            wgpu_vtx_attrs[vb_idx][wgpu_attr_idx].offset = (uint64_t)va_state->offset;
            wgpu_vtx_attrs[vb_idx][wgpu_attr_idx].shaderLocation = (uint32_t)va_idx;
        }

        WGPURenderPipelineDescriptor wgpu_pip_desc;
        _sg_clear(&wgpu_pip_desc, sizeof(wgpu_pip_desc));
        WGPUDepthStencilState wgpu_ds_state;
        _sg_clear(&wgpu_ds_state, sizeof(wgpu_ds_state));
        WGPUFragmentState wgpu_frag_state;
        _sg_clear(&wgpu_frag_state, sizeof(wgpu_frag_state));
        WGPUColorTargetState wgpu_ctgt_state[SG_MAX_COLOR_ATTACHMENTS];
        _sg_clear(&wgpu_ctgt_state, sizeof(wgpu_ctgt_state));
        WGPUBlendState wgpu_blend_state[SG_MAX_COLOR_ATTACHMENTS];
        _sg_clear(&wgpu_blend_state, sizeof(wgpu_blend_state));
        wgpu_pip_desc.label = _sg_wgpu_stringview(desc->label);
        wgpu_pip_desc.layout = wgpu_pip_layout;
        wgpu_pip_desc.vertex.module = shd->wgpu.vertex_func.module;
        wgpu_pip_desc.vertex.entryPoint = shd->wgpu.vertex_func.entry.buf;
        wgpu_pip_desc.vertex.bufferCount = (size_t)wgpu_vb_num;
        wgpu_pip_desc.vertex.buffers = &wgpu_vb_layouts[0];
        wgpu_pip_desc.primitive.topology = _sg_wgpu_topology(desc->primitive_type);
        wgpu_pip_desc.primitive.stripIndexFormat = _sg_wgpu_stripindexformat(desc->primitive_type, desc->index_type);
        wgpu_pip_desc.primitive.frontFace = _sg_wgpu_frontface(desc->face_winding);
        wgpu_pip_desc.primitive.cullMode = _sg_wgpu_cullmode(desc->cull_mode);
        if (SG_PIXELFORMAT_NONE != desc->depth.pixel_format) {
            wgpu_ds_state.format = _sg_wgpu_textureformat(desc->depth.pixel_format);
            wgpu_ds_state.depthWriteEnabled = _sg_wgpu_optional_bool(desc->depth.write_enabled);
            wgpu_ds_state.depthCompare = _sg_wgpu_comparefunc(desc->depth.compare);
            wgpu_ds_state.stencilFront.compare = _sg_wgpu_comparefunc(desc->stencil.front.compare);
            wgpu_ds_state.stencilFront.failOp = _sg_wgpu_stencilop(desc->stencil.front.fail_op);
            wgpu_ds_state.stencilFront.depthFailOp = _sg_wgpu_stencilop(desc->stencil.front.depth_fail_op);
            wgpu_ds_state.stencilFront.passOp = _sg_wgpu_stencilop(desc->stencil.front.pass_op);
            wgpu_ds_state.stencilBack.compare = _sg_wgpu_comparefunc(desc->stencil.back.compare);
            wgpu_ds_state.stencilBack.failOp = _sg_wgpu_stencilop(desc->stencil.back.fail_op);
            wgpu_ds_state.stencilBack.depthFailOp = _sg_wgpu_stencilop(desc->stencil.back.depth_fail_op);
            wgpu_ds_state.stencilBack.passOp = _sg_wgpu_stencilop(desc->stencil.back.pass_op);
            wgpu_ds_state.stencilReadMask = desc->stencil.read_mask;
            wgpu_ds_state.stencilWriteMask = desc->stencil.write_mask;
            wgpu_ds_state.depthBias = (int32_t)desc->depth.bias;
            wgpu_ds_state.depthBiasSlopeScale = desc->depth.bias_slope_scale;
            wgpu_ds_state.depthBiasClamp = desc->depth.bias_clamp;
            wgpu_pip_desc.depthStencil = &wgpu_ds_state;
        }
        wgpu_pip_desc.multisample.count = (uint32_t)desc->sample_count;
        wgpu_pip_desc.multisample.mask = 0xFFFFFFFF;
        wgpu_pip_desc.multisample.alphaToCoverageEnabled = desc->alpha_to_coverage_enabled;
        if (desc->color_count > 0) {
            wgpu_frag_state.module = shd->wgpu.fragment_func.module;
            wgpu_frag_state.entryPoint = shd->wgpu.fragment_func.entry.buf;
            wgpu_frag_state.targetCount = (size_t)desc->color_count;
            wgpu_frag_state.targets = &wgpu_ctgt_state[0];
            for (int i = 0; i < desc->color_count; i++) {
                SOKOL_ASSERT(i < SG_MAX_COLOR_ATTACHMENTS);
                wgpu_ctgt_state[i].format = _sg_wgpu_textureformat(desc->colors[i].pixel_format);
                wgpu_ctgt_state[i].writeMask = _sg_wgpu_colorwritemask(desc->colors[i].write_mask);
                if (desc->colors[i].blend.enabled) {
                    wgpu_ctgt_state[i].blend = &wgpu_blend_state[i];
                    wgpu_blend_state[i].color.operation = _sg_wgpu_blendop(desc->colors[i].blend.op_rgb);
                    wgpu_blend_state[i].color.srcFactor = _sg_wgpu_blendfactor(desc->colors[i].blend.src_factor_rgb);
                    wgpu_blend_state[i].color.dstFactor = _sg_wgpu_blendfactor(desc->colors[i].blend.dst_factor_rgb);
                    wgpu_blend_state[i].alpha.operation = _sg_wgpu_blendop(desc->colors[i].blend.op_alpha);
                    wgpu_blend_state[i].alpha.srcFactor = _sg_wgpu_blendfactor(desc->colors[i].blend.src_factor_alpha);
                    wgpu_blend_state[i].alpha.dstFactor = _sg_wgpu_blendfactor(desc->colors[i].blend.dst_factor_alpha);
                }
            }
            wgpu_pip_desc.fragment = &wgpu_frag_state;
        }
        pip->wgpu.rpip = wgpuDeviceCreateRenderPipeline(_sg.wgpu.dev, &wgpu_pip_desc);
        wgpuPipelineLayoutRelease(wgpu_pip_layout);
        if (0 == pip->wgpu.rpip) {
            _SG_ERROR(WGPU_CREATE_RENDER_PIPELINE_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    _sg_wgpu_bindgroups_cache_invalidate(_SG_WGPU_BINDGROUPSCACHEITEMTYPE_PIPELINE, pip->slot.id);
    if (pip == _sg.wgpu.cur_pipeline) {
        _sg.wgpu.cur_pipeline = 0;
        _sg.wgpu.cur_pipeline_id.id = SG_INVALID_ID;
    }
    if (pip->wgpu.rpip) {
        wgpuRenderPipelineRelease(pip->wgpu.rpip);
        pip->wgpu.rpip = 0;
    }
    if (pip->wgpu.cpip) {
        wgpuComputePipelineRelease(pip->wgpu.cpip);
        pip->wgpu.cpip = 0;
    }
}

_SOKOL_PRIVATE sg_resource_state _sg_wgpu_create_attachments(_sg_attachments_t* atts, const _sg_attachments_ptrs_t* atts_ptrs, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(atts && atts_ptrs && desc);

    // copy image pointers and create renderable wgpu texture views
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        const sg_attachment_desc* color_desc = &desc->colors[i];
        _SOKOL_UNUSED(color_desc);
        SOKOL_ASSERT(color_desc->image.id != SG_INVALID_ID);
        SOKOL_ASSERT(0 == atts->wgpu.colors[i].image);
        SOKOL_ASSERT(atts_ptrs->color_images[i]);
        _sg_image_t* clr_img = atts_ptrs->color_images[i];
        SOKOL_ASSERT(clr_img->slot.id == color_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_color_format(clr_img->cmn.pixel_format));
        SOKOL_ASSERT(clr_img->wgpu.tex);
        atts->wgpu.colors[i].image = clr_img;

        WGPUTextureViewDescriptor wgpu_color_view_desc;
        _sg_clear(&wgpu_color_view_desc, sizeof(wgpu_color_view_desc));
        wgpu_color_view_desc.baseMipLevel = (uint32_t) color_desc->mip_level;
        wgpu_color_view_desc.mipLevelCount = 1;
        wgpu_color_view_desc.baseArrayLayer = (uint32_t) color_desc->slice;
        wgpu_color_view_desc.arrayLayerCount = 1;
        atts->wgpu.colors[i].view = wgpuTextureCreateView(clr_img->wgpu.tex, &wgpu_color_view_desc);
        if (0 == atts->wgpu.colors[i].view) {
            _SG_ERROR(WGPU_ATTACHMENTS_CREATE_TEXTURE_VIEW_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }

        const sg_attachment_desc* resolve_desc = &desc->resolves[i];
        if (resolve_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->wgpu.resolves[i].image);
            SOKOL_ASSERT(atts_ptrs->resolve_images[i]);
            _sg_image_t* rsv_img = atts_ptrs->resolve_images[i];
            SOKOL_ASSERT(rsv_img->slot.id == resolve_desc->image.id);
            SOKOL_ASSERT(clr_img->cmn.pixel_format == rsv_img->cmn.pixel_format);
            SOKOL_ASSERT(rsv_img->wgpu.tex);
            atts->wgpu.resolves[i].image = rsv_img;

            WGPUTextureViewDescriptor wgpu_resolve_view_desc;
            _sg_clear(&wgpu_resolve_view_desc, sizeof(wgpu_resolve_view_desc));
            wgpu_resolve_view_desc.baseMipLevel = (uint32_t) resolve_desc->mip_level;
            wgpu_resolve_view_desc.mipLevelCount = 1;
            wgpu_resolve_view_desc.baseArrayLayer = (uint32_t) resolve_desc->slice;
            wgpu_resolve_view_desc.arrayLayerCount = 1;
            atts->wgpu.resolves[i].view = wgpuTextureCreateView(rsv_img->wgpu.tex, &wgpu_resolve_view_desc);
            if (0 == atts->wgpu.resolves[i].view) {
                _SG_ERROR(WGPU_ATTACHMENTS_CREATE_TEXTURE_VIEW_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
        }
    }
    SOKOL_ASSERT(0 == atts->wgpu.depth_stencil.image);
    const sg_attachment_desc* ds_desc = &desc->depth_stencil;
    if (ds_desc->image.id != SG_INVALID_ID) {
        SOKOL_ASSERT(atts_ptrs->ds_image);
        _sg_image_t* ds_img =atts_ptrs->ds_image;
        SOKOL_ASSERT(ds_img->slot.id == ds_desc->image.id);
        SOKOL_ASSERT(_sg_is_valid_attachment_depth_format(ds_img->cmn.pixel_format));
        SOKOL_ASSERT(ds_img->wgpu.tex);
        atts->wgpu.depth_stencil.image = ds_img;

        WGPUTextureViewDescriptor wgpu_ds_view_desc;
        _sg_clear(&wgpu_ds_view_desc, sizeof(wgpu_ds_view_desc));
        wgpu_ds_view_desc.baseMipLevel = (uint32_t) ds_desc->mip_level;
        wgpu_ds_view_desc.mipLevelCount = 1;
        wgpu_ds_view_desc.baseArrayLayer = (uint32_t) ds_desc->slice;
        wgpu_ds_view_desc.arrayLayerCount = 1;
        atts->wgpu.depth_stencil.view = wgpuTextureCreateView(ds_img->wgpu.tex, &wgpu_ds_view_desc);
        if (0 == atts->wgpu.depth_stencil.view) {
            _SG_ERROR(WGPU_ATTACHMENTS_CREATE_TEXTURE_VIEW_FAILED);
            return SG_RESOURCESTATE_FAILED;
        }
    }
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        const sg_attachment_desc* storage_desc = &desc->storages[i];
        if (storage_desc->image.id != SG_INVALID_ID) {
            SOKOL_ASSERT(0 == atts->wgpu.storages[i].image);
            SOKOL_ASSERT(atts_ptrs->storage_images[i]);
            _sg_image_t* stg_img = atts_ptrs->storage_images[i];
            SOKOL_ASSERT(stg_img->slot.id == storage_desc->image.id);
            SOKOL_ASSERT(_sg_is_valid_attachment_storage_format(stg_img->cmn.pixel_format));
            atts->wgpu.storages[i].image = stg_img;

            WGPUTextureViewDescriptor wgpu_storage_view_desc;
            _sg_clear(&wgpu_storage_view_desc, sizeof(wgpu_storage_view_desc));
            wgpu_storage_view_desc.baseMipLevel = (uint32_t) storage_desc->mip_level;
            wgpu_storage_view_desc.mipLevelCount = 1;
            wgpu_storage_view_desc.baseArrayLayer = (uint32_t) storage_desc->slice;
            wgpu_storage_view_desc.arrayLayerCount = 1;
            if (_sg_is_depth_or_depth_stencil_format(stg_img->cmn.pixel_format)) {
                wgpu_storage_view_desc.aspect = WGPUTextureAspect_DepthOnly;
            } else {
                wgpu_storage_view_desc.aspect = WGPUTextureAspect_All;
            }
            atts->wgpu.storages[i].view = wgpuTextureCreateView(stg_img->wgpu.tex, &wgpu_storage_view_desc);
            if (0 == atts->wgpu.storages[i].view) {
                _SG_ERROR(WGPU_ATTACHMENTS_CREATE_TEXTURE_VIEW_FAILED);
                return SG_RESOURCESTATE_FAILED;
            }
        }
    }
    return SG_RESOURCESTATE_VALID;
}

_SOKOL_PRIVATE void _sg_wgpu_discard_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    for (int i = 0; i < atts->cmn.num_colors; i++) {
        if (atts->wgpu.colors[i].view) {
            wgpuTextureViewRelease(atts->wgpu.colors[i].view);
            atts->wgpu.colors[i].view = 0;
        }
        if (atts->wgpu.resolves[i].view) {
            wgpuTextureViewRelease(atts->wgpu.resolves[i].view);
            atts->wgpu.resolves[i].view = 0;
        }
    }
    if (atts->wgpu.depth_stencil.view) {
        wgpuTextureViewRelease(atts->wgpu.depth_stencil.view);
        atts->wgpu.depth_stencil.view = 0;
    }
    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
        if (atts->wgpu.storages[i].view) {
            wgpuTextureViewRelease(atts->wgpu.storages[i].view);
            atts->wgpu.storages[i].view = 0;
        }
    }
}

_SOKOL_PRIVATE _sg_image_t* _sg_wgpu_attachments_color_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    // NOTE: may return null
    return atts->wgpu.colors[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_wgpu_attachments_resolve_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_COLOR_ATTACHMENTS));
    // NOTE: may return null
    return atts->wgpu.resolves[index].image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_wgpu_attachments_ds_image(const _sg_attachments_t* atts) {
    // NOTE: may return null
    SOKOL_ASSERT(atts);
    return atts->wgpu.depth_stencil.image;
}

_SOKOL_PRIVATE _sg_image_t* _sg_wgpu_attachments_storage_image(const _sg_attachments_t* atts, int index) {
    SOKOL_ASSERT(atts && (index >= 0) && (index < SG_MAX_STORAGE_ATTACHMENTS));
    return atts->wgpu.storages[index].image;
}

_SOKOL_PRIVATE void _sg_wgpu_init_color_att(WGPURenderPassColorAttachment* wgpu_att, const sg_color_attachment_action* action, WGPUTextureView color_view, WGPUTextureView resolve_view) {
    wgpu_att->depthSlice = WGPU_DEPTH_SLICE_UNDEFINED;
    wgpu_att->view = color_view;
    wgpu_att->resolveTarget = resolve_view;
    wgpu_att->loadOp = _sg_wgpu_load_op(color_view, action->load_action);
    wgpu_att->storeOp = _sg_wgpu_store_op(color_view, action->store_action);
    wgpu_att->clearValue.r = action->clear_value.r;
    wgpu_att->clearValue.g = action->clear_value.g;
    wgpu_att->clearValue.b = action->clear_value.b;
    wgpu_att->clearValue.a = action->clear_value.a;
}

_SOKOL_PRIVATE void _sg_wgpu_init_ds_att(WGPURenderPassDepthStencilAttachment* wgpu_att, const sg_pass_action* action, sg_pixel_format fmt, WGPUTextureView view) {
    wgpu_att->view = view;
    wgpu_att->depthLoadOp = _sg_wgpu_load_op(view, action->depth.load_action);
    wgpu_att->depthStoreOp = _sg_wgpu_store_op(view, action->depth.store_action);
    wgpu_att->depthClearValue = action->depth.clear_value;
    wgpu_att->depthReadOnly = false;
    if (_sg_is_depth_stencil_format(fmt)) {
        wgpu_att->stencilLoadOp = _sg_wgpu_load_op(view, action->stencil.load_action);
        wgpu_att->stencilStoreOp = _sg_wgpu_store_op(view, action->stencil.store_action);
    } else {
        wgpu_att->stencilLoadOp = WGPULoadOp_Undefined;
        wgpu_att->stencilStoreOp = WGPUStoreOp_Undefined;
    }
    wgpu_att->stencilClearValue = action->stencil.clear_value;
    wgpu_att->stencilReadOnly = false;
}

_SOKOL_PRIVATE void _sg_wgpu_begin_compute_pass(const sg_pass* pass) {
    WGPUComputePassDescriptor wgpu_pass_desc;
    _sg_clear(&wgpu_pass_desc, sizeof(wgpu_pass_desc));
    wgpu_pass_desc.label = _sg_wgpu_stringview(pass->label);
    _sg.wgpu.cpass_enc = wgpuCommandEncoderBeginComputePass(_sg.wgpu.cmd_enc, &wgpu_pass_desc);
    SOKOL_ASSERT(_sg.wgpu.cpass_enc);
    // clear initial bindings
    wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, _SG_WGPU_UB_BINDGROUP_INDEX, _sg.wgpu.empty_bind_group, 0, 0);
    wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, _SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX, _sg.wgpu.empty_bind_group, 0, 0);
    wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, _SG_WGPU_SIMG_BINDGROUP_INDEX, _sg.wgpu.empty_bind_group, 0, 0);
    _sg_stats_add(wgpu.bindings.num_set_bindgroup, 1);
}

_SOKOL_PRIVATE void _sg_wgpu_begin_render_pass(const sg_pass* pass) {
    const _sg_attachments_t* atts = _sg.cur_pass.atts;
    const sg_swapchain* swapchain = &pass->swapchain;
    const sg_pass_action* action = &pass->action;

    WGPURenderPassDescriptor wgpu_pass_desc;
    WGPURenderPassColorAttachment wgpu_color_att[SG_MAX_COLOR_ATTACHMENTS];
    WGPURenderPassDepthStencilAttachment wgpu_ds_att;
    _sg_clear(&wgpu_pass_desc, sizeof(wgpu_pass_desc));
    _sg_clear(&wgpu_color_att, sizeof(wgpu_color_att));
    _sg_clear(&wgpu_ds_att, sizeof(wgpu_ds_att));
    wgpu_pass_desc.label = _sg_wgpu_stringview(pass->label);
    if (atts) {
        SOKOL_ASSERT(atts->slot.state == SG_RESOURCESTATE_VALID);
        for (int i = 0; i < atts->cmn.num_colors; i++) {
            _sg_wgpu_init_color_att(&wgpu_color_att[i], &action->colors[i], atts->wgpu.colors[i].view, atts->wgpu.resolves[i].view);
        }
        wgpu_pass_desc.colorAttachmentCount = (size_t)atts->cmn.num_colors;
        wgpu_pass_desc.colorAttachments = &wgpu_color_att[0];
        if (atts->wgpu.depth_stencil.image) {
            _sg_wgpu_init_ds_att(&wgpu_ds_att, action, atts->wgpu.depth_stencil.image->cmn.pixel_format, atts->wgpu.depth_stencil.view);
            wgpu_pass_desc.depthStencilAttachment = &wgpu_ds_att;
        }
    } else {
        WGPUTextureView wgpu_color_view = (WGPUTextureView) swapchain->wgpu.render_view;
        WGPUTextureView wgpu_resolve_view = (WGPUTextureView) swapchain->wgpu.resolve_view;
        WGPUTextureView wgpu_depth_stencil_view = (WGPUTextureView) swapchain->wgpu.depth_stencil_view;
        _sg_wgpu_init_color_att(&wgpu_color_att[0], &action->colors[0], wgpu_color_view, wgpu_resolve_view);
        wgpu_pass_desc.colorAttachmentCount = 1;
        wgpu_pass_desc.colorAttachments = &wgpu_color_att[0];
        if (wgpu_depth_stencil_view) {
            SOKOL_ASSERT(swapchain->depth_format > SG_PIXELFORMAT_NONE);
            _sg_wgpu_init_ds_att(&wgpu_ds_att, action, swapchain->depth_format, wgpu_depth_stencil_view);
            wgpu_pass_desc.depthStencilAttachment = &wgpu_ds_att;
        }
    }
    _sg.wgpu.rpass_enc = wgpuCommandEncoderBeginRenderPass(_sg.wgpu.cmd_enc, &wgpu_pass_desc);
    SOKOL_ASSERT(_sg.wgpu.rpass_enc);

    wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.rpass_enc, _SG_WGPU_UB_BINDGROUP_INDEX, _sg.wgpu.empty_bind_group, 0, 0);
    wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.rpass_enc, _SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX, _sg.wgpu.empty_bind_group, 0, 0);
    _sg_stats_add(wgpu.bindings.num_set_bindgroup, 1);
}

_SOKOL_PRIVATE void _sg_wgpu_begin_pass(const sg_pass* pass) {
    SOKOL_ASSERT(pass);
    SOKOL_ASSERT(_sg.wgpu.dev);
    SOKOL_ASSERT(_sg.wgpu.cmd_enc);
    SOKOL_ASSERT(0 == _sg.wgpu.rpass_enc);
    SOKOL_ASSERT(0 == _sg.wgpu.cpass_enc);

    _sg.wgpu.cur_pipeline = 0;
    _sg.wgpu.cur_pipeline_id.id = SG_INVALID_ID;
    _sg_wgpu_bindings_cache_clear();

    if (pass->compute) {
        _sg_wgpu_begin_compute_pass(pass);
    } else {
        _sg_wgpu_begin_render_pass(pass);
    }
}

_SOKOL_PRIVATE void _sg_wgpu_end_pass(void) {
    if (_sg.wgpu.rpass_enc) {
        wgpuRenderPassEncoderEnd(_sg.wgpu.rpass_enc);
        wgpuRenderPassEncoderRelease(_sg.wgpu.rpass_enc);
        _sg.wgpu.rpass_enc = 0;
    }
    if (_sg.wgpu.cpass_enc) {
        wgpuComputePassEncoderEnd(_sg.wgpu.cpass_enc);
        wgpuComputePassEncoderRelease(_sg.wgpu.cpass_enc);
        _sg.wgpu.cpass_enc = 0;
    }
}

_SOKOL_PRIVATE void _sg_wgpu_commit(void) {
    SOKOL_ASSERT(_sg.wgpu.cmd_enc);

    _sg_wgpu_uniform_buffer_on_commit();

    WGPUCommandBufferDescriptor cmd_buf_desc;
    _sg_clear(&cmd_buf_desc, sizeof(cmd_buf_desc));
    WGPUCommandBuffer wgpu_cmd_buf = wgpuCommandEncoderFinish(_sg.wgpu.cmd_enc, &cmd_buf_desc);
    SOKOL_ASSERT(wgpu_cmd_buf);
    wgpuCommandEncoderRelease(_sg.wgpu.cmd_enc);
    _sg.wgpu.cmd_enc = 0;

    wgpuQueueSubmit(_sg.wgpu.queue, 1, &wgpu_cmd_buf);
    wgpuCommandBufferRelease(wgpu_cmd_buf);

    // create a new render-command-encoder for next frame
    WGPUCommandEncoderDescriptor cmd_enc_desc;
    _sg_clear(&cmd_enc_desc, sizeof(cmd_enc_desc));
    _sg.wgpu.cmd_enc = wgpuDeviceCreateCommandEncoder(_sg.wgpu.dev, &cmd_enc_desc);
}

_SOKOL_PRIVATE void _sg_wgpu_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {
    SOKOL_ASSERT(_sg.wgpu.rpass_enc);
    // FIXME FIXME FIXME: CLIPPING THE VIEWPORT HERE IS WRONG!!!
    // (but currently required because WebGPU insists that the viewport rectangle must be
    // fully contained inside the framebuffer, but this doesn't make any sense, and also
    // isn't required by the backend APIs)
    const _sg_recti_t clip = _sg_clipi(x, y, w, h, _sg.cur_pass.width, _sg.cur_pass.height);
    float xf = (float) clip.x;
    float yf = (float) (origin_top_left ? clip.y : (_sg.cur_pass.height - (clip.y + clip.h)));
    float wf = (float) clip.w;
    float hf = (float) clip.h;
    wgpuRenderPassEncoderSetViewport(_sg.wgpu.rpass_enc, xf, yf, wf, hf, 0.0f, 1.0f);
}

_SOKOL_PRIVATE void _sg_wgpu_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {
    SOKOL_ASSERT(_sg.wgpu.rpass_enc);
    const _sg_recti_t clip = _sg_clipi(x, y, w, h, _sg.cur_pass.width, _sg.cur_pass.height);
    uint32_t sx = (uint32_t) clip.x;
    uint32_t sy = (uint32_t) (origin_top_left ? clip.y : (_sg.cur_pass.height - (clip.y + clip.h)));
    uint32_t sw = (uint32_t) clip.w;
    uint32_t sh = (uint32_t) clip.h;
    wgpuRenderPassEncoderSetScissorRect(_sg.wgpu.rpass_enc, sx, sy, sw, sh);
}

_SOKOL_PRIVATE void _sg_wgpu_set_ub_bindgroup(const _sg_shader_t* shd) {
    // NOTE: dynamic offsets must be in binding order, not in BindGroupEntry order
    SOKOL_ASSERT(shd->wgpu.ub_num_dynoffsets < SG_MAX_UNIFORMBLOCK_BINDSLOTS);
    uint32_t dyn_offsets[SG_MAX_UNIFORMBLOCK_BINDSLOTS];
    _sg_clear(dyn_offsets, sizeof(dyn_offsets));
    for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
        if (shd->cmn.uniform_blocks[i].stage == SG_SHADERSTAGE_NONE) {
            continue;
        }
        uint8_t dynoffset_index = shd->wgpu.ub_dynoffsets[i];
        SOKOL_ASSERT(dynoffset_index < shd->wgpu.ub_num_dynoffsets);
        dyn_offsets[dynoffset_index] = _sg.wgpu.uniform.bind_offsets[i];
    }
    if (_sg.cur_pass.is_compute) {
        SOKOL_ASSERT(_sg.wgpu.cpass_enc);
        wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc,
            _SG_WGPU_UB_BINDGROUP_INDEX,
            shd->wgpu.bg_ub,
            shd->wgpu.ub_num_dynoffsets,
            dyn_offsets);
    } else {
        SOKOL_ASSERT(_sg.wgpu.rpass_enc);
        wgpuRenderPassEncoderSetBindGroup(_sg.wgpu.rpass_enc,
            _SG_WGPU_UB_BINDGROUP_INDEX,
            shd->wgpu.bg_ub,
            shd->wgpu.ub_num_dynoffsets,
            dyn_offsets);
    }
}

_SOKOL_PRIVATE void _sg_wgpu_apply_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    SOKOL_ASSERT(pip->shader && (pip->shader->slot.id == pip->cmn.shader_id.id));
    _sg.wgpu.cur_pipeline = pip;
    _sg.wgpu.cur_pipeline_id.id = pip->slot.id;
    if (pip->cmn.is_compute) {
        SOKOL_ASSERT(_sg.cur_pass.is_compute);
        SOKOL_ASSERT(pip->wgpu.cpip);
        SOKOL_ASSERT(_sg.wgpu.cpass_enc);
        wgpuComputePassEncoderSetPipeline(_sg.wgpu.cpass_enc, pip->wgpu.cpip);

        // adhoc-create a storage attachment bindgroup without going through the bindgroups cache
        // FIXME: the 'resource view update' will get rid of this special case because then storage images
        // will be regular resource bindings
        if (pip->shader->wgpu.bgl_simg) {
            _sg_stats_add(wgpu.bindings.num_create_bindgroup, 1);
            _sg_shader_t* shd = pip->shader;
            SOKOL_ASSERT(shd);
            WGPUBindGroupLayout bgl = shd->wgpu.bgl_simg;
            WGPUBindGroupEntry bg_entries[_SG_WGPU_MAX_SIMG_BINDGROUP_ENTRIES];
            _sg_clear(&bg_entries, sizeof(bg_entries));
            size_t bgl_index = 0;
            for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
                if (shd->cmn.storage_images[i].stage == SG_SHADERSTAGE_NONE) {
                    continue;
                }
                SOKOL_ASSERT(_sg.cur_pass.atts);
                _sg_attachments_t* atts = _sg.cur_pass.atts;
                SOKOL_ASSERT(atts->wgpu.storages[i].view);
                WGPUBindGroupEntry* bg_entry = &bg_entries[bgl_index];
                bg_entry->binding = shd->wgpu.simg_grp2_bnd_n[i];
                bg_entry->textureView = atts->wgpu.storages[i].view;
                bgl_index++;
            }
            SOKOL_ASSERT(bgl_index > 0);
            WGPUBindGroupDescriptor bg_desc;
            _sg_clear(&bg_desc, sizeof(bg_desc));
            bg_desc.layout = bgl;
            bg_desc.entryCount = bgl_index;
            bg_desc.entries = bg_entries;
            WGPUBindGroup bg = wgpuDeviceCreateBindGroup(_sg.wgpu.dev, &bg_desc);
            if (bg) {
                wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, _SG_WGPU_SIMG_BINDGROUP_INDEX, bg, 0, 0);
                wgpuBindGroupRelease(bg);
            } else {
                _SG_ERROR(WGPU_CREATEBINDGROUP_FAILED);
            }
        } else {
            // no storage attachment bindings, clear bindgroup slot
            wgpuComputePassEncoderSetBindGroup(_sg.wgpu.cpass_enc, _SG_WGPU_SIMG_BINDGROUP_INDEX, _sg.wgpu.empty_bind_group, 0, 0);
        }
    } else {
        SOKOL_ASSERT(!_sg.cur_pass.is_compute);
        SOKOL_ASSERT(pip->wgpu.rpip);
        SOKOL_ASSERT(_sg.wgpu.rpass_enc);
        _sg.wgpu.use_indexed_draw = (pip->cmn.index_type != SG_INDEXTYPE_NONE);
        wgpuRenderPassEncoderSetPipeline(_sg.wgpu.rpass_enc, pip->wgpu.rpip);
        wgpuRenderPassEncoderSetBlendConstant(_sg.wgpu.rpass_enc, &pip->wgpu.blend_color);
        wgpuRenderPassEncoderSetStencilReference(_sg.wgpu.rpass_enc, pip->cmn.stencil.ref);
    }
    // bind groups must be set because pipelines without uniform blocks or resource bindings
    // will still create 'empty' BindGroupLayouts
    _sg_wgpu_set_ub_bindgroup(pip->shader);
    _sg_wgpu_set_bindgroup(_SG_WGPU_IMG_SMP_SBUF_BINDGROUP_INDEX, 0); // this will set the 'empty bind group'
}

_SOKOL_PRIVATE bool _sg_wgpu_apply_bindings(_sg_bindings_ptrs_t* bnd) {
    SOKOL_ASSERT(bnd);
    SOKOL_ASSERT(bnd->pip->shader && (bnd->pip->cmn.shader_id.id == bnd->pip->shader->slot.id));
    bool retval = true;
    if (!_sg.cur_pass.is_compute) {
        retval &= _sg_wgpu_apply_index_buffer(bnd);
        retval &= _sg_wgpu_apply_vertex_buffers(bnd);
    }
    retval &= _sg_wgpu_apply_bindings_bindgroup(bnd);
    return retval;
}

_SOKOL_PRIVATE void _sg_wgpu_apply_uniforms(int ub_slot, const sg_range* data) {
    const uint32_t alignment = _sg.wgpu.limits.limits.minUniformBufferOffsetAlignment;
    SOKOL_ASSERT(_sg.wgpu.uniform.staging);
    SOKOL_ASSERT((ub_slot >= 0) && (ub_slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS));
    SOKOL_ASSERT((_sg.wgpu.uniform.offset + data->size) <= _sg.wgpu.uniform.num_bytes);
    SOKOL_ASSERT((_sg.wgpu.uniform.offset & (alignment - 1)) == 0);
    const _sg_pipeline_t* pip = _sg.wgpu.cur_pipeline;
    SOKOL_ASSERT(pip && pip->shader);
    SOKOL_ASSERT(pip->slot.id == _sg.wgpu.cur_pipeline_id.id);
    const _sg_shader_t* shd = pip->shader;
    SOKOL_ASSERT(shd->slot.id == pip->cmn.shader_id.id);
    SOKOL_ASSERT(data->size == shd->cmn.uniform_blocks[ub_slot].size);
    SOKOL_ASSERT(data->size <= _SG_WGPU_MAX_UNIFORM_UPDATE_SIZE);

    _sg_stats_add(wgpu.uniforms.num_set_bindgroup, 1);
    memcpy(_sg.wgpu.uniform.staging + _sg.wgpu.uniform.offset, data->ptr, data->size);
    _sg.wgpu.uniform.bind_offsets[ub_slot] = _sg.wgpu.uniform.offset;
    _sg.wgpu.uniform.offset = _sg_roundup_u32(_sg.wgpu.uniform.offset + (uint32_t)data->size, alignment);

    _sg_wgpu_set_ub_bindgroup(shd);
}

_SOKOL_PRIVATE void _sg_wgpu_draw(int base_element, int num_elements, int num_instances) {
    SOKOL_ASSERT(_sg.wgpu.rpass_enc);
    SOKOL_ASSERT(_sg.wgpu.cur_pipeline && (_sg.wgpu.cur_pipeline->slot.id == _sg.wgpu.cur_pipeline_id.id));
    if (SG_INDEXTYPE_NONE != _sg.wgpu.cur_pipeline->cmn.index_type) {
        wgpuRenderPassEncoderDrawIndexed(_sg.wgpu.rpass_enc, (uint32_t)num_elements, (uint32_t)num_instances, (uint32_t)base_element, 0, 0);
    } else {
        wgpuRenderPassEncoderDraw(_sg.wgpu.rpass_enc, (uint32_t)num_elements, (uint32_t)num_instances, (uint32_t)base_element, 0);
    }
}

_SOKOL_PRIVATE void _sg_wgpu_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    SOKOL_ASSERT(_sg.wgpu.cpass_enc);
    wgpuComputePassEncoderDispatchWorkgroups(_sg.wgpu.cpass_enc,
        (uint32_t)num_groups_x,
        (uint32_t)num_groups_y,
        (uint32_t)num_groups_z);
}

_SOKOL_PRIVATE void _sg_wgpu_update_buffer(_sg_buffer_t* buf, const sg_range* data) {
    SOKOL_ASSERT(data && data->ptr && (data->size > 0));
    SOKOL_ASSERT(buf);
    _sg_wgpu_copy_buffer_data(buf, 0, data);
}

_SOKOL_PRIVATE void _sg_wgpu_append_buffer(_sg_buffer_t* buf, const sg_range* data, bool new_frame) {
    SOKOL_ASSERT(data && data->ptr && (data->size > 0));
    _SOKOL_UNUSED(new_frame);
    _sg_wgpu_copy_buffer_data(buf, (uint64_t)buf->cmn.append_pos, data);
}

_SOKOL_PRIVATE void _sg_wgpu_update_image(_sg_image_t* img, const sg_image_data* data) {
    SOKOL_ASSERT(img && data);
    _sg_wgpu_copy_image_data(img, img->wgpu.tex, data);
}
#endif

//  ██████  ███████ ███    ██ ███████ ██████  ██  ██████     ██████   █████   ██████ ██   ██ ███████ ███    ██ ██████
// ██       ██      ████   ██ ██      ██   ██ ██ ██          ██   ██ ██   ██ ██      ██  ██  ██      ████   ██ ██   ██
// ██   ███ █████   ██ ██  ██ █████   ██████  ██ ██          ██████  ███████ ██      █████   █████   ██ ██  ██ ██   ██
// ██    ██ ██      ██  ██ ██ ██      ██   ██ ██ ██          ██   ██ ██   ██ ██      ██  ██  ██      ██  ██ ██ ██   ██
//  ██████  ███████ ██   ████ ███████ ██   ██ ██  ██████     ██████  ██   ██  ██████ ██   ██ ███████ ██   ████ ██████
//
// >>generic backend
static inline void _sg_setup_backend(const sg_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_setup_backend(desc);
    #elif defined(SOKOL_METAL)
    _sg_mtl_setup_backend(desc);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_setup_backend(desc);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_setup_backend(desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_setup_backend(desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_backend(void) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_backend();
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_backend();
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_backend();
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_discard_backend();
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_backend();
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_reset_state_cache(void) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_reset_state_cache();
    #elif defined(SOKOL_METAL)
    _sg_mtl_reset_state_cache();
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_reset_state_cache();
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_reset_state_cache();
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_reset_state_cache();
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline sg_resource_state _sg_create_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_create_buffer(buf, desc);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_create_buffer(buf, desc);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_create_buffer(buf, desc);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_create_buffer(buf, desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_create_buffer(buf, desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_buffer(_sg_buffer_t* buf) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_buffer(buf);
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_buffer(buf);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_buffer(buf);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_discard_buffer(buf);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_buffer(buf);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline sg_resource_state _sg_create_image(_sg_image_t* img, const sg_image_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_create_image(img, desc);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_create_image(img, desc);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_create_image(img, desc);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_create_image(img, desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_create_image(img, desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_image(_sg_image_t* img) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_image(img);
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_image(img);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_image(img);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_discard_image(img);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_image(img);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline sg_resource_state _sg_create_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_create_sampler(smp, desc);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_create_sampler(smp, desc);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_create_sampler(smp, desc);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_create_sampler(smp, desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_create_sampler(smp, desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_sampler(_sg_sampler_t* smp) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_sampler(smp);
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_sampler(smp);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_sampler(smp);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_discard_sampler(smp);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_sampler(smp);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline sg_resource_state _sg_create_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_create_shader(shd, desc);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_create_shader(shd, desc);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_create_shader(shd, desc);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_create_shader(shd, desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_create_shader(shd, desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_shader(_sg_shader_t* shd) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_shader(shd);
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_shader(shd);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_shader(shd);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_discard_shader(shd);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_shader(shd);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline sg_resource_state _sg_create_pipeline(_sg_pipeline_t* pip, _sg_shader_t* shd, const sg_pipeline_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_create_pipeline(pip, shd, desc);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_create_pipeline(pip, shd, desc);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_create_pipeline(pip, shd, desc);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_create_pipeline(pip, shd, desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_create_pipeline(pip, shd, desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_pipeline(_sg_pipeline_t* pip) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_pipeline(pip);
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_pipeline(pip);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_pipeline(pip);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_discard_pipeline(pip);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_pipeline(pip);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline sg_resource_state _sg_create_attachments(_sg_attachments_t* atts, _sg_attachments_ptrs_t* atts_ptrs, const sg_attachments_desc* desc) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_create_attachments(atts, atts_ptrs, desc);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_create_attachments(atts, atts_ptrs, desc);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_create_attachments(atts, atts_ptrs, desc);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_create_attachments(atts, atts_ptrs, desc);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_create_attachments(atts, atts_ptrs, desc);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_discard_attachments(_sg_attachments_t* atts) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_discard_attachments(atts);
    #elif defined(SOKOL_METAL)
    _sg_mtl_discard_attachments(atts);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_discard_attachments(atts);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_discard_attachments(atts);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_discard_attachments(atts);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline _sg_image_t* _sg_attachments_color_image(const _sg_attachments_t* atts, int index) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_attachments_color_image(atts, index);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_attachments_color_image(atts, index);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_attachments_color_image(atts, index);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_attachments_color_image(atts, index);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_attachments_color_image(atts, index);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline _sg_image_t* _sg_attachments_resolve_image(const _sg_attachments_t* atts, int index) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_attachments_resolve_image(atts, index);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_attachments_resolve_image(atts, index);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_attachments_resolve_image(atts, index);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_attachments_resolve_image(atts, index);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_attachments_resolve_image(atts, index);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline _sg_image_t* _sg_attachments_ds_image(const _sg_attachments_t* atts) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_attachments_ds_image(atts);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_attachments_ds_image(atts);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_attachments_ds_image(atts);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_attachments_ds_image(atts);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_attachments_ds_image(atts);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline _sg_image_t* _sg_attachments_storage_image(const _sg_attachments_t* atts, int index) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_attachments_storage_image(atts, index);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_attachments_storage_image(atts, index);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_attachments_storage_image(atts, index);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_attachments_storage_image(atts, index);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_attachments_storage_image(atts, index);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_begin_pass(const sg_pass* pass) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_begin_pass(pass);
    #elif defined(SOKOL_METAL)
    _sg_mtl_begin_pass(pass);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_begin_pass(pass);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_begin_pass(pass);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_begin_pass(pass);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_end_pass(void) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_end_pass();
    #elif defined(SOKOL_METAL)
    _sg_mtl_end_pass();
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_end_pass();
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_end_pass();
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_end_pass();
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_apply_viewport(int x, int y, int w, int h, bool origin_top_left) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_apply_viewport(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_METAL)
    _sg_mtl_apply_viewport(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_apply_viewport(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_apply_viewport(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_apply_viewport(x, y, w, h, origin_top_left);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_apply_scissor_rect(int x, int y, int w, int h, bool origin_top_left) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_apply_scissor_rect(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_METAL)
    _sg_mtl_apply_scissor_rect(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_apply_scissor_rect(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_apply_scissor_rect(x, y, w, h, origin_top_left);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_apply_scissor_rect(x, y, w, h, origin_top_left);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_apply_pipeline(_sg_pipeline_t* pip) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_apply_pipeline(pip);
    #elif defined(SOKOL_METAL)
    _sg_mtl_apply_pipeline(pip);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_apply_pipeline(pip);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_apply_pipeline(pip);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_apply_pipeline(pip);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline bool _sg_apply_bindings(_sg_bindings_ptrs_t* bnd) {
    #if defined(_SOKOL_ANY_GL)
    return _sg_gl_apply_bindings(bnd);
    #elif defined(SOKOL_METAL)
    return _sg_mtl_apply_bindings(bnd);
    #elif defined(SOKOL_D3D11)
    return _sg_d3d11_apply_bindings(bnd);
    #elif defined(SOKOL_WGPU)
    return _sg_wgpu_apply_bindings(bnd);
    #elif defined(SOKOL_DUMMY_BACKEND)
    return _sg_dummy_apply_bindings(bnd);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_apply_uniforms(int ub_slot, const sg_range* data) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_apply_uniforms(ub_slot, data);
    #elif defined(SOKOL_METAL)
    _sg_mtl_apply_uniforms(ub_slot, data);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_apply_uniforms(ub_slot, data);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_apply_uniforms(ub_slot, data);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_apply_uniforms(ub_slot, data);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_draw(int base_element, int num_elements, int num_instances) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_draw(base_element, num_elements, num_instances);
    #elif defined(SOKOL_METAL)
    _sg_mtl_draw(base_element, num_elements, num_instances);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_draw(base_element, num_elements, num_instances);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_draw(base_element, num_elements, num_instances);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_draw(base_element, num_elements, num_instances);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_dispatch(num_groups_x, num_groups_y, num_groups_z);
    #elif defined(SOKOL_METAL)
    _sg_mtl_dispatch(num_groups_x, num_groups_y, num_groups_z);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_dispatch(num_groups_x, num_groups_y, num_groups_z);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_dispatch(num_groups_x, num_groups_y, num_groups_z);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_dispatch(num_groups_x, num_groups_y, num_groups_z);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_commit(void) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_commit();
    #elif defined(SOKOL_METAL)
    _sg_mtl_commit();
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_commit();
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_commit();
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_commit();
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_update_buffer(_sg_buffer_t* buf, const sg_range* data) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_update_buffer(buf, data);
    #elif defined(SOKOL_METAL)
    _sg_mtl_update_buffer(buf, data);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_update_buffer(buf, data);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_update_buffer(buf, data);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_update_buffer(buf, data);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_append_buffer(_sg_buffer_t* buf, const sg_range* data, bool new_frame) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_append_buffer(buf, data, new_frame);
    #elif defined(SOKOL_METAL)
    _sg_mtl_append_buffer(buf, data, new_frame);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_append_buffer(buf, data, new_frame);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_append_buffer(buf, data, new_frame);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_append_buffer(buf, data, new_frame);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_update_image(_sg_image_t* img, const sg_image_data* data) {
    #if defined(_SOKOL_ANY_GL)
    _sg_gl_update_image(img, data);
    #elif defined(SOKOL_METAL)
    _sg_mtl_update_image(img, data);
    #elif defined(SOKOL_D3D11)
    _sg_d3d11_update_image(img, data);
    #elif defined(SOKOL_WGPU)
    _sg_wgpu_update_image(img, data);
    #elif defined(SOKOL_DUMMY_BACKEND)
    _sg_dummy_update_image(img, data);
    #else
    #error("INVALID BACKEND");
    #endif
}

static inline void _sg_push_debug_group(const char* name) {
    #if defined(SOKOL_METAL)
    _sg_mtl_push_debug_group(name);
    #else
    _SOKOL_UNUSED(name);
    #endif
}

static inline void _sg_pop_debug_group(void) {
    #if defined(SOKOL_METAL)
    _sg_mtl_pop_debug_group();
    #endif
}

// ██████   ██████   ██████  ██
// ██   ██ ██    ██ ██    ██ ██
// ██████  ██    ██ ██    ██ ██
// ██      ██    ██ ██    ██ ██
// ██       ██████   ██████  ███████
//
// >>pool
_SOKOL_PRIVATE void _sg_pool_init(_sg_pool_t* pool, int num) {
    SOKOL_ASSERT(pool && (num >= 1));
    // slot 0 is reserved for the 'invalid id', so bump the pool size by 1
    pool->size = num + 1;
    pool->queue_top = 0;
    // generation counters indexable by pool slot index, slot 0 is reserved
    size_t gen_ctrs_size = sizeof(uint32_t) * (size_t)pool->size;
    pool->gen_ctrs = (uint32_t*)_sg_malloc_clear(gen_ctrs_size);
    // it's not a bug to only reserve 'num' here
    pool->free_queue = (int*) _sg_malloc_clear(sizeof(int) * (size_t)num);
    // never allocate the zero-th pool item since the invalid id is 0
    for (int i = pool->size-1; i >= 1; i--) {
        pool->free_queue[pool->queue_top++] = i;
    }
}

_SOKOL_PRIVATE void _sg_pool_discard(_sg_pool_t* pool) {
    SOKOL_ASSERT(pool);
    SOKOL_ASSERT(pool->free_queue);
    _sg_free(pool->free_queue);
    pool->free_queue = 0;
    SOKOL_ASSERT(pool->gen_ctrs);
    _sg_free(pool->gen_ctrs);
    pool->gen_ctrs = 0;
    pool->size = 0;
    pool->queue_top = 0;
}

_SOKOL_PRIVATE int _sg_pool_alloc_index(_sg_pool_t* pool) {
    SOKOL_ASSERT(pool);
    SOKOL_ASSERT(pool->free_queue);
    if (pool->queue_top > 0) {
        int slot_index = pool->free_queue[--pool->queue_top];
        SOKOL_ASSERT((slot_index > 0) && (slot_index < pool->size));
        return slot_index;
    } else {
        // pool exhausted
        return _SG_INVALID_SLOT_INDEX;
    }
}

_SOKOL_PRIVATE void _sg_pool_free_index(_sg_pool_t* pool, int slot_index) {
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < pool->size));
    SOKOL_ASSERT(pool);
    SOKOL_ASSERT(pool->free_queue);
    SOKOL_ASSERT(pool->queue_top < pool->size);
    #ifdef SOKOL_DEBUG
    // debug check against double-free
    for (int i = 0; i < pool->queue_top; i++) {
        SOKOL_ASSERT(pool->free_queue[i] != slot_index);
    }
    #endif
    pool->free_queue[pool->queue_top++] = slot_index;
    SOKOL_ASSERT(pool->queue_top <= (pool->size-1));
}

_SOKOL_PRIVATE void _sg_slot_reset(_sg_slot_t* slot) {
    SOKOL_ASSERT(slot);
    _sg_clear(slot, sizeof(_sg_slot_t));
}

_SOKOL_PRIVATE void _sg_reset_buffer_to_alloc_state(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf);
    _sg_slot_t slot = buf->slot;
    _sg_clear(buf, sizeof(*buf));
    buf->slot = slot;
    buf->slot.state = SG_RESOURCESTATE_ALLOC;
}

_SOKOL_PRIVATE void _sg_reset_image_to_alloc_state(_sg_image_t* img) {
    SOKOL_ASSERT(img);
    _sg_slot_t slot = img->slot;
    _sg_clear(img, sizeof(*img));
    img->slot = slot;
    img->slot.state = SG_RESOURCESTATE_ALLOC;
}

_SOKOL_PRIVATE void _sg_reset_sampler_to_alloc_state(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp);
    _sg_slot_t slot = smp->slot;
    _sg_clear(smp, sizeof(*smp));
    smp->slot = slot;
    smp->slot.state = SG_RESOURCESTATE_ALLOC;
}

_SOKOL_PRIVATE void _sg_reset_shader_to_alloc_state(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd);
    _sg_slot_t slot = shd->slot;
    _sg_clear(shd, sizeof(*shd));
    shd->slot = slot;
    shd->slot.state = SG_RESOURCESTATE_ALLOC;
}

_SOKOL_PRIVATE void _sg_reset_pipeline_to_alloc_state(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip);
    _sg_slot_t slot = pip->slot;
    _sg_clear(pip, sizeof(*pip));
    pip->slot = slot;
    pip->slot.state = SG_RESOURCESTATE_ALLOC;
}

_SOKOL_PRIVATE void _sg_reset_attachments_to_alloc_state(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts);
    _sg_slot_t slot = atts->slot;
    _sg_clear(atts, sizeof(*atts));
    atts->slot = slot;
    atts->slot.state = SG_RESOURCESTATE_ALLOC;
}

_SOKOL_PRIVATE void _sg_setup_pools(_sg_pools_t* p, const sg_desc* desc) {
    SOKOL_ASSERT(p);
    SOKOL_ASSERT(desc);
    // note: the pools here will have an additional item, since slot 0 is reserved
    SOKOL_ASSERT((desc->buffer_pool_size > 0) && (desc->buffer_pool_size < _SG_MAX_POOL_SIZE));
    _sg_pool_init(&p->buffer_pool, desc->buffer_pool_size);
    size_t buffer_pool_byte_size = sizeof(_sg_buffer_t) * (size_t)p->buffer_pool.size;
    p->buffers = (_sg_buffer_t*) _sg_malloc_clear(buffer_pool_byte_size);

    SOKOL_ASSERT((desc->image_pool_size > 0) && (desc->image_pool_size < _SG_MAX_POOL_SIZE));
    _sg_pool_init(&p->image_pool, desc->image_pool_size);
    size_t image_pool_byte_size = sizeof(_sg_image_t) * (size_t)p->image_pool.size;
    p->images = (_sg_image_t*) _sg_malloc_clear(image_pool_byte_size);

    SOKOL_ASSERT((desc->sampler_pool_size > 0) && (desc->sampler_pool_size < _SG_MAX_POOL_SIZE));
    _sg_pool_init(&p->sampler_pool, desc->sampler_pool_size);
    size_t sampler_pool_byte_size = sizeof(_sg_sampler_t) * (size_t)p->sampler_pool.size;
    p->samplers = (_sg_sampler_t*) _sg_malloc_clear(sampler_pool_byte_size);

    SOKOL_ASSERT((desc->shader_pool_size > 0) && (desc->shader_pool_size < _SG_MAX_POOL_SIZE));
    _sg_pool_init(&p->shader_pool, desc->shader_pool_size);
    size_t shader_pool_byte_size = sizeof(_sg_shader_t) * (size_t)p->shader_pool.size;
    p->shaders = (_sg_shader_t*) _sg_malloc_clear(shader_pool_byte_size);

    SOKOL_ASSERT((desc->pipeline_pool_size > 0) && (desc->pipeline_pool_size < _SG_MAX_POOL_SIZE));
    _sg_pool_init(&p->pipeline_pool, desc->pipeline_pool_size);
    size_t pipeline_pool_byte_size = sizeof(_sg_pipeline_t) * (size_t)p->pipeline_pool.size;
    p->pipelines = (_sg_pipeline_t*) _sg_malloc_clear(pipeline_pool_byte_size);

    SOKOL_ASSERT((desc->attachments_pool_size > 0) && (desc->attachments_pool_size < _SG_MAX_POOL_SIZE));
    _sg_pool_init(&p->attachments_pool, desc->attachments_pool_size);
    size_t attachments_pool_byte_size = sizeof(_sg_attachments_t) * (size_t)p->attachments_pool.size;
    p->attachments = (_sg_attachments_t*) _sg_malloc_clear(attachments_pool_byte_size);
}

_SOKOL_PRIVATE void _sg_discard_pools(_sg_pools_t* p) {
    SOKOL_ASSERT(p);
    _sg_free(p->attachments); p->attachments = 0;
    _sg_free(p->pipelines);   p->pipelines = 0;
    _sg_free(p->shaders);     p->shaders = 0;
    _sg_free(p->samplers);    p->samplers = 0;
    _sg_free(p->images);      p->images = 0;
    _sg_free(p->buffers);     p->buffers = 0;
    _sg_pool_discard(&p->attachments_pool);
    _sg_pool_discard(&p->pipeline_pool);
    _sg_pool_discard(&p->shader_pool);
    _sg_pool_discard(&p->sampler_pool);
    _sg_pool_discard(&p->image_pool);
    _sg_pool_discard(&p->buffer_pool);
}

/* allocate the slot at slot_index:
    - bump the slot's generation counter
    - create a resource id from the generation counter and slot index
    - set the slot's id to this id
    - set the slot's state to ALLOC
    - return the resource id
*/
_SOKOL_PRIVATE uint32_t _sg_slot_alloc(_sg_pool_t* pool, _sg_slot_t* slot, int slot_index) {
    /* FIXME: add handling for an overflowing generation counter,
       for now, just overflow (another option is to disable
       the slot)
    */
    SOKOL_ASSERT(pool && pool->gen_ctrs);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < pool->size));
    SOKOL_ASSERT(slot->id == SG_INVALID_ID);
    SOKOL_ASSERT(slot->state == SG_RESOURCESTATE_INITIAL);
    uint32_t ctr = ++pool->gen_ctrs[slot_index];
    slot->id = (ctr<<_SG_SLOT_SHIFT)|(slot_index & _SG_SLOT_MASK);
    slot->state = SG_RESOURCESTATE_ALLOC;
    return slot->id;
}

// extract slot index from id
_SOKOL_PRIVATE int _sg_slot_index(uint32_t id) {
    int slot_index = (int) (id & _SG_SLOT_MASK);
    SOKOL_ASSERT(_SG_INVALID_SLOT_INDEX != slot_index);
    return slot_index;
}

// returns pointer to resource by id without matching id check
_SOKOL_PRIVATE _sg_buffer_t* _sg_buffer_at(const _sg_pools_t* p, uint32_t buf_id) {
    SOKOL_ASSERT(p && (SG_INVALID_ID != buf_id));
    int slot_index = _sg_slot_index(buf_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->buffer_pool.size));
    return &p->buffers[slot_index];
}

_SOKOL_PRIVATE _sg_image_t* _sg_image_at(const _sg_pools_t* p, uint32_t img_id) {
    SOKOL_ASSERT(p && (SG_INVALID_ID != img_id));
    int slot_index = _sg_slot_index(img_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->image_pool.size));
    return &p->images[slot_index];
}

_SOKOL_PRIVATE _sg_sampler_t* _sg_sampler_at(const _sg_pools_t* p, uint32_t smp_id) {
    SOKOL_ASSERT(p && (SG_INVALID_ID != smp_id));
    int slot_index = _sg_slot_index(smp_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->sampler_pool.size));
    return &p->samplers[slot_index];
}

_SOKOL_PRIVATE _sg_shader_t* _sg_shader_at(const _sg_pools_t* p, uint32_t shd_id) {
    SOKOL_ASSERT(p && (SG_INVALID_ID != shd_id));
    int slot_index = _sg_slot_index(shd_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->shader_pool.size));
    return &p->shaders[slot_index];
}

_SOKOL_PRIVATE _sg_pipeline_t* _sg_pipeline_at(const _sg_pools_t* p, uint32_t pip_id) {
    SOKOL_ASSERT(p && (SG_INVALID_ID != pip_id));
    int slot_index = _sg_slot_index(pip_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->pipeline_pool.size));
    return &p->pipelines[slot_index];
}

_SOKOL_PRIVATE _sg_attachments_t* _sg_attachments_at(const _sg_pools_t* p, uint32_t atts_id) {
    SOKOL_ASSERT(p && (SG_INVALID_ID != atts_id));
    int slot_index = _sg_slot_index(atts_id);
    SOKOL_ASSERT((slot_index > _SG_INVALID_SLOT_INDEX) && (slot_index < p->attachments_pool.size));
    return &p->attachments[slot_index];
}

// returns pointer to resource with matching id check, may return 0
_SOKOL_PRIVATE _sg_buffer_t* _sg_lookup_buffer(const _sg_pools_t* p, uint32_t buf_id) {
    if (SG_INVALID_ID != buf_id) {
        _sg_buffer_t* buf = _sg_buffer_at(p, buf_id);
        if (buf->slot.id == buf_id) {
            return buf;
        }
    }
    return 0;
}

_SOKOL_PRIVATE _sg_image_t* _sg_lookup_image(const _sg_pools_t* p, uint32_t img_id) {
    if (SG_INVALID_ID != img_id) {
        _sg_image_t* img = _sg_image_at(p, img_id);
        if (img->slot.id == img_id) {
            return img;
        }
    }
    return 0;
}

_SOKOL_PRIVATE _sg_sampler_t* _sg_lookup_sampler(const _sg_pools_t* p, uint32_t smp_id) {
    if (SG_INVALID_ID != smp_id) {
        _sg_sampler_t* smp = _sg_sampler_at(p, smp_id);
        if (smp->slot.id == smp_id) {
            return smp;
        }
    }
    return 0;
}

_SOKOL_PRIVATE _sg_shader_t* _sg_lookup_shader(const _sg_pools_t* p, uint32_t shd_id) {
    SOKOL_ASSERT(p);
    if (SG_INVALID_ID != shd_id) {
        _sg_shader_t* shd = _sg_shader_at(p, shd_id);
        if (shd->slot.id == shd_id) {
            return shd;
        }
    }
    return 0;
}

_SOKOL_PRIVATE _sg_pipeline_t* _sg_lookup_pipeline(const _sg_pools_t* p, uint32_t pip_id) {
    SOKOL_ASSERT(p);
    if (SG_INVALID_ID != pip_id) {
        _sg_pipeline_t* pip = _sg_pipeline_at(p, pip_id);
        if (pip->slot.id == pip_id) {
            return pip;
        }
    }
    return 0;
}

_SOKOL_PRIVATE _sg_attachments_t* _sg_lookup_attachments(const _sg_pools_t* p, uint32_t atts_id) {
    SOKOL_ASSERT(p);
    if (SG_INVALID_ID != atts_id) {
        _sg_attachments_t* atts = _sg_attachments_at(p, atts_id);
        if (atts->slot.id == atts_id) {
            return atts;
        }
    }
    return 0;
}

_SOKOL_PRIVATE void _sg_discard_all_resources(_sg_pools_t* p) {
    /*  this is a bit dumb since it loops over all pool slots to
        find the occupied slots, on the other hand it is only ever
        executed at shutdown
        NOTE: ONLY EXECUTE THIS AT SHUTDOWN
              ...because the free queues will not be reset
              and the resource slots not be cleared!
    */
    for (int i = 1; i < p->buffer_pool.size; i++) {
        sg_resource_state state = p->buffers[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_discard_buffer(&p->buffers[i]);
        }
    }
    for (int i = 1; i < p->image_pool.size; i++) {
        sg_resource_state state = p->images[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_discard_image(&p->images[i]);
        }
    }
    for (int i = 1; i < p->sampler_pool.size; i++) {
        sg_resource_state state = p->samplers[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_discard_sampler(&p->samplers[i]);
        }
    }
    for (int i = 1; i < p->shader_pool.size; i++) {
        sg_resource_state state = p->shaders[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_discard_shader(&p->shaders[i]);
        }
    }
    for (int i = 1; i < p->pipeline_pool.size; i++) {
        sg_resource_state state = p->pipelines[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_discard_pipeline(&p->pipelines[i]);
        }
    }
    for (int i = 1; i < p->attachments_pool.size; i++) {
        sg_resource_state state = p->attachments[i].slot.state;
        if ((state == SG_RESOURCESTATE_VALID) || (state == SG_RESOURCESTATE_FAILED)) {
            _sg_discard_attachments(&p->attachments[i]);
        }
    }
}

// ████████ ██████   █████   ██████ ██   ██ ███████ ██████
//    ██    ██   ██ ██   ██ ██      ██  ██  ██      ██   ██
//    ██    ██████  ███████ ██      █████   █████   ██████
//    ██    ██   ██ ██   ██ ██      ██  ██  ██      ██   ██
//    ██    ██   ██ ██   ██  ██████ ██   ██ ███████ ██   ██
//
// >>tracker
_SOKOL_PRIVATE void _sg_tracker_init(_sg_tracker_t* tracker, uint32_t num) {
    SOKOL_ASSERT(tracker);
    SOKOL_ASSERT(num > 0);
    SOKOL_ASSERT(0 == tracker->size);
    SOKOL_ASSERT(0 == tracker->cur);
    SOKOL_ASSERT(0 == tracker->items);
    tracker->size = (uint32_t)num;
    tracker->items = (uint32_t*)_sg_malloc_clear(num * sizeof(uint32_t));
}

_SOKOL_PRIVATE void _sg_tracker_discard(_sg_tracker_t* tracker) {
    SOKOL_ASSERT(tracker);
    if (tracker->items) {
        _sg_free(tracker->items);
    }
    tracker->size = 0;
    tracker->cur = 0;
    tracker->items = 0;
}

_SOKOL_PRIVATE void _sg_tracker_reset(_sg_tracker_t* tracker) {
    SOKOL_ASSERT(tracker && tracker->items);
    tracker->cur = 0;
}

_SOKOL_PRIVATE bool _sg_tracker_add(_sg_tracker_t* tracker, uint32_t res_id) {
    SOKOL_ASSERT(tracker && tracker->items);
    if (tracker->cur < tracker->size) {
        tracker->items[tracker->cur++] = res_id;
        return true;
    } else {
        return false;
    }
}

// ██    ██  █████  ██      ██ ██████   █████  ████████ ██  ██████  ███    ██
// ██    ██ ██   ██ ██      ██ ██   ██ ██   ██    ██    ██ ██    ██ ████   ██
// ██    ██ ███████ ██      ██ ██   ██ ███████    ██    ██ ██    ██ ██ ██  ██
//  ██  ██  ██   ██ ██      ██ ██   ██ ██   ██    ██    ██ ██    ██ ██  ██ ██
//   ████   ██   ██ ███████ ██ ██████  ██   ██    ██    ██  ██████  ██   ████
//
// >>validation
#if defined(SOKOL_DEBUG)
_SOKOL_PRIVATE void _sg_validate_begin(void) {
    _sg.validate_error = SG_LOGITEM_OK;
}

_SOKOL_PRIVATE bool _sg_validate_end(void) {
    if (_sg.validate_error != SG_LOGITEM_OK) {
        #if !defined(SOKOL_VALIDATE_NON_FATAL)
            _SG_PANIC(VALIDATION_FAILED);
            return false;
        #else
            return false;
        #endif
    } else {
        return true;
    }
}
#endif

_SOKOL_PRIVATE bool _sg_one(bool b0, bool b1, bool b2) {
    return (b0 && !b1 && !b2) || (!b0 && b1 && !b2) || (!b0 && !b1 && b2);
}

_SOKOL_PRIVATE bool _sg_validate_buffer_desc(const sg_buffer_desc* desc) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(desc);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(desc);
        _sg_validate_begin();
        _SG_VALIDATE(desc->_start_canary == 0, VALIDATE_BUFFERDESC_CANARY);
        _SG_VALIDATE(desc->_end_canary == 0, VALIDATE_BUFFERDESC_CANARY);
        _SG_VALIDATE(desc->size > 0, VALIDATE_BUFFERDESC_EXPECT_NONZERO_SIZE);
        _SG_VALIDATE(_sg_one(desc->usage.immutable, desc->usage.dynamic_update, desc->usage.stream_update), VALIDATE_BUFFERDESC_IMMUTABLE_DYNAMIC_STREAM);
        if (_sg.features.separate_buffer_types) {
            _SG_VALIDATE(_sg_one(desc->usage.vertex_buffer, desc->usage.index_buffer, desc->usage.storage_buffer), VALIDATE_BUFFERDESC_SEPARATE_BUFFER_TYPES);
        }
        bool injected = (0 != desc->gl_buffers[0]) ||
                        (0 != desc->mtl_buffers[0]) ||
                        (0 != desc->d3d11_buffer) ||
                        (0 != desc->wgpu_buffer);
        if (!injected && desc->usage.immutable) {
            if (desc->data.ptr) {
                _SG_VALIDATE(desc->size == desc->data.size, VALIDATE_BUFFERDESC_EXPECT_MATCHING_DATA_SIZE);
            } else {
                _SG_VALIDATE(desc->usage.storage_buffer, VALIDATE_BUFFERDESC_EXPECT_DATA);
                _SG_VALIDATE(desc->data.size == 0, VALIDATE_BUFFERDESC_EXPECT_ZERO_DATA_SIZE);
            }
        } else {
            _SG_VALIDATE(0 == desc->data.ptr, VALIDATE_BUFFERDESC_EXPECT_NO_DATA);
            _SG_VALIDATE(desc->data.size == 0, VALIDATE_BUFFERDESC_EXPECT_ZERO_DATA_SIZE);
        }
        if (desc->usage.storage_buffer) {
            _SG_VALIDATE(_sg.features.compute, VALIDATE_BUFFERDESC_STORAGEBUFFER_SUPPORTED);
            _SG_VALIDATE(_sg_multiple_u64(desc->size, 4), VALIDATE_BUFFERDESC_STORAGEBUFFER_SIZE_MULTIPLE_4);
        }
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE void _sg_validate_image_data(const sg_image_data* data, sg_pixel_format fmt, int width, int height, int num_faces, int num_mips, int num_slices) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(data);
        _SOKOL_UNUSED(fmt);
        _SOKOL_UNUSED(width);
        _SOKOL_UNUSED(height);
        _SOKOL_UNUSED(num_faces);
        _SOKOL_UNUSED(num_mips);
        _SOKOL_UNUSED(num_slices);
    #else
        for (int face_index = 0; face_index < num_faces; face_index++) {
            for (int mip_index = 0; mip_index < num_mips; mip_index++) {
                const bool has_data = data->subimage[face_index][mip_index].ptr != 0;
                const bool has_size = data->subimage[face_index][mip_index].size > 0;
                _SG_VALIDATE(has_data && has_size, VALIDATE_IMAGEDATA_NODATA);
                const int mip_width = _sg_miplevel_dim(width, mip_index);
                const int mip_height = _sg_miplevel_dim(height, mip_index);
                const int bytes_per_slice = _sg_surface_pitch(fmt, mip_width, mip_height, 1);
                const int expected_size = bytes_per_slice * num_slices;
                _SG_VALIDATE(expected_size == (int)data->subimage[face_index][mip_index].size, VALIDATE_IMAGEDATA_DATA_SIZE);
            }
        }
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_image_desc(const sg_image_desc* desc) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(desc);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(desc);
        _sg_validate_begin();
        _SG_VALIDATE(desc->_start_canary == 0, VALIDATE_IMAGEDESC_CANARY);
        _SG_VALIDATE(desc->_end_canary == 0, VALIDATE_IMAGEDESC_CANARY);
        _SG_VALIDATE(_sg_one(desc->usage.immutable, desc->usage.dynamic_update, desc->usage.stream_update), VALIDATE_IMAGEDESC_IMMUTABLE_DYNAMIC_STREAM);
        if (desc->usage.render_attachment || desc->usage.storage_attachment) {
            _SG_VALIDATE(_sg_one(desc->usage.render_attachment, desc->usage.storage_attachment, false), VALIDATE_IMAGEDESC_RENDER_VS_STORAGE_ATTACHMENT);
        }
        _SG_VALIDATE(desc->width > 0, VALIDATE_IMAGEDESC_WIDTH);
        _SG_VALIDATE(desc->height > 0, VALIDATE_IMAGEDESC_HEIGHT);
        const sg_pixel_format fmt = desc->pixel_format;
        const sg_image_usage* usage = &desc->usage;
        const bool injected = (0 != desc->gl_textures[0]) ||
                              (0 != desc->mtl_textures[0]) ||
                              (0 != desc->d3d11_texture) ||
                              (0 != desc->wgpu_texture);
        if (_sg_is_depth_or_depth_stencil_format(fmt)) {
            _SG_VALIDATE(desc->type != SG_IMAGETYPE_3D, VALIDATE_IMAGEDESC_DEPTH_3D_IMAGE);
        }
        if (usage->render_attachment || usage->storage_attachment) {
            SOKOL_ASSERT(((int)fmt >= 0) && ((int)fmt < _SG_PIXELFORMAT_NUM));
            _SG_VALIDATE(usage->immutable, VALIDATE_IMAGEDESC_ATTACHMENT_EXPECT_IMMUTABLE);
            _SG_VALIDATE(desc->data.subimage[0][0].ptr==0, VALIDATE_IMAGEDESC_ATTACHMENT_EXPECT_NO_DATA);
            if (usage->render_attachment) {
                _SG_VALIDATE(_sg.formats[fmt].render, VALIDATE_IMAGEDESC_RENDERATTACHMENT_PIXELFORMAT);
                if (desc->sample_count > 1) {
                    _SG_VALIDATE(_sg.formats[fmt].msaa, VALIDATE_IMAGEDESC_RENDERATTACHMENT_NO_MSAA_SUPPORT);
                    _SG_VALIDATE(desc->num_mipmaps == 1, VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_NUM_MIPMAPS);
                    _SG_VALIDATE(desc->type != SG_IMAGETYPE_ARRAY, VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_ARRAY_IMAGE);
                    _SG_VALIDATE(desc->type != SG_IMAGETYPE_3D, VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_3D_IMAGE);
                    _SG_VALIDATE(desc->type != SG_IMAGETYPE_CUBE, VALIDATE_IMAGEDESC_RENDERATTACHMENT_MSAA_CUBE_IMAGE);
                }
            } else if (usage->storage_attachment) {
                _SG_VALIDATE(_sg_is_valid_attachment_storage_format(fmt), VALIDATE_IMAGEDESC_STORAGEATTACHMENT_PIXELFORMAT);
                // D3D11 doesn't allow multisampled UAVs (see: https://github.com/gpuweb/gpuweb/issues/513)
                _SG_VALIDATE(desc->sample_count == 1, VALIDATE_IMAGEDESC_STORAGEATTACHMENT_EXPECT_NO_MSAA);
            }
        } else {
            _SG_VALIDATE(desc->sample_count == 1, VALIDATE_IMAGEDESC_MSAA_BUT_NO_ATTACHMENT);
            const bool valid_nonrt_fmt = !_sg_is_valid_attachment_depth_format(fmt);
            _SG_VALIDATE(valid_nonrt_fmt, VALIDATE_IMAGEDESC_NONRT_PIXELFORMAT);
            const bool is_compressed = _sg_is_compressed_pixel_format(desc->pixel_format);
            if (is_compressed) {
                _SG_VALIDATE(usage->immutable, VALIDATE_IMAGEDESC_COMPRESSED_IMMUTABLE);
            }
            if (!injected && usage->immutable) {
                // image desc must have valid data
                _sg_validate_image_data(&desc->data,
                    desc->pixel_format,
                    desc->width,
                    desc->height,
                    (desc->type == SG_IMAGETYPE_CUBE) ? 6 : 1,
                    desc->num_mipmaps,
                    desc->num_slices);
            } else {
                // image desc must not have data
                for (int face_index = 0; face_index < SG_CUBEFACE_NUM; face_index++) {
                    for (int mip_index = 0; mip_index < SG_MAX_MIPMAPS; mip_index++) {
                        const bool no_data = 0 == desc->data.subimage[face_index][mip_index].ptr;
                        const bool no_size = 0 == desc->data.subimage[face_index][mip_index].size;
                        if (injected) {
                            _SG_VALIDATE(no_data && no_size, VALIDATE_IMAGEDESC_INJECTED_NO_DATA);
                        }
                        if (!usage->immutable) {
                            _SG_VALIDATE(no_data && no_size, VALIDATE_IMAGEDESC_DYNAMIC_NO_DATA);
                        }
                    }
                }
            }
        }
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_sampler_desc(const sg_sampler_desc* desc) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(desc);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(desc);
        _sg_validate_begin();
        _SG_VALIDATE(desc->_start_canary == 0, VALIDATE_SAMPLERDESC_CANARY);
        _SG_VALIDATE(desc->_end_canary == 0, VALIDATE_SAMPLERDESC_CANARY);
        // restriction from WebGPU: when anisotropy > 1, all filters must be linear
        if (desc->max_anisotropy > 1) {
            _SG_VALIDATE((desc->min_filter == SG_FILTER_LINEAR)
                      && (desc->mag_filter == SG_FILTER_LINEAR)
                      && (desc->mipmap_filter == SG_FILTER_LINEAR),
                      VALIDATE_SAMPLERDESC_ANISTROPIC_REQUIRES_LINEAR_FILTERING);
        }
        return _sg_validate_end();
    #endif
}

typedef struct {
    uint64_t lo, hi;
} _sg_u128_t;

_SOKOL_PRIVATE _sg_u128_t _sg_u128(void) {
    _sg_u128_t res;
    _sg_clear(&res, sizeof(res));
    return res;
}

_SOKOL_PRIVATE _sg_u128_t _sg_validate_set_slot_bit(_sg_u128_t bits, sg_shader_stage stage, uint8_t slot) {
    switch (stage) {
        case SG_SHADERSTAGE_NONE:
            SOKOL_ASSERT(slot < 128);
            if (slot < 64) {
                bits.lo |= 1ULL << slot;
            } else {
                bits.hi |= 1ULL << (slot - 64);
            }
            break;
        case SG_SHADERSTAGE_VERTEX:
            SOKOL_ASSERT(slot < 64);
            bits.lo |= 1ULL << slot;
            break;
        case SG_SHADERSTAGE_FRAGMENT:
            SOKOL_ASSERT(slot < 64);
            bits.hi |= 1ULL << slot;
            break;
        case SG_SHADERSTAGE_COMPUTE:
            SOKOL_ASSERT(slot < 64);
            bits.lo |= 1ULL << slot;
            break;
        default:
            SOKOL_UNREACHABLE;
            break;
    }
    return bits;
}

_SOKOL_PRIVATE bool _sg_validate_slot_bits(_sg_u128_t bits, sg_shader_stage stage, uint8_t slot) {
    _sg_u128_t mask = _sg_u128();
    switch (stage) {
        case SG_SHADERSTAGE_NONE:
            SOKOL_ASSERT(slot < 128);
            if (slot < 64) {
                mask.lo = 1ULL << slot;
            } else {
                mask.hi = 1ULL << (slot - 64);
            }
            break;
        case SG_SHADERSTAGE_VERTEX:
            SOKOL_ASSERT(slot < 64);
            mask.lo = 1ULL << slot;
            break;
        case SG_SHADERSTAGE_FRAGMENT:
            SOKOL_ASSERT(slot < 64);
            mask.hi = 1ULL << slot;
            break;
        case SG_SHADERSTAGE_COMPUTE:
            SOKOL_ASSERT(slot < 64);
            mask.lo = 1ULL << slot;
            break;
        default:
            SOKOL_UNREACHABLE;
            break;
    }
    return ((bits.lo & mask.lo) == 0) && ((bits.hi & mask.hi) == 0);
}

_SOKOL_PRIVATE bool _sg_validate_shader_desc(const sg_shader_desc* desc) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(desc);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(desc);
        bool is_compute_shader = (desc->compute_func.source != 0) || (desc->compute_func.bytecode.ptr != 0);
        _sg_validate_begin();
        _SG_VALIDATE(desc->_start_canary == 0, VALIDATE_SHADERDESC_CANARY);
        _SG_VALIDATE(desc->_end_canary == 0, VALIDATE_SHADERDESC_CANARY);
        #if defined(SOKOL_GLCORE) || defined(SOKOL_GLES3) || defined(SOKOL_WGPU)
            // on GL or WebGPU, must provide shader source code
            if (is_compute_shader) {
                _SG_VALIDATE(0 != desc->compute_func.source, VALIDATE_SHADERDESC_COMPUTE_SOURCE);
            } else {
                _SG_VALIDATE(0 != desc->vertex_func.source, VALIDATE_SHADERDESC_VERTEX_SOURCE);
                _SG_VALIDATE(0 != desc->fragment_func.source, VALIDATE_SHADERDESC_FRAGMENT_SOURCE);
            }
        #elif defined(SOKOL_METAL) || defined(SOKOL_D3D11)
            // on Metal or D3D11, must provide shader source code or byte code
            if (is_compute_shader) {
                _SG_VALIDATE((0 != desc->compute_func.source) || (0 != desc->compute_func.bytecode.ptr), VALIDATE_SHADERDESC_COMPUTE_SOURCE_OR_BYTECODE);
            } else {
                _SG_VALIDATE((0 != desc->vertex_func.source)|| (0 != desc->vertex_func.bytecode.ptr), VALIDATE_SHADERDESC_VERTEX_SOURCE_OR_BYTECODE);
                _SG_VALIDATE((0 != desc->fragment_func.source) || (0 != desc->fragment_func.bytecode.ptr), VALIDATE_SHADERDESC_FRAGMENT_SOURCE_OR_BYTECODE);
            }
        #else
            // Dummy Backend, don't require source or bytecode
        #endif
        if (is_compute_shader) {
            _SG_VALIDATE((0 == desc->vertex_func.source) && (0 == desc->vertex_func.bytecode.ptr), VALIDATE_SHADERDESC_INVALID_SHADER_COMBO);
            _SG_VALIDATE((0 == desc->fragment_func.source) && (0 == desc->fragment_func.bytecode.ptr), VALIDATE_SHADERDESC_INVALID_SHADER_COMBO);
        } else {
            _SG_VALIDATE((0 == desc->compute_func.source) && (0 == desc->compute_func.bytecode.ptr), VALIDATE_SHADERDESC_INVALID_SHADER_COMBO);
        }
        #if defined(SOKOL_METAL)
        if (is_compute_shader) {
            _SG_VALIDATE(desc->mtl_threads_per_threadgroup.x > 0, VALIDATE_SHADERDESC_METAL_THREADS_PER_THREADGROUP);
            _SG_VALIDATE(desc->mtl_threads_per_threadgroup.y > 0, VALIDATE_SHADERDESC_METAL_THREADS_PER_THREADGROUP);
            _SG_VALIDATE(desc->mtl_threads_per_threadgroup.z > 0, VALIDATE_SHADERDESC_METAL_THREADS_PER_THREADGROUP);
        }
        #endif
        for (size_t i = 0; i < SG_MAX_VERTEX_ATTRIBUTES; i++) {
            if (desc->attrs[i].glsl_name) {
                _SG_VALIDATE(strlen(desc->attrs[i].glsl_name) < _SG_STRING_SIZE, VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG);
            }
            if (desc->attrs[i].hlsl_sem_name) {
                _SG_VALIDATE(strlen(desc->attrs[i].hlsl_sem_name) < _SG_STRING_SIZE, VALIDATE_SHADERDESC_ATTR_STRING_TOO_LONG);
            }
        }
        // if shader byte code, the size must also be provided
        if (0 != desc->vertex_func.bytecode.ptr) {
            _SG_VALIDATE(desc->vertex_func.bytecode.size > 0, VALIDATE_SHADERDESC_NO_BYTECODE_SIZE);
        }
        if (0 != desc->fragment_func.bytecode.ptr) {
            _SG_VALIDATE(desc->fragment_func.bytecode.size > 0, VALIDATE_SHADERDESC_NO_BYTECODE_SIZE);
        }
        if (0 != desc->compute_func.bytecode.ptr) {
            _SG_VALIDATE(desc->compute_func.bytecode.size > 0, VALIDATE_SHADERDESC_NO_BYTECODE_SIZE);
        }

        #if defined(SOKOL_METAL)
        _sg_u128_t msl_buf_bits = _sg_u128();
        _sg_u128_t msl_tex_bits = _sg_u128();
        _sg_u128_t msl_smp_bits = _sg_u128();
        #elif defined(SOKOL_D3D11)
        _sg_u128_t hlsl_buf_bits = _sg_u128();
        _sg_u128_t hlsl_srv_bits = _sg_u128();
        _sg_u128_t hlsl_uav_bits = _sg_u128();
        _sg_u128_t hlsl_smp_bits = _sg_u128();
        #elif defined(_SOKOL_ANY_GL)
        _sg_u128_t glsl_sbuf_bnd_bits = _sg_u128();
        _sg_u128_t glsl_simg_bnd_bits = _sg_u128();
        #elif defined(SOKOL_WGPU)
        _sg_u128_t wgsl_group0_bits = _sg_u128();
        _sg_u128_t wgsl_group1_bits = _sg_u128();
        _sg_u128_t wgsl_group2_bits = _sg_u128();
        #endif
        for (size_t ub_idx = 0; ub_idx < SG_MAX_UNIFORMBLOCK_BINDSLOTS; ub_idx++) {
            const sg_shader_uniform_block* ub_desc = &desc->uniform_blocks[ub_idx];
            if (ub_desc->stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            _SG_VALIDATE(ub_desc->size > 0, VALIDATE_SHADERDESC_UNIFORMBLOCK_SIZE_IS_ZERO);
            #if defined(SOKOL_METAL)
            _SG_VALIDATE(ub_desc->msl_buffer_n < _SG_MTL_MAX_STAGE_UB_BINDINGS, VALIDATE_SHADERDESC_UNIFORMBLOCK_METAL_BUFFER_SLOT_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(msl_buf_bits, ub_desc->stage, ub_desc->msl_buffer_n), VALIDATE_SHADERDESC_UNIFORMBLOCK_METAL_BUFFER_SLOT_COLLISION);
            msl_buf_bits = _sg_validate_set_slot_bit(msl_buf_bits, ub_desc->stage, ub_desc->msl_buffer_n);
            #elif defined(SOKOL_D3D11)
            _SG_VALIDATE(ub_desc->hlsl_register_b_n < _SG_D3D11_MAX_STAGE_UB_BINDINGS, VALIDATE_SHADERDESC_UNIFORMBLOCK_HLSL_REGISTER_B_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(hlsl_buf_bits, ub_desc->stage, ub_desc->hlsl_register_b_n), VALIDATE_SHADERDESC_UNIFORMBLOCK_HLSL_REGISTER_B_COLLISION);
            hlsl_buf_bits = _sg_validate_set_slot_bit(hlsl_buf_bits, ub_desc->stage, ub_desc->hlsl_register_b_n);
            #elif defined(SOKOL_WGPU)
            _SG_VALIDATE(ub_desc->wgsl_group0_binding_n < _SG_WGPU_MAX_UB_BINDGROUP_BIND_SLOTS, VALIDATE_SHADERDESC_UNIFORMBLOCK_WGSL_GROUP0_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(wgsl_group0_bits, SG_SHADERSTAGE_NONE, ub_desc->wgsl_group0_binding_n), VALIDATE_SHADERDESC_UNIFORMBLOCK_WGSL_GROUP0_BINDING_COLLISION);
            wgsl_group0_bits = _sg_validate_set_slot_bit(wgsl_group0_bits, SG_SHADERSTAGE_NONE, ub_desc->wgsl_group0_binding_n);
            #endif
            #if defined(_SOKOL_ANY_GL)
            bool uniforms_continuous = true;
            uint32_t uniform_offset = 0;
            int num_uniforms = 0;
            for (size_t u_index = 0; u_index < SG_MAX_UNIFORMBLOCK_MEMBERS; u_index++) {
                const sg_glsl_shader_uniform* u_desc = &ub_desc->glsl_uniforms[u_index];
                if (u_desc->type != SG_UNIFORMTYPE_INVALID) {
                    _SG_VALIDATE(uniforms_continuous, VALIDATE_SHADERDESC_UNIFORMBLOCK_NO_CONT_MEMBERS);
                    _SG_VALIDATE(u_desc->glsl_name, VALIDATE_SHADERDESC_UNIFORMBLOCK_UNIFORM_GLSL_NAME);
                    const int array_count = u_desc->array_count;
                    _SG_VALIDATE(array_count > 0, VALIDATE_SHADERDESC_UNIFORMBLOCK_ARRAY_COUNT);
                    const uint32_t u_align = _sg_uniform_alignment(u_desc->type, array_count, ub_desc->layout);
                    const uint32_t u_size  = _sg_uniform_size(u_desc->type, array_count, ub_desc->layout);
                    uniform_offset = _sg_align_u32(uniform_offset, u_align);
                    uniform_offset += u_size;
                    num_uniforms++;
                    // with std140, arrays are only allowed for FLOAT4, INT4, MAT4
                    if (ub_desc->layout == SG_UNIFORMLAYOUT_STD140) {
                        if (array_count > 1) {
                            _SG_VALIDATE((u_desc->type == SG_UNIFORMTYPE_FLOAT4) || (u_desc->type == SG_UNIFORMTYPE_INT4) || (u_desc->type == SG_UNIFORMTYPE_MAT4), VALIDATE_SHADERDESC_UNIFORMBLOCK_STD140_ARRAY_TYPE);
                        }
                    }
                } else {
                    uniforms_continuous = false;
                }
            }
            if (ub_desc->layout == SG_UNIFORMLAYOUT_STD140) {
                uniform_offset = _sg_align_u32(uniform_offset, 16);
            }
            _SG_VALIDATE((size_t)uniform_offset == ub_desc->size, VALIDATE_SHADERDESC_UNIFORMBLOCK_SIZE_MISMATCH);
            _SG_VALIDATE(num_uniforms > 0, VALIDATE_SHADERDESC_UNIFORMBLOCK_NO_MEMBERS);
            #endif
        }

        for (size_t sbuf_idx = 0; sbuf_idx < SG_MAX_STORAGEBUFFER_BINDSLOTS; sbuf_idx++) {
            const sg_shader_storage_buffer* sbuf_desc = &desc->storage_buffers[sbuf_idx];
            if (sbuf_desc->stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            #if defined(SOKOL_METAL)
            _SG_VALIDATE((sbuf_desc->msl_buffer_n >= _SG_MTL_MAX_STAGE_UB_BINDINGS) && (sbuf_desc->msl_buffer_n < _SG_MTL_MAX_STAGE_UB_SBUF_BINDINGS), VALIDATE_SHADERDESC_STORAGEBUFFER_METAL_BUFFER_SLOT_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(msl_buf_bits, sbuf_desc->stage, sbuf_desc->msl_buffer_n), VALIDATE_SHADERDESC_STORAGEBUFFER_METAL_BUFFER_SLOT_COLLISION);
            msl_buf_bits = _sg_validate_set_slot_bit(msl_buf_bits, sbuf_desc->stage, sbuf_desc->msl_buffer_n);
            #elif defined(SOKOL_D3D11)
            if (sbuf_desc->readonly) {
                _SG_VALIDATE(sbuf_desc->hlsl_register_t_n < _SG_D3D11_MAX_STAGE_SRV_BINDINGS, VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_T_OUT_OF_RANGE);
                _SG_VALIDATE(_sg_validate_slot_bits(hlsl_srv_bits, sbuf_desc->stage, sbuf_desc->hlsl_register_t_n), VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_T_COLLISION);
                hlsl_srv_bits = _sg_validate_set_slot_bit(hlsl_srv_bits, sbuf_desc->stage, sbuf_desc->hlsl_register_t_n);
            } else {
                _SG_VALIDATE(sbuf_desc->hlsl_register_u_n < _SG_D3D11_MAX_STAGE_UAV_BINDINGS, VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_U_OUT_OF_RANGE);
                _SG_VALIDATE(_sg_validate_slot_bits(hlsl_uav_bits, sbuf_desc->stage, sbuf_desc->hlsl_register_u_n), VALIDATE_SHADERDESC_STORAGEBUFFER_HLSL_REGISTER_U_COLLISION);
                hlsl_uav_bits = _sg_validate_set_slot_bit(hlsl_uav_bits, sbuf_desc->stage, sbuf_desc->hlsl_register_u_n);
            }
            #elif defined(_SOKOL_ANY_GL)
            _SG_VALIDATE(sbuf_desc->glsl_binding_n < _SG_GL_MAX_SBUF_BINDINGS, VALIDATE_SHADERDESC_STORAGEBUFFER_GLSL_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(glsl_sbuf_bnd_bits, SG_SHADERSTAGE_NONE, sbuf_desc->glsl_binding_n), VALIDATE_SHADERDESC_STORAGEBUFFER_GLSL_BINDING_COLLISION);
            glsl_sbuf_bnd_bits = _sg_validate_set_slot_bit(glsl_sbuf_bnd_bits, SG_SHADERSTAGE_NONE, sbuf_desc->glsl_binding_n);
            #elif defined(SOKOL_WGPU)
            _SG_VALIDATE(sbuf_desc->wgsl_group1_binding_n < _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS, VALIDATE_SHADERDESC_STORAGEBUFFER_WGSL_GROUP1_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(wgsl_group1_bits, SG_SHADERSTAGE_NONE, sbuf_desc->wgsl_group1_binding_n), VALIDATE_SHADERDESC_STORAGEBUFFER_WGSL_GROUP1_BINDING_COLLISION);
            wgsl_group1_bits = _sg_validate_set_slot_bit(wgsl_group1_bits, SG_SHADERSTAGE_NONE, sbuf_desc->wgsl_group1_binding_n);
            #endif
        }

        for (size_t simg_idx = 0; simg_idx < SG_MAX_STORAGE_ATTACHMENTS; simg_idx++) {
            const sg_shader_storage_image* simg_desc = &desc->storage_images[simg_idx];
            if (simg_desc->stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            _SG_VALIDATE(simg_desc->stage == SG_SHADERSTAGE_COMPUTE, VALIDATE_SHADERDESC_STORAGEIMAGE_EXPECT_COMPUTE_STAGE);
            #if defined(SOKOL_METAL)
            _SG_VALIDATE(simg_desc->msl_texture_n < _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS, VALIDATE_SHADERDESC_STORAGEIMAGE_METAL_TEXTURE_SLOT_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(msl_tex_bits, simg_desc->stage, simg_desc->msl_texture_n), VALIDATE_SHADERDESC_STORAGEIMAGE_METAL_TEXTURE_SLOT_COLLISION);
            msl_tex_bits = _sg_validate_set_slot_bit(msl_tex_bits, simg_desc->stage, simg_desc->msl_texture_n);
            #elif defined(SOKOL_D3D11)
            _SG_VALIDATE(simg_desc->hlsl_register_u_n < _SG_D3D11_MAX_STAGE_UAV_BINDINGS, VALIDATE_SHADERDESC_STORAGEIMAGE_HLSL_REGISTER_U_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(hlsl_uav_bits, simg_desc->stage, simg_desc->hlsl_register_u_n), VALIDATE_SHADERDESC_STORAGEIMAGE_HLSL_REGISTER_U_COLLISION);
            hlsl_uav_bits = _sg_validate_set_slot_bit(hlsl_uav_bits, simg_desc->stage, simg_desc->hlsl_register_u_n);
            #elif defined(_SOKOL_ANY_GL)
            _SG_VALIDATE(simg_desc->glsl_binding_n < _SG_GL_MAX_SIMG_BINDINGS, VALIDATE_SHADERDESC_STORAGEIMAGE_GLSL_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(glsl_simg_bnd_bits, SG_SHADERSTAGE_NONE, simg_desc->glsl_binding_n), VALIDATE_SHADERDESC_STORAGEIMAGE_GLSL_BINDING_COLLISION);
            glsl_simg_bnd_bits = _sg_validate_set_slot_bit(glsl_simg_bnd_bits, SG_SHADERSTAGE_NONE, simg_desc->glsl_binding_n);
            #elif defined(SOKOL_WGPU)
            _SG_VALIDATE(simg_desc->wgsl_group2_binding_n < _SG_WGPU_MAX_SIMG_BIND_SLOTS, VALIDATE_SHADERDESC_STORAGEIMAGE_WGSL_GROUP2_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(wgsl_group2_bits, SG_SHADERSTAGE_NONE, simg_desc->wgsl_group2_binding_n), VALIDATE_SHADERDESC_STORAGEIMAGE_WGSL_GROUP2_BINDING_COLLISION);
            wgsl_group2_bits = _sg_validate_set_slot_bit(wgsl_group2_bits, SG_SHADERSTAGE_NONE, simg_desc->wgsl_group2_binding_n);
            #endif
        }

        uint32_t img_slot_mask = 0;
        for (size_t img_idx = 0; img_idx < SG_MAX_IMAGE_BINDSLOTS; img_idx++) {
            const sg_shader_image* img_desc = &desc->images[img_idx];
            if (img_desc->stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            img_slot_mask |= (1 << img_idx);
            #if defined(SOKOL_METAL)
            _SG_VALIDATE(img_desc->msl_texture_n < _SG_MTL_MAX_STAGE_TEXTURE_BINDINGS, VALIDATE_SHADERDESC_IMAGE_METAL_TEXTURE_SLOT_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(msl_tex_bits, img_desc->stage, img_desc->msl_texture_n), VALIDATE_SHADERDESC_IMAGE_METAL_TEXTURE_SLOT_COLLISION);
            msl_tex_bits = _sg_validate_set_slot_bit(msl_tex_bits, img_desc->stage, img_desc->msl_texture_n);
            #elif defined(SOKOL_D3D11)
            _SG_VALIDATE(img_desc->hlsl_register_t_n < _SG_D3D11_MAX_STAGE_SRV_BINDINGS, VALIDATE_SHADERDESC_IMAGE_HLSL_REGISTER_T_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(hlsl_srv_bits, img_desc->stage, img_desc->hlsl_register_t_n), VALIDATE_SHADERDESC_IMAGE_HLSL_REGISTER_T_COLLISION);
            hlsl_srv_bits = _sg_validate_set_slot_bit(hlsl_srv_bits, img_desc->stage, img_desc->hlsl_register_t_n);
            #elif defined(SOKOL_WGPU)
            _SG_VALIDATE(img_desc->wgsl_group1_binding_n < _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS, VALIDATE_SHADERDESC_IMAGE_WGSL_GROUP1_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(wgsl_group1_bits, SG_SHADERSTAGE_NONE, img_desc->wgsl_group1_binding_n), VALIDATE_SHADERDESC_IMAGE_WGSL_GROUP1_BINDING_COLLISION);
            wgsl_group1_bits = _sg_validate_set_slot_bit(wgsl_group1_bits, SG_SHADERSTAGE_NONE, img_desc->wgsl_group1_binding_n);
            #endif
        }

        uint32_t smp_slot_mask = 0;
        for (size_t smp_idx = 0; smp_idx < SG_MAX_SAMPLER_BINDSLOTS; smp_idx++) {
            const sg_shader_sampler* smp_desc = &desc->samplers[smp_idx];
            if (smp_desc->stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            smp_slot_mask |= (1 << smp_idx);
            #if defined(SOKOL_METAL)
            _SG_VALIDATE(smp_desc->msl_sampler_n < _SG_MTL_MAX_STAGE_SAMPLER_BINDINGS, VALIDATE_SHADERDESC_SAMPLER_METAL_SAMPLER_SLOT_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(msl_smp_bits, smp_desc->stage, smp_desc->msl_sampler_n), VALIDATE_SHADERDESC_SAMPLER_METAL_SAMPLER_SLOT_COLLISION);
            msl_smp_bits = _sg_validate_set_slot_bit(msl_smp_bits, smp_desc->stage, smp_desc->msl_sampler_n);
            #elif defined(SOKOL_D3D11)
            _SG_VALIDATE(smp_desc->hlsl_register_s_n < _SG_D3D11_MAX_STAGE_SMP_BINDINGS, VALIDATE_SHADERDESC_SAMPLER_HLSL_REGISTER_S_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(hlsl_smp_bits, smp_desc->stage, smp_desc->hlsl_register_s_n), VALIDATE_SHADERDESC_SAMPLER_HLSL_REGISTER_S_COLLISION);
            hlsl_smp_bits = _sg_validate_set_slot_bit(hlsl_smp_bits, smp_desc->stage, smp_desc->hlsl_register_s_n);
            #elif defined(SOKOL_WGPU)
            _SG_VALIDATE(smp_desc->wgsl_group1_binding_n < _SG_WGPU_MAX_IMG_SMP_SBUF_BIND_SLOTS, VALIDATE_SHADERDESC_SAMPLER_WGSL_GROUP1_BINDING_OUT_OF_RANGE);
            _SG_VALIDATE(_sg_validate_slot_bits(wgsl_group1_bits, SG_SHADERSTAGE_NONE, smp_desc->wgsl_group1_binding_n), VALIDATE_SHADERDESC_SAMPLER_WGSL_GROUP1_BINDING_COLLISION);
            wgsl_group1_bits = _sg_validate_set_slot_bit(wgsl_group1_bits, SG_SHADERSTAGE_NONE, smp_desc->wgsl_group1_binding_n);
            #endif
        }

        uint32_t ref_img_slot_mask = 0;
        uint32_t ref_smp_slot_mask = 0;
        for (size_t img_smp_idx = 0; img_smp_idx < SG_MAX_IMAGE_SAMPLER_PAIRS; img_smp_idx++) {
            const sg_shader_image_sampler_pair* img_smp_desc = &desc->image_sampler_pairs[img_smp_idx];
            if (img_smp_desc->stage == SG_SHADERSTAGE_NONE) {
                continue;
            }
            #if defined(_SOKOL_ANY_GL)
            _SG_VALIDATE(img_smp_desc->glsl_name != 0, VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_GLSL_NAME);
            #endif
            const bool img_slot_in_range = img_smp_desc->image_slot < SG_MAX_IMAGE_BINDSLOTS;
            const bool smp_slot_in_range = img_smp_desc->sampler_slot < SG_MAX_SAMPLER_BINDSLOTS;
            _SG_VALIDATE(img_slot_in_range, VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_IMAGE_SLOT_OUT_OF_RANGE);
            _SG_VALIDATE(smp_slot_in_range, VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_SAMPLER_SLOT_OUT_OF_RANGE);
            if (img_slot_in_range && smp_slot_in_range) {
                ref_img_slot_mask |= 1 << img_smp_desc->image_slot;
                ref_smp_slot_mask |= 1 << img_smp_desc->sampler_slot;
                const sg_shader_image* img_desc = &desc->images[img_smp_desc->image_slot];
                const sg_shader_sampler* smp_desc = &desc->samplers[img_smp_desc->sampler_slot];
                _SG_VALIDATE(img_desc->stage == img_smp_desc->stage, VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_IMAGE_STAGE_MISMATCH);
                _SG_VALIDATE(smp_desc->stage == img_smp_desc->stage, VALIDATE_SHADERDESC_IMAGE_SAMPLER_PAIR_SAMPLER_STAGE_MISMATCH);
                const bool needs_nonfiltering = (img_desc->sample_type == SG_IMAGESAMPLETYPE_UINT)
                                             || (img_desc->sample_type == SG_IMAGESAMPLETYPE_SINT)
                                             || (img_desc->sample_type == SG_IMAGESAMPLETYPE_UNFILTERABLE_FLOAT);
                const bool needs_comparison = img_desc->sample_type == SG_IMAGESAMPLETYPE_DEPTH;
                if (needs_nonfiltering) {
                    _SG_VALIDATE(needs_nonfiltering && (smp_desc->sampler_type == SG_SAMPLERTYPE_NONFILTERING), VALIDATE_SHADERDESC_NONFILTERING_SAMPLER_REQUIRED);
                }
                if (needs_comparison) {
                    _SG_VALIDATE(needs_comparison && (smp_desc->sampler_type == SG_SAMPLERTYPE_COMPARISON), VALIDATE_SHADERDESC_COMPARISON_SAMPLER_REQUIRED);
                }
            }
        }
        // each image and sampler must be referenced by an image sampler
        _SG_VALIDATE(img_slot_mask == ref_img_slot_mask, VALIDATE_SHADERDESC_IMAGE_NOT_REFERENCED_BY_IMAGE_SAMPLER_PAIRS);
        _SG_VALIDATE(smp_slot_mask == ref_smp_slot_mask, VALIDATE_SHADERDESC_SAMPLER_NOT_REFERENCED_BY_IMAGE_SAMPLER_PAIRS);

        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_pipeline_desc(const sg_pipeline_desc* desc) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(desc);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(desc);
        _sg_validate_begin();
        _SG_VALIDATE(desc->_start_canary == 0, VALIDATE_PIPELINEDESC_CANARY);
        _SG_VALIDATE(desc->_end_canary == 0, VALIDATE_PIPELINEDESC_CANARY);
        _SG_VALIDATE(desc->shader.id != SG_INVALID_ID, VALIDATE_PIPELINEDESC_SHADER);
        const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, desc->shader.id);
        _SG_VALIDATE(0 != shd, VALIDATE_PIPELINEDESC_SHADER);
        if (shd) {
            _SG_VALIDATE(shd->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_PIPELINEDESC_SHADER);
            if (desc->compute) {
                _SG_VALIDATE(shd->cmn.is_compute, VALIDATE_PIPELINEDESC_COMPUTE_SHADER_EXPECTED);
            } else {
                _SG_VALIDATE(!shd->cmn.is_compute, VALIDATE_PIPELINEDESC_NO_COMPUTE_SHADER_EXPECTED);
                bool attrs_cont = true;
                for (size_t attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
                    const sg_vertex_attr_state* a_state = &desc->layout.attrs[attr_index];
                    if (a_state->format == SG_VERTEXFORMAT_INVALID) {
                        attrs_cont = false;
                        continue;
                    }
                    _SG_VALIDATE(attrs_cont, VALIDATE_PIPELINEDESC_NO_CONT_ATTRS);
                    SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
                    // vertex format must match expected shader attribute base type (if provided)
                    if (shd->cmn.attrs[attr_index].base_type != SG_SHADERATTRBASETYPE_UNDEFINED) {
                        if (_sg_vertexformat_basetype(a_state->format) != shd->cmn.attrs[attr_index].base_type) {
                            _SG_VALIDATE(false, VALIDATE_PIPELINEDESC_ATTR_BASETYPE_MISMATCH);
                            _SG_LOGMSG(VALIDATE_PIPELINEDESC_ATTR_BASETYPE_MISMATCH, "attr format:");
                            _SG_LOGMSG(VALIDATE_PIPELINEDESC_ATTR_BASETYPE_MISMATCH, _sg_vertexformat_to_string(a_state->format));
                            _SG_LOGMSG(VALIDATE_PIPELINEDESC_ATTR_BASETYPE_MISMATCH, "shader attr base type:");
                            _SG_LOGMSG(VALIDATE_PIPELINEDESC_ATTR_BASETYPE_MISMATCH, _sg_shaderattrbasetype_to_string(shd->cmn.attrs[attr_index].base_type));
                        }
                    }
                    #if defined(SOKOL_D3D11)
                    // on D3D11, semantic names (and semantic indices) must be provided
                    _SG_VALIDATE(!_sg_strempty(&shd->d3d11.attrs[attr_index].sem_name), VALIDATE_PIPELINEDESC_ATTR_SEMANTICS);
                    #endif
                }
                // must only use readonly storage buffer bindings in render pipelines
                for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
                    if (shd->cmn.storage_buffers[i].stage != SG_SHADERSTAGE_NONE) {
                        _SG_VALIDATE(shd->cmn.storage_buffers[i].readonly, VALIDATE_PIPELINEDESC_SHADER_READONLY_STORAGEBUFFERS);
                    }
                }
                for (int buf_index = 0; buf_index < SG_MAX_VERTEXBUFFER_BINDSLOTS; buf_index++) {
                    const sg_vertex_buffer_layout_state* l_state = &desc->layout.buffers[buf_index];
                    if (l_state->stride == 0) {
                        continue;
                    }
                    _SG_VALIDATE(_sg_multiple_u64((uint64_t)l_state->stride, 4), VALIDATE_PIPELINEDESC_LAYOUT_STRIDE4);
                }
            }
        }
        for (size_t color_index = 0; color_index < (size_t)desc->color_count; color_index++) {
            const sg_blend_state* bs = &desc->colors[color_index].blend;
            if ((bs->op_rgb == SG_BLENDOP_MIN) || (bs->op_rgb == SG_BLENDOP_MAX)) {
                _SG_VALIDATE((bs->src_factor_rgb == SG_BLENDFACTOR_ONE) && (bs->dst_factor_rgb == SG_BLENDFACTOR_ONE), VALIDATE_PIPELINEDESC_BLENDOP_MINMAX_REQUIRES_BLENDFACTOR_ONE);
            }
            if ((bs->op_alpha == SG_BLENDOP_MIN) || (bs->op_alpha == SG_BLENDOP_MAX)) {
                _SG_VALIDATE((bs->src_factor_alpha == SG_BLENDFACTOR_ONE) && (bs->dst_factor_alpha == SG_BLENDFACTOR_ONE), VALIDATE_PIPELINEDESC_BLENDOP_MINMAX_REQUIRES_BLENDFACTOR_ONE);
            }
        }
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_attachments_desc(const sg_attachments_desc* desc) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(desc);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(desc);
        _sg_validate_begin();
        _SG_VALIDATE(desc->_start_canary == 0, VALIDATE_ATTACHMENTSDESC_CANARY);
        _SG_VALIDATE(desc->_end_canary == 0, VALIDATE_ATTACHMENTSDESC_CANARY);

        // check color attachments
        bool has_color_atts = false;
        bool has_depth_stencil_att = false;
        {
            bool atts_cont = true;
            int color_width = -1, color_height = -1, color_sample_count = -1;
            for (int att_index = 0; att_index < SG_MAX_COLOR_ATTACHMENTS; att_index++) {
                const sg_attachment_desc* att = &desc->colors[att_index];
                if (att->image.id == SG_INVALID_ID) {
                    atts_cont = false;
                    continue;
                }
                has_color_atts = true;
                _SG_VALIDATE(atts_cont, VALIDATE_ATTACHMENTSDESC_NO_CONT_COLOR_ATTS);
                const _sg_image_t* img = _sg_lookup_image(&_sg.pools, att->image.id);
                _SG_VALIDATE(img, VALIDATE_ATTACHMENTSDESC_COLOR_IMAGE);
                if (0 != img) {
                    _SG_VALIDATE(img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_ATTACHMENTSDESC_COLOR_IMAGE);
                    _SG_VALIDATE(img->cmn.usage.render_attachment, VALIDATE_ATTACHMENTSDESC_COLOR_IMAGE_NO_RENDERATTACHMENT);
                    _SG_VALIDATE(att->mip_level < img->cmn.num_mipmaps, VALIDATE_ATTACHMENTSDESC_COLOR_MIPLEVEL);
                    if (img->cmn.type == SG_IMAGETYPE_CUBE) {
                        _SG_VALIDATE(att->slice < 6, VALIDATE_ATTACHMENTSDESC_COLOR_FACE);
                    } else if (img->cmn.type == SG_IMAGETYPE_ARRAY) {
                        _SG_VALIDATE(att->slice < img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_COLOR_LAYER);
                    } else if (img->cmn.type == SG_IMAGETYPE_3D) {
                        _SG_VALIDATE(att->slice < img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_COLOR_SLICE);
                    }
                    if (att_index == 0) {
                        color_width = _sg_miplevel_dim(img->cmn.width, att->mip_level);
                        color_height = _sg_miplevel_dim(img->cmn.height, att->mip_level);
                        color_sample_count = img->cmn.sample_count;
                    } else {
                        _SG_VALIDATE(color_width == _sg_miplevel_dim(img->cmn.width, att->mip_level), VALIDATE_ATTACHMENTSDESC_IMAGE_SIZES);
                        _SG_VALIDATE(color_height == _sg_miplevel_dim(img->cmn.height, att->mip_level), VALIDATE_ATTACHMENTSDESC_IMAGE_SIZES);
                        _SG_VALIDATE(color_sample_count == img->cmn.sample_count, VALIDATE_ATTACHMENTSDESC_IMAGE_SAMPLE_COUNTS);
                    }
                    _SG_VALIDATE(_sg_is_valid_attachment_color_format(img->cmn.pixel_format), VALIDATE_ATTACHMENTSDESC_COLOR_INV_PIXELFORMAT);

                    // check resolve attachment
                    const sg_attachment_desc* res_att = &desc->resolves[att_index];
                    if (res_att->image.id != SG_INVALID_ID) {
                        // associated color attachment must be MSAA
                        _SG_VALIDATE(img->cmn.sample_count > 1, VALIDATE_ATTACHMENTSDESC_RESOLVE_COLOR_IMAGE_MSAA);
                        const _sg_image_t* res_img = _sg_lookup_image(&_sg.pools, res_att->image.id);
                        _SG_VALIDATE(res_img, VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE);
                        if (res_img != 0) {
                            _SG_VALIDATE(res_img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE);
                            _SG_VALIDATE(res_img->cmn.usage.render_attachment, VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_NO_RT);
                            _SG_VALIDATE(res_img->cmn.sample_count == 1, VALIDATE_ATTACHMENTSDESC_RESOLVE_SAMPLE_COUNT);
                            _SG_VALIDATE(res_att->mip_level < res_img->cmn.num_mipmaps, VALIDATE_ATTACHMENTSDESC_RESOLVE_MIPLEVEL);
                            if (res_img->cmn.type == SG_IMAGETYPE_CUBE) {
                                _SG_VALIDATE(res_att->slice < SG_CUBEFACE_NUM, VALIDATE_ATTACHMENTSDESC_RESOLVE_FACE);
                            } else if (res_img->cmn.type == SG_IMAGETYPE_ARRAY) {
                                _SG_VALIDATE(res_att->slice < res_img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_RESOLVE_LAYER);
                            } else if (res_img->cmn.type == SG_IMAGETYPE_3D) {
                                _SG_VALIDATE(res_att->slice < res_img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_RESOLVE_SLICE);
                            }
                            _SG_VALIDATE(img->cmn.pixel_format == res_img->cmn.pixel_format, VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_FORMAT);
                            _SG_VALIDATE(color_width == _sg_miplevel_dim(res_img->cmn.width, res_att->mip_level), VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_SIZES);
                            _SG_VALIDATE(color_height == _sg_miplevel_dim(res_img->cmn.height, res_att->mip_level), VALIDATE_ATTACHMENTSDESC_RESOLVE_IMAGE_SIZES);
                        }
                    }
                }
            }
            // check depth stencil attachments
            if (desc->depth_stencil.image.id != SG_INVALID_ID) {
                has_depth_stencil_att = true;
                const sg_attachment_desc* att = &desc->depth_stencil;
                const _sg_image_t* img = _sg_lookup_image(&_sg.pools, att->image.id);
                _SG_VALIDATE(img, VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE);
                if (img) {
                    _SG_VALIDATE(img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE);
                    _SG_VALIDATE(att->mip_level < img->cmn.num_mipmaps, VALIDATE_ATTACHMENTSDESC_DEPTH_MIPLEVEL);
                    if (img->cmn.type == SG_IMAGETYPE_CUBE) {
                        _SG_VALIDATE(att->slice < 6, VALIDATE_ATTACHMENTSDESC_DEPTH_FACE);
                    } else if (img->cmn.type == SG_IMAGETYPE_ARRAY) {
                        _SG_VALIDATE(att->slice < img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_DEPTH_LAYER);
                    } else if (img->cmn.type == SG_IMAGETYPE_3D) {
                        // NOTE: this can't actually happen because of VALIDATE_IMAGEDESC_DEPTH_3D_IMAGE
                        _SG_VALIDATE(att->slice < img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_DEPTH_SLICE);
                    }
                    _SG_VALIDATE(img->cmn.usage.render_attachment, VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_NO_RENDERATTACHMENT);
                    _SG_VALIDATE((color_width == -1) || (color_width == _sg_miplevel_dim(img->cmn.width, att->mip_level)), VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_SIZES);
                    _SG_VALIDATE((color_height == -1) || (color_height == _sg_miplevel_dim(img->cmn.height, att->mip_level)), VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_SIZES);
                    _SG_VALIDATE((color_sample_count == -1) || (color_sample_count == img->cmn.sample_count), VALIDATE_ATTACHMENTSDESC_DEPTH_IMAGE_SAMPLE_COUNT);
                    _SG_VALIDATE(_sg_is_valid_attachment_depth_format(img->cmn.pixel_format), VALIDATE_ATTACHMENTSDESC_DEPTH_INV_PIXELFORMAT);
                }
            }
        }

        // check storage attachments (note: storage attachments don't need to continuous)
        bool has_storage_atts = false;
        {
            for (int att_index = 0; att_index < SG_MAX_STORAGE_ATTACHMENTS; att_index++) {
                const sg_attachment_desc* att = &desc->storages[att_index];
                if (att->image.id == SG_INVALID_ID) {
                    continue;
                }
                has_storage_atts = true;
                const _sg_image_t* img = _sg_lookup_image(&_sg.pools, att->image.id);
                _SG_VALIDATE(img, VALIDATE_ATTACHMENTSDESC_STORAGE_IMAGE);
                if (0 != img) {
                    _SG_VALIDATE(img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_ATTACHMENTSDESC_STORAGE_IMAGE);
                    _SG_VALIDATE(img->cmn.usage.storage_attachment, VALIDATE_ATTACHMENTSDESC_STORAGE_IMAGE_NO_STORAGEATTACHMENT);
                    _SG_VALIDATE(att->mip_level < img->cmn.num_mipmaps, VALIDATE_ATTACHMENTSDESC_STORAGE_MIPLEVEL);
                    if (img->cmn.type == SG_IMAGETYPE_CUBE) {
                        _SG_VALIDATE(att->slice < 6, VALIDATE_ATTACHMENTSDESC_STORAGE_FACE);
                    } else if (img->cmn.type == SG_IMAGETYPE_ARRAY) {
                        _SG_VALIDATE(att->slice < img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_STORAGE_LAYER);
                    } else if (img->cmn.type == SG_IMAGETYPE_3D) {
                        _SG_VALIDATE(att->slice < img->cmn.num_slices, VALIDATE_ATTACHMENTSDESC_STORAGE_SLICE);
                    }
                    _SG_VALIDATE(_sg_is_valid_attachment_storage_format(img->cmn.pixel_format), VALIDATE_ATTACHMENTSDESC_STORAGE_INV_PIXELFORMAT);
                }
            }
        }
        _SG_VALIDATE(has_color_atts || has_depth_stencil_att || has_storage_atts, VALIDATE_ATTACHMENTSDESC_NO_ATTACHMENTS);
        if (has_color_atts || has_depth_stencil_att) {
            _SG_VALIDATE(!has_storage_atts, VALIDATE_ATTACHMENTSDESC_RENDER_VS_STORAGE_ATTACHMENTS);
        }
        if (has_storage_atts) {
            _SG_VALIDATE(!(has_color_atts || has_depth_stencil_att), VALIDATE_ATTACHMENTSDESC_RENDER_VS_STORAGE_ATTACHMENTS);
        }
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_begin_pass(const sg_pass* pass) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(pass);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        const bool is_compute_pass = pass->compute;
        const bool is_swapchain_pass = !is_compute_pass && (pass->attachments.id == SG_INVALID_ID);
        const bool is_offscreen_pass = !(is_compute_pass || is_swapchain_pass);
        _sg_validate_begin();
        _SG_VALIDATE(pass->_start_canary == 0, VALIDATE_BEGINPASS_CANARY);
        _SG_VALIDATE(pass->_end_canary == 0, VALIDATE_BEGINPASS_CANARY);
        if (is_compute_pass) {
            // this is a compute pass with optional storage attachments
            if (pass->attachments.id) {
                const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, pass->attachments.id);
                if (atts) {
                    _SG_VALIDATE(atts->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_BEGINPASS_ATTACHMENTS_VALID);
                    _SG_VALIDATE(!atts->cmn.has_render_attachments, VALIDATE_BEGINPASS_COMPUTEPASS_STORAGE_ATTACHMENTS_ONLY);
                    for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
                        const _sg_attachment_common_t* storage_att = &atts->cmn.storages[i];
                        const _sg_image_t* storage_img = _sg_attachments_storage_image(atts, i);
                        if (storage_img) {
                            _SG_VALIDATE(storage_img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_BEGINPASS_STORAGE_ATTACHMENT_IMAGE);
                            _SG_VALIDATE(storage_img->slot.id == storage_att->image_id.id, VALIDATE_BEGINPASS_STORAGE_ATTACHMENT_IMAGE);
                        }
                    }
                } else {
                    _SG_VALIDATE(atts != 0, VALIDATE_BEGINPASS_ATTACHMENTS_EXISTS);
                }
            }
        } else if (is_swapchain_pass) {
            // this is a swapchain pass
            _SG_VALIDATE(pass->swapchain.width > 0, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_WIDTH);
            _SG_VALIDATE(pass->swapchain.height > 0, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_HEIGHT);
            _SG_VALIDATE(pass->swapchain.sample_count > 0, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_SAMPLECOUNT);
            _SG_VALIDATE(pass->swapchain.color_format > SG_PIXELFORMAT_NONE, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_COLORFORMAT);
            // NOTE: depth buffer is optional, so depth_format is allowed to be invalid
            // NOTE: the GL framebuffer handle may actually be 0
            #if defined(SOKOL_METAL)
                _SG_VALIDATE(pass->swapchain.metal.current_drawable != 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_CURRENTDRAWABLE);
                if (pass->swapchain.depth_format == SG_PIXELFORMAT_NONE) {
                    _SG_VALIDATE(pass->swapchain.metal.depth_stencil_texture == 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_DEPTHSTENCILTEXTURE_NOTSET);
                } else {
                    _SG_VALIDATE(pass->swapchain.metal.depth_stencil_texture != 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_DEPTHSTENCILTEXTURE);
                }
                if (pass->swapchain.sample_count > 1) {
                    _SG_VALIDATE(pass->swapchain.metal.msaa_color_texture != 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_MSAACOLORTEXTURE);
                } else {
                    _SG_VALIDATE(pass->swapchain.metal.msaa_color_texture == 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_MSAACOLORTEXTURE_NOTSET);
                }
            #elif defined(SOKOL_D3D11)
                _SG_VALIDATE(pass->swapchain.d3d11.render_view != 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RENDERVIEW);
                if (pass->swapchain.depth_format == SG_PIXELFORMAT_NONE) {
                    _SG_VALIDATE(pass->swapchain.d3d11.depth_stencil_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_DEPTHSTENCILVIEW_NOTSET);
                } else {
                    _SG_VALIDATE(pass->swapchain.d3d11.depth_stencil_view != 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_DEPTHSTENCILVIEW);
                }
                if (pass->swapchain.sample_count > 1) {
                    _SG_VALIDATE(pass->swapchain.d3d11.resolve_view != 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RESOLVEVIEW);
                } else {
                    _SG_VALIDATE(pass->swapchain.d3d11.resolve_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RESOLVEVIEW_NOTSET);
                }
            #elif defined(SOKOL_WGPU)
                _SG_VALIDATE(pass->swapchain.wgpu.render_view != 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RENDERVIEW);
                if (pass->swapchain.depth_format == SG_PIXELFORMAT_NONE) {
                    _SG_VALIDATE(pass->swapchain.wgpu.depth_stencil_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_DEPTHSTENCILVIEW_NOTSET);
                } else {
                    _SG_VALIDATE(pass->swapchain.wgpu.depth_stencil_view != 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_DEPTHSTENCILVIEW);
                }
                if (pass->swapchain.sample_count > 1) {
                    _SG_VALIDATE(pass->swapchain.wgpu.resolve_view != 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RESOLVEVIEW);
                } else {
                    _SG_VALIDATE(pass->swapchain.wgpu.resolve_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RESOLVEVIEW_NOTSET);
                }
            #endif
        } else {
            // this is an 'offscreen pass'
            const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, pass->attachments.id);
            if (atts) {
                _SG_VALIDATE(atts->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_BEGINPASS_ATTACHMENTS_VALID);
                _SG_VALIDATE(!atts->cmn.has_storage_attachments, VALIDATE_BEGINPASS_RENDERPASS_RENDER_ATTACHMENTS_ONLY);
                for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
                    const _sg_attachment_common_t* color_att = &atts->cmn.colors[i];
                    const _sg_image_t* color_img = _sg_attachments_color_image(atts, i);
                    if (color_img) {
                        _SG_VALIDATE(color_img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_BEGINPASS_COLOR_ATTACHMENT_IMAGE);
                        _SG_VALIDATE(color_img->slot.id == color_att->image_id.id, VALIDATE_BEGINPASS_COLOR_ATTACHMENT_IMAGE);
                    }
                    const _sg_attachment_common_t* resolve_att = &atts->cmn.resolves[i];
                    const _sg_image_t* resolve_img = _sg_attachments_resolve_image(atts, i);
                    if (resolve_img) {
                        _SG_VALIDATE(resolve_img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_BEGINPASS_RESOLVE_ATTACHMENT_IMAGE);
                        _SG_VALIDATE(resolve_img->slot.id == resolve_att->image_id.id, VALIDATE_BEGINPASS_RESOLVE_ATTACHMENT_IMAGE);
                    }
                }
                const _sg_image_t* ds_img = _sg_attachments_ds_image(atts);
                if (ds_img) {
                    const _sg_attachment_common_t* att = &atts->cmn.depth_stencil;
                    _SG_VALIDATE(ds_img->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_BEGINPASS_DEPTHSTENCIL_ATTACHMENT_IMAGE);
                    _SG_VALIDATE(ds_img->slot.id == att->image_id.id, VALIDATE_BEGINPASS_DEPTHSTENCIL_ATTACHMENT_IMAGE);
                }
            } else {
                _SG_VALIDATE(atts != 0, VALIDATE_BEGINPASS_ATTACHMENTS_EXISTS);
            }
        }
        if (is_compute_pass || is_offscreen_pass) {
            _SG_VALIDATE(pass->swapchain.width == 0, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_WIDTH_NOTSET);
            _SG_VALIDATE(pass->swapchain.height == 0, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_HEIGHT_NOTSET);
            _SG_VALIDATE(pass->swapchain.sample_count == 0, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_SAMPLECOUNT_NOTSET);
            _SG_VALIDATE(pass->swapchain.color_format == _SG_PIXELFORMAT_DEFAULT, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_COLORFORMAT_NOTSET);
            _SG_VALIDATE(pass->swapchain.depth_format == _SG_PIXELFORMAT_DEFAULT, VALIDATE_BEGINPASS_SWAPCHAIN_EXPECT_DEPTHFORMAT_NOTSET);
            #if defined(SOKOL_METAL)
                _SG_VALIDATE(pass->swapchain.metal.current_drawable == 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_CURRENTDRAWABLE_NOTSET);
                _SG_VALIDATE(pass->swapchain.metal.depth_stencil_texture == 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_DEPTHSTENCILTEXTURE_NOTSET);
                _SG_VALIDATE(pass->swapchain.metal.msaa_color_texture == 0, VALIDATE_BEGINPASS_SWAPCHAIN_METAL_EXPECT_MSAACOLORTEXTURE_NOTSET);
            #elif defined(SOKOL_D3D11)
                _SG_VALIDATE(pass->swapchain.d3d11.render_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RENDERVIEW_NOTSET);
                _SG_VALIDATE(pass->swapchain.d3d11.depth_stencil_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_DEPTHSTENCILVIEW_NOTSET);
                _SG_VALIDATE(pass->swapchain.d3d11.resolve_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_D3D11_EXPECT_RESOLVEVIEW_NOTSET);
            #elif defined(SOKOL_WGPU)
                _SG_VALIDATE(pass->swapchain.wgpu.render_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RENDERVIEW_NOTSET);
                _SG_VALIDATE(pass->swapchain.wgpu.depth_stencil_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_DEPTHSTENCILVIEW_NOTSET);
                _SG_VALIDATE(pass->swapchain.wgpu.resolve_view == 0, VALIDATE_BEGINPASS_SWAPCHAIN_WGPU_EXPECT_RESOLVEVIEW_NOTSET);
            #elif defined(_SOKOL_ANY_GL)
                _SG_VALIDATE(pass->swapchain.gl.framebuffer == 0, VALIDATE_BEGINPASS_SWAPCHAIN_GL_EXPECT_FRAMEBUFFER_NOTSET);
            #endif
        }
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_apply_viewport(int x, int y, int width, int height, bool origin_top_left) {
    _SOKOL_UNUSED(x);
    _SOKOL_UNUSED(y);
    _SOKOL_UNUSED(width);
    _SOKOL_UNUSED(height);
    _SOKOL_UNUSED(origin_top_left);
    #if !defined(SOKOL_DEBUG)
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        _sg_validate_begin();
        _SG_VALIDATE(_sg.cur_pass.in_pass && !_sg.cur_pass.is_compute, VALIDATE_AVP_RENDERPASS_EXPECTED);
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left) {
    _SOKOL_UNUSED(x);
    _SOKOL_UNUSED(y);
    _SOKOL_UNUSED(width);
    _SOKOL_UNUSED(height);
    _SOKOL_UNUSED(origin_top_left);
    #if !defined(SOKOL_DEBUG)
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        _sg_validate_begin();
        _SG_VALIDATE(_sg.cur_pass.in_pass && !_sg.cur_pass.is_compute, VALIDATE_ASR_RENDERPASS_EXPECTED);
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_apply_pipeline(sg_pipeline pip_id) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(pip_id);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        _sg_validate_begin();
        // the pipeline object must be alive and valid
        _SG_VALIDATE(pip_id.id != SG_INVALID_ID, VALIDATE_APIP_PIPELINE_VALID_ID);
        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
        _SG_VALIDATE(pip != 0, VALIDATE_APIP_PIPELINE_EXISTS);
        if (!pip) {
            return _sg_validate_end();
        }
        _SG_VALIDATE(pip->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_APIP_PIPELINE_VALID);
        // the pipeline's shader must be alive and valid
        SOKOL_ASSERT(pip->shader);
        const _sg_shader_t* shd = pip->shader;
        _SG_VALIDATE(_sg.cur_pass.in_pass, VALIDATE_APIP_PASS_EXPECTED);
        _SG_VALIDATE(shd->slot.id == pip->cmn.shader_id.id, VALIDATE_APIP_SHADER_EXISTS);
        _SG_VALIDATE(shd->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_APIP_SHADER_VALID);

        // if pass attachments exist, check that the attachment object is still valid
        if (_sg.cur_pass.atts_id.id != SG_INVALID_ID) {
            const _sg_attachments_t* atts = _sg.cur_pass.atts;
            SOKOL_ASSERT(atts);
            _SG_VALIDATE(atts->slot.id == _sg.cur_pass.atts_id.id, VALIDATE_APIP_CURPASS_ATTACHMENTS_EXISTS);
            _SG_VALIDATE(atts->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_APIP_CURPASS_ATTACHMENTS_VALID);
        }
        if (pip->cmn.is_compute) {
            _SG_VALIDATE(_sg.cur_pass.is_compute, VALIDATE_APIP_COMPUTEPASS_EXPECTED);
            if (_sg.cur_pass.atts_id.id != SG_INVALID_ID) {
                const _sg_attachments_t* atts = _sg.cur_pass.atts;
                // a compute pass with storage attachments
                // check that the pass storage attachments match the shader expectations
                for (int i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
                    if (shd->cmn.storage_images[i].stage != SG_SHADERSTAGE_NONE) {
                        _SG_VALIDATE(atts->cmn.storages[i].image_id.id != SG_INVALID_ID, VALIDATE_APIP_EXPECTED_STORAGE_ATTACHMENT_IMAGE);
                        if (atts->cmn.storages[i].image_id.id != SG_INVALID_ID) {
                            const _sg_image_t* att_simg = _sg_lookup_image(&_sg.pools, atts->cmn.storages[i].image_id.id);
                            _SG_VALIDATE(att_simg && att_simg == _sg_attachments_storage_image(atts, i), VALIDATE_APIP_STORAGE_ATTACHMENT_IMAGE_EXISTS);
                            if (att_simg) {
                                _SG_VALIDATE(att_simg->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_APIP_STORAGE_ATTACHMENT_IMAGE_VALID);
                                _SG_VALIDATE(att_simg->cmn.pixel_format == shd->cmn.storage_images[i].access_format, VALIDATE_APIP_STORAGE_ATTACHMENT_PIXELFORMAT);
                                _SG_VALIDATE(att_simg->cmn.type == shd->cmn.storage_images[i].image_type, VALIDATE_APIP_STORAGE_ATTACHMENT_IMAGE_TYPE);
                            }
                        }
                    }
                }
            }
        } else {
            _SG_VALIDATE(!_sg.cur_pass.is_compute, VALIDATE_APIP_RENDERPASS_EXPECTED);
            // check that pipeline attributes match current pass attributes
            if (_sg.cur_pass.atts_id.id != SG_INVALID_ID) {
                const _sg_attachments_t* atts = _sg.cur_pass.atts;
                // an offscreen pass
                _SG_VALIDATE(pip->cmn.color_count == atts->cmn.num_colors, VALIDATE_APIP_ATT_COUNT);
                for (int i = 0; i < pip->cmn.color_count; i++) {
                    const _sg_image_t* att_img = _sg_attachments_color_image(atts, i);
                    SOKOL_ASSERT(att_img);
                    _SG_VALIDATE(pip->cmn.colors[i].pixel_format == att_img->cmn.pixel_format, VALIDATE_APIP_COLOR_FORMAT);
                    _SG_VALIDATE(pip->cmn.sample_count == att_img->cmn.sample_count, VALIDATE_APIP_SAMPLE_COUNT);
                }
                const _sg_image_t* att_dsimg = _sg_attachments_ds_image(atts);
                if (att_dsimg) {
                    _SG_VALIDATE(pip->cmn.depth.pixel_format == att_dsimg->cmn.pixel_format, VALIDATE_APIP_DEPTH_FORMAT);
                } else {
                    _SG_VALIDATE(pip->cmn.depth.pixel_format == SG_PIXELFORMAT_NONE, VALIDATE_APIP_DEPTH_FORMAT);
                }
            } else {
                // default pass
                _SG_VALIDATE(pip->cmn.color_count == 1, VALIDATE_APIP_ATT_COUNT);
                _SG_VALIDATE(pip->cmn.colors[0].pixel_format == _sg.cur_pass.swapchain.color_fmt, VALIDATE_APIP_COLOR_FORMAT);
                _SG_VALIDATE(pip->cmn.depth.pixel_format == _sg.cur_pass.swapchain.depth_fmt, VALIDATE_APIP_DEPTH_FORMAT);
                _SG_VALIDATE(pip->cmn.sample_count == _sg.cur_pass.swapchain.sample_count, VALIDATE_APIP_SAMPLE_COUNT);
            }
        }
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_apply_bindings(const sg_bindings* bindings) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(bindings);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        _sg_validate_begin();

        // must be called in a pass
        _SG_VALIDATE(_sg.cur_pass.in_pass, VALIDATE_ABND_PASS_EXPECTED);

        // bindings must not be empty
        bool has_any_bindings = bindings->index_buffer.id != SG_INVALID_ID;
        if (!has_any_bindings) for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
            has_any_bindings |= bindings->vertex_buffers[i].id != SG_INVALID_ID;
        }
        if (!has_any_bindings) for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
            has_any_bindings |= bindings->images[i].id != SG_INVALID_ID;
        }
        if (!has_any_bindings) for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
            has_any_bindings |= bindings->samplers[i].id != SG_INVALID_ID;
        }
        if (!has_any_bindings) for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
            has_any_bindings |= bindings->storage_buffers[i].id != SG_INVALID_ID;
        }
        _SG_VALIDATE(has_any_bindings, VALIDATE_ABND_EMPTY_BINDINGS);

        // a pipeline object must have been applied
        _SG_VALIDATE(_sg.cur_pipeline.id != SG_INVALID_ID, VALIDATE_ABND_PIPELINE);
        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, _sg.cur_pipeline.id);
        _SG_VALIDATE(pip != 0, VALIDATE_ABND_PIPELINE_EXISTS);
        if (!pip) {
            return _sg_validate_end();
        }
        _SG_VALIDATE(pip->slot.state == SG_RESOURCESTATE_VALID, VALIDATE_ABND_PIPELINE_VALID);
        SOKOL_ASSERT(pip->shader && (pip->cmn.shader_id.id == pip->shader->slot.id));
        const _sg_shader_t* shd = pip->shader;

        if (_sg.cur_pass.is_compute) {
            for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
                _SG_VALIDATE(bindings->vertex_buffers[i].id == SG_INVALID_ID, VALIDATE_ABND_COMPUTE_EXPECTED_NO_VBS);
            }
        } else {
            // has expected vertex buffers, and vertex buffers still exist
            for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
                if (pip->cmn.vertex_buffer_layout_active[i]) {
                    _SG_VALIDATE(bindings->vertex_buffers[i].id != SG_INVALID_ID, VALIDATE_ABND_EXPECTED_VB);
                    // buffers in vertex-buffer-slots must have vertex buffer usage
                    if (bindings->vertex_buffers[i].id != SG_INVALID_ID) {
                        const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, bindings->vertex_buffers[i].id);
                        _SG_VALIDATE(buf != 0, VALIDATE_ABND_VB_EXISTS);
                        if (buf && buf->slot.state == SG_RESOURCESTATE_VALID) {
                            _SG_VALIDATE(buf->cmn.usage.vertex_buffer, VALIDATE_ABND_VB_TYPE);
                            _SG_VALIDATE(!buf->cmn.append_overflow, VALIDATE_ABND_VB_OVERFLOW);
                        }
                    }
                }
            }
        }

        if (_sg.cur_pass.is_compute) {
            _SG_VALIDATE(bindings->index_buffer.id == SG_INVALID_ID, VALIDATE_ABND_COMPUTE_EXPECTED_NO_IB);
        } else {
            // index buffer expected or not, and index buffer still exists
            if (pip->cmn.index_type == SG_INDEXTYPE_NONE) {
                // pipeline defines non-indexed rendering, but index buffer provided
                _SG_VALIDATE(bindings->index_buffer.id == SG_INVALID_ID, VALIDATE_ABND_IB);
            } else {
                // pipeline defines indexed rendering, but no index buffer provided
                _SG_VALIDATE(bindings->index_buffer.id != SG_INVALID_ID, VALIDATE_ABND_NO_IB);
            }
            if (bindings->index_buffer.id != SG_INVALID_ID) {
                // buffer in index-buffer-slot must have index buffer usage
                const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, bindings->index_buffer.id);
                _SG_VALIDATE(buf != 0, VALIDATE_ABND_IB_EXISTS);
                if (buf && buf->slot.state == SG_RESOURCESTATE_VALID) {
                    _SG_VALIDATE(buf->cmn.usage.index_buffer, VALIDATE_ABND_IB_TYPE);
                    _SG_VALIDATE(!buf->cmn.append_overflow, VALIDATE_ABND_IB_OVERFLOW);
                }
            }
        }

        // has expected images
        for (size_t i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
            if (shd->cmn.images[i].stage != SG_SHADERSTAGE_NONE) {
                _SG_VALIDATE(bindings->images[i].id != SG_INVALID_ID, VALIDATE_ABND_EXPECTED_IMAGE_BINDING);
                if (bindings->images[i].id != SG_INVALID_ID) {
                    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, bindings->images[i].id);
                    _SG_VALIDATE(img != 0, VALIDATE_ABND_IMG_EXISTS);
                    if (img && img->slot.state == SG_RESOURCESTATE_VALID) {
                        _SG_VALIDATE(img->cmn.type == shd->cmn.images[i].image_type, VALIDATE_ABND_IMAGE_TYPE_MISMATCH);
                        if (!_sg.features.msaa_image_bindings) {
                            _SG_VALIDATE(img->cmn.sample_count == 1, VALIDATE_ABND_IMAGE_MSAA);
                        }
                        if (shd->cmn.images[i].multisampled) {
                            _SG_VALIDATE(img->cmn.sample_count > 1, VALIDATE_ABND_EXPECTED_MULTISAMPLED_IMAGE);
                        }
                        const _sg_pixelformat_info_t* info = &_sg.formats[img->cmn.pixel_format];
                        switch (shd->cmn.images[i].sample_type) {
                            case SG_IMAGESAMPLETYPE_FLOAT:
                                _SG_VALIDATE(info->filter, VALIDATE_ABND_EXPECTED_FILTERABLE_IMAGE);
                                break;
                            case SG_IMAGESAMPLETYPE_DEPTH:
                                _SG_VALIDATE(info->depth, VALIDATE_ABND_EXPECTED_DEPTH_IMAGE);
                                break;
                            default:
                                break;
                        }
                    }
                }
            }
        }

        // has expected samplers
        for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
            if (shd->cmn.samplers[i].stage != SG_SHADERSTAGE_NONE) {
                _SG_VALIDATE(bindings->samplers[i].id != SG_INVALID_ID, VALIDATE_ABND_EXPECTED_SAMPLER_BINDING);
                if (bindings->samplers[i].id != SG_INVALID_ID) {
                    const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, bindings->samplers[i].id);
                    _SG_VALIDATE(smp != 0, VALIDATE_ABND_SMP_EXISTS);
                    if (smp) {
                        if (shd->cmn.samplers[i].sampler_type == SG_SAMPLERTYPE_COMPARISON) {
                            _SG_VALIDATE(smp->cmn.compare != SG_COMPAREFUNC_NEVER, VALIDATE_ABND_UNEXPECTED_SAMPLER_COMPARE_NEVER);
                        } else {
                            _SG_VALIDATE(smp->cmn.compare == SG_COMPAREFUNC_NEVER, VALIDATE_ABND_EXPECTED_SAMPLER_COMPARE_NEVER);
                        }
                        if (shd->cmn.samplers[i].sampler_type == SG_SAMPLERTYPE_NONFILTERING) {
                            const bool nonfiltering = (smp->cmn.min_filter != SG_FILTER_LINEAR)
                                                   && (smp->cmn.mag_filter != SG_FILTER_LINEAR)
                                                   && (smp->cmn.mipmap_filter != SG_FILTER_LINEAR);
                            _SG_VALIDATE(nonfiltering, VALIDATE_ABND_EXPECTED_NONFILTERING_SAMPLER);
                        }
                    }
                }
            }
        }

        // has expected storage buffers
        for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
            if (shd->cmn.storage_buffers[i].stage != SG_SHADERSTAGE_NONE) {
                _SG_VALIDATE(bindings->storage_buffers[i].id != SG_INVALID_ID, VALIDATE_ABND_EXPECTED_STORAGEBUFFER_BINDING);
                if (bindings->storage_buffers[i].id != SG_INVALID_ID) {
                    const _sg_buffer_t* sbuf = _sg_lookup_buffer(&_sg.pools, bindings->storage_buffers[i].id);
                    _SG_VALIDATE(sbuf != 0, VALIDATE_ABND_STORAGEBUFFER_EXISTS);
                    if (sbuf) {
                        _SG_VALIDATE(sbuf->cmn.usage.storage_buffer, VALIDATE_ABND_STORAGEBUFFER_BINDING_BUFFERTYPE);
                        // read/write bindings are only allowed for immutable buffers
                        if (!shd->cmn.storage_buffers[i].readonly) {
                            _SG_VALIDATE(sbuf->cmn.usage.immutable, VALIDATE_ABND_STORAGEBUFFER_READWRITE_IMMUTABLE);
                        }
                    }
                }
            }
        }

        // the same image cannot be bound as texture and pass attachment
        if (_sg.cur_pass.atts) {
            for (size_t img_idx = 0; img_idx < SG_MAX_IMAGE_BINDSLOTS; img_idx++) {
                if (shd->cmn.images[img_idx].stage != SG_SHADERSTAGE_NONE) {
                    const uint32_t img_id = bindings->images[img_idx].id;
                    if (img_id == SG_INVALID_ID) {
                        continue;
                    }
                    _SG_VALIDATE(img_id != _sg.cur_pass.atts->cmn.depth_stencil.image_id.id, VALIDATE_ABND_IMAGE_BINDING_VS_DEPTHSTENCIL_ATTACHMENT);
                    for (size_t att_idx = 0; att_idx < SG_MAX_COLOR_ATTACHMENTS; att_idx++) {
                        _SG_VALIDATE(img_id != _sg.cur_pass.atts->cmn.colors[att_idx].image_id.id, VALIDATE_ABND_IMAGE_BINDING_VS_COLOR_ATTACHMENT);
                        _SG_VALIDATE(img_id != _sg.cur_pass.atts->cmn.resolves[att_idx].image_id.id, VALIDATE_ABND_IMAGE_BINDING_VS_RESOLVE_ATTACHMENT);
                    }
                    for (size_t att_idx = 0; att_idx < SG_MAX_STORAGE_ATTACHMENTS; att_idx++) {
                        _SG_VALIDATE(img_id != _sg.cur_pass.atts->cmn.storages[att_idx].image_id.id, VALIDATE_ABND_IMAGE_BINDING_VS_STORAGE_ATTACHMENT);
                    }
                }
            }
        }

        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_apply_uniforms(int ub_slot, const sg_range* data) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(ub_slot);
        _SOKOL_UNUSED(data);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT((ub_slot >= 0) && (ub_slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS));
        _sg_validate_begin();
        _SG_VALIDATE(_sg.cur_pass.in_pass, VALIDATE_AU_PASS_EXPECTED);
        _SG_VALIDATE(_sg.cur_pipeline.id != SG_INVALID_ID, VALIDATE_AU_NO_PIPELINE);
        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, _sg.cur_pipeline.id);
        SOKOL_ASSERT(pip && (pip->slot.id == _sg.cur_pipeline.id));
        SOKOL_ASSERT(pip->shader && (pip->shader->slot.id == pip->cmn.shader_id.id));

        const _sg_shader_t* shd = pip->shader;
        _SG_VALIDATE(shd->cmn.uniform_blocks[ub_slot].stage != SG_SHADERSTAGE_NONE, VALIDATE_AU_NO_UNIFORMBLOCK_AT_SLOT);
        _SG_VALIDATE(data->size == shd->cmn.uniform_blocks[ub_slot].size, VALIDATE_AU_SIZE);

        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_draw(int base_element, int num_elements, int num_instances) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(base_element);
        _SOKOL_UNUSED(num_elements);
        _SOKOL_UNUSED(num_instances);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        _sg_validate_begin();
        _SG_VALIDATE(_sg.cur_pass.in_pass && !_sg.cur_pass.is_compute, VALIDATE_DRAW_RENDERPASS_EXPECTED);
        _SG_VALIDATE(base_element >= 0, VALIDATE_DRAW_BASEELEMENT);
        _SG_VALIDATE(num_elements >= 0, VALIDATE_DRAW_NUMELEMENTS);
        _SG_VALIDATE(num_instances >= 0, VALIDATE_DRAW_NUMINSTANCES);
        _SG_VALIDATE(_sg.required_bindings_and_uniforms == _sg.applied_bindings_and_uniforms, VALIDATE_DRAW_REQUIRED_BINDINGS_OR_UNIFORMS_MISSING);
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(num_groups_x);
        _SOKOL_UNUSED(num_groups_y);
        _SOKOL_UNUSED(num_groups_z);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        _sg_validate_begin();
        _SG_VALIDATE(_sg.cur_pass.in_pass && _sg.cur_pass.is_compute, VALIDATE_DISPATCH_COMPUTEPASS_EXPECTED);
        _SG_VALIDATE((num_groups_x >= 0) && (num_groups_x < (1<<16)), VALIDATE_DISPATCH_NUMGROUPSX);
        _SG_VALIDATE((num_groups_y >= 0) && (num_groups_y < (1<<16)), VALIDATE_DISPATCH_NUMGROUPSY);
        _SG_VALIDATE((num_groups_z >= 0) && (num_groups_z < (1<<16)), VALIDATE_DISPATCH_NUMGROUPSZ);
        _SG_VALIDATE(_sg.required_bindings_and_uniforms == _sg.applied_bindings_and_uniforms, VALIDATE_DRAW_REQUIRED_BINDINGS_OR_UNIFORMS_MISSING);
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_update_buffer(const _sg_buffer_t* buf, const sg_range* data) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(buf);
        _SOKOL_UNUSED(data);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(buf && data && data->ptr);
        _sg_validate_begin();
        _SG_VALIDATE(!buf->cmn.usage.immutable, VALIDATE_UPDATEBUF_USAGE);
        _SG_VALIDATE(buf->cmn.size >= (int)data->size, VALIDATE_UPDATEBUF_SIZE);
        _SG_VALIDATE(buf->cmn.update_frame_index != _sg.frame_index, VALIDATE_UPDATEBUF_ONCE);
        _SG_VALIDATE(buf->cmn.append_frame_index != _sg.frame_index, VALIDATE_UPDATEBUF_APPEND);
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_append_buffer(const _sg_buffer_t* buf, const sg_range* data) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(buf);
        _SOKOL_UNUSED(data);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(buf && data && data->ptr);
        _sg_validate_begin();
        _SG_VALIDATE(!buf->cmn.usage.immutable, VALIDATE_APPENDBUF_USAGE);
        _SG_VALIDATE(buf->cmn.size >= (buf->cmn.append_pos + (int)data->size), VALIDATE_APPENDBUF_SIZE);
        _SG_VALIDATE(buf->cmn.update_frame_index != _sg.frame_index, VALIDATE_APPENDBUF_UPDATE);
        return _sg_validate_end();
    #endif
}

_SOKOL_PRIVATE bool _sg_validate_update_image(const _sg_image_t* img, const sg_image_data* data) {
    #if !defined(SOKOL_DEBUG)
        _SOKOL_UNUSED(img);
        _SOKOL_UNUSED(data);
        return true;
    #else
        if (_sg.desc.disable_validation) {
            return true;
        }
        SOKOL_ASSERT(img && data);
        _sg_validate_begin();
        _SG_VALIDATE(!img->cmn.usage.immutable, VALIDATE_UPDIMG_USAGE);
        _SG_VALIDATE(img->cmn.upd_frame_index != _sg.frame_index, VALIDATE_UPDIMG_ONCE);
        _sg_validate_image_data(data,
            img->cmn.pixel_format,
            img->cmn.width,
            img->cmn.height,
            (img->cmn.type == SG_IMAGETYPE_CUBE) ? 6 : 1,
            img->cmn.num_mipmaps,
            img->cmn.num_slices);
        return _sg_validate_end();
    #endif
}

// ██████  ███████ ███████  ██████  ██    ██ ██████   ██████ ███████ ███████
// ██   ██ ██      ██      ██    ██ ██    ██ ██   ██ ██      ██      ██
// ██████  █████   ███████ ██    ██ ██    ██ ██████  ██      █████   ███████
// ██   ██ ██           ██ ██    ██ ██    ██ ██   ██ ██      ██           ██
// ██   ██ ███████ ███████  ██████   ██████  ██   ██  ██████ ███████ ███████
//
// >>resources
_SOKOL_PRIVATE sg_buffer_usage _sg_buffer_usage_defaults(const sg_buffer_usage* usg) {
    sg_buffer_usage def = *usg;
    if (!(def.vertex_buffer || def.index_buffer || def.storage_buffer)) {
        def.vertex_buffer = true;
    }
    if (!(def.immutable || def.stream_update || def.dynamic_update)) {
        def.immutable = true;
    }
    return def;
}


_SOKOL_PRIVATE sg_buffer_desc _sg_buffer_desc_defaults(const sg_buffer_desc* desc) {
    sg_buffer_desc def = *desc;
    def.usage = _sg_buffer_usage_defaults(&def.usage);
    if (def.size == 0) {
        def.size = def.data.size;
    }
    return def;
}

_SOKOL_PRIVATE sg_image_usage _sg_image_usage_defaults(const sg_image_usage *usg) {
    sg_image_usage def = *usg;
    if (!(def.immutable || def.stream_update || def.dynamic_update)) {
        def.immutable = true;
    }
    return def;
}

_SOKOL_PRIVATE sg_image_desc _sg_image_desc_defaults(const sg_image_desc* desc) {
    sg_image_desc def = *desc;
    def.type = _sg_def(def.type, SG_IMAGETYPE_2D);
    def.usage = _sg_image_usage_defaults(&def.usage);
    def.num_slices = _sg_def(def.num_slices, 1);
    def.num_mipmaps = _sg_def(def.num_mipmaps, 1);
    if (def.usage.render_attachment) {
        def.pixel_format = _sg_def(def.pixel_format, _sg.desc.environment.defaults.color_format);
        def.sample_count = _sg_def(def.sample_count, _sg.desc.environment.defaults.sample_count);
    } else {
        def.pixel_format = _sg_def(def.pixel_format, SG_PIXELFORMAT_RGBA8);
        def.sample_count = _sg_def(def.sample_count, 1);
    }
    return def;
}

_SOKOL_PRIVATE sg_sampler_desc _sg_sampler_desc_defaults(const sg_sampler_desc* desc) {
    sg_sampler_desc def = *desc;
    def.min_filter = _sg_def(def.min_filter, SG_FILTER_NEAREST);
    def.mag_filter = _sg_def(def.mag_filter, SG_FILTER_NEAREST);
    def.mipmap_filter = _sg_def(def.mipmap_filter, SG_FILTER_NEAREST);
    def.wrap_u = _sg_def(def.wrap_u, SG_WRAP_REPEAT);
    def.wrap_v = _sg_def(def.wrap_v, SG_WRAP_REPEAT);
    def.wrap_w = _sg_def(def.wrap_w, SG_WRAP_REPEAT);
    def.max_lod = _sg_def_flt(def.max_lod, FLT_MAX);
    def.border_color = _sg_def(def.border_color, SG_BORDERCOLOR_OPAQUE_BLACK);
    def.compare = _sg_def(def.compare, SG_COMPAREFUNC_NEVER);
    def.max_anisotropy = _sg_def(def.max_anisotropy, 1);
    return def;
}

_SOKOL_PRIVATE sg_shader_desc _sg_shader_desc_defaults(const sg_shader_desc* desc) {
    sg_shader_desc def = *desc;
    #if defined(SOKOL_METAL)
        def.vertex_func.entry = _sg_def(def.vertex_func.entry, "_main");
        def.fragment_func.entry = _sg_def(def.fragment_func.entry, "_main");
        def.compute_func.entry = _sg_def(def.compute_func.entry, "_main");
    #else
        def.vertex_func.entry = _sg_def(def.vertex_func.entry, "main");
        def.fragment_func.entry = _sg_def(def.fragment_func.entry, "main");
        def.compute_func.entry = _sg_def(def.compute_func.entry, "main");
    #endif
    #if defined(SOKOL_D3D11)
        if (def.vertex_func.source) {
            def.vertex_func.d3d11_target = _sg_def(def.vertex_func.d3d11_target, "vs_4_0");
        }
        if (def.fragment_func.source) {
            def.fragment_func.d3d11_target = _sg_def(def.fragment_func.d3d11_target, "ps_4_0");
        }
        if (def.compute_func.source) {
            def.compute_func.d3d11_target = _sg_def(def.fragment_func.d3d11_target,"cs_5_0");
        }
    #endif
    def.mtl_threads_per_threadgroup.y = _sg_def(desc->mtl_threads_per_threadgroup.y, 1);
    def.mtl_threads_per_threadgroup.z = _sg_def(desc->mtl_threads_per_threadgroup.z, 1);
    for (size_t ub_index = 0; ub_index < SG_MAX_UNIFORMBLOCK_BINDSLOTS; ub_index++) {
        sg_shader_uniform_block* ub_desc = &def.uniform_blocks[ub_index];
        if (ub_desc->stage != SG_SHADERSTAGE_NONE) {
            ub_desc->layout = _sg_def(ub_desc->layout, SG_UNIFORMLAYOUT_NATIVE);
            for (size_t u_index = 0; u_index < SG_MAX_UNIFORMBLOCK_MEMBERS; u_index++) {
                sg_glsl_shader_uniform* u_desc = &ub_desc->glsl_uniforms[u_index];
                if (u_desc->type == SG_UNIFORMTYPE_INVALID) {
                    break;
                }
                u_desc->array_count = _sg_def(u_desc->array_count, 1);
            }
        }
    }
    for (size_t img_index = 0; img_index < SG_MAX_IMAGE_BINDSLOTS; img_index++) {
        sg_shader_image* img_desc = &def.images[img_index];
        if (img_desc->stage != SG_SHADERSTAGE_NONE) {
            img_desc->image_type = _sg_def(img_desc->image_type, SG_IMAGETYPE_2D);
            img_desc->sample_type = _sg_def(img_desc->sample_type, SG_IMAGESAMPLETYPE_FLOAT);
        }
    }
    for (size_t smp_index = 0; smp_index < SG_MAX_SAMPLER_BINDSLOTS; smp_index++) {
        sg_shader_sampler* smp_desc = &def.samplers[smp_index];
        if (smp_desc->stage != SG_SHADERSTAGE_NONE) {
            smp_desc->sampler_type = _sg_def(smp_desc->sampler_type, SG_SAMPLERTYPE_FILTERING);
        }
    }
    return def;
}

_SOKOL_PRIVATE sg_pipeline_desc _sg_pipeline_desc_defaults(const sg_pipeline_desc* desc) {
    sg_pipeline_desc def = *desc;

    // FIXME: should we actually do all this stuff for a compute pipeline?

    def.primitive_type = _sg_def(def.primitive_type, SG_PRIMITIVETYPE_TRIANGLES);
    def.index_type = _sg_def(def.index_type, SG_INDEXTYPE_NONE);
    def.cull_mode = _sg_def(def.cull_mode, SG_CULLMODE_NONE);
    def.face_winding = _sg_def(def.face_winding, SG_FACEWINDING_CW);
    def.sample_count = _sg_def(def.sample_count, _sg.desc.environment.defaults.sample_count);

    def.stencil.front.compare = _sg_def(def.stencil.front.compare, SG_COMPAREFUNC_ALWAYS);
    def.stencil.front.fail_op = _sg_def(def.stencil.front.fail_op, SG_STENCILOP_KEEP);
    def.stencil.front.depth_fail_op = _sg_def(def.stencil.front.depth_fail_op, SG_STENCILOP_KEEP);
    def.stencil.front.pass_op = _sg_def(def.stencil.front.pass_op, SG_STENCILOP_KEEP);
    def.stencil.back.compare = _sg_def(def.stencil.back.compare, SG_COMPAREFUNC_ALWAYS);
    def.stencil.back.fail_op = _sg_def(def.stencil.back.fail_op, SG_STENCILOP_KEEP);
    def.stencil.back.depth_fail_op = _sg_def(def.stencil.back.depth_fail_op, SG_STENCILOP_KEEP);
    def.stencil.back.pass_op = _sg_def(def.stencil.back.pass_op, SG_STENCILOP_KEEP);

    def.depth.compare = _sg_def(def.depth.compare, SG_COMPAREFUNC_ALWAYS);
    def.depth.pixel_format = _sg_def(def.depth.pixel_format, _sg.desc.environment.defaults.depth_format);
    if (def.colors[0].pixel_format == SG_PIXELFORMAT_NONE) {
        // special case depth-only rendering, enforce a color count of 0
        def.color_count = 0;
    } else {
        def.color_count = _sg_def(def.color_count, 1);
    }
    if (def.color_count > SG_MAX_COLOR_ATTACHMENTS) {
        def.color_count = SG_MAX_COLOR_ATTACHMENTS;
    }
    for (int i = 0; i < def.color_count; i++) {
        sg_color_target_state* cs = &def.colors[i];
        cs->pixel_format = _sg_def(cs->pixel_format, _sg.desc.environment.defaults.color_format);
        cs->write_mask = _sg_def(cs->write_mask, SG_COLORMASK_RGBA);
        sg_blend_state* bs = &def.colors[i].blend;
        bs->op_rgb = _sg_def(bs->op_rgb, SG_BLENDOP_ADD);
        bs->src_factor_rgb = _sg_def(bs->src_factor_rgb, SG_BLENDFACTOR_ONE);
        if ((bs->op_rgb == SG_BLENDOP_MIN) || (bs->op_rgb == SG_BLENDOP_MAX)) {
            bs->dst_factor_rgb = _sg_def(bs->dst_factor_rgb, SG_BLENDFACTOR_ONE);
        } else {
            bs->dst_factor_rgb = _sg_def(bs->dst_factor_rgb, SG_BLENDFACTOR_ZERO);
        }
        bs->op_alpha = _sg_def(bs->op_alpha, SG_BLENDOP_ADD);
        bs->src_factor_alpha = _sg_def(bs->src_factor_alpha, SG_BLENDFACTOR_ONE);
        if ((bs->op_alpha == SG_BLENDOP_MIN) || (bs->op_alpha == SG_BLENDOP_MAX)) {
            bs->dst_factor_alpha = _sg_def(bs->dst_factor_alpha, SG_BLENDFACTOR_ONE);
        } else {
            bs->dst_factor_alpha = _sg_def(bs->dst_factor_alpha, SG_BLENDFACTOR_ZERO);
        }
    }

    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
        sg_vertex_attr_state* a_state = &def.layout.attrs[attr_index];
        if (a_state->format == SG_VERTEXFORMAT_INVALID) {
            break;
        }
        SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
        sg_vertex_buffer_layout_state* l_state = &def.layout.buffers[a_state->buffer_index];
        l_state->step_func = _sg_def(l_state->step_func, SG_VERTEXSTEP_PER_VERTEX);
        l_state->step_rate = _sg_def(l_state->step_rate, 1);
    }

    // resolve vertex layout strides and offsets
    int auto_offset[SG_MAX_VERTEXBUFFER_BINDSLOTS];
    _sg_clear(auto_offset, sizeof(auto_offset));
    bool use_auto_offset = true;
    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
        // to use computed offsets, *all* attr offsets must be 0
        if (def.layout.attrs[attr_index].offset != 0) {
            use_auto_offset = false;
        }
    }
    for (int attr_index = 0; attr_index < SG_MAX_VERTEX_ATTRIBUTES; attr_index++) {
        sg_vertex_attr_state* a_state = &def.layout.attrs[attr_index];
        if (a_state->format == SG_VERTEXFORMAT_INVALID) {
            break;
        }
        SOKOL_ASSERT(a_state->buffer_index < SG_MAX_VERTEXBUFFER_BINDSLOTS);
        if (use_auto_offset) {
            a_state->offset = auto_offset[a_state->buffer_index];
        }
        auto_offset[a_state->buffer_index] += _sg_vertexformat_bytesize(a_state->format);
    }
    // compute vertex strides if needed
    for (int buf_index = 0; buf_index < SG_MAX_VERTEXBUFFER_BINDSLOTS; buf_index++) {
        sg_vertex_buffer_layout_state* l_state = &def.layout.buffers[buf_index];
        if (l_state->stride == 0) {
            l_state->stride = auto_offset[buf_index];
        }
    }

    return def;
}

_SOKOL_PRIVATE sg_attachments_desc _sg_attachments_desc_defaults(const sg_attachments_desc* desc) {
    sg_attachments_desc def = *desc;
    return def;
}

_SOKOL_PRIVATE sg_buffer _sg_alloc_buffer(void) {
    sg_buffer res;
    int slot_index = _sg_pool_alloc_index(&_sg.pools.buffer_pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id = _sg_slot_alloc(&_sg.pools.buffer_pool, &_sg.pools.buffers[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(BUFFER_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE sg_image _sg_alloc_image(void) {
    sg_image res;
    int slot_index = _sg_pool_alloc_index(&_sg.pools.image_pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id = _sg_slot_alloc(&_sg.pools.image_pool, &_sg.pools.images[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(IMAGE_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE sg_sampler _sg_alloc_sampler(void) {
    sg_sampler res;
    int slot_index = _sg_pool_alloc_index(&_sg.pools.sampler_pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id = _sg_slot_alloc(&_sg.pools.sampler_pool, &_sg.pools.samplers[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(SAMPLER_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE sg_shader _sg_alloc_shader(void) {
    sg_shader res;
    int slot_index = _sg_pool_alloc_index(&_sg.pools.shader_pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id = _sg_slot_alloc(&_sg.pools.shader_pool, &_sg.pools.shaders[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(SHADER_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE sg_pipeline _sg_alloc_pipeline(void) {
    sg_pipeline res;
    int slot_index = _sg_pool_alloc_index(&_sg.pools.pipeline_pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id =_sg_slot_alloc(&_sg.pools.pipeline_pool, &_sg.pools.pipelines[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(PIPELINE_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE sg_attachments _sg_alloc_attachments(void) {
    sg_attachments res;
    int slot_index = _sg_pool_alloc_index(&_sg.pools.attachments_pool);
    if (_SG_INVALID_SLOT_INDEX != slot_index) {
        res.id = _sg_slot_alloc(&_sg.pools.attachments_pool, &_sg.pools.attachments[slot_index].slot, slot_index);
    } else {
        res.id = SG_INVALID_ID;
        _SG_ERROR(PASS_POOL_EXHAUSTED);
    }
    return res;
}

_SOKOL_PRIVATE void _sg_dealloc_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf && (buf->slot.state == SG_RESOURCESTATE_ALLOC) && (buf->slot.id != SG_INVALID_ID));
    _sg_pool_free_index(&_sg.pools.buffer_pool, _sg_slot_index(buf->slot.id));
    _sg_slot_reset(&buf->slot);
}

_SOKOL_PRIVATE void _sg_dealloc_image(_sg_image_t* img) {
    SOKOL_ASSERT(img && (img->slot.state == SG_RESOURCESTATE_ALLOC) && (img->slot.id != SG_INVALID_ID));
    _sg_pool_free_index(&_sg.pools.image_pool, _sg_slot_index(img->slot.id));
    _sg_slot_reset(&img->slot);
}

_SOKOL_PRIVATE void _sg_dealloc_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp && (smp->slot.state == SG_RESOURCESTATE_ALLOC) && (smp->slot.id != SG_INVALID_ID));
    _sg_pool_free_index(&_sg.pools.sampler_pool, _sg_slot_index(smp->slot.id));
    _sg_slot_reset(&smp->slot);
}

_SOKOL_PRIVATE void _sg_dealloc_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd && (shd->slot.state == SG_RESOURCESTATE_ALLOC) && (shd->slot.id != SG_INVALID_ID));
    _sg_pool_free_index(&_sg.pools.shader_pool, _sg_slot_index(shd->slot.id));
    _sg_slot_reset(&shd->slot);
}

_SOKOL_PRIVATE void _sg_dealloc_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip && (pip->slot.state == SG_RESOURCESTATE_ALLOC) && (pip->slot.id != SG_INVALID_ID));
    _sg_pool_free_index(&_sg.pools.pipeline_pool, _sg_slot_index(pip->slot.id));
    _sg_slot_reset(&pip->slot);
}

_SOKOL_PRIVATE void _sg_dealloc_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts && (atts->slot.state == SG_RESOURCESTATE_ALLOC) && (atts->slot.id != SG_INVALID_ID));
    _sg_pool_free_index(&_sg.pools.attachments_pool, _sg_slot_index(atts->slot.id));
    _sg_slot_reset(&atts->slot);
}

_SOKOL_PRIVATE void _sg_init_buffer(_sg_buffer_t* buf, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(buf && (buf->slot.state == SG_RESOURCESTATE_ALLOC));
    SOKOL_ASSERT(desc);
    if (_sg_validate_buffer_desc(desc)) {
        _sg_buffer_common_init(&buf->cmn, desc);
        buf->slot.state = _sg_create_buffer(buf, desc);
    } else {
        buf->slot.state = SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT((buf->slot.state == SG_RESOURCESTATE_VALID)||(buf->slot.state == SG_RESOURCESTATE_FAILED));
}

_SOKOL_PRIVATE void _sg_init_image(_sg_image_t* img, const sg_image_desc* desc) {
    SOKOL_ASSERT(img && (img->slot.state == SG_RESOURCESTATE_ALLOC));
    SOKOL_ASSERT(desc);
    if (_sg_validate_image_desc(desc)) {
        _sg_image_common_init(&img->cmn, desc);
        img->slot.state = _sg_create_image(img, desc);
    } else {
        img->slot.state = SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT((img->slot.state == SG_RESOURCESTATE_VALID)||(img->slot.state == SG_RESOURCESTATE_FAILED));
}

_SOKOL_PRIVATE void _sg_init_sampler(_sg_sampler_t* smp, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(smp && (smp->slot.state == SG_RESOURCESTATE_ALLOC));
    SOKOL_ASSERT(desc);
    if (_sg_validate_sampler_desc(desc)) {
        _sg_sampler_common_init(&smp->cmn, desc);
        smp->slot.state = _sg_create_sampler(smp, desc);
    } else {
        smp->slot.state = SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT((smp->slot.state == SG_RESOURCESTATE_VALID)||(smp->slot.state == SG_RESOURCESTATE_FAILED));
}

_SOKOL_PRIVATE void _sg_init_shader(_sg_shader_t* shd, const sg_shader_desc* desc) {
    SOKOL_ASSERT(shd && (shd->slot.state == SG_RESOURCESTATE_ALLOC));
    SOKOL_ASSERT(desc);
    if (_sg_validate_shader_desc(desc)) {
        _sg_shader_common_init(&shd->cmn, desc);
        shd->slot.state = _sg_create_shader(shd, desc);
    } else {
        shd->slot.state = SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT((shd->slot.state == SG_RESOURCESTATE_VALID)||(shd->slot.state == SG_RESOURCESTATE_FAILED));
}

_SOKOL_PRIVATE void _sg_init_pipeline(_sg_pipeline_t* pip, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(pip && (pip->slot.state == SG_RESOURCESTATE_ALLOC));
    SOKOL_ASSERT(desc);
    if (_sg_validate_pipeline_desc(desc)) {
        _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, desc->shader.id);
        if (shd && (shd->slot.state == SG_RESOURCESTATE_VALID)) {
            _sg_pipeline_common_init(&pip->cmn, desc);
            pip->slot.state = _sg_create_pipeline(pip, shd, desc);
        } else {
            pip->slot.state = SG_RESOURCESTATE_FAILED;
        }
    } else {
        pip->slot.state = SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT((pip->slot.state == SG_RESOURCESTATE_VALID)||(pip->slot.state == SG_RESOURCESTATE_FAILED));
}

_SOKOL_PRIVATE void _sg_init_attachments(_sg_attachments_t* atts, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(atts && atts->slot.state == SG_RESOURCESTATE_ALLOC);
    SOKOL_ASSERT(desc);
    if (_sg_validate_attachments_desc(desc)) {
        // resolve image pointers, track width and height of render attachments,
        // the validation layer already ensured that render attachments have the
        // same width and height (which doesn't matter for storage attachments)
        _sg_attachments_ptrs_t atts_ptrs;
        _sg_clear(&atts_ptrs, sizeof(atts_ptrs));
        int width = 0;
        int height = 0;
        for (size_t i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
            if (desc->colors[i].image.id) {
                _sg_image_t* img = _sg_lookup_image(&_sg.pools, desc->colors[i].image.id);
                if (!(img && img->slot.state == SG_RESOURCESTATE_VALID)) {
                    atts->slot.state = SG_RESOURCESTATE_FAILED;
                    return;
                }
                const int mip_level = desc->colors[i].mip_level;
                width = _sg_miplevel_dim(img->cmn.width, mip_level);
                height = _sg_miplevel_dim(img->cmn.height, mip_level);
                atts_ptrs.color_images[i] = img;
            }
            if (desc->resolves[i].image.id) {
                _sg_image_t* img = _sg_lookup_image(&_sg.pools, desc->resolves[i].image.id);
                if (!(img && img->slot.state == SG_RESOURCESTATE_VALID)) {
                    atts->slot.state = SG_RESOURCESTATE_FAILED;
                    return;
                }
                atts_ptrs.resolve_images[i] = img;
            }
        }
        if (desc->depth_stencil.image.id) {
            _sg_image_t* img = _sg_lookup_image(&_sg.pools, desc->depth_stencil.image.id);
            if (!(img && img->slot.state == SG_RESOURCESTATE_VALID)) {
                atts->slot.state = SG_RESOURCESTATE_FAILED;
                return;
            }
            const int mip_level = desc->depth_stencil.mip_level;
            width = _sg_miplevel_dim(img->cmn.width, mip_level);
            height = _sg_miplevel_dim(img->cmn.height, mip_level);
            atts_ptrs.ds_image = img;
        }
        for (size_t i = 0; i < SG_MAX_STORAGE_ATTACHMENTS; i++) {
            if (desc->storages[i].image.id) {
                _sg_image_t* img = _sg_lookup_image(&_sg.pools, desc->storages[i].image.id);
                if (!(img && img->slot.state == SG_RESOURCESTATE_VALID)) {
                    atts->slot.state = SG_RESOURCESTATE_FAILED;
                    return;
                }
                atts_ptrs.storage_images[i] = img;
            }
        }
        _sg_attachments_common_init(&atts->cmn, desc, width, height);
        atts->slot.state = _sg_create_attachments(atts, &atts_ptrs, desc);
    } else {
        atts->slot.state = SG_RESOURCESTATE_FAILED;
    }
    SOKOL_ASSERT((atts->slot.state == SG_RESOURCESTATE_VALID)||(atts->slot.state == SG_RESOURCESTATE_FAILED));
}

_SOKOL_PRIVATE void _sg_uninit_buffer(_sg_buffer_t* buf) {
    SOKOL_ASSERT(buf && ((buf->slot.state == SG_RESOURCESTATE_VALID) || (buf->slot.state == SG_RESOURCESTATE_FAILED)));
    _sg_discard_buffer(buf);
    _sg_reset_buffer_to_alloc_state(buf);
}

_SOKOL_PRIVATE void _sg_uninit_image(_sg_image_t* img) {
    SOKOL_ASSERT(img && ((img->slot.state == SG_RESOURCESTATE_VALID) || (img->slot.state == SG_RESOURCESTATE_FAILED)));
    _sg_discard_image(img);
    _sg_reset_image_to_alloc_state(img);
}

_SOKOL_PRIVATE void _sg_uninit_sampler(_sg_sampler_t* smp) {
    SOKOL_ASSERT(smp && ((smp->slot.state == SG_RESOURCESTATE_VALID) || (smp->slot.state == SG_RESOURCESTATE_FAILED)));
    _sg_discard_sampler(smp);
    _sg_reset_sampler_to_alloc_state(smp);
}

_SOKOL_PRIVATE void _sg_uninit_shader(_sg_shader_t* shd) {
    SOKOL_ASSERT(shd && ((shd->slot.state == SG_RESOURCESTATE_VALID) || (shd->slot.state == SG_RESOURCESTATE_FAILED)));
    _sg_discard_shader(shd);
    _sg_reset_shader_to_alloc_state(shd);
}

_SOKOL_PRIVATE void _sg_uninit_pipeline(_sg_pipeline_t* pip) {
    SOKOL_ASSERT(pip && ((pip->slot.state == SG_RESOURCESTATE_VALID) || (pip->slot.state == SG_RESOURCESTATE_FAILED)));
    _sg_discard_pipeline(pip);
    _sg_reset_pipeline_to_alloc_state(pip);
}

_SOKOL_PRIVATE void _sg_uninit_attachments(_sg_attachments_t* atts) {
    SOKOL_ASSERT(atts && ((atts->slot.state == SG_RESOURCESTATE_VALID) || (atts->slot.state == SG_RESOURCESTATE_FAILED)));
    _sg_discard_attachments(atts);
    _sg_reset_attachments_to_alloc_state(atts);
}

_SOKOL_PRIVATE void _sg_setup_commit_listeners(const sg_desc* desc) {
    SOKOL_ASSERT(desc->max_commit_listeners > 0);
    SOKOL_ASSERT(0 == _sg.commit_listeners.items);
    SOKOL_ASSERT(0 == _sg.commit_listeners.num);
    SOKOL_ASSERT(0 == _sg.commit_listeners.upper);
    _sg.commit_listeners.num = desc->max_commit_listeners;
    const size_t size = (size_t)_sg.commit_listeners.num * sizeof(sg_commit_listener);
    _sg.commit_listeners.items = (sg_commit_listener*)_sg_malloc_clear(size);
}

_SOKOL_PRIVATE void _sg_discard_commit_listeners(void) {
    SOKOL_ASSERT(0 != _sg.commit_listeners.items);
    _sg_free(_sg.commit_listeners.items);
    _sg.commit_listeners.items = 0;
}

_SOKOL_PRIVATE void _sg_notify_commit_listeners(void) {
    SOKOL_ASSERT(_sg.commit_listeners.items);
    for (int i = 0; i < _sg.commit_listeners.upper; i++) {
        const sg_commit_listener* listener = &_sg.commit_listeners.items[i];
        if (listener->func) {
            listener->func(listener->user_data);
        }
    }
}

_SOKOL_PRIVATE bool _sg_add_commit_listener(const sg_commit_listener* new_listener) {
    SOKOL_ASSERT(new_listener && new_listener->func);
    SOKOL_ASSERT(_sg.commit_listeners.items);
    // first check if the listener hadn't been added already
    for (int i = 0; i < _sg.commit_listeners.upper; i++) {
        const sg_commit_listener* slot = &_sg.commit_listeners.items[i];
        if ((slot->func == new_listener->func) && (slot->user_data == new_listener->user_data)) {
            _SG_ERROR(IDENTICAL_COMMIT_LISTENER);
            return false;
        }
    }
    // first try to plug a hole
    sg_commit_listener* slot = 0;
    for (int i = 0; i < _sg.commit_listeners.upper; i++) {
        if (_sg.commit_listeners.items[i].func == 0) {
            slot = &_sg.commit_listeners.items[i];
            break;
        }
    }
    if (!slot) {
        // append to end
        if (_sg.commit_listeners.upper < _sg.commit_listeners.num) {
            slot = &_sg.commit_listeners.items[_sg.commit_listeners.upper++];
        }
    }
    if (!slot) {
        _SG_ERROR(COMMIT_LISTENER_ARRAY_FULL);
        return false;
    }
    *slot = *new_listener;
    return true;
}

_SOKOL_PRIVATE bool _sg_remove_commit_listener(const sg_commit_listener* listener) {
    SOKOL_ASSERT(listener && listener->func);
    SOKOL_ASSERT(_sg.commit_listeners.items);
    for (int i = 0; i < _sg.commit_listeners.upper; i++) {
        sg_commit_listener* slot = &_sg.commit_listeners.items[i];
        // both the function pointer and user data must match!
        if ((slot->func == listener->func) && (slot->user_data == listener->user_data)) {
            slot->func = 0;
            slot->user_data = 0;
            // NOTE: since _sg_add_commit_listener() already catches duplicates,
            // we don't need to worry about them here
            return true;
        }
    }
    return false;
}

_SOKOL_PRIVATE void _sg_setup_compute(const sg_desc* desc) {
    SOKOL_ASSERT(desc && (desc->max_dispatch_calls_per_pass > 0));
    const uint32_t max_tracked_sbufs = (uint32_t)desc->max_dispatch_calls_per_pass * SG_MAX_STORAGEBUFFER_BINDSLOTS;
    _sg_tracker_init(&_sg.compute.readwrite_sbufs, max_tracked_sbufs);
}

_SOKOL_PRIVATE void _sg_discard_compute(void) {
    _sg_tracker_discard(&_sg.compute.readwrite_sbufs);
}

_SOKOL_PRIVATE void _sg_compute_pass_track_storage_buffer(_sg_buffer_t* sbuf, bool readonly) {
    SOKOL_ASSERT(sbuf);
    if (!readonly) {
        _sg_tracker_add(&_sg.compute.readwrite_sbufs, sbuf->slot.id);
    }
}

_SOKOL_PRIVATE void _sg_compute_on_endpass(void) {
    SOKOL_ASSERT(_sg.cur_pass.in_pass);
    SOKOL_ASSERT(_sg.cur_pass.is_compute);
    _sg_tracker_reset(&_sg.compute.readwrite_sbufs);
}

_SOKOL_PRIVATE sg_desc _sg_desc_defaults(const sg_desc* desc) {
    /*
        NOTE: on WebGPU, the default color pixel format MUST be provided,
        cannot be a default compile-time constant.
    */
    sg_desc res = *desc;
    #if defined(SOKOL_WGPU)
        SOKOL_ASSERT(SG_PIXELFORMAT_NONE < res.environment.defaults.color_format);
    #elif defined(SOKOL_METAL) || defined(SOKOL_D3D11)
        res.environment.defaults.color_format = _sg_def(res.environment.defaults.color_format, SG_PIXELFORMAT_BGRA8);
    #else
        res.environment.defaults.color_format = _sg_def(res.environment.defaults.color_format, SG_PIXELFORMAT_RGBA8);
    #endif
    res.environment.defaults.depth_format = _sg_def(res.environment.defaults.depth_format, SG_PIXELFORMAT_DEPTH_STENCIL);
    res.environment.defaults.sample_count = _sg_def(res.environment.defaults.sample_count, 1);
    res.buffer_pool_size = _sg_def(res.buffer_pool_size, _SG_DEFAULT_BUFFER_POOL_SIZE);
    res.image_pool_size = _sg_def(res.image_pool_size, _SG_DEFAULT_IMAGE_POOL_SIZE);
    res.sampler_pool_size = _sg_def(res.sampler_pool_size, _SG_DEFAULT_SAMPLER_POOL_SIZE);
    res.shader_pool_size = _sg_def(res.shader_pool_size, _SG_DEFAULT_SHADER_POOL_SIZE);
    res.pipeline_pool_size = _sg_def(res.pipeline_pool_size, _SG_DEFAULT_PIPELINE_POOL_SIZE);
    res.attachments_pool_size = _sg_def(res.attachments_pool_size, _SG_DEFAULT_ATTACHMENTS_POOL_SIZE);
    res.uniform_buffer_size = _sg_def(res.uniform_buffer_size, _SG_DEFAULT_UB_SIZE);
    res.max_dispatch_calls_per_pass = _sg_def(res.max_dispatch_calls_per_pass, _SG_DEFAULT_MAX_DISPATCH_CALLS_PER_PASS);
    res.max_commit_listeners = _sg_def(res.max_commit_listeners, _SG_DEFAULT_MAX_COMMIT_LISTENERS);
    res.wgpu_bindgroups_cache_size = _sg_def(res.wgpu_bindgroups_cache_size, _SG_DEFAULT_WGPU_BINDGROUP_CACHE_SIZE);
    return res;
}

_SOKOL_PRIVATE sg_pass _sg_pass_defaults(const sg_pass* pass) {
    sg_pass res = *pass;
    if (!res.compute) {
        if (res.compute && res.attachments.id == SG_INVALID_ID) {
            // this is a swapchain-pass
            res.swapchain.sample_count = _sg_def(res.swapchain.sample_count, _sg.desc.environment.defaults.sample_count);
            res.swapchain.color_format = _sg_def(res.swapchain.color_format, _sg.desc.environment.defaults.color_format);
            res.swapchain.depth_format = _sg_def(res.swapchain.depth_format, _sg.desc.environment.defaults.depth_format);
        }
        res.action = _sg_pass_action_defaults(&res.action);
    }
    return res;
}

// ██████  ██    ██ ██████  ██      ██  ██████
// ██   ██ ██    ██ ██   ██ ██      ██ ██
// ██████  ██    ██ ██████  ██      ██ ██
// ██      ██    ██ ██   ██ ██      ██ ██
// ██       ██████  ██████  ███████ ██  ██████
//
// >>public
SOKOL_API_IMPL void sg_setup(const sg_desc* desc) {
    SOKOL_ASSERT(desc);
    SOKOL_ASSERT((desc->_start_canary == 0) && (desc->_end_canary == 0));
    SOKOL_ASSERT((desc->allocator.alloc_fn && desc->allocator.free_fn) || (!desc->allocator.alloc_fn && !desc->allocator.free_fn));
    _SG_CLEAR_ARC_STRUCT(_sg_state_t, _sg);
    _sg.desc = _sg_desc_defaults(desc);
    _sg_setup_pools(&_sg.pools, &_sg.desc);
    _sg_setup_compute(&_sg.desc);
    _sg_setup_commit_listeners(&_sg.desc);
    _sg.frame_index = 1;
    _sg.stats_enabled = true;
    _sg_setup_backend(&_sg.desc);
    _sg.valid = true;
}

SOKOL_API_IMPL void sg_shutdown(void) {
    _sg_discard_all_resources(&_sg.pools);
    _sg_discard_backend();
    _sg_discard_commit_listeners();
    _sg_discard_compute();
    _sg_discard_pools(&_sg.pools);
    _SG_CLEAR_ARC_STRUCT(_sg_state_t, _sg);
}

SOKOL_API_IMPL bool sg_isvalid(void) {
    return _sg.valid;
}

SOKOL_API_IMPL sg_desc sg_query_desc(void) {
    SOKOL_ASSERT(_sg.valid);
    return _sg.desc;
}

SOKOL_API_IMPL sg_backend sg_query_backend(void) {
    SOKOL_ASSERT(_sg.valid);
    return _sg.backend;
}

SOKOL_API_IMPL sg_features sg_query_features(void) {
    SOKOL_ASSERT(_sg.valid);
    return _sg.features;
}

SOKOL_API_IMPL sg_limits sg_query_limits(void) {
    SOKOL_ASSERT(_sg.valid);
    return _sg.limits;
}

SOKOL_API_IMPL sg_pixelformat_info sg_query_pixelformat(sg_pixel_format fmt) {
    SOKOL_ASSERT(_sg.valid);
    int fmt_index = (int) fmt;
    SOKOL_ASSERT((fmt_index > SG_PIXELFORMAT_NONE) && (fmt_index < _SG_PIXELFORMAT_NUM));
    const _sg_pixelformat_info_t* src = &_sg.formats[fmt_index];
    sg_pixelformat_info res;
    _sg_clear(&res, sizeof(res));
    res.sample = src->sample;
    res.filter = src->filter;
    res.render = src->render;
    res.blend = src->blend;
    res.msaa = src->msaa;
    res.depth = src->depth;
    res.compressed = _sg_is_compressed_pixel_format(fmt);
    res.read = src->read;
    res.write = src->write;
    if (!res.compressed) {
        res.bytes_per_pixel = _sg_pixelformat_bytesize(fmt);
    }
    return res;
}

SOKOL_API_IMPL int sg_query_row_pitch(sg_pixel_format fmt, int width, int row_align_bytes) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(width > 0);
    SOKOL_ASSERT((row_align_bytes > 0) && _sg_ispow2(row_align_bytes));
    SOKOL_ASSERT(((int)fmt > SG_PIXELFORMAT_NONE) && ((int)fmt < _SG_PIXELFORMAT_NUM));
    return _sg_row_pitch(fmt, width, row_align_bytes);
}

SOKOL_API_IMPL int sg_query_surface_pitch(sg_pixel_format fmt, int width, int height, int row_align_bytes) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT((width > 0) && (height > 0));
    SOKOL_ASSERT((row_align_bytes > 0) && _sg_ispow2(row_align_bytes));
    SOKOL_ASSERT(((int)fmt > SG_PIXELFORMAT_NONE) && ((int)fmt < _SG_PIXELFORMAT_NUM));
    return _sg_surface_pitch(fmt, width, height, row_align_bytes);
}

SOKOL_API_IMPL sg_frame_stats sg_query_frame_stats(void) {
    SOKOL_ASSERT(_sg.valid);
    return _sg.prev_stats;
}

SOKOL_API_IMPL sg_trace_hooks sg_install_trace_hooks(const sg_trace_hooks* trace_hooks) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(trace_hooks);
    _SOKOL_UNUSED(trace_hooks);
    #if defined(SOKOL_TRACE_HOOKS)
        sg_trace_hooks old_hooks = _sg.hooks;
        _sg.hooks = *trace_hooks;
    #else
        static sg_trace_hooks old_hooks;
        _SG_WARN(TRACE_HOOKS_NOT_ENABLED);
    #endif
    return old_hooks;
}

SOKOL_API_IMPL sg_buffer sg_alloc_buffer(void) {
    SOKOL_ASSERT(_sg.valid);
    sg_buffer res = _sg_alloc_buffer();
    _SG_TRACE_ARGS(alloc_buffer, res);
    return res;
}

SOKOL_API_IMPL sg_image sg_alloc_image(void) {
    SOKOL_ASSERT(_sg.valid);
    sg_image res = _sg_alloc_image();
    _SG_TRACE_ARGS(alloc_image, res);
    return res;
}

SOKOL_API_IMPL sg_sampler sg_alloc_sampler(void) {
    SOKOL_ASSERT(_sg.valid);
    sg_sampler res = _sg_alloc_sampler();
    _SG_TRACE_ARGS(alloc_sampler, res);
    return res;
}

SOKOL_API_IMPL sg_shader sg_alloc_shader(void) {
    SOKOL_ASSERT(_sg.valid);
    sg_shader res = _sg_alloc_shader();
    _SG_TRACE_ARGS(alloc_shader, res);
    return res;
}

SOKOL_API_IMPL sg_pipeline sg_alloc_pipeline(void) {
    SOKOL_ASSERT(_sg.valid);
    sg_pipeline res = _sg_alloc_pipeline();
    _SG_TRACE_ARGS(alloc_pipeline, res);
    return res;
}

SOKOL_API_IMPL sg_attachments sg_alloc_attachments(void) {
    SOKOL_ASSERT(_sg.valid);
    sg_attachments res = _sg_alloc_attachments();
    _SG_TRACE_ARGS(alloc_attachments, res);
    return res;
}

SOKOL_API_IMPL void sg_dealloc_buffer(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        if (buf->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_buffer(buf);
        } else {
            _SG_ERROR(DEALLOC_BUFFER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(dealloc_buffer, buf_id);
}

SOKOL_API_IMPL void sg_dealloc_image(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        if (img->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_image(img);
        } else {
            _SG_ERROR(DEALLOC_IMAGE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(dealloc_image, img_id);
}

SOKOL_API_IMPL void sg_dealloc_sampler(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        if (smp->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_sampler(smp);
        } else {
            _SG_ERROR(DEALLOC_SAMPLER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(dealloc_sampler, smp_id);
}

SOKOL_API_IMPL void sg_dealloc_shader(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        if (shd->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_shader(shd);
        } else {
            _SG_ERROR(DEALLOC_SHADER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(dealloc_shader, shd_id);
}

SOKOL_API_IMPL void sg_dealloc_pipeline(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        if (pip->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_pipeline(pip);
        } else {
            _SG_ERROR(DEALLOC_PIPELINE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(dealloc_pipeline, pip_id);
}

SOKOL_API_IMPL void sg_dealloc_attachments(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        if (atts->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_attachments(atts);
        } else {
            _SG_ERROR(DEALLOC_ATTACHMENTS_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(dealloc_attachments, atts_id);
}

SOKOL_API_IMPL void sg_init_buffer(sg_buffer buf_id, const sg_buffer_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    sg_buffer_desc desc_def = _sg_buffer_desc_defaults(desc);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        if (buf->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_init_buffer(buf, &desc_def);
            SOKOL_ASSERT((buf->slot.state == SG_RESOURCESTATE_VALID) || (buf->slot.state == SG_RESOURCESTATE_FAILED));
        } else {
            _SG_ERROR(INIT_BUFFER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(init_buffer, buf_id, &desc_def);
}

SOKOL_API_IMPL void sg_init_image(sg_image img_id, const sg_image_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    sg_image_desc desc_def = _sg_image_desc_defaults(desc);
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        if (img->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_init_image(img, &desc_def);
            SOKOL_ASSERT((img->slot.state == SG_RESOURCESTATE_VALID) || (img->slot.state == SG_RESOURCESTATE_FAILED));
        } else {
            _SG_ERROR(INIT_IMAGE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(init_image, img_id, &desc_def);
}

SOKOL_API_IMPL void sg_init_sampler(sg_sampler smp_id, const sg_sampler_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    sg_sampler_desc desc_def = _sg_sampler_desc_defaults(desc);
    _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        if (smp->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_init_sampler(smp, &desc_def);
            SOKOL_ASSERT((smp->slot.state == SG_RESOURCESTATE_VALID) || (smp->slot.state == SG_RESOURCESTATE_FAILED));
        } else {
            _SG_ERROR(INIT_SAMPLER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(init_sampler, smp_id, &desc_def);
}

SOKOL_API_IMPL void sg_init_shader(sg_shader shd_id, const sg_shader_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    sg_shader_desc desc_def = _sg_shader_desc_defaults(desc);
    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        if (shd->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_init_shader(shd, &desc_def);
            SOKOL_ASSERT((shd->slot.state == SG_RESOURCESTATE_VALID) || (shd->slot.state == SG_RESOURCESTATE_FAILED));
        } else {
            _SG_ERROR(INIT_SHADER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(init_shader, shd_id, &desc_def);
}

SOKOL_API_IMPL void sg_init_pipeline(sg_pipeline pip_id, const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    sg_pipeline_desc desc_def = _sg_pipeline_desc_defaults(desc);
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        if (pip->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_init_pipeline(pip, &desc_def);
            SOKOL_ASSERT((pip->slot.state == SG_RESOURCESTATE_VALID) || (pip->slot.state == SG_RESOURCESTATE_FAILED));
        } else {
            _SG_ERROR(INIT_PIPELINE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(init_pipeline, pip_id, &desc_def);
}

SOKOL_API_IMPL void sg_init_attachments(sg_attachments atts_id, const sg_attachments_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    sg_attachments_desc desc_def = _sg_attachments_desc_defaults(desc);
    _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        if (atts->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_init_attachments(atts, &desc_def);
            SOKOL_ASSERT((atts->slot.state == SG_RESOURCESTATE_VALID) || (atts->slot.state == SG_RESOURCESTATE_FAILED));
        } else {
            _SG_ERROR(INIT_ATTACHMENTS_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(init_attachments, atts_id, &desc_def);
}

SOKOL_API_IMPL void sg_uninit_buffer(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        if ((buf->slot.state == SG_RESOURCESTATE_VALID) || (buf->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_buffer(buf);
            SOKOL_ASSERT(buf->slot.state == SG_RESOURCESTATE_ALLOC);
        } else {
            _SG_ERROR(UNINIT_BUFFER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(uninit_buffer, buf_id);
}

SOKOL_API_IMPL void sg_uninit_image(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        if ((img->slot.state == SG_RESOURCESTATE_VALID) || (img->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_image(img);
            SOKOL_ASSERT(img->slot.state == SG_RESOURCESTATE_ALLOC);
        } else {
            _SG_ERROR(UNINIT_IMAGE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(uninit_image, img_id);
}

SOKOL_API_IMPL void sg_uninit_sampler(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        if ((smp->slot.state == SG_RESOURCESTATE_VALID) || (smp->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_sampler(smp);
            SOKOL_ASSERT(smp->slot.state == SG_RESOURCESTATE_ALLOC);
        } else {
            _SG_ERROR(UNINIT_SAMPLER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(uninit_sampler, smp_id);
}

SOKOL_API_IMPL void sg_uninit_shader(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        if ((shd->slot.state == SG_RESOURCESTATE_VALID) || (shd->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_shader(shd);
            SOKOL_ASSERT(shd->slot.state == SG_RESOURCESTATE_ALLOC);
        } else {
            _SG_ERROR(UNINIT_SHADER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(uninit_shader, shd_id);
}

SOKOL_API_IMPL void sg_uninit_pipeline(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        if ((pip->slot.state == SG_RESOURCESTATE_VALID) || (pip->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_pipeline(pip);
            SOKOL_ASSERT(pip->slot.state == SG_RESOURCESTATE_ALLOC);
        } else {
            _SG_ERROR(UNINIT_PIPELINE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(uninit_pipeline, pip_id);
}

SOKOL_API_IMPL void sg_uninit_attachments(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        if ((atts->slot.state == SG_RESOURCESTATE_VALID) || (atts->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_attachments(atts);
            SOKOL_ASSERT(atts->slot.state == SG_RESOURCESTATE_ALLOC);
        } else {
            _SG_ERROR(UNINIT_ATTACHMENTS_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(uninit_attachments, atts_id);
}

SOKOL_API_IMPL void sg_fail_buffer(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        if (buf->slot.state == SG_RESOURCESTATE_ALLOC) {
            buf->slot.state = SG_RESOURCESTATE_FAILED;
        } else {
            _SG_ERROR(FAIL_BUFFER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(fail_buffer, buf_id);
}

SOKOL_API_IMPL void sg_fail_image(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        if (img->slot.state == SG_RESOURCESTATE_ALLOC) {
            img->slot.state = SG_RESOURCESTATE_FAILED;
        } else {
            _SG_ERROR(FAIL_IMAGE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(fail_image, img_id);
}

SOKOL_API_IMPL void sg_fail_sampler(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        if (smp->slot.state == SG_RESOURCESTATE_ALLOC) {
            smp->slot.state = SG_RESOURCESTATE_FAILED;
        } else {
            _SG_ERROR(FAIL_SAMPLER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(fail_sampler, smp_id);
}

SOKOL_API_IMPL void sg_fail_shader(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        if (shd->slot.state == SG_RESOURCESTATE_ALLOC) {
            shd->slot.state = SG_RESOURCESTATE_FAILED;
        } else {
            _SG_ERROR(FAIL_SHADER_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(fail_shader, shd_id);
}

SOKOL_API_IMPL void sg_fail_pipeline(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        if (pip->slot.state == SG_RESOURCESTATE_ALLOC) {
            pip->slot.state = SG_RESOURCESTATE_FAILED;
        } else {
            _SG_ERROR(FAIL_PIPELINE_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(fail_pipeline, pip_id);
}

SOKOL_API_IMPL void sg_fail_attachments(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        if (atts->slot.state == SG_RESOURCESTATE_ALLOC) {
            atts->slot.state = SG_RESOURCESTATE_FAILED;
        } else {
            _SG_ERROR(FAIL_ATTACHMENTS_INVALID_STATE);
        }
    }
    _SG_TRACE_ARGS(fail_attachments, atts_id);
}

SOKOL_API_IMPL sg_resource_state sg_query_buffer_state(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    sg_resource_state res = buf ? buf->slot.state : SG_RESOURCESTATE_INVALID;
    return res;
}

SOKOL_API_IMPL sg_resource_state sg_query_image_state(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    sg_resource_state res = img ? img->slot.state : SG_RESOURCESTATE_INVALID;
    return res;
}

SOKOL_API_IMPL sg_resource_state sg_query_sampler_state(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    sg_resource_state res = smp ? smp->slot.state : SG_RESOURCESTATE_INVALID;
    return res;
}

SOKOL_API_IMPL sg_resource_state sg_query_shader_state(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    sg_resource_state res = shd ? shd->slot.state : SG_RESOURCESTATE_INVALID;
    return res;
}

SOKOL_API_IMPL sg_resource_state sg_query_pipeline_state(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    sg_resource_state res = pip ? pip->slot.state : SG_RESOURCESTATE_INVALID;
    return res;
}

SOKOL_API_IMPL sg_resource_state sg_query_attachments_state(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    sg_resource_state res = atts ? atts->slot.state : SG_RESOURCESTATE_INVALID;
    return res;
}

SOKOL_API_IMPL sg_buffer sg_make_buffer(const sg_buffer_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(desc);
    sg_buffer_desc desc_def = _sg_buffer_desc_defaults(desc);
    sg_buffer buf_id = _sg_alloc_buffer();
    if (buf_id.id != SG_INVALID_ID) {
        _sg_buffer_t* buf = _sg_buffer_at(&_sg.pools, buf_id.id);
        SOKOL_ASSERT(buf && (buf->slot.state == SG_RESOURCESTATE_ALLOC));
        _sg_init_buffer(buf, &desc_def);
        SOKOL_ASSERT((buf->slot.state == SG_RESOURCESTATE_VALID) || (buf->slot.state == SG_RESOURCESTATE_FAILED));
    }
    _SG_TRACE_ARGS(make_buffer, &desc_def, buf_id);
    return buf_id;
}

SOKOL_API_IMPL sg_image sg_make_image(const sg_image_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(desc);
    sg_image_desc desc_def = _sg_image_desc_defaults(desc);
    sg_image img_id = _sg_alloc_image();
    if (img_id.id != SG_INVALID_ID) {
        _sg_image_t* img = _sg_image_at(&_sg.pools, img_id.id);
        SOKOL_ASSERT(img && (img->slot.state == SG_RESOURCESTATE_ALLOC));
        _sg_init_image(img, &desc_def);
        SOKOL_ASSERT((img->slot.state == SG_RESOURCESTATE_VALID) || (img->slot.state == SG_RESOURCESTATE_FAILED));
    }
    _SG_TRACE_ARGS(make_image, &desc_def, img_id);
    return img_id;
}

SOKOL_API_IMPL sg_sampler sg_make_sampler(const sg_sampler_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(desc);
    sg_sampler_desc desc_def = _sg_sampler_desc_defaults(desc);
    sg_sampler smp_id = _sg_alloc_sampler();
    if (smp_id.id != SG_INVALID_ID) {
        _sg_sampler_t* smp = _sg_sampler_at(&_sg.pools, smp_id.id);
        SOKOL_ASSERT(smp && (smp->slot.state == SG_RESOURCESTATE_ALLOC));
        _sg_init_sampler(smp, &desc_def);
        SOKOL_ASSERT((smp->slot.state == SG_RESOURCESTATE_VALID) || (smp->slot.state == SG_RESOURCESTATE_FAILED));
    }
    _SG_TRACE_ARGS(make_sampler, &desc_def, smp_id);
    return smp_id;
}

SOKOL_API_IMPL sg_shader sg_make_shader(const sg_shader_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(desc);
    sg_shader_desc desc_def = _sg_shader_desc_defaults(desc);
    sg_shader shd_id = _sg_alloc_shader();
    if (shd_id.id != SG_INVALID_ID) {
        _sg_shader_t* shd = _sg_shader_at(&_sg.pools, shd_id.id);
        SOKOL_ASSERT(shd && (shd->slot.state == SG_RESOURCESTATE_ALLOC));
        _sg_init_shader(shd, &desc_def);
        SOKOL_ASSERT((shd->slot.state == SG_RESOURCESTATE_VALID) || (shd->slot.state == SG_RESOURCESTATE_FAILED));
    }
    _SG_TRACE_ARGS(make_shader, &desc_def, shd_id);
    return shd_id;
}

SOKOL_API_IMPL sg_pipeline sg_make_pipeline(const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(desc);
    sg_pipeline_desc desc_def = _sg_pipeline_desc_defaults(desc);
    sg_pipeline pip_id = _sg_alloc_pipeline();
    if (pip_id.id != SG_INVALID_ID) {
        _sg_pipeline_t* pip = _sg_pipeline_at(&_sg.pools, pip_id.id);
        SOKOL_ASSERT(pip && (pip->slot.state == SG_RESOURCESTATE_ALLOC));
        _sg_init_pipeline(pip, &desc_def);
        SOKOL_ASSERT((pip->slot.state == SG_RESOURCESTATE_VALID) || (pip->slot.state == SG_RESOURCESTATE_FAILED));
    }
    _SG_TRACE_ARGS(make_pipeline, &desc_def, pip_id);
    return pip_id;
}

SOKOL_API_IMPL sg_attachments sg_make_attachments(const sg_attachments_desc* desc) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(desc);
    sg_attachments_desc desc_def = _sg_attachments_desc_defaults(desc);
    sg_attachments atts_id = _sg_alloc_attachments();
    if (atts_id.id != SG_INVALID_ID) {
        _sg_attachments_t* atts = _sg_attachments_at(&_sg.pools, atts_id.id);
        SOKOL_ASSERT(atts && (atts->slot.state == SG_RESOURCESTATE_ALLOC));
        _sg_init_attachments(atts, &desc_def);
        SOKOL_ASSERT((atts->slot.state == SG_RESOURCESTATE_VALID) || (atts->slot.state == SG_RESOURCESTATE_FAILED));
    }
    _SG_TRACE_ARGS(make_attachments, &desc_def, atts_id);
    return atts_id;
}

SOKOL_API_IMPL void sg_destroy_buffer(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    _SG_TRACE_ARGS(destroy_buffer, buf_id);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        if ((buf->slot.state == SG_RESOURCESTATE_VALID) || (buf->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_buffer(buf);
            SOKOL_ASSERT(buf->slot.state == SG_RESOURCESTATE_ALLOC);
        }
        if (buf->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_buffer(buf);
            SOKOL_ASSERT(buf->slot.state == SG_RESOURCESTATE_INITIAL);
        }
    }
}

SOKOL_API_IMPL void sg_destroy_image(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    _SG_TRACE_ARGS(destroy_image, img_id);
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        if ((img->slot.state == SG_RESOURCESTATE_VALID) || (img->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_image(img);
            SOKOL_ASSERT(img->slot.state == SG_RESOURCESTATE_ALLOC);
        }
        if (img->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_image(img);
            SOKOL_ASSERT(img->slot.state == SG_RESOURCESTATE_INITIAL);
        }
    }
}

SOKOL_API_IMPL void sg_destroy_sampler(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    _SG_TRACE_ARGS(destroy_sampler, smp_id);
    _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        if ((smp->slot.state == SG_RESOURCESTATE_VALID) || (smp->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_sampler(smp);
            SOKOL_ASSERT(smp->slot.state == SG_RESOURCESTATE_ALLOC);
        }
        if (smp->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_sampler(smp);
            SOKOL_ASSERT(smp->slot.state == SG_RESOURCESTATE_INITIAL);
        }
    }
}

SOKOL_API_IMPL void sg_destroy_shader(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    _SG_TRACE_ARGS(destroy_shader, shd_id);
    _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        if ((shd->slot.state == SG_RESOURCESTATE_VALID) || (shd->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_shader(shd);
            SOKOL_ASSERT(shd->slot.state == SG_RESOURCESTATE_ALLOC);
        }
        if (shd->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_shader(shd);
            SOKOL_ASSERT(shd->slot.state == SG_RESOURCESTATE_INITIAL);
        }
    }
}

SOKOL_API_IMPL void sg_destroy_pipeline(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    _SG_TRACE_ARGS(destroy_pipeline, pip_id);
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        if ((pip->slot.state == SG_RESOURCESTATE_VALID) || (pip->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_pipeline(pip);
            SOKOL_ASSERT(pip->slot.state == SG_RESOURCESTATE_ALLOC);
        }
        if (pip->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_pipeline(pip);
            SOKOL_ASSERT(pip->slot.state == SG_RESOURCESTATE_INITIAL);
        }
    }
}

SOKOL_API_IMPL void sg_destroy_attachments(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    _SG_TRACE_ARGS(destroy_attachments, atts_id);
    _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        if ((atts->slot.state == SG_RESOURCESTATE_VALID) || (atts->slot.state == SG_RESOURCESTATE_FAILED)) {
            _sg_uninit_attachments(atts);
            SOKOL_ASSERT(atts->slot.state == SG_RESOURCESTATE_ALLOC);
        }
        if (atts->slot.state == SG_RESOURCESTATE_ALLOC) {
            _sg_dealloc_attachments(atts);
            SOKOL_ASSERT(atts->slot.state == SG_RESOURCESTATE_INITIAL);
        }
    }
}

SOKOL_API_IMPL void sg_begin_pass(const sg_pass* pass) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(!_sg.cur_pass.valid);
    SOKOL_ASSERT(!_sg.cur_pass.in_pass);
    SOKOL_ASSERT(_sg.cur_pass.atts == 0);
    SOKOL_ASSERT(pass);
    SOKOL_ASSERT((pass->_start_canary == 0) && (pass->_end_canary == 0));
    const sg_pass pass_def = _sg_pass_defaults(pass);
    if (!_sg_validate_begin_pass(&pass_def)) {
        return;
    }
    if (pass_def.attachments.id != SG_INVALID_ID) {
        _sg.cur_pass.atts = _sg_lookup_attachments(&_sg.pools, pass_def.attachments.id);
        if (0 == _sg.cur_pass.atts) {
            _SG_ERROR(BEGINPASS_ATTACHMENT_INVALID);
            return;
        }
        _sg.cur_pass.atts_id = pass_def.attachments;
        _sg.cur_pass.width = _sg.cur_pass.atts->cmn.width;
        _sg.cur_pass.height = _sg.cur_pass.atts->cmn.height;
    } else if (!pass_def.compute) {
        // a swapchain pass
        SOKOL_ASSERT(pass_def.swapchain.width > 0);
        SOKOL_ASSERT(pass_def.swapchain.height > 0);
        SOKOL_ASSERT(pass_def.swapchain.color_format > SG_PIXELFORMAT_NONE);
        SOKOL_ASSERT(pass_def.swapchain.sample_count > 0);
        _sg.cur_pass.width = pass_def.swapchain.width;
        _sg.cur_pass.height = pass_def.swapchain.height;
        _sg.cur_pass.swapchain.color_fmt = pass_def.swapchain.color_format;
        _sg.cur_pass.swapchain.depth_fmt = pass_def.swapchain.depth_format;
        _sg.cur_pass.swapchain.sample_count = pass_def.swapchain.sample_count;
    }
    _sg.cur_pass.valid = true;  // may be overruled by backend begin-pass functions
    _sg.cur_pass.in_pass = true;
    _sg.cur_pass.is_compute = pass_def.compute;
    _sg_begin_pass(&pass_def);
    _SG_TRACE_ARGS(begin_pass, &pass_def);
}

SOKOL_API_IMPL void sg_apply_viewport(int x, int y, int width, int height, bool origin_top_left) {
    SOKOL_ASSERT(_sg.valid);
    #if defined(SOKOL_DEBUG)
    if (!_sg_validate_apply_viewport(x, y, width, height, origin_top_left)) {
        return;
    }
    #endif
    _sg_stats_add(num_apply_viewport, 1);
    if (!_sg.cur_pass.valid) {
        return;
    }
    _sg_apply_viewport(x, y, width, height, origin_top_left);
    _SG_TRACE_ARGS(apply_viewport, x, y, width, height, origin_top_left);
}

SOKOL_API_IMPL void sg_apply_viewportf(float x, float y, float width, float height, bool origin_top_left) {
    sg_apply_viewport((int)x, (int)y, (int)width, (int)height, origin_top_left);
}

SOKOL_API_IMPL void sg_apply_scissor_rect(int x, int y, int width, int height, bool origin_top_left) {
    SOKOL_ASSERT(_sg.valid);
    #if defined(SOKOL_DEBUG)
    if (!_sg_validate_apply_scissor_rect(x, y, width, height, origin_top_left)) {
        return;
    }
    #endif
    _sg_stats_add(num_apply_scissor_rect, 1);
    if (!_sg.cur_pass.valid) {
        return;
    }
    _sg_apply_scissor_rect(x, y, width, height, origin_top_left);
    _SG_TRACE_ARGS(apply_scissor_rect, x, y, width, height, origin_top_left);
}

SOKOL_API_IMPL void sg_apply_scissor_rectf(float x, float y, float width, float height, bool origin_top_left) {
    sg_apply_scissor_rect((int)x, (int)y, (int)width, (int)height, origin_top_left);
}

SOKOL_API_IMPL void sg_apply_pipeline(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_stats_add(num_apply_pipeline, 1);
    if (!_sg_validate_apply_pipeline(pip_id)) {
        _sg.next_draw_valid = false;
        return;
    }
    if (!_sg.cur_pass.valid) {
        return;
    }
    _sg.cur_pipeline = pip_id;
    _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    SOKOL_ASSERT(pip);

    _sg.next_draw_valid = (SG_RESOURCESTATE_VALID == pip->slot.state);
    if (!_sg.next_draw_valid) {
        return;
    }

    SOKOL_ASSERT(pip->shader && (pip->shader->slot.id == pip->cmn.shader_id.id));
    _sg_apply_pipeline(pip);

    // set the expected bindings and uniform block flags
    _sg.required_bindings_and_uniforms = pip->cmn.required_bindings_and_uniforms | pip->shader->cmn.required_bindings_and_uniforms;
    _sg.applied_bindings_and_uniforms = 0;

    _SG_TRACE_ARGS(apply_pipeline, pip_id);
}

SOKOL_API_IMPL void sg_apply_bindings(const sg_bindings* bindings) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(bindings);
    SOKOL_ASSERT((bindings->_start_canary == 0) && (bindings->_end_canary==0));
    _sg_stats_add(num_apply_bindings, 1);
    _sg.applied_bindings_and_uniforms |= (1 << SG_MAX_UNIFORMBLOCK_BINDSLOTS);
    if (!_sg_validate_apply_bindings(bindings)) {
        _sg.next_draw_valid = false;
        return;
    }
    if (!_sg.cur_pass.valid) {
        return;
    }
    if (!_sg.next_draw_valid) {
        return;
    }

    _sg_bindings_ptrs_t bnd;
    _sg_clear(&bnd, sizeof(bnd));
    bnd.pip = _sg_lookup_pipeline(&_sg.pools, _sg.cur_pipeline.id);
    if (0 == bnd.pip) {
        _sg.next_draw_valid = false;
    }
    SOKOL_ASSERT(bnd.pip->shader && (bnd.pip->cmn.shader_id.id == bnd.pip->shader->slot.id));
    const _sg_shader_t* shd = bnd.pip->shader;

    if (!_sg.cur_pass.is_compute) {
        for (size_t i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; i++) {
            if (bnd.pip->cmn.vertex_buffer_layout_active[i]) {
                SOKOL_ASSERT(bindings->vertex_buffers[i].id != SG_INVALID_ID);
                bnd.vbs[i] = _sg_lookup_buffer(&_sg.pools, bindings->vertex_buffers[i].id);
                bnd.vb_offsets[i] = bindings->vertex_buffer_offsets[i];
                if (bnd.vbs[i]) {
                    _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == bnd.vbs[i]->slot.state);
                    _sg.next_draw_valid &= !bnd.vbs[i]->cmn.append_overflow;
                } else {
                    _sg.next_draw_valid = false;
                }
            }
        }
        if (bindings->index_buffer.id) {
            bnd.ib = _sg_lookup_buffer(&_sg.pools, bindings->index_buffer.id);
            bnd.ib_offset = bindings->index_buffer_offset;
            if (bnd.ib) {
                _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == bnd.ib->slot.state);
                _sg.next_draw_valid &= !bnd.ib->cmn.append_overflow;
            } else {
                _sg.next_draw_valid = false;
            }
        }
    }

    for (int i = 0; i < SG_MAX_IMAGE_BINDSLOTS; i++) {
        if (shd->cmn.images[i].stage != SG_SHADERSTAGE_NONE) {
            SOKOL_ASSERT(bindings->images[i].id != SG_INVALID_ID);
            bnd.imgs[i] = _sg_lookup_image(&_sg.pools, bindings->images[i].id);
            if (bnd.imgs[i]) {
                _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == bnd.imgs[i]->slot.state);
            } else {
                _sg.next_draw_valid = false;
            }
        }
    }

    for (size_t i = 0; i < SG_MAX_SAMPLER_BINDSLOTS; i++) {
        if (shd->cmn.samplers[i].stage != SG_SHADERSTAGE_NONE) {
            SOKOL_ASSERT(bindings->samplers[i].id != SG_INVALID_ID);
            bnd.smps[i] = _sg_lookup_sampler(&_sg.pools, bindings->samplers[i].id);
            if (bnd.smps[i]) {
                _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == bnd.smps[i]->slot.state);
            } else {
                _sg.next_draw_valid = false;
            }
        }
    }

    for (size_t i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; i++) {
        if (shd->cmn.storage_buffers[i].stage != SG_SHADERSTAGE_NONE) {
            SOKOL_ASSERT(bindings->storage_buffers[i].id != SG_INVALID_ID);
            bnd.sbufs[i] = _sg_lookup_buffer(&_sg.pools, bindings->storage_buffers[i].id);
            if (bnd.sbufs[i]) {
                _sg.next_draw_valid &= (SG_RESOURCESTATE_VALID == bnd.sbufs[i]->slot.state);
                if (_sg.cur_pass.is_compute) {
                    _sg_compute_pass_track_storage_buffer(bnd.sbufs[i], shd->cmn.storage_buffers[i].readonly);
                }
            } else {
                _sg.next_draw_valid = false;
            }
        }
    }

    if (_sg.next_draw_valid) {
        _sg.next_draw_valid &= _sg_apply_bindings(&bnd);
        _SG_TRACE_ARGS(apply_bindings, bindings);
    }
}

SOKOL_API_IMPL void sg_apply_uniforms(int ub_slot, const sg_range* data) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT((ub_slot >= 0) && (ub_slot < SG_MAX_UNIFORMBLOCK_BINDSLOTS));
    SOKOL_ASSERT(data && data->ptr && (data->size > 0));
    _sg_stats_add(num_apply_uniforms, 1);
    _sg_stats_add(size_apply_uniforms, (uint32_t)data->size);
    _sg.applied_bindings_and_uniforms |= 1 << ub_slot;
    if (!_sg_validate_apply_uniforms(ub_slot, data)) {
        _sg.next_draw_valid = false;
        return;
    }
    if (!_sg.cur_pass.valid) {
        return;
    }
    if (!_sg.next_draw_valid) {
        return;
    }
    _sg_apply_uniforms(ub_slot, data);
    _SG_TRACE_ARGS(apply_uniforms, ub_slot, data);
}

SOKOL_API_IMPL void sg_draw(int base_element, int num_elements, int num_instances) {
    SOKOL_ASSERT(_sg.valid);
    #if defined(SOKOL_DEBUG)
    if (!_sg_validate_draw(base_element, num_elements, num_instances)) {
        return;
    }
    #endif
    _sg_stats_add(num_draw, 1);
    if (!_sg.cur_pass.valid) {
        return;
    }
    if (!_sg.next_draw_valid) {
        return;
    }
    // skip no-op draws
    if ((0 == num_elements) || (0 == num_instances)) {
        return;
    }
    _sg_draw(base_element, num_elements, num_instances);
    _SG_TRACE_ARGS(draw, base_element, num_elements, num_instances);
}

SOKOL_API_IMPL void sg_dispatch(int num_groups_x, int num_groups_y, int num_groups_z) {
    SOKOL_ASSERT(_sg.valid);
    #if defined(SOKOL_DEBUG)
    if (!_sg_validate_dispatch(num_groups_x, num_groups_y, num_groups_z)) {
        return;
    }
    #endif
    _sg_stats_add(num_dispatch, 1);
    if (!_sg.cur_pass.valid) {
        return;
    }
    if (!_sg.next_draw_valid) {
        return;
    }
    // skip no-op dispatches
    if ((0 == num_groups_x) || (0 == num_groups_y) || (0 == num_groups_z)) {
        return;
    }
    _sg_dispatch(num_groups_x, num_groups_y, num_groups_z);
    _SG_TRACE_ARGS(dispatch, num_groups_x, num_groups_y, num_groups_z);
}

SOKOL_API_IMPL void sg_end_pass(void) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(_sg.cur_pass.in_pass);
    _sg_stats_add(num_passes, 1);
    // NOTE: don't exit early if !_sg.cur_pass.valid
    _sg_end_pass();
    _sg.cur_pipeline.id = SG_INVALID_ID;
    if (_sg.cur_pass.is_compute) {
        _sg_compute_on_endpass();
    }
    _sg_clear(&_sg.cur_pass, sizeof(_sg.cur_pass));
    _SG_TRACE_NOARGS(end_pass);
}

SOKOL_API_IMPL void sg_commit(void) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(!_sg.cur_pass.valid);
    SOKOL_ASSERT(!_sg.cur_pass.in_pass);
    _sg_commit();
    _sg.stats.frame_index = _sg.frame_index;
    _sg.prev_stats = _sg.stats;
    _sg_clear(&_sg.stats, sizeof(_sg.stats));
    _sg_notify_commit_listeners();
    _SG_TRACE_NOARGS(commit);
    _sg.frame_index++;
}

SOKOL_API_IMPL void sg_reset_state_cache(void) {
    SOKOL_ASSERT(_sg.valid);
    _sg_reset_state_cache();
    _SG_TRACE_NOARGS(reset_state_cache);
}

SOKOL_API_IMPL void sg_update_buffer(sg_buffer buf_id, const sg_range* data) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(data && data->ptr && (data->size > 0));
    _sg_stats_add(num_update_buffer, 1);
    _sg_stats_add(size_update_buffer, (uint32_t)data->size);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if ((data->size > 0) && buf && (buf->slot.state == SG_RESOURCESTATE_VALID)) {
        if (_sg_validate_update_buffer(buf, data)) {
            SOKOL_ASSERT(data->size <= (size_t)buf->cmn.size);
            // only one update allowed per buffer and frame
            SOKOL_ASSERT(buf->cmn.update_frame_index != _sg.frame_index);
            // update and append on same buffer in same frame not allowed
            SOKOL_ASSERT(buf->cmn.append_frame_index != _sg.frame_index);
            _sg_update_buffer(buf, data);
            buf->cmn.update_frame_index = _sg.frame_index;
        }
    }
    _SG_TRACE_ARGS(update_buffer, buf_id, data);
}

SOKOL_API_IMPL int sg_append_buffer(sg_buffer buf_id, const sg_range* data) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(data && data->ptr);
    _sg_stats_add(num_append_buffer, 1);
    _sg_stats_add(size_append_buffer, (uint32_t)data->size);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    int result;
    if (buf) {
        // rewind append cursor in a new frame
        if (buf->cmn.append_frame_index != _sg.frame_index) {
            buf->cmn.append_pos = 0;
            buf->cmn.append_overflow = false;
        }
        if (((size_t)buf->cmn.append_pos + data->size) > (size_t)buf->cmn.size) {
            buf->cmn.append_overflow = true;
        }
        const int start_pos = buf->cmn.append_pos;
        // NOTE: the multiple-of-4 requirement for the buffer offset is coming
        // from WebGPU, but we want identical behaviour between backends
        SOKOL_ASSERT(_sg_multiple_u64((uint64_t)start_pos, 4));
        if (buf->slot.state == SG_RESOURCESTATE_VALID) {
            if (_sg_validate_append_buffer(buf, data)) {
                if (!buf->cmn.append_overflow && (data->size > 0)) {
                    // update and append on same buffer in same frame not allowed
                    SOKOL_ASSERT(buf->cmn.update_frame_index != _sg.frame_index);
                    _sg_append_buffer(buf, data, buf->cmn.append_frame_index != _sg.frame_index);
                    buf->cmn.append_pos += (int) _sg_roundup_u64(data->size, 4);
                    buf->cmn.append_frame_index = _sg.frame_index;
                }
            }
        }
        result = start_pos;
    } else {
        // FIXME: should we return -1 here?
        result = 0;
    }
    _SG_TRACE_ARGS(append_buffer, buf_id, data, result);
    return result;
}

SOKOL_API_IMPL bool sg_query_buffer_overflow(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    bool result = buf ? buf->cmn.append_overflow : false;
    return result;
}

SOKOL_API_IMPL bool sg_query_buffer_will_overflow(sg_buffer buf_id, size_t size) {
    SOKOL_ASSERT(_sg.valid);
    _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    bool result = false;
    if (buf) {
        int append_pos = buf->cmn.append_pos;
        // rewind append cursor in a new frame
        if (buf->cmn.append_frame_index != _sg.frame_index) {
            append_pos = 0;
        }
        if ((append_pos + _sg_roundup((int)size, 4)) > buf->cmn.size) {
            result = true;
        }
    }
    return result;
}

SOKOL_API_IMPL void sg_update_image(sg_image img_id, const sg_image_data* data) {
    SOKOL_ASSERT(_sg.valid);
    _sg_stats_add(num_update_image, 1);
    for (int face_index = 0; face_index < SG_CUBEFACE_NUM; face_index++) {
        for (int mip_index = 0; mip_index < SG_MAX_MIPMAPS; mip_index++) {
            if (data->subimage[face_index][mip_index].size == 0) {
                break;
            }
            _sg_stats_add(size_update_image, (uint32_t)data->subimage[face_index][mip_index].size);
        }
    }
    _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img && img->slot.state == SG_RESOURCESTATE_VALID) {
        if (_sg_validate_update_image(img, data)) {
            SOKOL_ASSERT(img->cmn.upd_frame_index != _sg.frame_index);
            _sg_update_image(img, data);
            img->cmn.upd_frame_index = _sg.frame_index;
        }
    }
    _SG_TRACE_ARGS(update_image, img_id, data);
}

SOKOL_API_IMPL void sg_push_debug_group(const char* name) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(name);
    _sg_push_debug_group(name);
    _SG_TRACE_ARGS(push_debug_group, name);
}

SOKOL_API_IMPL void sg_pop_debug_group(void) {
    SOKOL_ASSERT(_sg.valid);
    _sg_pop_debug_group();
    _SG_TRACE_NOARGS(pop_debug_group);
}

SOKOL_API_IMPL bool sg_add_commit_listener(sg_commit_listener listener) {
    SOKOL_ASSERT(_sg.valid);
    return _sg_add_commit_listener(&listener);
}

SOKOL_API_IMPL bool sg_remove_commit_listener(sg_commit_listener listener) {
    SOKOL_ASSERT(_sg.valid);
    return _sg_remove_commit_listener(&listener);
}

SOKOL_API_IMPL void sg_enable_frame_stats(void) {
    SOKOL_ASSERT(_sg.valid);
    _sg.stats_enabled = true;
}

SOKOL_API_IMPL void sg_disable_frame_stats(void) {
    SOKOL_ASSERT(_sg.valid);
    _sg.stats_enabled = false;
}

SOKOL_API_IMPL bool sg_frame_stats_enabled(void) {
    return _sg.stats_enabled;
}

SOKOL_API_IMPL sg_buffer_info sg_query_buffer_info(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_buffer_info info;
    _sg_clear(&info, sizeof(info));
    const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        info.slot.state = buf->slot.state;
        info.slot.res_id = buf->slot.id;
        info.update_frame_index = buf->cmn.update_frame_index;
        info.append_frame_index = buf->cmn.append_frame_index;
        info.append_pos = buf->cmn.append_pos;
        info.append_overflow = buf->cmn.append_overflow;
        #if defined(SOKOL_D3D11)
        info.num_slots = 1;
        info.active_slot = 0;
        #else
        info.num_slots = buf->cmn.num_slots;
        info.active_slot = buf->cmn.active_slot;
        #endif
    }
    return info;
}

SOKOL_API_IMPL sg_image_info sg_query_image_info(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_image_info info;
    _sg_clear(&info, sizeof(info));
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        info.slot.state = img->slot.state;
        info.slot.res_id = img->slot.id;
        info.upd_frame_index = img->cmn.upd_frame_index;
        #if defined(SOKOL_D3D11)
        info.num_slots = 1;
        info.active_slot = 0;
        #else
        info.num_slots = img->cmn.num_slots;
        info.active_slot = img->cmn.active_slot;
        #endif
    }
    return info;
}

SOKOL_API_IMPL sg_sampler_info sg_query_sampler_info(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_sampler_info info;
    _sg_clear(&info, sizeof(info));
    const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        info.slot.state = smp->slot.state;
        info.slot.res_id = smp->slot.id;
    }
    return info;
}

SOKOL_API_IMPL sg_shader_info sg_query_shader_info(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_shader_info info;
    _sg_clear(&info, sizeof(info));
    const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        info.slot.state = shd->slot.state;
        info.slot.res_id = shd->slot.id;
    }
    return info;
}

SOKOL_API_IMPL sg_pipeline_info sg_query_pipeline_info(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_pipeline_info info;
    _sg_clear(&info, sizeof(info));
    const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        info.slot.state = pip->slot.state;
        info.slot.res_id = pip->slot.id;
    }
    return info;
}

SOKOL_API_IMPL sg_attachments_info sg_query_attachments_info(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_attachments_info info;
    _sg_clear(&info, sizeof(info));
    const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        info.slot.state = atts->slot.state;
        info.slot.res_id = atts->slot.id;
    }
    return info;
}

SOKOL_API_IMPL sg_buffer_desc sg_query_buffer_desc(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_buffer_desc desc;
    _sg_clear(&desc, sizeof(desc));
    const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        desc.size = (size_t)buf->cmn.size;
        desc.usage = buf->cmn.usage;
    }
    return desc;
}

SOKOL_API_IMPL size_t sg_query_buffer_size(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        return (size_t)buf->cmn.size;
    }
    return 0;
}

SOKOL_API_IMPL sg_buffer_usage sg_query_buffer_usage(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_buffer_usage usg;
    _sg_clear(&usg, sizeof(usg));
    const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
    if (buf) {
        usg = buf->cmn.usage;
    }
    return usg;
}

SOKOL_API_IMPL sg_image_desc sg_query_image_desc(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_image_desc desc;
    _sg_clear(&desc, sizeof(desc));
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        desc.type = img->cmn.type;
        desc.width = img->cmn.width;
        desc.height = img->cmn.height;
        desc.num_slices = img->cmn.num_slices;
        desc.num_mipmaps = img->cmn.num_mipmaps;
        desc.usage = img->cmn.usage;
        desc.pixel_format = img->cmn.pixel_format;
        desc.sample_count = img->cmn.sample_count;
    }
    return desc;
}

SOKOL_API_IMPL sg_image_type sg_query_image_type(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.type;
    }
    return _SG_IMAGETYPE_DEFAULT;
}

SOKOL_API_IMPL int sg_query_image_width(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.width;
    }
    return 0;
}

SOKOL_API_IMPL int sg_query_image_height(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.height;
    }
    return 0;
}

SOKOL_API_IMPL int sg_query_image_num_slices(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.num_slices;
    }
    return 0;
}

SOKOL_API_IMPL int sg_query_image_num_mipmaps(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.num_mipmaps;
    }
    return 0;
}

SOKOL_API_IMPL sg_pixel_format sg_query_image_pixelformat(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.pixel_format;
    }
    return _SG_PIXELFORMAT_DEFAULT;
}

SOKOL_API_IMPL sg_image_usage sg_query_image_usage(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_image_usage usg;
    _sg_clear(&usg, sizeof(usg));
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        usg = img->cmn.usage;
    }
    return usg;
}

SOKOL_API_IMPL int sg_query_image_sample_count(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    SOKOL_ASSERT(_sg.valid);
    const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
    if (img) {
        return img->cmn.sample_count;
    }
    return 0;
}

SOKOL_API_IMPL sg_sampler_desc sg_query_sampler_desc(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_sampler_desc desc;
    _sg_clear(&desc, sizeof(desc));
    const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
    if (smp) {
        desc.min_filter = smp->cmn.min_filter;
        desc.mag_filter = smp->cmn.mag_filter;
        desc.mipmap_filter = smp->cmn.mipmap_filter;
        desc.wrap_u = smp->cmn.wrap_u;
        desc.wrap_v = smp->cmn.wrap_v;
        desc.wrap_w = smp->cmn.wrap_w;
        desc.min_lod = smp->cmn.min_lod;
        desc.max_lod = smp->cmn.max_lod;
        desc.border_color = smp->cmn.border_color;
        desc.compare = smp->cmn.compare;
        desc.max_anisotropy = smp->cmn.max_anisotropy;
    }
    return desc;
}

SOKOL_API_IMPL sg_shader_desc sg_query_shader_desc(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_shader_desc desc;
    _sg_clear(&desc, sizeof(desc));
    const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
    if (shd) {
        for (size_t ub_idx = 0; ub_idx < SG_MAX_UNIFORMBLOCK_BINDSLOTS; ub_idx++) {
            sg_shader_uniform_block* ub_desc = &desc.uniform_blocks[ub_idx];
            const _sg_shader_uniform_block_t* ub = &shd->cmn.uniform_blocks[ub_idx];
            ub_desc->stage = ub->stage;
            ub_desc->size = ub->size;
        }
        for (size_t sbuf_idx = 0; sbuf_idx < SG_MAX_STORAGEBUFFER_BINDSLOTS; sbuf_idx++) {
            sg_shader_storage_buffer* sbuf_desc = &desc.storage_buffers[sbuf_idx];
            const _sg_shader_storage_buffer_t* sbuf = &shd->cmn.storage_buffers[sbuf_idx];
            sbuf_desc->stage = sbuf->stage;
            sbuf_desc->readonly = sbuf->readonly;
        }
        for (size_t simg_idx = 0; simg_idx < SG_MAX_STORAGE_ATTACHMENTS; simg_idx++) {
            sg_shader_storage_image* simg_desc = &desc.storage_images[simg_idx];
            const _sg_shader_storage_image_t* simg = &shd->cmn.storage_images[simg_idx];
            simg_desc->stage = simg->stage;
            simg_desc->access_format = simg->access_format;
            simg_desc->image_type = simg->image_type;
            simg_desc->writeonly = simg->writeonly;
        }
        for (size_t img_idx = 0; img_idx < SG_MAX_IMAGE_BINDSLOTS; img_idx++) {
            sg_shader_image* img_desc = &desc.images[img_idx];
            const _sg_shader_image_t* img = &shd->cmn.images[img_idx];
            img_desc->stage = img->stage;
            img_desc->image_type = img->image_type;
            img_desc->sample_type = img->sample_type;
            img_desc->multisampled = img->multisampled;
        }
        for (size_t smp_idx = 0; smp_idx < SG_MAX_SAMPLER_BINDSLOTS; smp_idx++) {
            sg_shader_sampler* smp_desc = &desc.samplers[smp_idx];
            const _sg_shader_sampler_t* smp = &shd->cmn.samplers[smp_idx];
            smp_desc->stage = smp->stage;
            smp_desc->sampler_type = smp->sampler_type;
        }
        for (size_t img_smp_idx = 0; img_smp_idx < SG_MAX_IMAGE_SAMPLER_PAIRS; img_smp_idx++) {
            sg_shader_image_sampler_pair* img_smp_desc = &desc.image_sampler_pairs[img_smp_idx];
            const _sg_shader_image_sampler_t* img_smp = &shd->cmn.image_samplers[img_smp_idx];
            img_smp_desc->stage = img_smp->stage;
            img_smp_desc->image_slot = img_smp->image_slot;
            img_smp_desc->sampler_slot = img_smp->sampler_slot;
        }
    }
    return desc;
}

SOKOL_API_IMPL sg_pipeline_desc sg_query_pipeline_desc(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_pipeline_desc desc;
    _sg_clear(&desc, sizeof(desc));
    const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
    if (pip) {
        desc.compute = pip->cmn.is_compute;
        desc.shader = pip->cmn.shader_id;
        desc.layout = pip->cmn.layout;
        desc.depth = pip->cmn.depth;
        desc.stencil = pip->cmn.stencil;
        desc.color_count = pip->cmn.color_count;
        for (int i = 0; i < pip->cmn.color_count; i++) {
            desc.colors[i] = pip->cmn.colors[i];
        }
        desc.primitive_type = pip->cmn.primitive_type;
        desc.index_type = pip->cmn.index_type;
        desc.cull_mode = pip->cmn.cull_mode;
        desc.face_winding = pip->cmn.face_winding;
        desc.sample_count = pip->cmn.sample_count;
        desc.blend_color = pip->cmn.blend_color;
        desc.alpha_to_coverage_enabled = pip->cmn.alpha_to_coverage_enabled;
    }
    return desc;
}

SOKOL_API_IMPL sg_attachments_desc sg_query_attachments_desc(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_attachments_desc desc;
    _sg_clear(&desc, sizeof(desc));
    const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
    if (atts) {
        for (int i = 0; i < atts->cmn.num_colors; i++) {
            desc.colors[i].image = atts->cmn.colors[i].image_id;
            desc.colors[i].mip_level = atts->cmn.colors[i].mip_level;
            desc.colors[i].slice = atts->cmn.colors[i].slice;
        }
        desc.depth_stencil.image = atts->cmn.depth_stencil.image_id;
        desc.depth_stencil.mip_level = atts->cmn.depth_stencil.mip_level;
        desc.depth_stencil.slice = atts->cmn.depth_stencil.slice;
    }
    return desc;
}

SOKOL_API_IMPL sg_buffer_desc sg_query_buffer_defaults(const sg_buffer_desc* desc) {
    SOKOL_ASSERT(_sg.valid && desc);
    return _sg_buffer_desc_defaults(desc);
}

SOKOL_API_IMPL sg_image_desc sg_query_image_defaults(const sg_image_desc* desc) {
    SOKOL_ASSERT(_sg.valid && desc);
    return _sg_image_desc_defaults(desc);
}

SOKOL_API_IMPL sg_sampler_desc sg_query_sampler_defaults(const sg_sampler_desc* desc) {
    SOKOL_ASSERT(_sg.valid && desc);
    return _sg_sampler_desc_defaults(desc);
}

SOKOL_API_IMPL sg_shader_desc sg_query_shader_defaults(const sg_shader_desc* desc) {
    SOKOL_ASSERT(_sg.valid && desc);
    return _sg_shader_desc_defaults(desc);
}

SOKOL_API_IMPL sg_pipeline_desc sg_query_pipeline_defaults(const sg_pipeline_desc* desc) {
    SOKOL_ASSERT(_sg.valid && desc);
    return _sg_pipeline_desc_defaults(desc);
}

SOKOL_API_IMPL sg_attachments_desc sg_query_attachments_defaults(const sg_attachments_desc* desc) {
    SOKOL_ASSERT(_sg.valid && desc);
    return _sg_attachments_desc_defaults(desc);
}

SOKOL_API_IMPL const void* sg_d3d11_device(void) {
    #if defined(SOKOL_D3D11)
        return (const void*) _sg.d3d11.dev;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_d3d11_device_context(void) {
    #if defined(SOKOL_D3D11)
        return (const void*) _sg.d3d11.ctx;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL sg_d3d11_buffer_info sg_d3d11_query_buffer_info(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_d3d11_buffer_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_D3D11)
        const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
        if (buf) {
            res.buf = (const void*) buf->d3d11.buf;
        }
    #else
        _SOKOL_UNUSED(buf_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_d3d11_image_info sg_d3d11_query_image_info(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_d3d11_image_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_D3D11)
        const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
        if (img) {
            res.tex2d = (const void*) img->d3d11.tex2d;
            res.tex3d = (const void*) img->d3d11.tex3d;
            res.res = (const void*) img->d3d11.res;
            res.srv = (const void*) img->d3d11.srv;
        }
    #else
        _SOKOL_UNUSED(img_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_d3d11_sampler_info sg_d3d11_query_sampler_info(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_d3d11_sampler_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_D3D11)
        const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
        if (smp) {
            res.smp = (const void*) smp->d3d11.smp;
        }
    #else
        _SOKOL_UNUSED(smp_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_d3d11_shader_info sg_d3d11_query_shader_info(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_d3d11_shader_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_D3D11)
        const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
        if (shd) {
            for (size_t i = 0; i < SG_MAX_UNIFORMBLOCK_BINDSLOTS; i++) {
                res.cbufs[i] = (const void*) shd->d3d11.all_cbufs[i];
            }
            res.vs = (const void*) shd->d3d11.vs;
            res.fs = (const void*) shd->d3d11.fs;
        }
    #else
        _SOKOL_UNUSED(shd_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_d3d11_pipeline_info sg_d3d11_query_pipeline_info(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_d3d11_pipeline_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_D3D11)
        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
        if (pip) {
            res.il = (const void*) pip->d3d11.il;
            res.rs = (const void*) pip->d3d11.rs;
            res.dss = (const void*) pip->d3d11.dss;
            res.bs = (const void*) pip->d3d11.bs;
        }
    #else
        _SOKOL_UNUSED(pip_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_d3d11_attachments_info sg_d3d11_query_attachments_info(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_d3d11_attachments_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_D3D11)
        const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
        if (atts) {
            for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
                res.color_rtv[i] = (const void*) atts->d3d11.colors[i].view.rtv;
                res.resolve_rtv[i] = (const void*) atts->d3d11.resolves[i].view.rtv;
            }
            res.dsv = (const void*) atts->d3d11.depth_stencil.view.dsv;
        }
    #else
        _SOKOL_UNUSED(atts_id);
    #endif
    return res;
}

SOKOL_API_IMPL const void* sg_mtl_device(void) {
    #if defined(SOKOL_METAL)
        if (nil != _sg.mtl.device) {
            return (__bridge const void*) _sg.mtl.device;
        } else {
            return 0;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_mtl_render_command_encoder(void) {
    #if defined(SOKOL_METAL)
        if (nil != _sg.mtl.render_cmd_encoder) {
            return (__bridge const void*) _sg.mtl.render_cmd_encoder;
        } else {
            return 0;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_mtl_compute_command_encoder(void) {
    #if defined(SOKOL_METAL)
        if (nil != _sg.mtl.compute_cmd_encoder) {
            return (__bridge const void*) _sg.mtl.compute_cmd_encoder;
        } else {
            return 0;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL sg_mtl_buffer_info sg_mtl_query_buffer_info(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_mtl_buffer_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_METAL)
        const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
        if (buf) {
            for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
                if (buf->mtl.buf[i] != 0) {
                    res.buf[i] = (__bridge void*) _sg_mtl_id(buf->mtl.buf[i]);
                }
            }
            res.active_slot = buf->cmn.active_slot;
        }
    #else
        _SOKOL_UNUSED(buf_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_mtl_image_info sg_mtl_query_image_info(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_mtl_image_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_METAL)
        const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
        if (img) {
            for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
                if (img->mtl.tex[i] != 0) {
                    res.tex[i] = (__bridge void*) _sg_mtl_id(img->mtl.tex[i]);
                }
            }
            res.active_slot = img->cmn.active_slot;
        }
    #else
        _SOKOL_UNUSED(img_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_mtl_sampler_info sg_mtl_query_sampler_info(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_mtl_sampler_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_METAL)
        const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
        if (smp) {
            if (smp->mtl.sampler_state != 0) {
                res.smp = (__bridge void*) _sg_mtl_id(smp->mtl.sampler_state);
            }
        }
    #else
        _SOKOL_UNUSED(smp_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_mtl_shader_info sg_mtl_query_shader_info(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_mtl_shader_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_METAL)
        const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
        if (shd) {
            const int vertex_lib  = shd->mtl.vertex_func.mtl_lib;
            const int vertex_func = shd->mtl.vertex_func.mtl_func;
            const int fragment_lib  = shd->mtl.fragment_func.mtl_lib;
            const int fragment_func = shd->mtl.fragment_func.mtl_func;
            if (vertex_lib != 0) {
                res.vertex_lib = (__bridge void*) _sg_mtl_id(vertex_lib);
            }
            if (fragment_lib != 0) {
                res.fragment_lib = (__bridge void*) _sg_mtl_id(fragment_lib);
            }
            if (vertex_func != 0) {
                res.vertex_func = (__bridge void*) _sg_mtl_id(vertex_func);
            }
            if (fragment_func != 0) {
                res.fragment_func = (__bridge void*) _sg_mtl_id(fragment_func);
            }
        }
    #else
        _SOKOL_UNUSED(shd_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_mtl_pipeline_info sg_mtl_query_pipeline_info(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_mtl_pipeline_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_METAL)
        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
        if (pip) {
            if (pip->mtl.rps != 0) {
                res.rps = (__bridge void*) _sg_mtl_id(pip->mtl.rps);
            }
            if (pip->mtl.dss != 0) {
                res.dss = (__bridge void*) _sg_mtl_id(pip->mtl.dss);
            }
        }
    #else
        _SOKOL_UNUSED(pip_id);
    #endif
    return res;
}

SOKOL_API_IMPL const void* sg_wgpu_device(void) {
    #if defined(SOKOL_WGPU)
        return (const void*) _sg.wgpu.dev;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_wgpu_queue(void) {
    #if defined(SOKOL_WGPU)
        return (const void*) _sg.wgpu.queue;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_wgpu_command_encoder(void) {
    #if defined(SOKOL_WGPU)
        return (const void*) _sg.wgpu.cmd_enc;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_wgpu_render_pass_encoder(void) {
    #if defined(SOKOL_WGPU)
        return (const void*) _sg.wgpu.rpass_enc;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sg_wgpu_compute_pass_encoder(void) {
    #if defined(SOKOL_WGPU)
        return (const void*) _sg.wgpu.cpass_enc;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL sg_wgpu_buffer_info sg_wgpu_query_buffer_info(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_wgpu_buffer_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_WGPU)
        const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
        if (buf) {
            res.buf = (const void*) buf->wgpu.buf;
        }
    #else
        _SOKOL_UNUSED(buf_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_wgpu_image_info sg_wgpu_query_image_info(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_wgpu_image_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_WGPU)
        const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
        if (img) {
            res.tex = (const void*) img->wgpu.tex;
            res.view = (const void*) img->wgpu.view;
        }
    #else
        _SOKOL_UNUSED(img_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_wgpu_sampler_info sg_wgpu_query_sampler_info(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_wgpu_sampler_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_WGPU)
        const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
        if (smp) {
            res.smp = (const void*) smp->wgpu.smp;
        }
    #else
        _SOKOL_UNUSED(smp_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_wgpu_shader_info sg_wgpu_query_shader_info(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_wgpu_shader_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_WGPU)
        const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
        if (shd) {
            res.vs_mod = (const void*) shd->wgpu.vertex_func.module;
            res.fs_mod = (const void*) shd->wgpu.fragment_func.module;
            res.bgl = (const void*) shd->wgpu.bgl_img_smp_sbuf;
        }
    #else
        _SOKOL_UNUSED(shd_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_wgpu_pipeline_info sg_wgpu_query_pipeline_info(sg_pipeline pip_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_wgpu_pipeline_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_WGPU)
        const _sg_pipeline_t* pip = _sg_lookup_pipeline(&_sg.pools, pip_id.id);
        if (pip) {
            res.render_pipeline = (const void*) pip->wgpu.rpip;
            res.compute_pipeline = (const void*) pip->wgpu.cpip;
        }
    #else
        _SOKOL_UNUSED(pip_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_wgpu_attachments_info sg_wgpu_query_attachments_info(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_wgpu_attachments_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(SOKOL_WGPU)
        const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
        if (atts) {
            for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
                res.color_view[i] = (const void*) atts->wgpu.colors[i].view;
                res.resolve_view[i] = (const void*) atts->wgpu.resolves[i].view;
            }
            res.ds_view = (const void*) atts->wgpu.depth_stencil.view;
        }
    #else
        _SOKOL_UNUSED(atts_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_gl_buffer_info sg_gl_query_buffer_info(sg_buffer buf_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_gl_buffer_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(_SOKOL_ANY_GL)
        const _sg_buffer_t* buf = _sg_lookup_buffer(&_sg.pools, buf_id.id);
        if (buf) {
            for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
                res.buf[i] = buf->gl.buf[i];
            }
            res.active_slot = buf->cmn.active_slot;
        }
    #else
        _SOKOL_UNUSED(buf_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_gl_image_info sg_gl_query_image_info(sg_image img_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_gl_image_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(_SOKOL_ANY_GL)
        const _sg_image_t* img = _sg_lookup_image(&_sg.pools, img_id.id);
        if (img) {
            for (int i = 0; i < SG_NUM_INFLIGHT_FRAMES; i++) {
                res.tex[i] = img->gl.tex[i];
            }
            res.tex_target = img->gl.target;
            res.msaa_render_buffer = img->gl.msaa_render_buffer;
            res.active_slot = img->cmn.active_slot;
        }
    #else
        _SOKOL_UNUSED(img_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_gl_sampler_info sg_gl_query_sampler_info(sg_sampler smp_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_gl_sampler_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(_SOKOL_ANY_GL)
        const _sg_sampler_t* smp = _sg_lookup_sampler(&_sg.pools, smp_id.id);
        if (smp) {
            res.smp = smp->gl.smp;
        }
    #else
        _SOKOL_UNUSED(smp_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_gl_shader_info sg_gl_query_shader_info(sg_shader shd_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_gl_shader_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(_SOKOL_ANY_GL)
        const _sg_shader_t* shd = _sg_lookup_shader(&_sg.pools, shd_id.id);
        if (shd) {
            res.prog = shd->gl.prog;
        }
    #else
        _SOKOL_UNUSED(shd_id);
    #endif
    return res;
}

SOKOL_API_IMPL sg_gl_attachments_info sg_gl_query_attachments_info(sg_attachments atts_id) {
    SOKOL_ASSERT(_sg.valid);
    sg_gl_attachments_info res;
    _sg_clear(&res, sizeof(res));
    #if defined(_SOKOL_ANY_GL)
        const _sg_attachments_t* atts = _sg_lookup_attachments(&_sg.pools, atts_id.id);
        if (atts) {
            res.framebuffer = atts->gl.fb;
            for (int i = 0; i < SG_MAX_COLOR_ATTACHMENTS; i++) {
                res.msaa_resolve_framebuffer[i] = atts->gl.msaa_resolve_framebuffer[i];
            }
        }
    #else
        _SOKOL_UNUSED(atts_id);
    #endif
    return res;
}

#ifdef _MSC_VER
#pragma warning(pop)
#endif

#endif // SOKOL_GFX_IMPL
//FILE_END
//FILE_START:deps/sokol_fetch.h
#if defined(SOKOL_IMPL) && !defined(SOKOL_FETCH_IMPL)
#define SOKOL_FETCH_IMPL
#endif
#ifndef SOKOL_FETCH_INCLUDED
/*
    sokol_fetch.h -- asynchronous data loading/streaming

    Project URL: https://github.com/floooh/sokol

    Do this:
        #define SOKOL_IMPL or
        #define SOKOL_FETCH_IMPL
    before you include this file in *one* C or C++ file to create the
    implementation.

    Optionally provide the following defines with your own implementations:

    SOKOL_ASSERT(c)             - your own assert macro (default: assert(c))
    SOKOL_UNREACHABLE()         - a guard macro for unreachable code (default: assert(false))
    SOKOL_FETCH_API_DECL        - public function declaration prefix (default: extern)
    SOKOL_API_DECL              - same as SOKOL_FETCH_API_DECL
    SOKOL_API_IMPL              - public function implementation prefix (default: -)
    SFETCH_MAX_PATH             - max length of UTF-8 filesystem path / URL (default: 1024 bytes)
    SFETCH_MAX_USERDATA_UINT64  - max size of embedded userdata in number of uint64_t, userdata
                                  will be copied into an 8-byte aligned memory region associated
                                  with each in-flight request, default value is 16 (== 128 bytes)
    SFETCH_MAX_CHANNELS         - max number of IO channels (default is 16, also see sfetch_desc_t.num_channels)

    If sokol_fetch.h is compiled as a DLL, define the following before
    including the declaration or implementation:

    SOKOL_DLL

    On Windows, SOKOL_DLL will define SOKOL_FETCH_API_DECL as __declspec(dllexport)
    or __declspec(dllimport) as needed.

    NOTE: The following documentation talks a lot about "IO threads". Actual
    threads are only used on platforms where threads are available. The web
    version (emscripten/wasm) doesn't use POSIX-style threads, but instead
    asynchronous Javascript calls chained together by callbacks. The actual
    source code differences between the two approaches have been kept to
    a minimum though.

    FEATURE OVERVIEW
    ================

    - Asynchronously load complete files, or stream files incrementally via
      HTTP (on web platform), or the local file system (on native platforms)

    - Request / response-callback model, user code sends a request
      to initiate a file-load, sokol_fetch.h calls the response callback
      on the same thread when data is ready or user-code needs
      to respond otherwise

    - Not limited to the main-thread or a single thread: A sokol-fetch
      "context" can live on any thread, and multiple contexts
      can operate side-by-side on different threads.

    - Memory management for data buffers is under full control of user code.
      sokol_fetch.h won't allocate memory after it has been setup.

    - Automatic rate-limiting guarantees that only a maximum number of
      requests is processed at any one time, allowing a zero-allocation
      model, where all data is streamed into fixed-size, pre-allocated
      buffers.

    - Active Requests can be paused, continued and cancelled from anywhere
      in the user-thread which sent this request.


    TL;DR EXAMPLE CODE
    ==================
    This is the most-simple example code to load a single data file with a
    known maximum size:

    (1) initialize sokol-fetch with default parameters (but NOTE that the
        default setup parameters provide a safe-but-slow "serialized"
        operation). In order to see any logging output in case or errors
        you should always provide a logging function
        (such as 'slog_func' from sokol_log.h):

        sfetch_setup(&(sfetch_desc_t){ .logger.func = slog_func });

    (2) send a fetch-request to load a file from the current directory
        into a buffer big enough to hold the entire file content:

        static uint8_t buf[MAX_FILE_SIZE];

        sfetch_send(&(sfetch_request_t){
            .path = "my_file.txt",
            .callback = response_callback,
            .buffer = {
                .ptr = buf,
                .size = sizeof(buf)
            }
        });

        If 'buf' is a value (e.g. an array or struct item), the .buffer item can
        be initialized with the SFETCH_RANGE() helper macro:

        sfetch_send(&(sfetch_request_t){
            .path = "my_file.txt",
            .callback = response_callback,
            .buffer = SFETCH_RANGE(buf)
        });

    (3) write a 'response-callback' function, this will be called whenever
        the user-code must respond to state changes of the request
        (most importantly when data has been loaded):

        void response_callback(const sfetch_response_t* response) {
            if (response->fetched) {
                // data has been loaded, and is available via the
                // sfetch_range_t struct item 'data':
                const void* ptr = response->data.ptr;
                size_t num_bytes = response->data.size;
            }
            if (response->finished) {
                // the 'finished'-flag is the catch-all flag for when the request
                // is finished, no matter if loading was successful or failed,
                // so any cleanup-work should happen here...
                ...
                if (response->failed) {
                    // 'failed' is true in (addition to 'finished') if something
                    // went wrong (file doesn't exist, or less bytes could be
                    // read from the file than expected)
                }
            }
        }

    (4) pump the sokol-fetch message queues, and invoke response callbacks
        by calling:

        sfetch_dowork();

        In an event-driven app this should be called in the event loop. If you
        use sokol-app this would be in your frame_cb function.

    (5) finally, call sfetch_shutdown() at the end of the application:

    There's many other loading-scenarios, for instance one doesn't have to
    provide a buffer upfront, this can also happen in the response callback.

    Or it's possible to stream huge files into small fixed-size buffer,
    complete with pausing and continuing the download.

    It's also possible to improve the 'pipeline throughput' by fetching
    multiple files in parallel, but at the same time limit the maximum
    number of requests that can be 'in-flight'.

    For how this all works, please read the following documentation sections :)


    API DOCUMENTATION
    =================

    void sfetch_setup(const sfetch_desc_t* desc)
    --------------------------------------------
    First call sfetch_setup(const sfetch_desc_t*) on any thread before calling
    any other sokol-fetch functions on the same thread.

    sfetch_setup() takes a pointer to an sfetch_desc_t struct with setup
    parameters. Parameters which should use their default values must
    be zero-initialized:

        - max_requests (uint32_t):
            The maximum number of requests that can be alive at any time, the
            default is 128.

        - num_channels (uint32_t):
            The number of "IO channels" used to parallelize and prioritize
            requests, the default is 1.

        - num_lanes (uint32_t):
            The number of "lanes" on a single channel. Each request which is
            currently 'inflight' on a channel occupies one lane until the
            request is finished. This is used for automatic rate-limiting
            (search below for CHANNELS AND LANES for more details). The
            default number of lanes is 1.

    For example, to setup sokol-fetch for max 1024 active requests, 4 channels,
    and 8 lanes per channel in C99:

        sfetch_setup(&(sfetch_desc_t){
            .max_requests = 1024,
            .num_channels = 4,
            .num_lanes = 8
        });

    sfetch_setup() is the only place where sokol-fetch will allocate memory.

    NOTE that the default setup parameters of 1 channel and 1 lane per channel
    has a very poor 'pipeline throughput' since this essentially serializes
    IO requests (a new request will only be processed when the last one has
    finished), and since each request needs at least one roundtrip between
    the user- and IO-thread the throughput will be at most one request per
    frame. Search for LATENCY AND THROUGHPUT below for more information on
    how to increase throughput.

    NOTE that you can call sfetch_setup() on multiple threads, each thread
    will get its own thread-local sokol-fetch instance, which will work
    independently from sokol-fetch instances on other threads.

    void sfetch_shutdown(void)
    --------------------------
    Call sfetch_shutdown() at the end of the application to stop any
    IO threads and free all memory that was allocated in sfetch_setup().

    sfetch_handle_t sfetch_send(const sfetch_request_t* request)
    ------------------------------------------------------------
    Call sfetch_send() to start loading data, the function takes a pointer to an
    sfetch_request_t struct with request parameters and returns a
    sfetch_handle_t identifying the request for later calls. At least
    a path/URL and callback must be provided:

        sfetch_handle_t h = sfetch_send(&(sfetch_request_t){
            .path = "my_file.txt",
            .callback = my_response_callback
        });

    sfetch_send() will return an invalid handle if no request can be allocated
    from the internal pool because all available request items are 'in-flight'.

    The sfetch_request_t struct contains the following parameters (optional
    parameters that are not provided must be zero-initialized):

        - path (const char*, required)
            Pointer to an UTF-8 encoded C string describing the filesystem
            path or HTTP URL. The string will be copied into an internal data
            structure, and passed "as is" (apart from any required
            encoding-conversions) to fopen(), CreateFileW() or
            the html fetch API call. The maximum length of the string is defined by
            the SFETCH_MAX_PATH configuration define, the default is 1024 bytes
            including the 0-terminator byte.

        - callback (sfetch_callback_t, required)
            Pointer to a response-callback function which is called when the
            request needs "user code attention". Search below for REQUEST
            STATES AND THE RESPONSE CALLBACK for detailed information about
            handling responses in the response callback.

        - channel (uint32_t, optional)
            Index of the IO channel where the request should be processed.
            Channels are used to parallelize and prioritize requests relative
            to each other. Search below for CHANNELS AND LANES for more
            information. The default channel is 0.

        - chunk_size (uint32_t, optional)
            The chunk_size member is used for streaming data incrementally
            in small chunks. After 'chunk_size' bytes have been loaded into
            to the streaming buffer, the response callback will be called
            with the buffer containing the fetched data for the current chunk.
            If chunk_size is 0 (the default), than the whole file will be loaded.
            Please search below for CHUNK SIZE AND HTTP COMPRESSION for
            important information how streaming works if the web server
            is serving compressed data.

        - buffer (sfetch_range_t)
            This is a optional pointer/size pair describing a chunk of memory where
            data will be loaded into (if no buffer is provided upfront, this
            must happen in the response callback). If a buffer is provided,
            it must be big enough to either hold the entire file (if chunk_size
            is zero), or the *uncompressed* data for one downloaded chunk
            (if chunk_size is > 0).

        - user_data (sfetch_range_t)
            The user_data ptr/size range struct describe an optional POD blob
            (plain-old-data) associated with the request which will be copied(!)
            into an internal memory block. The maximum default size of this
            memory block is 128 bytes (but can be overridden by defining
            SFETCH_MAX_USERDATA_UINT64 before including the notification, note
            that this define is in "number of uint64_t", not number of bytes).
            The user-data block is 8-byte aligned, and will be copied via
            memcpy() (so don't put any C++ "smart members" in there).

    NOTE that request handles are strictly thread-local and only unique
    within the thread the handle was created on, and all function calls
    involving a request handle must happen on that same thread.

    bool sfetch_handle_valid(sfetch_handle_t request)
    -------------------------------------------------
    This checks if the provided request handle is valid, and is associated with
    a currently active request. It will return false if:

        - sfetch_send() returned an invalid handle because it couldn't allocate
          a new request from the internal request pool (because they're all
          in flight)
        - the request associated with the handle is no longer alive (because
          it either finished successfully, or the request failed for some
          reason)

    void sfetch_dowork(void)
    ------------------------
    Call sfetch_dowork(void) in regular intervals (for instance once per frame)
    on the same thread as sfetch_setup() to "turn the gears". If you are sending
    requests but never hear back from them in the response callback function, then
    the most likely reason is that you forgot to add the call to sfetch_dowork()
    in the per-frame function.

    sfetch_dowork() roughly performs the following work:

        - any new requests that have been sent with sfetch_send() since the
        last call to sfetch_dowork() will be dispatched to their IO channels
        and assigned a free lane. If all lanes on that channel are occupied
        by requests 'in flight', incoming requests must wait until
        a lane becomes available

        - for all new requests which have been enqueued on a channel which
        don't already have a buffer assigned the response callback will be
        called with (response->dispatched == true) so that the response
        callback can inspect the dynamically assigned lane and bind a buffer
        to the request (search below for CHANNELS AND LANE for more info)

        - a state transition from "user side" to "IO thread side" happens for
        each new request that has been dispatched to a channel.

        - requests dispatched to a channel are either forwarded into that
        channel's worker thread (on native platforms), or cause an HTTP
        request to be sent via an asynchronous fetch() call (on the web
        platform)

        - for all requests which have finished their current IO operation a
        state transition from "IO thread side" to "user side" happens,
        and the response callback is called so that the fetched data
        can be processed.

        - requests which are completely finished (either because the entire
        file content has been loaded, or they are in the FAILED state) are
        freed (this just changes their state in the 'request pool', no actual
        memory is freed)

        - requests which are not yet finished are fed back into the
        'incoming' queue of their channel, and the cycle starts again, this
        only happens for requests which perform data streaming (not load
        the entire file at once).

    void sfetch_cancel(sfetch_handle_t request)
    -------------------------------------------
    This cancels a request in the next sfetch_dowork() call and invokes the
    response callback with (response.failed == true) and (response.finished
    == true) to give user-code a chance to do any cleanup work for the
    request. If sfetch_cancel() is called for a request that is no longer
    alive, nothing bad will happen (the call will simply do nothing).

    void sfetch_pause(sfetch_handle_t request)
    ------------------------------------------
    This pauses an active request in the next sfetch_dowork() call and puts
    it into the PAUSED state. For all requests in PAUSED state, the response
    callback will be called in each call to sfetch_dowork() to give user-code
    a chance to CONTINUE the request (by calling sfetch_continue()). Pausing
    a request makes sense for dynamic rate-limiting in streaming scenarios
    (like video/audio streaming with a fixed number of streaming buffers. As
    soon as all available buffers are filled with download data, downloading
    more data must be prevented to allow video/audio playback to catch up and
    free up empty buffers for new download data.

    void sfetch_continue(sfetch_handle_t request)
    ---------------------------------------------
    Continues a paused request, counterpart to the sfetch_pause() function.

    void sfetch_bind_buffer(sfetch_handle_t request, sfetch_range_t buffer)
    ----------------------------------------------------------------------------------------
    This "binds" a new buffer (as pointer/size pair) to an active request. The
    function *must* be called from inside the response-callback, and there
    must not already be another buffer bound.

    void* sfetch_unbind_buffer(sfetch_handle_t request)
    ---------------------------------------------------
    This removes the current buffer binding from the request and returns
    a pointer to the previous buffer (useful if the buffer was dynamically
    allocated and it must be freed).

    sfetch_unbind_buffer() *must* be called from inside the response callback.

    The usual code sequence to bind a different buffer in the response
    callback might look like this:

        void response_callback(const sfetch_response_t* response) {
            if (response.fetched) {
                ...
                // switch to a different buffer (in the FETCHED state it is
                // guaranteed that the request has a buffer, otherwise it
                // would have gone into the FAILED state
                void* old_buf_ptr = sfetch_unbind_buffer(response.handle);
                free(old_buf_ptr);
                void* new_buf_ptr = malloc(new_buf_size);
                sfetch_bind_buffer(response.handle, new_buf_ptr, new_buf_size);
            }
            if (response.finished) {
                // unbind and free the currently associated buffer,
                // the buffer pointer could be null if the request has failed
                // NOTE that it is legal to call free() with a nullptr,
                // this happens if the request failed to open its file
                // and never goes into the OPENED state
                void* buf_ptr = sfetch_unbind_buffer(response.handle);
                free(buf_ptr);
            }
        }

    sfetch_desc_t sfetch_desc(void)
    -------------------------------
    sfetch_desc() returns a copy of the sfetch_desc_t struct passed to
    sfetch_setup(), with zero-initialized values replaced with
    their default values.

    int sfetch_max_userdata_bytes(void)
    -----------------------------------
    This returns the value of the SFETCH_MAX_USERDATA_UINT64 config
    define, but in number of bytes (so SFETCH_MAX_USERDATA_UINT64*8).

    int sfetch_max_path(void)
    -------------------------
    Returns the value of the SFETCH_MAX_PATH config define.


    REQUEST STATES AND THE RESPONSE CALLBACK
    ========================================
    A request goes through a number of states during its lifetime. Depending
    on the current state of a request, it will be 'owned' either by the
    "user-thread" (where the request was sent) or an IO thread.

    You can think of a request as "ping-ponging" between the IO thread and
    user thread, any actual IO work is done on the IO thread, while
    invocations of the response-callback happen on the user-thread.

    All state transitions and callback invocations happen inside the
    sfetch_dowork() function.

    An active request goes through the following states:

    ALLOCATED (user-thread)

        The request has been allocated in sfetch_send() and is
        waiting to be dispatched into its IO channel. When this
        happens, the request will transition into the DISPATCHED state.

    DISPATCHED (IO thread)

        The request has been dispatched into its IO channel, and a
        lane has been assigned to the request.

        If a buffer was provided in sfetch_send() the request will
        immediately transition into the FETCHING state and start loading
        data into the buffer.

        If no buffer was provided in sfetch_send(), the response
        callback will be called with (response->dispatched == true),
        so that the response callback can bind a buffer to the
        request. Binding the buffer in the response callback makes
        sense if the buffer isn't dynamically allocated, but instead
        a pre-allocated buffer must be selected from the request's
        channel and lane.

        Note that it isn't possible to get a file size in the response callback
        which would help with allocating a buffer of the right size, this is
        because it isn't possible in HTTP to query the file size before the
        entire file is downloaded (...when the web server serves files compressed).

        If opening the file failed, the request will transition into
        the FAILED state with the error code SFETCH_ERROR_FILE_NOT_FOUND.

    FETCHING (IO thread)

        While a request is in the FETCHING state, data will be loaded into
        the user-provided buffer.

        If no buffer was provided, the request will go into the FAILED
        state with the error code SFETCH_ERROR_NO_BUFFER.

        If a buffer was provided, but it is too small to contain the
        fetched data, the request will go into the FAILED state with
        error code SFETCH_ERROR_BUFFER_TOO_SMALL.

        If less data can be read from the file than expected, the request
        will go into the FAILED state with error code SFETCH_ERROR_UNEXPECTED_EOF.

        If loading data into the provided buffer works as expected, the
        request will go into the FETCHED state.

    FETCHED (user thread)

        The request goes into the FETCHED state either when the entire file
        has been loaded into the provided buffer (when request.chunk_size == 0),
        or a chunk has been loaded (and optionally decompressed) into the
        buffer (when request.chunk_size > 0).

        The response callback will be called so that the user-code can
        process the loaded data using the following sfetch_response_t struct members:

            - data.ptr: pointer to the start of fetched data
            - data.size: the number of bytes in the provided buffer
            - data_offset: the byte offset of the loaded data chunk in the
              overall file (this is only set to a non-zero value in a streaming
              scenario)

        Once all file data has been loaded, the 'finished' flag will be set
        in the response callback's sfetch_response_t argument.

        After the user callback returns, and all file data has been loaded
        (response.finished flag is set) the request has reached its end-of-life
        and will be recycled.

        Otherwise, if there's still data to load (because streaming was
        requested by providing a non-zero request.chunk_size), the request
        will switch back to the FETCHING state to load the next chunk of data.

        Note that it is ok to associate a different buffer or buffer-size
        with the request by calling sfetch_bind_buffer() in the response-callback.

        To check in the response callback for the FETCHED state, and
        independently whether the request is finished:

            void response_callback(const sfetch_response_t* response) {
                if (response->fetched) {
                    // request is in FETCHED state, the loaded data is available
                    // in .data.ptr, and the number of bytes that have been
                    // loaded in .data.size:
                    const void* data = response->data.ptr;
                    size_t num_bytes = response->data.size;
                }
                if (response->finished) {
                    // the finished flag is set either when all data
                    // has been loaded, the request has been cancelled,
                    // or the file operation has failed, this is where
                    // any required per-request cleanup work should happen
                }
            }


    FAILED (user thread)

        A request will transition into the FAILED state in the following situations:

            - if the file doesn't exist or couldn't be opened for other
              reasons (SFETCH_ERROR_FILE_NOT_FOUND)
            - if no buffer is associated with the request in the FETCHING state
              (SFETCH_ERROR_NO_BUFFER)
            - if the provided buffer is too small to hold the entire file
              (if request.chunk_size == 0), or the (potentially decompressed)
              partial data chunk (SFETCH_ERROR_BUFFER_TOO_SMALL)
            - if less bytes could be read from the file then expected
              (SFETCH_ERROR_UNEXPECTED_EOF)
            - if a request has been cancelled via sfetch_cancel()
              (SFETCH_ERROR_CANCELLED)

        The response callback will be called once after a request goes into
        the FAILED state, with the 'response->finished' and
        'response->failed' flags set to true.

        This gives the user-code a chance to cleanup any resources associated
        with the request.

        To check for the failed state in the response callback:

            void response_callback(const sfetch_response_t* response) {
                if (response->failed) {
                    // specifically check for the failed state...
                }
                // or you can do a catch-all check via the finished-flag:
                if (response->finished) {
                    if (response->failed) {
                        // if more detailed error handling is needed:
                        switch (response->error_code) {
                            ...
                        }
                    }
                }
            }

    PAUSED (user thread)

        A request will transition into the PAUSED state after user-code
        calls the function sfetch_pause() on the request's handle. Usually
        this happens from within the response-callback in streaming scenarios
        when the data streaming needs to wait for a data decoder (like
        a video/audio player) to catch up.

        While a request is in PAUSED state, the response-callback will be
        called in each sfetch_dowork(), so that the user-code can either
        continue the request by calling sfetch_continue(), or cancel
        the request by calling sfetch_cancel().

        When calling sfetch_continue() on a paused request, the request will
        transition into the FETCHING state. Otherwise if sfetch_cancel() is
        called, the request will switch into the FAILED state.

        To check for the PAUSED state in the response callback:

            void response_callback(const sfetch_response_t* response) {
                if (response->paused) {
                    // we can check here whether the request should
                    // continue to load data:
                    if (should_continue(response->handle)) {
                        sfetch_continue(response->handle);
                    }
                }
            }


    CHUNK SIZE AND HTTP COMPRESSION
    ===============================
    TL;DR: for streaming scenarios, the provided chunk-size must be smaller
    than the provided buffer-size because the web server may decide to
    serve the data compressed and the chunk-size must be given in 'compressed
    bytes' while the buffer receives 'uncompressed bytes'. It's not possible
    in HTTP to query the uncompressed size for a compressed download until
    that download has finished.

    With vanilla HTTP, it is not possible to query the actual size of a file
    without downloading the entire file first (the Content-Length response
    header only provides the compressed size). Furthermore, for HTTP
    range-requests, the range is given on the compressed data, not the
    uncompressed data. So if the web server decides to serve the data
    compressed, the content-length and range-request parameters don't
    correspond to the uncompressed data that's arriving in the sokol-fetch
    buffers, and there's no way from JS or WASM to either force uncompressed
    downloads (e.g. by setting the Accept-Encoding field), or access the
    compressed data.

    This has some implications for sokol_fetch.h, most notably that buffers
    can't be provided in the exactly right size, because that size can't
    be queried from HTTP before the data is actually downloaded.

    When downloading whole files at once, it is basically expected that you
    know the maximum files size upfront through other means (for instance
    through a separate meta-data-file which contains the file sizes and
    other meta-data for each file that needs to be loaded).

    For streaming downloads the situation is a bit more complicated. These
    use HTTP range-requests, and those ranges are defined on the (potentially)
    compressed data which the JS/WASM side doesn't have access to. However,
    the JS/WASM side only ever sees the uncompressed data, and it's not possible
    to query the uncompressed size of a range request before that range request
    has finished.

    If the provided buffer is too small to contain the uncompressed data,
    the request will fail with error code SFETCH_ERROR_BUFFER_TOO_SMALL.


    CHANNELS AND LANES
    ==================
    Channels and lanes are (somewhat artificial) concepts to manage
    parallelization, prioritization and rate-limiting.

    Channels can be used to parallelize message processing for better 'pipeline
    throughput', and to prioritize requests: user-code could reserve one
    channel for streaming downloads which need to run in parallel to other
    requests, another channel for "regular" downloads and yet another
    high-priority channel which would only be used for small files which need
    to start loading immediately.

    Each channel comes with its own IO thread and message queues for pumping
    messages in and out of the thread. The channel where a request is
    processed is selected manually when sending a message:

        sfetch_send(&(sfetch_request_t){
            .path = "my_file.txt",
            .callback = my_response_callback,
            .channel = 2
        });

    The number of channels is configured at startup in sfetch_setup() and
    cannot be changed afterwards.

    Channels are completely separate from each other, and a request will
    never "hop" from one channel to another.

    Each channel consists of a fixed number of "lanes" for automatic rate
    limiting:

    When a request is sent to a channel via sfetch_send(), a "free lane" will
    be picked and assigned to the request. The request will occupy this lane
    for its entire life time (also while it is paused). If all lanes of a
    channel are currently occupied, new requests will wait until a
    lane becomes unoccupied.

    Since the number of channels and lanes is known upfront, it is guaranteed
    that there will never be more than "num_channels * num_lanes" requests
    in flight at any one time.

    This guarantee eliminates unexpected load- and memory-spikes when
    many requests are sent in very short time, and it allows to pre-allocate
    a fixed number of memory buffers which can be reused for the entire
    "lifetime" of a sokol-fetch context.

    In the most simple scenario - when a maximum file size is known - buffers
    can be statically allocated like this:

        uint8_t buffer[NUM_CHANNELS][NUM_LANES][MAX_FILE_SIZE];

    Then in the user callback pick a buffer by channel and lane,
    and associate it with the request like this:

        void response_callback(const sfetch_response_t* response) {
            if (response->dispatched) {
                void* ptr = buffer[response->channel][response->lane];
                sfetch_bind_buffer(response->handle, ptr, MAX_FILE_SIZE);
            }
            ...
        }


    NOTES ON OPTIMIZING PIPELINE LATENCY AND THROUGHPUT
    ===================================================
    With the default configuration of 1 channel and 1 lane per channel,
    sokol_fetch.h will appear to have a shockingly bad loading performance
    if several files are loaded.

    This has two reasons:

        (1) all parallelization when loading data has been disabled. A new
        request will only be processed, when the last request has finished.

        (2) every invocation of the response-callback adds one frame of latency
        to the request, because callbacks will only be called from within
        sfetch_dowork()

    sokol-fetch takes a few shortcuts to improve step (2) and reduce
    the 'inherent latency' of a request:

        - if a buffer is provided upfront, the response-callback won't be
        called in the DISPATCHED state, but start right with the FETCHED state
        where data has already been loaded into the buffer

        - there is no separate CLOSED state where the callback is invoked
        separately when loading has finished (or the request has failed),
        instead the finished and failed flags will be set as part of
        the last FETCHED invocation

    This means providing a big-enough buffer to fit the entire file is the
    best case, the response callback will only be called once, ideally in
    the next frame (or two calls to sfetch_dowork()).

    If no buffer is provided upfront, one frame of latency is added because
    the response callback needs to be invoked in the DISPATCHED state so that
    the user code can bind a buffer.

    This means the best case for a request without an upfront-provided
    buffer is 2 frames (or 3 calls to sfetch_dowork()).

    That's about what can be done to improve the latency for a single request,
    but the really important step is to improve overall throughput. If you
    need to load thousands of files you don't want that to be completely
    serialized.

    The most important action to increase throughput is to increase the
    number of lanes per channel. This defines how many requests can be
    'in flight' on a single channel at the same time. The guiding decision
    factor for how many lanes you can "afford" is the memory size you want
    to set aside for buffers. Each lane needs its own buffer so that
    the data loaded for one request doesn't scribble over the data
    loaded for another request.

    Here's a simple example of sending 4 requests without upfront buffer
    on a channel with 1, 2 and 4 lanes, each line is one frame:

        1 LANE (8 frames):
            Lane 0:
            -------------
            REQ 0 DISPATCHED
            REQ 0 FETCHED
            REQ 1 DISPATCHED
            REQ 1 FETCHED
            REQ 2 DISPATCHED
            REQ 2 FETCHED
            REQ 3 DISPATCHED
            REQ 3 FETCHED

    Note how the request don't overlap, so they can all use the same buffer.

        2 LANES (4 frames):
            Lane 0:             Lane 1:
            ------------------------------------
            REQ 0 DISPATCHED    REQ 1 DISPATCHED
            REQ 0 FETCHED       REQ 1 FETCHED
            REQ 2 DISPATCHED    REQ 3 DISPATCHED
            REQ 2 FETCHED       REQ 3 FETCHED

    This reduces the overall time to 4 frames, but now you need 2 buffers so
    that requests don't scribble over each other.

        4 LANES (2 frames):
            Lane 0:             Lane 1:             Lane 2:             Lane 3:
            ----------------------------------------------------------------------------
            REQ 0 DISPATCHED    REQ 1 DISPATCHED    REQ 2 DISPATCHED    REQ 3 DISPATCHED
            REQ 0 FETCHED       REQ 1 FETCHED       REQ 2 FETCHED       REQ 3 FETCHED

    Now we're down to the same 'best-case' latency as sending a single
    request.

    Apart from the memory requirements for the streaming buffers (which is
    under your control), you can be generous with the number of lanes,
    they don't add any processing overhead.

    The last option for tweaking latency and throughput is channels. Each
    channel works independently from other channels, so while one
    channel is busy working through a large number of requests (or one
    very long streaming download), you can set aside a high-priority channel
    for requests that need to start as soon as possible.

    On platforms with threading support, each channel runs on its own
    thread, but this is mainly an implementation detail to work around
    the traditional blocking file IO functions, not for performance reasons.


    MEMORY ALLOCATION OVERRIDE
    ==========================
    You can override the memory allocation functions at initialization time
    like this:

        void* my_alloc(size_t size, void* user_data) {
            return malloc(size);
        }

        void my_free(void* ptr, void* user_data) {
            free(ptr);
        }

        ...
            sfetch_setup(&(sfetch_desc_t){
                // ...
                .allocator = {
                    .alloc_fn = my_alloc,
                    .free_fn = my_free,
                    .user_data = ...,
                }
            });
        ...

    If no overrides are provided, malloc and free will be used.

    This only affects memory allocation calls done by sokol_fetch.h
    itself though, not any allocations in OS libraries.

    Memory allocation will only happen on the same thread where sfetch_setup()
    was called, so you don't need to worry about thread-safety.


    ERROR REPORTING AND LOGGING
    ===========================
    To get any logging information at all you need to provide a logging callback in the setup call,
    the easiest way is to use sokol_log.h:

        #include "sokol_log.h"

        sfetch_setup(&(sfetch_desc_t){
            // ...
            .logger.func = slog_func
        });

    To override logging with your own callback, first write a logging function like this:

        void my_log(const char* tag,                // e.g. 'sfetch'
                    uint32_t log_level,             // 0=panic, 1=error, 2=warn, 3=info
                    uint32_t log_item_id,           // SFETCH_LOGITEM_*
                    const char* message_or_null,    // a message string, may be nullptr in release mode
                    uint32_t line_nr,               // line number in sokol_fetch.h
                    const char* filename_or_null,   // source filename, may be nullptr in release mode
                    void* user_data)
        {
            ...
        }

    ...and then setup sokol-fetch like this:

        sfetch_setup(&(sfetch_desc_t){
            .logger = {
                .func = my_log,
                .user_data = my_user_data,
            }
        });

    The provided logging function must be reentrant (e.g. be callable from
    different threads).

    If you don't want to provide your own custom logger it is highly recommended to use
    the standard logger in sokol_log.h instead, otherwise you won't see any warnings or
    errors.


    FUTURE PLANS / V2.0 IDEA DUMP
    =============================
    - An optional polling API (as alternative to callback API)
    - Move buffer-management into the API? The "manual management"
      can be quite tricky especially for dynamic allocation scenarios,
      API support for buffer management would simplify cases like
      preventing that requests scribble over each other's buffers, or
      an automatic garbage collection for dynamically allocated buffers,
      or automatically falling back to dynamic allocation if static
      buffers aren't big enough.
    - Pluggable request handlers to load data from other "sources"
      (especially HTTP downloads on native platforms via e.g. libcurl
      would be useful)
    - I'm currently not happy how the user-data block is handled, this
      should getting and updating the user-data should be wrapped by
      API functions (similar to bind/unbind buffer)


    LICENSE
    =======
    zlib/libpng license

    Copyright (c) 2019 Andre Weissflog

    This software is provided 'as-is', without any express or implied warranty.
    In no event will the authors be held liable for any damages arising from the
    use of this software.

    Permission is granted to anyone to use this software for any purpose,
    including commercial applications, and to alter it and redistribute it
    freely, subject to the following restrictions:

        1. The origin of this software must not be misrepresented; you must not
        claim that you wrote the original software. If you use this software in a
        product, an acknowledgment in the product documentation would be
        appreciated but is not required.

        2. Altered source versions must be plainly marked as such, and must not
        be misrepresented as being the original software.

        3. This notice may not be removed or altered from any source
        distribution.
*/
#define SOKOL_FETCH_INCLUDED (1)
#include <stddef.h> // size_t
#include <stdint.h>
#include <stdbool.h>

#if defined(SOKOL_API_DECL) && !defined(SOKOL_FETCH_API_DECL)
#define SOKOL_FETCH_API_DECL SOKOL_API_DECL
#endif
#ifndef SOKOL_FETCH_API_DECL
#if defined(_WIN32) && defined(SOKOL_DLL) && defined(SOKOL_FETCH_IMPL)
#define SOKOL_FETCH_API_DECL __declspec(dllexport)
#elif defined(_WIN32) && defined(SOKOL_DLL)
#define SOKOL_FETCH_API_DECL __declspec(dllimport)
#else
#define SOKOL_FETCH_API_DECL extern
#endif
#endif

#ifdef __cplusplus
extern "C" {
#endif

/*
    sfetch_log_item_t

    Log items are defined via X-Macros, and expanded to an
    enum 'sfetch_log_item', and in debug mode only,
    corresponding strings.

    Used as parameter in the logging callback.
*/
#define _SFETCH_LOG_ITEMS \
    _SFETCH_LOGITEM_XMACRO(OK, "Ok") \
    _SFETCH_LOGITEM_XMACRO(MALLOC_FAILED, "memory allocation failed") \
    _SFETCH_LOGITEM_XMACRO(FILE_PATH_UTF8_DECODING_FAILED, "failed converting file path from UTF8 to wide") \
    _SFETCH_LOGITEM_XMACRO(SEND_QUEUE_FULL, "send queue full (adjust via sfetch_desc_t.max_requests)")  \
    _SFETCH_LOGITEM_XMACRO(REQUEST_CHANNEL_INDEX_TOO_BIG, "channel index too big (adjust via sfetch_desc_t.num_channels)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_PATH_IS_NULL, "file path is nullptr (sfetch_request_t.path)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_PATH_TOO_LONG, "file path is too long (SFETCH_MAX_PATH)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_CALLBACK_MISSING, "no callback provided (sfetch_request_t.callback)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_CHUNK_SIZE_GREATER_BUFFER_SIZE, "chunk size is greater buffer size (sfetch_request_t.chunk_size vs .buffer.size)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_USERDATA_PTR_IS_SET_BUT_USERDATA_SIZE_IS_NULL, "user data ptr is set but user data size is null (sfetch_request_t.user_data.ptr vs .size)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_USERDATA_PTR_IS_NULL_BUT_USERDATA_SIZE_IS_NOT, "user data ptr is null but size is not (sfetch_request_t.user_data.ptr vs .size)") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_USERDATA_SIZE_TOO_BIG, "user data size too big (see SFETCH_MAX_USERDATA_UINT64)") \
    _SFETCH_LOGITEM_XMACRO(CLAMPING_NUM_CHANNELS_TO_MAX_CHANNELS, "clamping num channels to SFETCH_MAX_CHANNELS") \
    _SFETCH_LOGITEM_XMACRO(REQUEST_POOL_EXHAUSTED, "request pool exhausted (tweak via sfetch_desc_t.max_requests)") \

#define _SFETCH_LOGITEM_XMACRO(item,msg) SFETCH_LOGITEM_##item,
typedef enum sfetch_log_item_t {
    _SFETCH_LOG_ITEMS
} sfetch_log_item_t;
#undef _SFETCH_LOGITEM_XMACRO

/*
    sfetch_logger_t

    Used in sfetch_desc_t to provide a custom logging and error reporting
    callback to sokol-fetch.
*/
typedef struct sfetch_logger_t {
    void (*func)(
        const char* tag,                // always "sfetch"
        uint32_t log_level,             // 0=panic, 1=error, 2=warning, 3=info
        uint32_t log_item_id,           // SFETCH_LOGITEM_*
        const char* message_or_null,    // a message string, may be nullptr in release mode
        uint32_t line_nr,               // line number in sokol_fetch.h
        const char* filename_or_null,   // source filename, may be nullptr in release mode
        void* user_data);
    void* user_data;
} sfetch_logger_t;

/*
    sfetch_range_t

    A pointer-size pair struct to pass memory ranges into and out of sokol-fetch.
    When initialized from a value type (array or struct) you can use the
    SFETCH_RANGE() helper macro to build an sfetch_range_t struct.
*/
typedef struct sfetch_range_t {
    const void* ptr;
    size_t size;
} sfetch_range_t;

// disabling this for every includer isn't great, but the warnings are also quite pointless
#if defined(_MSC_VER)
#pragma warning(disable:4221)   // /W4 only: nonstandard extension used: 'x': cannot be initialized using address of automatic variable 'y'
#pragma warning(disable:4204)   // VS2015: nonstandard extension used: non-constant aggregate initializer
#endif
#if defined(__cplusplus)
#define SFETCH_RANGE(x) sfetch_range_t{ &x, sizeof(x) }
#else
#define SFETCH_RANGE(x) (sfetch_range_t){ &x, sizeof(x) }
#endif

/*
    sfetch_allocator_t

    Used in sfetch_desc_t to provide custom memory-alloc and -free functions
    to sokol_fetch.h. If memory management should be overridden, both the
    alloc and free function must be provided (e.g. it's not valid to
    override one function but not the other).
*/
typedef struct sfetch_allocator_t {
    void* (*alloc_fn)(size_t size, void* user_data);
    void (*free_fn)(void* ptr, void* user_data);
    void* user_data;
} sfetch_allocator_t;

/* configuration values for sfetch_setup() */
typedef struct sfetch_desc_t {
    uint32_t max_requests;          // max number of active requests across all channels (default: 128)
    uint32_t num_channels;          // number of channels to fetch requests in parallel (default: 1)
    uint32_t num_lanes;             // max number of requests active on the same channel (default: 1)
    sfetch_allocator_t allocator;   // optional memory allocation overrides (default: malloc/free)
    sfetch_logger_t logger;         // optional log function overrides (default: NO LOGGING!)
} sfetch_desc_t;

/* a request handle to identify an active fetch request, returned by sfetch_send() */
typedef struct sfetch_handle_t { uint32_t id; } sfetch_handle_t;

/* error codes */
typedef enum sfetch_error_t {
    SFETCH_ERROR_NO_ERROR,
    SFETCH_ERROR_FILE_NOT_FOUND,
    SFETCH_ERROR_NO_BUFFER,
    SFETCH_ERROR_BUFFER_TOO_SMALL,
    SFETCH_ERROR_UNEXPECTED_EOF,
    SFETCH_ERROR_INVALID_HTTP_STATUS,
    SFETCH_ERROR_CANCELLED,
    SFETCH_ERROR_JS_OTHER,          // check browser console for detailed error info
} sfetch_error_t;

/* the response struct passed to the response callback */
typedef struct sfetch_response_t {
    sfetch_handle_t handle;         // request handle this response belongs to
    bool dispatched;                // true when request is in DISPATCHED state (lane has been assigned)
    bool fetched;                   // true when request is in FETCHED state (fetched data is available)
    bool paused;                    // request is currently in paused state
    bool finished;                  // this is the last response for this request
    bool failed;                    // request has failed (always set together with 'finished')
    bool cancelled;                 // request was cancelled (always set together with 'finished')
    sfetch_error_t error_code;      // more detailed error code when failed is true
    uint32_t channel;               // the channel which processes this request
    uint32_t lane;                  // the lane this request occupies on its channel
    const char* path;               // the original filesystem path of the request
    void* user_data;                // pointer to read/write user-data area
    uint32_t data_offset;           // current offset of fetched data chunk in the overall file data
    sfetch_range_t data;            // the fetched data as ptr/size pair (data.ptr == buffer.ptr, data.size <= buffer.size)
    sfetch_range_t buffer;          // the user-provided buffer which holds the fetched data
} sfetch_response_t;

/* request parameters passed to sfetch_send() */
typedef struct sfetch_request_t {
    uint32_t channel;                                // index of channel this request is assigned to (default: 0)
    const char* path;                                // filesystem path or HTTP URL (required)
    void (*callback) (const sfetch_response_t*);     // response callback function pointer (required)
    uint32_t chunk_size;                             // number of bytes to load per stream-block (optional)
    sfetch_range_t buffer;                           // a memory buffer where the data will be loaded into (optional)
    sfetch_range_t user_data;                        // ptr/size of a POD user data block which will be memcpy'd (optional)
} sfetch_request_t;

/* setup sokol-fetch (can be called on multiple threads) */
SOKOL_FETCH_API_DECL void sfetch_setup(const sfetch_desc_t* desc);
/* discard a sokol-fetch context */
SOKOL_FETCH_API_DECL void sfetch_shutdown(void);
/* return true if sokol-fetch has been setup */
SOKOL_FETCH_API_DECL bool sfetch_valid(void);
/* get the desc struct that was passed to sfetch_setup() */
SOKOL_FETCH_API_DECL sfetch_desc_t sfetch_desc(void);
/* return the max userdata size in number of bytes (SFETCH_MAX_USERDATA_UINT64 * sizeof(uint64_t)) */
SOKOL_FETCH_API_DECL int sfetch_max_userdata_bytes(void);
/* return the value of the SFETCH_MAX_PATH implementation config value */
SOKOL_FETCH_API_DECL int sfetch_max_path(void);

/* send a fetch-request, get handle to request back */
SOKOL_FETCH_API_DECL sfetch_handle_t sfetch_send(const sfetch_request_t* request);
/* return true if a handle is valid *and* the request is alive */
SOKOL_FETCH_API_DECL bool sfetch_handle_valid(sfetch_handle_t h);
/* do per-frame work, moves requests into and out of IO threads, and invokes response-callbacks */
SOKOL_FETCH_API_DECL void sfetch_dowork(void);

/* bind a data buffer to a request (request must not currently have a buffer bound, must be called from response callback */
SOKOL_FETCH_API_DECL void sfetch_bind_buffer(sfetch_handle_t h, sfetch_range_t buffer);
/* clear the 'buffer binding' of a request, returns previous buffer pointer (can be 0), must be called from response callback */
SOKOL_FETCH_API_DECL void* sfetch_unbind_buffer(sfetch_handle_t h);
/* cancel a request that's in flight (will call response callback with .cancelled + .finished) */
SOKOL_FETCH_API_DECL void sfetch_cancel(sfetch_handle_t h);
/* pause a request (will call response callback each frame with .paused) */
SOKOL_FETCH_API_DECL void sfetch_pause(sfetch_handle_t h);
/* continue a paused request */
SOKOL_FETCH_API_DECL void sfetch_continue(sfetch_handle_t h);

#ifdef __cplusplus
} /* extern "C" */

/* reference-based equivalents for c++ */
inline void sfetch_setup(const sfetch_desc_t& desc) { return sfetch_setup(&desc); }
inline sfetch_handle_t sfetch_send(const sfetch_request_t& request) { return sfetch_send(&request); }

#endif
#endif // SOKOL_FETCH_INCLUDED

// ██ ███    ███ ██████  ██      ███████ ███    ███ ███████ ███    ██ ████████  █████  ████████ ██  ██████  ███    ██
// ██ ████  ████ ██   ██ ██      ██      ████  ████ ██      ████   ██    ██    ██   ██    ██    ██ ██    ██ ████   ██
// ██ ██ ████ ██ ██████  ██      █████   ██ ████ ██ █████   ██ ██  ██    ██    ███████    ██    ██ ██    ██ ██ ██  ██
// ██ ██  ██  ██ ██      ██      ██      ██  ██  ██ ██      ██  ██ ██    ██    ██   ██    ██    ██ ██    ██ ██  ██ ██
// ██ ██      ██ ██      ███████ ███████ ██      ██ ███████ ██   ████    ██    ██   ██    ██    ██  ██████  ██   ████
//
// >>implementation
#ifdef SOKOL_FETCH_IMPL
#define SOKOL_FETCH_IMPL_INCLUDED (1)

#if defined(SOKOL_MALLOC) || defined(SOKOL_CALLOC) || defined(SOKOL_FREE)
#error "SOKOL_MALLOC/CALLOC/FREE macros are no longer supported, please use sfetch_desc_t.allocator to override memory allocation functions"
#endif

#include <stdlib.h> /* malloc, free */
#include <string.h> /* memset, memcpy */

#ifndef SFETCH_MAX_PATH
#define SFETCH_MAX_PATH (1024)
#endif
#ifndef SFETCH_MAX_USERDATA_UINT64
#define SFETCH_MAX_USERDATA_UINT64 (16)
#endif
#ifndef SFETCH_MAX_CHANNELS
#define SFETCH_MAX_CHANNELS (16)
#endif

#ifndef SOKOL_API_IMPL
    #define SOKOL_API_IMPL
#endif
#ifndef SOKOL_DEBUG
    #ifndef NDEBUG
        #define SOKOL_DEBUG
    #endif
#endif
#ifndef SOKOL_ASSERT
    #include <assert.h>
    #define SOKOL_ASSERT(c) assert(c)
#endif

#ifndef _SOKOL_PRIVATE
    #if defined(__GNUC__) || defined(__clang__)
        #define _SOKOL_PRIVATE __attribute__((unused)) static
    #else
        #define _SOKOL_PRIVATE static
    #endif
#endif

#ifndef _SOKOL_UNUSED
    #define _SOKOL_UNUSED(x) (void)(x)
#endif

#if defined(__EMSCRIPTEN__)
    #include <emscripten/emscripten.h>
    #define _SFETCH_PLATFORM_EMSCRIPTEN (1)
    #define _SFETCH_PLATFORM_WINDOWS (0)
    #define _SFETCH_PLATFORM_POSIX (0)
    #define _SFETCH_HAS_THREADS (0)
#elif defined(_WIN32)
    #ifndef WIN32_LEAN_AND_MEAN
    #define WIN32_LEAN_AND_MEAN
    #endif
    #ifndef NOMINMAX
    #define NOMINMAX
    #endif
    #include <windows.h>
    #define _SFETCH_PLATFORM_WINDOWS (1)
    #define _SFETCH_PLATFORM_EMSCRIPTEN (0)
    #define _SFETCH_PLATFORM_POSIX (0)
    #define _SFETCH_HAS_THREADS (1)
#else
    #include <pthread.h>
    #include <stdio.h>  /* fopen, fread, fseek, fclose */
    #define _SFETCH_PLATFORM_POSIX (1)
    #define _SFETCH_PLATFORM_EMSCRIPTEN (0)
    #define _SFETCH_PLATFORM_WINDOWS (0)
    #define _SFETCH_HAS_THREADS (1)
#endif

#ifdef _MSC_VER
#pragma warning(push)
#pragma warning(disable:4724) // potential mod by 0
#endif

// ███████ ████████ ██████  ██    ██  ██████ ████████ ███████
// ██         ██    ██   ██ ██    ██ ██         ██    ██
// ███████    ██    ██████  ██    ██ ██         ██    ███████
//      ██    ██    ██   ██ ██    ██ ██         ██         ██
// ███████    ██    ██   ██  ██████   ██████    ██    ███████
//
// >>structs
typedef struct _sfetch_path_t {
    char buf[SFETCH_MAX_PATH];
} _sfetch_path_t;

/* a thread with incoming and outgoing message queue syncing */
#if _SFETCH_PLATFORM_POSIX
typedef struct {
    pthread_t thread;
    pthread_cond_t incoming_cond;
    pthread_mutex_t incoming_mutex;
    pthread_mutex_t outgoing_mutex;
    pthread_mutex_t running_mutex;
    pthread_mutex_t stop_mutex;
    bool stop_requested;
    bool valid;
} _sfetch_thread_t;
#elif _SFETCH_PLATFORM_WINDOWS
typedef struct {
    HANDLE thread;
    HANDLE incoming_event;
    CRITICAL_SECTION incoming_critsec;
    CRITICAL_SECTION outgoing_critsec;
    CRITICAL_SECTION running_critsec;
    CRITICAL_SECTION stop_critsec;
    bool stop_requested;
    bool valid;
} _sfetch_thread_t;
#endif

/* file handle abstraction */
#if _SFETCH_PLATFORM_POSIX
typedef FILE* _sfetch_file_handle_t;
#define _SFETCH_INVALID_FILE_HANDLE (0)
typedef void*(*_sfetch_thread_func_t)(void*);
#elif _SFETCH_PLATFORM_WINDOWS
typedef HANDLE _sfetch_file_handle_t;
#define _SFETCH_INVALID_FILE_HANDLE (INVALID_HANDLE_VALUE)
typedef LPTHREAD_START_ROUTINE _sfetch_thread_func_t;
#endif

/* user-side per-request state */
typedef struct {
    bool pause;                 /* switch item to PAUSED state if true */
    bool cont;                  /* switch item back to FETCHING if true */
    bool cancel;                /* cancel the request, switch into FAILED state */
    /* transfer IO => user thread */
    uint32_t fetched_offset;    /* number of bytes fetched so far */
    uint32_t fetched_size;      /* size of last fetched chunk */
    sfetch_error_t error_code;
    bool finished;
    /* user thread only */
    size_t user_data_size;
    uint64_t user_data[SFETCH_MAX_USERDATA_UINT64];
} _sfetch_item_user_t;

/* thread-side per-request state */
typedef struct {
    /* transfer IO => user thread */
    uint32_t fetched_offset;
    uint32_t fetched_size;
    sfetch_error_t error_code;
    bool failed;
    bool finished;
    /* IO thread only */
    #if _SFETCH_PLATFORM_EMSCRIPTEN
    uint32_t http_range_offset;
    #else
    _sfetch_file_handle_t file_handle;
    #endif
    uint32_t content_size;
} _sfetch_item_thread_t;

/* a request goes through the following states, ping-ponging between IO and user thread */
typedef enum _sfetch_state_t {
    _SFETCH_STATE_INITIAL,      /* internal: request has just been initialized */
    _SFETCH_STATE_ALLOCATED,    /* internal: request has been allocated from internal pool */
    _SFETCH_STATE_DISPATCHED,   /* user thread: request has been dispatched to its IO channel */
    _SFETCH_STATE_FETCHING,     /* IO thread: waiting for data to be fetched */
    _SFETCH_STATE_FETCHED,      /* user thread: fetched data available */
    _SFETCH_STATE_PAUSED,       /* user thread: request has been paused via sfetch_pause() */
    _SFETCH_STATE_FAILED,       /* user thread: follow state or FETCHING if something went wrong */
} _sfetch_state_t;

/* an internal request item */
#define _SFETCH_INVALID_LANE (0xFFFFFFFF)
typedef struct {
    sfetch_handle_t handle;
    _sfetch_state_t state;
    uint32_t channel;
    uint32_t lane;
    uint32_t chunk_size;
    void (*callback) (const sfetch_response_t*);
    sfetch_range_t buffer;

    /* updated by IO-thread, off-limits to user thread */
    _sfetch_item_thread_t thread;

    /* accessible by user-thread, off-limits to IO thread */
    _sfetch_item_user_t user;

    /* big stuff at the end */
    _sfetch_path_t path;
} _sfetch_item_t;

/* a pool of internal per-request items */
typedef struct {
    uint32_t size;
    uint32_t free_top;
    _sfetch_item_t* items;
    uint32_t* free_slots;
    uint32_t* gen_ctrs;
    bool valid;
} _sfetch_pool_t;

/* a ringbuffer for pool-slot ids */
typedef struct {
    uint32_t head;
    uint32_t tail;
    uint32_t num;
    uint32_t* buf;
} _sfetch_ring_t;

/* an IO channel with its own IO thread */
struct _sfetch_t;
typedef struct {
    struct _sfetch_t* ctx;  // back-pointer to thread-local _sfetch state pointer, since this isn't accessible from the IO threads
    _sfetch_ring_t free_lanes;
    _sfetch_ring_t user_sent;
    _sfetch_ring_t user_incoming;
    _sfetch_ring_t user_outgoing;
    #if _SFETCH_HAS_THREADS
    _sfetch_ring_t thread_incoming;
    _sfetch_ring_t thread_outgoing;
    _sfetch_thread_t thread;
    #endif
    void (*request_handler)(struct _sfetch_t* ctx, uint32_t slot_id);
    bool valid;
} _sfetch_channel_t;

/* the sfetch global state */
typedef struct _sfetch_t {
    bool setup;
    bool valid;
    bool in_callback;
    sfetch_desc_t desc;
    _sfetch_pool_t pool;
    _sfetch_channel_t chn[SFETCH_MAX_CHANNELS];
} _sfetch_t;
#if _SFETCH_HAS_THREADS
#if defined(_MSC_VER)
static __declspec(thread) _sfetch_t* _sfetch;
#else
static __thread _sfetch_t* _sfetch;
#endif
#else
static _sfetch_t* _sfetch;
#endif
#define _sfetch_def(val, def) (((val) == 0) ? (def) : (val))

// ██       ██████   ██████   ██████  ██ ███    ██  ██████
// ██      ██    ██ ██       ██       ██ ████   ██ ██
// ██      ██    ██ ██   ███ ██   ███ ██ ██ ██  ██ ██   ███
// ██      ██    ██ ██    ██ ██    ██ ██ ██  ██ ██ ██    ██
// ███████  ██████   ██████   ██████  ██ ██   ████  ██████
//
// >>logging
#if defined(SOKOL_DEBUG)
#define _SFETCH_LOGITEM_XMACRO(item,msg) #item ": " msg,
static const char* _sfetch_log_messages[] = {
    _SFETCH_LOG_ITEMS
};
#undef _SFETCH_LOGITEM_XMACRO
#endif // SOKOL_DEBUG

#define _SFETCH_PANIC(code) _sfetch_log(SFETCH_LOGITEM_ ##code, 0, __LINE__)
#define _SFETCH_ERROR(code) _sfetch_log(SFETCH_LOGITEM_ ##code, 1, __LINE__)
#define _SFETCH_WARN(code) _sfetch_log(SFETCH_LOGITEM_ ##code, 2, __LINE__)
#define _SFETCH_INFO(code) _sfetch_log(SFETCH_LOGITEM_ ##code, 3, __LINE__)

static void _sfetch_log(sfetch_log_item_t log_item, uint32_t log_level, uint32_t line_nr) {
    if (_sfetch->desc.logger.func) {
        #if defined(SOKOL_DEBUG)
            const char* filename = __FILE__;
            const char* message = _sfetch_log_messages[log_item];
        #else
            const char* filename = 0;
            const char* message = 0;
        #endif
        _sfetch->desc.logger.func("sfetch", log_level, (uint32_t)log_item, message, line_nr, filename, _sfetch->desc.logger.user_data);
    } else {
        // for log level PANIC it would be 'undefined behaviour' to continue
        if (log_level == 0) {
            abort();
        }
    }
}

// ███    ███ ███████ ███    ███  ██████  ██████  ██    ██
// ████  ████ ██      ████  ████ ██    ██ ██   ██  ██  ██
// ██ ████ ██ █████   ██ ████ ██ ██    ██ ██████    ████
// ██  ██  ██ ██      ██  ██  ██ ██    ██ ██   ██    ██
// ██      ██ ███████ ██      ██  ██████  ██   ██    ██
//
// >>memory
_SOKOL_PRIVATE void _sfetch_clear(void* ptr, size_t size) {
    SOKOL_ASSERT(ptr && (size > 0));
    memset(ptr, 0, size);
}

_SOKOL_PRIVATE void* _sfetch_malloc_with_allocator(const sfetch_allocator_t* allocator, size_t size) {
    SOKOL_ASSERT(size > 0);
    void* ptr;
    if (allocator->alloc_fn) {
        ptr = allocator->alloc_fn(size, allocator->user_data);
    } else {
        ptr = malloc(size);
    }
    if (0 == ptr) {
        _SFETCH_PANIC(MALLOC_FAILED);
    }
    return ptr;
}

_SOKOL_PRIVATE void* _sfetch_malloc(size_t size) {
    return _sfetch_malloc_with_allocator(&_sfetch->desc.allocator, size);
}

_SOKOL_PRIVATE void* _sfetch_malloc_clear(size_t size) {
    void* ptr = _sfetch_malloc(size);
    _sfetch_clear(ptr, size);
    return ptr;
}

_SOKOL_PRIVATE void _sfetch_free(void* ptr) {
    if (_sfetch->desc.allocator.free_fn) {
        _sfetch->desc.allocator.free_fn(ptr, _sfetch->desc.allocator.user_data);
    } else {
        free(ptr);
    }
}

_SOKOL_PRIVATE _sfetch_t* _sfetch_ctx(void) {
    return _sfetch;
}

_SOKOL_PRIVATE void _sfetch_path_copy(_sfetch_path_t* dst, const char* src) {
    SOKOL_ASSERT(dst);
    if (src && (strlen(src) < SFETCH_MAX_PATH)) {
        #if defined(_MSC_VER)
        strncpy_s(dst->buf, SFETCH_MAX_PATH, src, (SFETCH_MAX_PATH-1));
        #else
        strncpy(dst->buf, src, SFETCH_MAX_PATH);
        #endif
        dst->buf[SFETCH_MAX_PATH-1] = 0;
    } else {
        _sfetch_clear(dst->buf, SFETCH_MAX_PATH);
    }
}

_SOKOL_PRIVATE _sfetch_path_t _sfetch_path_make(const char* str) {
    _sfetch_path_t res;
    _sfetch_path_copy(&res, str);
    return res;
}

// ███    ███ ███████ ███████ ███████  █████   ██████  ███████      ██████  ██    ██ ███████ ██    ██ ███████
// ████  ████ ██      ██      ██      ██   ██ ██       ██          ██    ██ ██    ██ ██      ██    ██ ██
// ██ ████ ██ █████   ███████ ███████ ███████ ██   ███ █████       ██    ██ ██    ██ █████   ██    ██ █████
// ██  ██  ██ ██           ██      ██ ██   ██ ██    ██ ██          ██ ▄▄ ██ ██    ██ ██      ██    ██ ██
// ██      ██ ███████ ███████ ███████ ██   ██  ██████  ███████      ██████   ██████  ███████  ██████  ███████
//                                                                     ▀▀
// >>message queue
_SOKOL_PRIVATE uint32_t _sfetch_ring_wrap(const _sfetch_ring_t* rb, uint32_t i) {
    return i % rb->num;
}

_SOKOL_PRIVATE void _sfetch_ring_discard(_sfetch_ring_t* rb) {
    SOKOL_ASSERT(rb);
    if (rb->buf) {
        _sfetch_free(rb->buf);
        rb->buf = 0;
    }
    rb->head = 0;
    rb->tail = 0;
    rb->num = 0;
}

_SOKOL_PRIVATE bool _sfetch_ring_init(_sfetch_ring_t* rb, uint32_t num_slots) {
    SOKOL_ASSERT(rb && (num_slots > 0));
    SOKOL_ASSERT(0 == rb->buf);
    rb->head = 0;
    rb->tail = 0;
    /* one slot reserved to detect full vs empty */
    rb->num = num_slots + 1;
    const size_t queue_size = rb->num * sizeof(sfetch_handle_t);
    rb->buf = (uint32_t*) _sfetch_malloc_clear(queue_size);
    if (rb->buf) {
        return true;
    } else {
        _sfetch_ring_discard(rb);
        return false;
    }
}

_SOKOL_PRIVATE bool _sfetch_ring_full(const _sfetch_ring_t* rb) {
    SOKOL_ASSERT(rb && rb->buf);
    return _sfetch_ring_wrap(rb, rb->head + 1) == rb->tail;
}

_SOKOL_PRIVATE bool _sfetch_ring_empty(const _sfetch_ring_t* rb) {
    SOKOL_ASSERT(rb && rb->buf);
    return rb->head == rb->tail;
}

_SOKOL_PRIVATE uint32_t _sfetch_ring_count(const _sfetch_ring_t* rb) {
    SOKOL_ASSERT(rb && rb->buf);
    uint32_t count;
    if (rb->head >= rb->tail) {
        count = rb->head - rb->tail;
    } else {
        count = (rb->head + rb->num) - rb->tail;
    }
    SOKOL_ASSERT(count < rb->num);
    return count;
}

_SOKOL_PRIVATE void _sfetch_ring_enqueue(_sfetch_ring_t* rb, uint32_t slot_id) {
    SOKOL_ASSERT(rb && rb->buf);
    SOKOL_ASSERT(!_sfetch_ring_full(rb));
    SOKOL_ASSERT(rb->head < rb->num);
    rb->buf[rb->head] = slot_id;
    rb->head = _sfetch_ring_wrap(rb, rb->head + 1);
}

_SOKOL_PRIVATE uint32_t _sfetch_ring_dequeue(_sfetch_ring_t* rb) {
    SOKOL_ASSERT(rb && rb->buf);
    SOKOL_ASSERT(!_sfetch_ring_empty(rb));
    SOKOL_ASSERT(rb->tail < rb->num);
    uint32_t slot_id = rb->buf[rb->tail];
    rb->tail = _sfetch_ring_wrap(rb, rb->tail + 1);
    return slot_id;
}

_SOKOL_PRIVATE uint32_t _sfetch_ring_peek(const _sfetch_ring_t* rb, uint32_t index) {
    SOKOL_ASSERT(rb && rb->buf);
    SOKOL_ASSERT(!_sfetch_ring_empty(rb));
    SOKOL_ASSERT(index < _sfetch_ring_count(rb));
    uint32_t rb_index = _sfetch_ring_wrap(rb, rb->tail + index);
    return rb->buf[rb_index];
}

// ██████  ███████  ██████  ██    ██ ███████ ███████ ████████     ██████   ██████   ██████  ██
// ██   ██ ██      ██    ██ ██    ██ ██      ██         ██        ██   ██ ██    ██ ██    ██ ██
// ██████  █████   ██    ██ ██    ██ █████   ███████    ██        ██████  ██    ██ ██    ██ ██
// ██   ██ ██      ██ ▄▄ ██ ██    ██ ██           ██    ██        ██      ██    ██ ██    ██ ██
// ██   ██ ███████  ██████   ██████  ███████ ███████    ██        ██       ██████   ██████  ███████
//                     ▀▀
// >>request pool
_SOKOL_PRIVATE uint32_t _sfetch_make_id(uint32_t index, uint32_t gen_ctr) {
    return (gen_ctr<<16) | (index & 0xFFFF);
}

_SOKOL_PRIVATE sfetch_handle_t _sfetch_make_handle(uint32_t slot_id) {
    sfetch_handle_t h;
    h.id = slot_id;
    return h;
}

_SOKOL_PRIVATE uint32_t _sfetch_slot_index(uint32_t slot_id) {
    return slot_id & 0xFFFF;
}

_SOKOL_PRIVATE void _sfetch_item_init(_sfetch_item_t* item, uint32_t slot_id, const sfetch_request_t* request) {
    SOKOL_ASSERT(item && (0 == item->handle.id));
    SOKOL_ASSERT(request && request->path);
    _sfetch_clear(item, sizeof(_sfetch_item_t));
    item->handle.id = slot_id;
    item->state = _SFETCH_STATE_INITIAL;
    item->channel = request->channel;
    item->chunk_size = request->chunk_size;
    item->lane = _SFETCH_INVALID_LANE;
    item->callback = request->callback;
    item->buffer = request->buffer;
    item->path = _sfetch_path_make(request->path);
    #if !_SFETCH_PLATFORM_EMSCRIPTEN
    item->thread.file_handle = _SFETCH_INVALID_FILE_HANDLE;
    #endif
    if (request->user_data.ptr &&
        (request->user_data.size > 0) &&
        (request->user_data.size <= (SFETCH_MAX_USERDATA_UINT64*8)))
    {
        item->user.user_data_size = request->user_data.size;
        memcpy(item->user.user_data, request->user_data.ptr, request->user_data.size);
    }
}

_SOKOL_PRIVATE void _sfetch_item_discard(_sfetch_item_t* item) {
    SOKOL_ASSERT(item && (0 != item->handle.id));
    _sfetch_clear(item, sizeof(_sfetch_item_t));
}

_SOKOL_PRIVATE void _sfetch_pool_discard(_sfetch_pool_t* pool) {
    SOKOL_ASSERT(pool);
    if (pool->free_slots) {
        _sfetch_free(pool->free_slots);
        pool->free_slots = 0;
    }
    if (pool->gen_ctrs) {
        _sfetch_free(pool->gen_ctrs);
        pool->gen_ctrs = 0;
    }
    if (pool->items) {
        _sfetch_free(pool->items);
        pool->items = 0;
    }
    pool->size = 0;
    pool->free_top = 0;
    pool->valid = false;
}

_SOKOL_PRIVATE bool _sfetch_pool_init(_sfetch_pool_t* pool, uint32_t num_items) {
    SOKOL_ASSERT(pool && (num_items > 0) && (num_items < ((1<<16)-1)));
    SOKOL_ASSERT(0 == pool->items);
    /* NOTE: item slot 0 is reserved for the special "invalid" item index 0*/
    pool->size = num_items + 1;
    pool->free_top = 0;
    const size_t items_size = pool->size * sizeof(_sfetch_item_t);
    pool->items = (_sfetch_item_t*) _sfetch_malloc_clear(items_size);
    /* generation counters indexable by pool slot index, slot 0 is reserved */
    const size_t gen_ctrs_size = sizeof(uint32_t) * pool->size;
    pool->gen_ctrs = (uint32_t*) _sfetch_malloc_clear(gen_ctrs_size);
    SOKOL_ASSERT(pool->gen_ctrs);
    /* NOTE: it's not a bug to only reserve num_items here */
    const size_t free_slots_size = num_items * sizeof(int);
    pool->free_slots = (uint32_t*) _sfetch_malloc_clear(free_slots_size);
    if (pool->items && pool->free_slots) {
        /* never allocate the 0-th item, this is the reserved 'invalid item' */
        for (uint32_t i = pool->size - 1; i >= 1; i--) {
            pool->free_slots[pool->free_top++] = i;
        }
        pool->valid = true;
    } else {
        /* allocation error */
        _sfetch_pool_discard(pool);
    }
    return pool->valid;
}

_SOKOL_PRIVATE uint32_t _sfetch_pool_item_alloc(_sfetch_pool_t* pool, const sfetch_request_t* request) {
    SOKOL_ASSERT(pool && pool->valid);
    if (pool->free_top > 0) {
        uint32_t slot_index = pool->free_slots[--pool->free_top];
        SOKOL_ASSERT((slot_index > 0) && (slot_index < pool->size));
        uint32_t slot_id = _sfetch_make_id(slot_index, ++pool->gen_ctrs[slot_index]);
        _sfetch_item_init(&pool->items[slot_index], slot_id, request);
        pool->items[slot_index].state = _SFETCH_STATE_ALLOCATED;
        return slot_id;
    } else {
        /* pool exhausted, return the 'invalid handle' */
        return _sfetch_make_id(0, 0);
    }
}

_SOKOL_PRIVATE void _sfetch_pool_item_free(_sfetch_pool_t* pool, uint32_t slot_id) {
    SOKOL_ASSERT(pool && pool->valid);
    uint32_t slot_index = _sfetch_slot_index(slot_id);
    SOKOL_ASSERT((slot_index > 0) && (slot_index < pool->size));
    SOKOL_ASSERT(pool->items[slot_index].handle.id == slot_id);
    #if defined(SOKOL_DEBUG)
    /* debug check against double-free */
    for (uint32_t i = 0; i < pool->free_top; i++) {
        SOKOL_ASSERT(pool->free_slots[i] != slot_index);
    }
    #endif
    _sfetch_item_discard(&pool->items[slot_index]);
    pool->free_slots[pool->free_top++] = slot_index;
    SOKOL_ASSERT(pool->free_top <= (pool->size - 1));
}

/* return pointer to item by handle without matching id check */
_SOKOL_PRIVATE _sfetch_item_t* _sfetch_pool_item_at(_sfetch_pool_t* pool, uint32_t slot_id) {
    SOKOL_ASSERT(pool && pool->valid);
    uint32_t slot_index = _sfetch_slot_index(slot_id);
    SOKOL_ASSERT((slot_index > 0) && (slot_index < pool->size));
    return &pool->items[slot_index];
}

/* return pointer to item by handle with matching id check */
_SOKOL_PRIVATE _sfetch_item_t* _sfetch_pool_item_lookup(_sfetch_pool_t* pool, uint32_t slot_id) {
    SOKOL_ASSERT(pool && pool->valid);
    if (0 != slot_id) {
        _sfetch_item_t* item = _sfetch_pool_item_at(pool, slot_id);
        if (item->handle.id == slot_id) {
            return item;
        }
    }
    return 0;
}

// ██████   ██████  ███████ ██ ██   ██
// ██   ██ ██    ██ ██      ██  ██ ██
// ██████  ██    ██ ███████ ██   ███
// ██      ██    ██      ██ ██  ██ ██
// ██       ██████  ███████ ██ ██   ██
//
// >>posix
#if _SFETCH_PLATFORM_POSIX
_SOKOL_PRIVATE _sfetch_file_handle_t _sfetch_file_open(const _sfetch_path_t* path) {
    return fopen(path->buf, "rb");
}

_SOKOL_PRIVATE void _sfetch_file_close(_sfetch_file_handle_t h) {
    fclose(h);
}

_SOKOL_PRIVATE bool _sfetch_file_handle_valid(_sfetch_file_handle_t h) {
    return h != _SFETCH_INVALID_FILE_HANDLE;
}

_SOKOL_PRIVATE uint32_t _sfetch_file_size(_sfetch_file_handle_t h) {
    fseek(h, 0, SEEK_END);
    return (uint32_t) ftell(h);
}

_SOKOL_PRIVATE bool _sfetch_file_read(_sfetch_file_handle_t h, uint32_t offset, uint32_t num_bytes, void* ptr) {
    fseek(h, (long)offset, SEEK_SET);
    return num_bytes == fread(ptr, 1, num_bytes, h);
}

_SOKOL_PRIVATE bool _sfetch_thread_init(_sfetch_thread_t* thread, _sfetch_thread_func_t thread_func, void* thread_arg) {
    SOKOL_ASSERT(thread && !thread->valid && !thread->stop_requested);

    pthread_mutexattr_t attr;
    pthread_mutexattr_init(&attr);
    pthread_mutex_init(&thread->incoming_mutex, &attr);
    pthread_mutexattr_destroy(&attr);

    pthread_mutexattr_init(&attr);
    pthread_mutex_init(&thread->outgoing_mutex, &attr);
    pthread_mutexattr_destroy(&attr);

    pthread_mutexattr_init(&attr);
    pthread_mutex_init(&thread->running_mutex, &attr);
    pthread_mutexattr_destroy(&attr);

    pthread_mutexattr_init(&attr);
    pthread_mutex_init(&thread->stop_mutex, &attr);
    pthread_mutexattr_destroy(&attr);

    pthread_condattr_t cond_attr;
    pthread_condattr_init(&cond_attr);
    pthread_cond_init(&thread->incoming_cond, &cond_attr);
    pthread_condattr_destroy(&cond_attr);

    /* FIXME: in debug mode, the threads should be named */
    pthread_mutex_lock(&thread->running_mutex);
    int res = pthread_create(&thread->thread, 0, thread_func, thread_arg);
    thread->valid = (0 == res);
    pthread_mutex_unlock(&thread->running_mutex);
    return thread->valid;
}

_SOKOL_PRIVATE void _sfetch_thread_request_stop(_sfetch_thread_t* thread) {
    pthread_mutex_lock(&thread->stop_mutex);
    thread->stop_requested = true;
    pthread_mutex_unlock(&thread->stop_mutex);
}

_SOKOL_PRIVATE bool _sfetch_thread_stop_requested(_sfetch_thread_t* thread) {
    pthread_mutex_lock(&thread->stop_mutex);
    bool stop_requested = thread->stop_requested;
    pthread_mutex_unlock(&thread->stop_mutex);
    return stop_requested;
}

_SOKOL_PRIVATE void _sfetch_thread_join(_sfetch_thread_t* thread) {
    SOKOL_ASSERT(thread);
    if (thread->valid) {
        pthread_mutex_lock(&thread->incoming_mutex);
        _sfetch_thread_request_stop(thread);
        pthread_cond_signal(&thread->incoming_cond);
        pthread_mutex_unlock(&thread->incoming_mutex);
        pthread_join(thread->thread, 0);
        thread->valid = false;
    }
    pthread_mutex_destroy(&thread->stop_mutex);
    pthread_mutex_destroy(&thread->running_mutex);
    pthread_mutex_destroy(&thread->incoming_mutex);
    pthread_mutex_destroy(&thread->outgoing_mutex);
    pthread_cond_destroy(&thread->incoming_cond);
}

/* called when the thread-func is entered, this blocks the thread func until
   the _sfetch_thread_t object is fully initialized
*/
_SOKOL_PRIVATE void _sfetch_thread_entered(_sfetch_thread_t* thread) {
    pthread_mutex_lock(&thread->running_mutex);
}

/* called by the thread-func right before it is left */
_SOKOL_PRIVATE void _sfetch_thread_leaving(_sfetch_thread_t* thread) {
    pthread_mutex_unlock(&thread->running_mutex);
}

_SOKOL_PRIVATE void _sfetch_thread_enqueue_incoming(_sfetch_thread_t* thread, _sfetch_ring_t* incoming, _sfetch_ring_t* src) {
    /* called from user thread */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(incoming && incoming->buf);
    SOKOL_ASSERT(src && src->buf);
    if (!_sfetch_ring_empty(src)) {
        pthread_mutex_lock(&thread->incoming_mutex);
        while (!_sfetch_ring_full(incoming) && !_sfetch_ring_empty(src)) {
            _sfetch_ring_enqueue(incoming, _sfetch_ring_dequeue(src));
        }
        pthread_cond_signal(&thread->incoming_cond);
        pthread_mutex_unlock(&thread->incoming_mutex);
    }
}

_SOKOL_PRIVATE uint32_t _sfetch_thread_dequeue_incoming(_sfetch_thread_t* thread, _sfetch_ring_t* incoming) {
    /* called from thread function */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(incoming && incoming->buf);
    pthread_mutex_lock(&thread->incoming_mutex);
    while (_sfetch_ring_empty(incoming) && !thread->stop_requested) {
        pthread_cond_wait(&thread->incoming_cond, &thread->incoming_mutex);
    }
    uint32_t item = 0;
    if (!thread->stop_requested) {
        item = _sfetch_ring_dequeue(incoming);
    }
    pthread_mutex_unlock(&thread->incoming_mutex);
    return item;
}

_SOKOL_PRIVATE bool _sfetch_thread_enqueue_outgoing(_sfetch_thread_t* thread, _sfetch_ring_t* outgoing, uint32_t item) {
    /* called from thread function */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(outgoing && outgoing->buf);
    SOKOL_ASSERT(0 != item);
    pthread_mutex_lock(&thread->outgoing_mutex);
    bool result = false;
    if (!_sfetch_ring_full(outgoing)) {
        _sfetch_ring_enqueue(outgoing, item);
    }
    pthread_mutex_unlock(&thread->outgoing_mutex);
    return result;
}

_SOKOL_PRIVATE void _sfetch_thread_dequeue_outgoing(_sfetch_thread_t* thread, _sfetch_ring_t* outgoing, _sfetch_ring_t* dst) {
    /* called from user thread */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(outgoing && outgoing->buf);
    SOKOL_ASSERT(dst && dst->buf);
    pthread_mutex_lock(&thread->outgoing_mutex);
    while (!_sfetch_ring_full(dst) && !_sfetch_ring_empty(outgoing)) {
        _sfetch_ring_enqueue(dst, _sfetch_ring_dequeue(outgoing));
    }
    pthread_mutex_unlock(&thread->outgoing_mutex);
}
#endif /* _SFETCH_PLATFORM_POSIX */

// ██     ██ ██ ███    ██ ██████   ██████  ██     ██ ███████
// ██     ██ ██ ████   ██ ██   ██ ██    ██ ██     ██ ██
// ██  █  ██ ██ ██ ██  ██ ██   ██ ██    ██ ██  █  ██ ███████
// ██ ███ ██ ██ ██  ██ ██ ██   ██ ██    ██ ██ ███ ██      ██
//  ███ ███  ██ ██   ████ ██████   ██████   ███ ███  ███████
//
// >>windows
#if _SFETCH_PLATFORM_WINDOWS
_SOKOL_PRIVATE bool _sfetch_win32_utf8_to_wide(const char* src, wchar_t* dst, int dst_num_bytes) {
    SOKOL_ASSERT(src && dst && (dst_num_bytes > 1));
    _sfetch_clear(dst, (size_t)dst_num_bytes);
    const int dst_chars = dst_num_bytes / (int)sizeof(wchar_t);
    const int dst_needed = MultiByteToWideChar(CP_UTF8, 0, src, -1, 0, 0);
    if ((dst_needed > 0) && (dst_needed < dst_chars)) {
        MultiByteToWideChar(CP_UTF8, 0, src, -1, dst, dst_chars);
        return true;
    } else {
        /* input string doesn't fit into destination buffer */
        return false;
    }
}

_SOKOL_PRIVATE _sfetch_file_handle_t _sfetch_file_open(const _sfetch_path_t* path) {
    wchar_t w_path[SFETCH_MAX_PATH];
    if (!_sfetch_win32_utf8_to_wide(path->buf, w_path, sizeof(w_path))) {
        _SFETCH_ERROR(FILE_PATH_UTF8_DECODING_FAILED);
        return 0;
    }
    _sfetch_file_handle_t h = CreateFileW(
        w_path,                 /* lpFileName */
        GENERIC_READ,           /* dwDesiredAccess */
        FILE_SHARE_READ,        /* dwShareMode */
        NULL,                   /* lpSecurityAttributes */
        OPEN_EXISTING,          /* dwCreationDisposition */
        FILE_ATTRIBUTE_NORMAL|FILE_FLAG_SEQUENTIAL_SCAN,    /* dwFlagsAndAttributes */
        NULL);                  /* hTemplateFile */
    return h;
}

_SOKOL_PRIVATE void _sfetch_file_close(_sfetch_file_handle_t h) {
    CloseHandle(h);
}

_SOKOL_PRIVATE bool _sfetch_file_handle_valid(_sfetch_file_handle_t h) {
    return h != _SFETCH_INVALID_FILE_HANDLE;
}

_SOKOL_PRIVATE uint32_t _sfetch_file_size(_sfetch_file_handle_t h) {
    return GetFileSize(h, NULL);
}

_SOKOL_PRIVATE bool _sfetch_file_read(_sfetch_file_handle_t h, uint32_t offset, uint32_t num_bytes, void* ptr) {
    LARGE_INTEGER offset_li;
    offset_li.QuadPart = offset;
    BOOL seek_res = SetFilePointerEx(h, offset_li, NULL, FILE_BEGIN);
    if (seek_res) {
        DWORD bytes_read = 0;
        BOOL read_res = ReadFile(h, ptr, (DWORD)num_bytes, &bytes_read, NULL);
        return read_res && (bytes_read == num_bytes);
    } else {
        return false;
    }
}

_SOKOL_PRIVATE bool _sfetch_thread_init(_sfetch_thread_t* thread, _sfetch_thread_func_t thread_func, void* thread_arg) {
    SOKOL_ASSERT(thread && !thread->valid && !thread->stop_requested);

    thread->incoming_event = CreateEventA(NULL, FALSE, FALSE, NULL);
    SOKOL_ASSERT(NULL != thread->incoming_event);
    InitializeCriticalSection(&thread->incoming_critsec);
    InitializeCriticalSection(&thread->outgoing_critsec);
    InitializeCriticalSection(&thread->running_critsec);
    InitializeCriticalSection(&thread->stop_critsec);

    EnterCriticalSection(&thread->running_critsec);
    const SIZE_T stack_size = 512 * 1024;
    thread->thread = CreateThread(NULL, stack_size, thread_func, thread_arg, 0, NULL);
    thread->valid = (NULL != thread->thread);
    LeaveCriticalSection(&thread->running_critsec);
    return thread->valid;
}

_SOKOL_PRIVATE void _sfetch_thread_request_stop(_sfetch_thread_t* thread) {
    EnterCriticalSection(&thread->stop_critsec);
    thread->stop_requested = true;
    LeaveCriticalSection(&thread->stop_critsec);
}

_SOKOL_PRIVATE bool _sfetch_thread_stop_requested(_sfetch_thread_t* thread) {
    EnterCriticalSection(&thread->stop_critsec);
    bool stop_requested = thread->stop_requested;
    LeaveCriticalSection(&thread->stop_critsec);
    return stop_requested;
}

_SOKOL_PRIVATE void _sfetch_thread_join(_sfetch_thread_t* thread) {
    if (thread->valid) {
        EnterCriticalSection(&thread->incoming_critsec);
        _sfetch_thread_request_stop(thread);
        BOOL set_event_res = SetEvent(thread->incoming_event);
        _SOKOL_UNUSED(set_event_res);
        SOKOL_ASSERT(set_event_res);
        LeaveCriticalSection(&thread->incoming_critsec);
        WaitForSingleObject(thread->thread, INFINITE);
        CloseHandle(thread->thread);
        thread->valid = false;
    }
    CloseHandle(thread->incoming_event);
    DeleteCriticalSection(&thread->stop_critsec);
    DeleteCriticalSection(&thread->running_critsec);
    DeleteCriticalSection(&thread->outgoing_critsec);
    DeleteCriticalSection(&thread->incoming_critsec);
}

_SOKOL_PRIVATE void _sfetch_thread_entered(_sfetch_thread_t* thread) {
    EnterCriticalSection(&thread->running_critsec);
}

/* called by the thread-func right before it is left */
_SOKOL_PRIVATE void _sfetch_thread_leaving(_sfetch_thread_t* thread) {
    LeaveCriticalSection(&thread->running_critsec);
}

_SOKOL_PRIVATE void _sfetch_thread_enqueue_incoming(_sfetch_thread_t* thread, _sfetch_ring_t* incoming, _sfetch_ring_t* src) {
    /* called from user thread */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(incoming && incoming->buf);
    SOKOL_ASSERT(src && src->buf);
    if (!_sfetch_ring_empty(src)) {
        EnterCriticalSection(&thread->incoming_critsec);
        while (!_sfetch_ring_full(incoming) && !_sfetch_ring_empty(src)) {
            _sfetch_ring_enqueue(incoming, _sfetch_ring_dequeue(src));
        }
        LeaveCriticalSection(&thread->incoming_critsec);
        BOOL set_event_res = SetEvent(thread->incoming_event);
        _SOKOL_UNUSED(set_event_res);
        SOKOL_ASSERT(set_event_res);
    }
}

_SOKOL_PRIVATE uint32_t _sfetch_thread_dequeue_incoming(_sfetch_thread_t* thread, _sfetch_ring_t* incoming) {
    /* called from thread function */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(incoming && incoming->buf);
    EnterCriticalSection(&thread->incoming_critsec);
    while (_sfetch_ring_empty(incoming) && !thread->stop_requested) {
        LeaveCriticalSection(&thread->incoming_critsec);
        WaitForSingleObject(thread->incoming_event, INFINITE);
        EnterCriticalSection(&thread->incoming_critsec);
    }
    uint32_t item = 0;
    if (!thread->stop_requested) {
        item = _sfetch_ring_dequeue(incoming);
    }
    LeaveCriticalSection(&thread->incoming_critsec);
    return item;
}

_SOKOL_PRIVATE bool _sfetch_thread_enqueue_outgoing(_sfetch_thread_t* thread, _sfetch_ring_t* outgoing, uint32_t item) {
    /* called from thread function */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(outgoing && outgoing->buf);
    EnterCriticalSection(&thread->outgoing_critsec);
    bool result = false;
    if (!_sfetch_ring_full(outgoing)) {
        _sfetch_ring_enqueue(outgoing, item);
    }
    LeaveCriticalSection(&thread->outgoing_critsec);
    return result;
}

_SOKOL_PRIVATE void _sfetch_thread_dequeue_outgoing(_sfetch_thread_t* thread, _sfetch_ring_t* outgoing, _sfetch_ring_t* dst) {
    /* called from user thread */
    SOKOL_ASSERT(thread && thread->valid);
    SOKOL_ASSERT(outgoing && outgoing->buf);
    SOKOL_ASSERT(dst && dst->buf);
    EnterCriticalSection(&thread->outgoing_critsec);
    while (!_sfetch_ring_full(dst) && !_sfetch_ring_empty(outgoing)) {
        _sfetch_ring_enqueue(dst, _sfetch_ring_dequeue(outgoing));
    }
    LeaveCriticalSection(&thread->outgoing_critsec);
}
#endif /* _SFETCH_PLATFORM_WINDOWS */

//  ██████ ██   ██  █████  ███    ██ ███    ██ ███████ ██      ███████
// ██      ██   ██ ██   ██ ████   ██ ████   ██ ██      ██      ██
// ██      ███████ ███████ ██ ██  ██ ██ ██  ██ █████   ██      ███████
// ██      ██   ██ ██   ██ ██  ██ ██ ██  ██ ██ ██      ██           ██
//  ██████ ██   ██ ██   ██ ██   ████ ██   ████ ███████ ███████ ███████
//
// >>channels

/* per-channel request handler for native platforms accessing the local filesystem */
#if _SFETCH_HAS_THREADS
_SOKOL_PRIVATE void _sfetch_request_handler(_sfetch_t* ctx, uint32_t slot_id) {
    _sfetch_state_t state;
    _sfetch_path_t* path;
    _sfetch_item_thread_t* thread;
    sfetch_range_t* buffer;
    uint32_t chunk_size;
    {
        _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
        if (!item) {
            return;
        }
        state = item->state;
        SOKOL_ASSERT((state == _SFETCH_STATE_FETCHING) ||
                     (state == _SFETCH_STATE_PAUSED) ||
                     (state == _SFETCH_STATE_FAILED));
        path = &item->path;
        thread = &item->thread;
        buffer = &item->buffer;
        chunk_size = item->chunk_size;
    }
    if (thread->failed) {
        return;
    }
    if (state == _SFETCH_STATE_FETCHING) {
        if ((buffer->ptr == 0) || (buffer->size == 0)) {
            thread->error_code = SFETCH_ERROR_NO_BUFFER;
            thread->failed = true;
        } else {
            /* open file if not happened yet */
            if (!_sfetch_file_handle_valid(thread->file_handle)) {
                SOKOL_ASSERT(path->buf[0]);
                SOKOL_ASSERT(thread->fetched_offset == 0);
                SOKOL_ASSERT(thread->fetched_size == 0);
                thread->file_handle = _sfetch_file_open(path);
                if (_sfetch_file_handle_valid(thread->file_handle)) {
                    thread->content_size = _sfetch_file_size(thread->file_handle);
                } else {
                    thread->error_code = SFETCH_ERROR_FILE_NOT_FOUND;
                    thread->failed = true;
                }
            }
            if (!thread->failed) {
                uint32_t read_offset = 0;
                uint32_t bytes_to_read = 0;
                if (chunk_size == 0) {
                    /* load entire file */
                    if (thread->content_size <= buffer->size) {
                        bytes_to_read = thread->content_size;
                        read_offset = 0;
                    } else {
                        /* provided buffer to small to fit entire file */
                        thread->error_code = SFETCH_ERROR_BUFFER_TOO_SMALL;
                        thread->failed = true;
                    }
                } else {
                    if (chunk_size <= buffer->size) {
                        bytes_to_read = chunk_size;
                        read_offset = thread->fetched_offset;
                        if ((read_offset + bytes_to_read) > thread->content_size) {
                            bytes_to_read = thread->content_size - read_offset;
                        }
                    } else {
                        /* provided buffer to small to fit next chunk */
                        thread->error_code = SFETCH_ERROR_BUFFER_TOO_SMALL;
                        thread->failed = true;
                    }
                }
                if (!thread->failed) {
                    if (_sfetch_file_read(thread->file_handle, read_offset, bytes_to_read, (void*)buffer->ptr)) {
                        thread->fetched_size = bytes_to_read;
                        thread->fetched_offset += bytes_to_read;
                    } else {
                        thread->error_code = SFETCH_ERROR_UNEXPECTED_EOF;
                        thread->failed = true;
                    }
                }
            }
        }
        SOKOL_ASSERT(thread->fetched_offset <= thread->content_size);
        if (thread->failed || (thread->fetched_offset == thread->content_size)) {
            if (_sfetch_file_handle_valid(thread->file_handle)) {
                _sfetch_file_close(thread->file_handle);
                thread->file_handle = _SFETCH_INVALID_FILE_HANDLE;
            }
            thread->finished = true;
        }
    }
    /* ignore items in PAUSED or FAILED state */
}

#if _SFETCH_PLATFORM_WINDOWS
_SOKOL_PRIVATE DWORD WINAPI _sfetch_channel_thread_func(LPVOID arg) {
#else
_SOKOL_PRIVATE void* _sfetch_channel_thread_func(void* arg) {
#endif
    _sfetch_channel_t* chn = (_sfetch_channel_t*) arg;
    _sfetch_thread_entered(&chn->thread);
    while (!_sfetch_thread_stop_requested(&chn->thread)) {
        /* block until work arrives */
        uint32_t slot_id = _sfetch_thread_dequeue_incoming(&chn->thread, &chn->thread_incoming);
        /* slot_id will be invalid if the thread was woken up to join */
        if (!_sfetch_thread_stop_requested(&chn->thread)) {
            SOKOL_ASSERT(0 != slot_id);
            chn->request_handler(chn->ctx, slot_id);
            SOKOL_ASSERT(!_sfetch_ring_full(&chn->thread_outgoing));
            _sfetch_thread_enqueue_outgoing(&chn->thread, &chn->thread_outgoing, slot_id);
        }
    }
    _sfetch_thread_leaving(&chn->thread);
    return 0;
}
#endif /* _SFETCH_HAS_THREADS */

#if _SFETCH_PLATFORM_EMSCRIPTEN
EM_JS(void, sfetch_js_send_head_request, (uint32_t slot_id, const char* path_cstr), {
    const path_str = UTF8ToString(path_cstr);
    fetch(path_str, { method: 'HEAD' }).then((response) => {
        if (response.ok) {
            const content_length = response.headers.get('Content-Length');
            if (content_length === null) {
                console.warn(`sokol_fetch.h: HEAD ${path_str} response has no Content-Length`);
                __sfetch_emsc_failed_other(slot_id);
            } else {
                __sfetch_emsc_head_response(slot_id, Number(content_length));
            }
        } else {
            __sfetch_emsc_failed_http_status(slot_id, response.status);
        }
    }).catch((err) => {
        console.error(`sokol_fetch.h: HEAD ${path_str} failed with: `, err);
        __sfetch_emsc_failed_other(slot_id);
    });
})

/* if bytes_to_read != 0, a range-request will be sent, otherwise a normal request */
EM_JS(void, sfetch_js_send_get_request, (uint32_t slot_id, const char* path_cstr, uint32_t offset, uint32_t bytes_to_read, void* buf_ptr, uint32_t buf_size), {
    const path_str = UTF8ToString(path_cstr);
    const headers = new Headers();
    const range_request = bytes_to_read > 0;
    if (range_request) {
        headers.append('Range', `bytes=${offset}-${offset+bytes_to_read-1}`);
    }
    fetch(path_str, { method: 'GET', headers }).then((response) => {
        if (response.ok) {
            response.arrayBuffer().then((data) => {
                const u8_data = new Uint8Array(data);
                if (u8_data.length <= buf_size) {
                    HEAPU8.set(u8_data, buf_ptr);
                    __sfetch_emsc_get_response(slot_id, bytes_to_read, u8_data.length);
                } else {
                    __sfetch_emsc_failed_buffer_too_small(slot_id);
                }
            }).catch((err) => {
                console.error(`sokol_fetch.h: GET ${path_str} failed with: `, err);
                __sfetch_emsc_failed_other(slot_id);
            });
        } else {
            __sfetch_emsc_failed_http_status(slot_id, response.status);
        }
    }).catch((err) => {
        console.error(`sokol_fetch.h: GET ${path_str} failed with: `, err);
        __sfetch_emsc_failed_other(slot_id);
    });
})

/*=== emscripten specific C helper functions =================================*/
#ifdef __cplusplus
extern "C" {
#endif
void _sfetch_emsc_send_get_request(uint32_t slot_id, _sfetch_item_t* item) {
    if ((item->buffer.ptr == 0) || (item->buffer.size == 0)) {
        item->thread.error_code = SFETCH_ERROR_NO_BUFFER;
        item->thread.failed = true;
    } else {
        uint32_t offset = 0;
        uint32_t bytes_to_read = 0;
        if (item->chunk_size > 0) {
            /* send HTTP range request */
            SOKOL_ASSERT(item->thread.content_size > 0);
            SOKOL_ASSERT(item->thread.http_range_offset < item->thread.content_size);
            bytes_to_read = item->thread.content_size - item->thread.http_range_offset;
            if (bytes_to_read > item->chunk_size) {
                bytes_to_read = item->chunk_size;
            }
            SOKOL_ASSERT(bytes_to_read > 0);
            offset = item->thread.http_range_offset;
        }
        sfetch_js_send_get_request(slot_id, item->path.buf, offset, bytes_to_read, (void*)item->buffer.ptr, item->buffer.size);
    }
}

/* called by JS when an initial HEAD request finished successfully (only when streaming chunks) */
EMSCRIPTEN_KEEPALIVE void _sfetch_emsc_head_response(uint32_t slot_id, uint32_t content_length) {
    _sfetch_t* ctx = _sfetch_ctx();
    if (ctx && ctx->valid) {
        _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
        if (item) {
            SOKOL_ASSERT(item->buffer.ptr && (item->buffer.size > 0));
            item->thread.content_size = content_length;
            _sfetch_emsc_send_get_request(slot_id, item);
        }
    }
}

/* called by JS when a followup GET request finished successfully */
EMSCRIPTEN_KEEPALIVE void _sfetch_emsc_get_response(uint32_t slot_id, uint32_t range_fetched_size, uint32_t content_fetched_size) {
    _sfetch_t* ctx = _sfetch_ctx();
    if (ctx && ctx->valid) {
        _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
        if (item) {
            item->thread.fetched_size = content_fetched_size;
            item->thread.fetched_offset += content_fetched_size;
            item->thread.http_range_offset += range_fetched_size;
            if (item->chunk_size == 0) {
                item->thread.finished = true;
            } else if (item->thread.http_range_offset >= item->thread.content_size) {
                item->thread.finished = true;
            }
            _sfetch_ring_enqueue(&ctx->chn[item->channel].user_outgoing, slot_id);
        }
    }
}

/* called by JS when an error occurred */
EMSCRIPTEN_KEEPALIVE void _sfetch_emsc_failed_http_status(uint32_t slot_id, uint32_t http_status) {
    _sfetch_t* ctx = _sfetch_ctx();
    if (ctx && ctx->valid) {
        _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
        if (item) {
            if (http_status == 404) {
                item->thread.error_code = SFETCH_ERROR_FILE_NOT_FOUND;
            } else {
                item->thread.error_code = SFETCH_ERROR_INVALID_HTTP_STATUS;
            }
            item->thread.failed = true;
            item->thread.finished = true;
            _sfetch_ring_enqueue(&ctx->chn[item->channel].user_outgoing, slot_id);
        }
    }
}

EMSCRIPTEN_KEEPALIVE void _sfetch_emsc_failed_buffer_too_small(uint32_t slot_id) {
    _sfetch_t* ctx = _sfetch_ctx();
    if (ctx && ctx->valid) {
        _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
        if (item) {
            item->thread.error_code = SFETCH_ERROR_BUFFER_TOO_SMALL;
            item->thread.failed = true;
            item->thread.finished = true;
            _sfetch_ring_enqueue(&ctx->chn[item->channel].user_outgoing, slot_id);
        }
    }
}

EMSCRIPTEN_KEEPALIVE void _sfetch_emsc_failed_other(uint32_t slot_id) {
    _sfetch_t* ctx = _sfetch_ctx();
    if (ctx && ctx->valid) {
        _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
        if (item) {
            item->thread.error_code = SFETCH_ERROR_JS_OTHER;
            item->thread.failed = true;
            item->thread.finished = true;
            _sfetch_ring_enqueue(&ctx->chn[item->channel].user_outgoing, slot_id);
        }
    }
}

#ifdef __cplusplus
} /* extern "C" */
#endif

_SOKOL_PRIVATE void _sfetch_request_handler(_sfetch_t* ctx, uint32_t slot_id) {
    _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, slot_id);
    if (!item) {
        return;
    }
    if (item->state == _SFETCH_STATE_FETCHING) {
        if ((item->chunk_size > 0) && (item->thread.content_size == 0)) {
            /* if streaming download is requested, and the content-length isn't known
               yet, need to send a HEAD request first
             */
            sfetch_js_send_head_request(slot_id, item->path.buf);
        } else {
            /* otherwise, this is either a request to load the entire file, or
               to load the next streaming chunk
             */
            _sfetch_emsc_send_get_request(slot_id, item);
        }
    } else {
        /* just move all other items (e.g. paused or cancelled)
           into the outgoing queue, so they won't get lost
        */
        _sfetch_ring_enqueue(&ctx->chn[item->channel].user_outgoing, slot_id);
    }
    if (item->thread.failed) {
        item->thread.finished = true;
    }
}
#endif /* _SFETCH_PLATFORM_EMSCRIPTEN */

_SOKOL_PRIVATE void _sfetch_channel_discard(_sfetch_channel_t* chn) {
    SOKOL_ASSERT(chn);
    #if _SFETCH_HAS_THREADS
        if (chn->valid) {
            _sfetch_thread_join(&chn->thread);
        }
        _sfetch_ring_discard(&chn->thread_incoming);
        _sfetch_ring_discard(&chn->thread_outgoing);
    #endif
    _sfetch_ring_discard(&chn->free_lanes);
    _sfetch_ring_discard(&chn->user_sent);
    _sfetch_ring_discard(&chn->user_incoming);
    _sfetch_ring_discard(&chn->user_outgoing);
    _sfetch_ring_discard(&chn->free_lanes);
    chn->valid = false;
}

_SOKOL_PRIVATE bool _sfetch_channel_init(_sfetch_channel_t* chn, _sfetch_t* ctx, uint32_t num_items, uint32_t num_lanes, void (*request_handler)(_sfetch_t* ctx, uint32_t)) {
    SOKOL_ASSERT(chn && (num_items > 0) && request_handler);
    SOKOL_ASSERT(!chn->valid);
    bool valid = true;
    chn->request_handler = request_handler;
    chn->ctx = ctx;
    valid &= _sfetch_ring_init(&chn->free_lanes, num_lanes);
    for (uint32_t lane = 0; lane < num_lanes; lane++) {
        _sfetch_ring_enqueue(&chn->free_lanes, lane);
    }
    valid &= _sfetch_ring_init(&chn->user_sent, num_items);
    valid &= _sfetch_ring_init(&chn->user_incoming, num_lanes);
    valid &= _sfetch_ring_init(&chn->user_outgoing, num_lanes);
    #if _SFETCH_HAS_THREADS
        valid &= _sfetch_ring_init(&chn->thread_incoming, num_lanes);
        valid &= _sfetch_ring_init(&chn->thread_outgoing, num_lanes);
    #endif
    if (valid) {
        chn->valid = true;
        #if _SFETCH_HAS_THREADS
        _sfetch_thread_init(&chn->thread, _sfetch_channel_thread_func, chn);
        #endif
        return true;
    } else {
        _sfetch_channel_discard(chn);
        return false;
    }
}

/* put a request into the channels sent-queue, this is where all new requests
   are stored until a lane becomes free.
*/
_SOKOL_PRIVATE bool _sfetch_channel_send(_sfetch_channel_t* chn, uint32_t slot_id) {
    SOKOL_ASSERT(chn && chn->valid);
    if (!_sfetch_ring_full(&chn->user_sent)) {
        _sfetch_ring_enqueue(&chn->user_sent, slot_id);
        return true;
    } else {
        _SFETCH_ERROR(SEND_QUEUE_FULL);
        return false;
    }
}

_SOKOL_PRIVATE void _sfetch_invoke_response_callback(_sfetch_item_t* item) {
    sfetch_response_t response;
    _sfetch_clear(&response, sizeof(response));
    response.handle = item->handle;
    response.dispatched = (item->state == _SFETCH_STATE_DISPATCHED);
    response.fetched = (item->state == _SFETCH_STATE_FETCHED);
    response.paused = (item->state == _SFETCH_STATE_PAUSED);
    response.finished = item->user.finished;
    response.failed = (item->state == _SFETCH_STATE_FAILED);
    response.cancelled = item->user.cancel;
    response.error_code = item->user.error_code;
    response.channel = item->channel;
    response.lane = item->lane;
    response.path = item->path.buf;
    response.user_data = item->user.user_data;
    response.data_offset = item->user.fetched_offset - item->user.fetched_size;
    response.data.ptr = item->buffer.ptr;
    response.data.size = item->user.fetched_size;
    response.buffer = item->buffer;
    item->callback(&response);
}

_SOKOL_PRIVATE void _sfetch_cancel_item(_sfetch_item_t* item) {
    item->state = _SFETCH_STATE_FAILED;
    item->user.finished = true;
    item->user.error_code = SFETCH_ERROR_CANCELLED;
}

/* per-frame channel stuff: move requests in and out of the IO threads, call response callbacks */
_SOKOL_PRIVATE void _sfetch_channel_dowork(_sfetch_channel_t* chn, _sfetch_pool_t* pool) {

    /* move items from sent- to incoming-queue permitting free lanes */
    const uint32_t num_sent = _sfetch_ring_count(&chn->user_sent);
    const uint32_t avail_lanes = _sfetch_ring_count(&chn->free_lanes);
    const uint32_t num_move = (num_sent < avail_lanes) ? num_sent : avail_lanes;
    for (uint32_t i = 0; i < num_move; i++) {
        const uint32_t slot_id = _sfetch_ring_dequeue(&chn->user_sent);
        _sfetch_item_t* item = _sfetch_pool_item_lookup(pool, slot_id);
        SOKOL_ASSERT(item);
        SOKOL_ASSERT(item->state == _SFETCH_STATE_ALLOCATED);
        // if the item was cancelled early, kick it out immediately
        if (item->user.cancel) {
            _sfetch_cancel_item(item);
            _sfetch_invoke_response_callback(item);
            _sfetch_pool_item_free(pool, slot_id);
            continue;
        }
        item->state = _SFETCH_STATE_DISPATCHED;
        item->lane = _sfetch_ring_dequeue(&chn->free_lanes);
        // if no buffer provided yet, invoke response callback to do so
        if (0 == item->buffer.ptr) {
            _sfetch_invoke_response_callback(item);
        }
        _sfetch_ring_enqueue(&chn->user_incoming, slot_id);
    }

    /* prepare incoming items for being moved into the IO thread */
    const uint32_t num_incoming = _sfetch_ring_count(&chn->user_incoming);
    for (uint32_t i = 0; i < num_incoming; i++) {
        const uint32_t slot_id = _sfetch_ring_peek(&chn->user_incoming, i);
        _sfetch_item_t* item = _sfetch_pool_item_lookup(pool, slot_id);
        SOKOL_ASSERT(item);
        SOKOL_ASSERT(item->state != _SFETCH_STATE_INITIAL);
        SOKOL_ASSERT(item->state != _SFETCH_STATE_FETCHING);
        /* transfer input params from user- to thread-data */
        if (item->user.pause) {
            item->state = _SFETCH_STATE_PAUSED;
            item->user.pause = false;
        }
        if (item->user.cont) {
            if (item->state == _SFETCH_STATE_PAUSED) {
                item->state = _SFETCH_STATE_FETCHED;
            }
            item->user.cont = false;
        }
        if (item->user.cancel) {
            _sfetch_cancel_item(item);
        }
        switch (item->state) {
            case _SFETCH_STATE_DISPATCHED:
            case _SFETCH_STATE_FETCHED:
                item->state = _SFETCH_STATE_FETCHING;
                break;
            default: break;
        }
    }

    #if _SFETCH_HAS_THREADS
        /* move new items into the IO threads and processed items out of IO threads */
        _sfetch_thread_enqueue_incoming(&chn->thread, &chn->thread_incoming, &chn->user_incoming);
        _sfetch_thread_dequeue_outgoing(&chn->thread, &chn->thread_outgoing, &chn->user_outgoing);
    #else
        /* without threading just directly dequeue items from the user_incoming queue and
           call the request handler, the user_outgoing queue will be filled as the
           asynchronous HTTP requests sent by the request handler are completed
        */
        while (!_sfetch_ring_empty(&chn->user_incoming)) {
            uint32_t slot_id = _sfetch_ring_dequeue(&chn->user_incoming);
            _sfetch_request_handler(chn->ctx, slot_id);
        }
    #endif

    /* drain the outgoing queue, prepare items for invoking the response
       callback, and finally call the response callback, free finished items
    */
    while (!_sfetch_ring_empty(&chn->user_outgoing)) {
        const uint32_t slot_id = _sfetch_ring_dequeue(&chn->user_outgoing);
        SOKOL_ASSERT(slot_id);
        _sfetch_item_t* item = _sfetch_pool_item_lookup(pool, slot_id);
        SOKOL_ASSERT(item && item->callback);
        SOKOL_ASSERT(item->state != _SFETCH_STATE_INITIAL);
        SOKOL_ASSERT(item->state != _SFETCH_STATE_ALLOCATED);
        SOKOL_ASSERT(item->state != _SFETCH_STATE_DISPATCHED);
        SOKOL_ASSERT(item->state != _SFETCH_STATE_FETCHED);
        /* transfer output params from thread- to user-data */
        item->user.fetched_offset = item->thread.fetched_offset;
        item->user.fetched_size = item->thread.fetched_size;
        if (item->user.cancel) {
            _sfetch_cancel_item(item);
        } else {
            item->user.error_code = item->thread.error_code;
        }
        if (item->thread.finished) {
            item->user.finished = true;
        }
        /* state transition */
        if (item->thread.failed) {
            item->state = _SFETCH_STATE_FAILED;
        } else if (item->state == _SFETCH_STATE_FETCHING) {
            item->state = _SFETCH_STATE_FETCHED;
        }
        _sfetch_invoke_response_callback(item);

        /* when the request is finished, free the lane for another request,
           otherwise feed it back into the incoming queue
        */
        if (item->user.finished) {
            _sfetch_ring_enqueue(&chn->free_lanes, item->lane);
            _sfetch_pool_item_free(pool, slot_id);
        } else {
            _sfetch_ring_enqueue(&chn->user_incoming, slot_id);
        }
    }
}

_SOKOL_PRIVATE bool _sfetch_validate_request(_sfetch_t* ctx, const sfetch_request_t* req) {
    if (req->channel >= ctx->desc.num_channels) {
        _SFETCH_ERROR(REQUEST_CHANNEL_INDEX_TOO_BIG);
        return false;
    }
    if (!req->path) {
        _SFETCH_ERROR(REQUEST_PATH_IS_NULL);
        return false;
    }
    if (strlen(req->path) >= (SFETCH_MAX_PATH-1)) {
        _SFETCH_ERROR(REQUEST_PATH_TOO_LONG);
        return false;
    }
    if (!req->callback) {
        _SFETCH_ERROR(REQUEST_CALLBACK_MISSING);
        return false;
    }
    if (req->chunk_size > req->buffer.size) {
        _SFETCH_ERROR(REQUEST_CHUNK_SIZE_GREATER_BUFFER_SIZE);
        return false;
    }
    if (req->user_data.ptr && (req->user_data.size == 0)) {
        _SFETCH_ERROR(REQUEST_USERDATA_PTR_IS_SET_BUT_USERDATA_SIZE_IS_NULL);
        return false;
    }
    if (!req->user_data.ptr && (req->user_data.size > 0)) {
        _SFETCH_ERROR(REQUEST_USERDATA_PTR_IS_NULL_BUT_USERDATA_SIZE_IS_NOT);
        return false;
    }
    if (req->user_data.size > SFETCH_MAX_USERDATA_UINT64 * sizeof(uint64_t)) {
        _SFETCH_ERROR(REQUEST_USERDATA_SIZE_TOO_BIG);
        return false;
    }
    return true;
}

_SOKOL_PRIVATE sfetch_desc_t _sfetch_desc_defaults(const sfetch_desc_t* desc) {
    SOKOL_ASSERT((desc->allocator.alloc_fn && desc->allocator.free_fn) || (!desc->allocator.alloc_fn && !desc->allocator.free_fn));
    sfetch_desc_t res = *desc;
    res.max_requests = _sfetch_def(desc->max_requests, 128);
    res.num_channels = _sfetch_def(desc->num_channels, 1);
    res.num_lanes = _sfetch_def(desc->num_lanes, 1);
    return res;
}

// ██████  ██    ██ ██████  ██      ██  ██████
// ██   ██ ██    ██ ██   ██ ██      ██ ██
// ██████  ██    ██ ██████  ██      ██ ██
// ██      ██    ██ ██   ██ ██      ██ ██
// ██       ██████  ██████  ███████ ██  ██████
//
// >>public
SOKOL_API_IMPL void sfetch_setup(const sfetch_desc_t* desc_) {
    SOKOL_ASSERT(desc_);
    SOKOL_ASSERT(0 == _sfetch);

    sfetch_desc_t desc = _sfetch_desc_defaults(desc_);
    _sfetch = (_sfetch_t*) _sfetch_malloc_with_allocator(&desc.allocator, sizeof(_sfetch_t));
    SOKOL_ASSERT(_sfetch);
    _sfetch_t* ctx = _sfetch_ctx();
    _sfetch_clear(ctx, sizeof(_sfetch_t));
    ctx->desc = desc;
    ctx->setup = true;
    ctx->valid = true;

    /* replace zero-init items with default values */
    if (ctx->desc.num_channels > SFETCH_MAX_CHANNELS) {
        ctx->desc.num_channels = SFETCH_MAX_CHANNELS;
        _SFETCH_WARN(CLAMPING_NUM_CHANNELS_TO_MAX_CHANNELS);
    }

    /* setup the global request item pool */
    ctx->valid &= _sfetch_pool_init(&ctx->pool, ctx->desc.max_requests);

    /* setup IO channels (one thread per channel) */
    for (uint32_t i = 0; i < ctx->desc.num_channels; i++) {
        ctx->valid &= _sfetch_channel_init(&ctx->chn[i], ctx, ctx->desc.max_requests, ctx->desc.num_lanes, _sfetch_request_handler);
    }
}

SOKOL_API_IMPL void sfetch_shutdown(void) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->setup);
    ctx->valid = false;
    /* IO threads must be shutdown first */
    for (uint32_t i = 0; i < ctx->desc.num_channels; i++) {
        if (ctx->chn[i].valid) {
            _sfetch_channel_discard(&ctx->chn[i]);
        }
    }
    _sfetch_pool_discard(&ctx->pool);
    ctx->setup = false;
    _sfetch_free(ctx);
    _sfetch = 0;
}

SOKOL_API_IMPL bool sfetch_valid(void) {
    _sfetch_t* ctx = _sfetch_ctx();
    return ctx && ctx->valid;
}

SOKOL_API_IMPL sfetch_desc_t sfetch_desc(void) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    return ctx->desc;
}

SOKOL_API_IMPL int sfetch_max_userdata_bytes(void) {
    return SFETCH_MAX_USERDATA_UINT64 * 8;
}

SOKOL_API_IMPL int sfetch_max_path(void) {
    return SFETCH_MAX_PATH;
}

SOKOL_API_IMPL bool sfetch_handle_valid(sfetch_handle_t h) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    /* shortcut invalid handle */
    if (h.id == 0) {
        return false;
    }
    return 0 != _sfetch_pool_item_lookup(&ctx->pool, h.id);
}

SOKOL_API_IMPL sfetch_handle_t sfetch_send(const sfetch_request_t* request) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->setup);

    const sfetch_handle_t invalid_handle = _sfetch_make_handle(0);
    if (!ctx->valid) {
        return invalid_handle;
    }
    if (!_sfetch_validate_request(ctx, request)) {
        return invalid_handle;
    }
    SOKOL_ASSERT(request->channel < ctx->desc.num_channels);

    uint32_t slot_id = _sfetch_pool_item_alloc(&ctx->pool, request);
    if (0 == slot_id) {
        _SFETCH_WARN(REQUEST_POOL_EXHAUSTED);
        return invalid_handle;
    }
    if (!_sfetch_channel_send(&ctx->chn[request->channel], slot_id)) {
        /* send failed because the channels sent-queue overflowed */
        _sfetch_pool_item_free(&ctx->pool, slot_id);
        return invalid_handle;
    }
    return _sfetch_make_handle(slot_id);
}

SOKOL_API_IMPL void sfetch_dowork(void) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->setup);
    if (!ctx->valid) {
        return;
    }
    /* we're pumping each channel 2x so that unfinished request items coming out the
       IO threads can be moved back into the IO-thread immediately without
       having to wait a frame
     */
    ctx->in_callback = true;
    for (int pass = 0; pass < 2; pass++) {
        for (uint32_t chn_index = 0; chn_index < ctx->desc.num_channels; chn_index++) {
            _sfetch_channel_dowork(&ctx->chn[chn_index], &ctx->pool);
        }
    }
    ctx->in_callback = false;
}

SOKOL_API_IMPL void sfetch_bind_buffer(sfetch_handle_t h, sfetch_range_t buffer) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    SOKOL_ASSERT(ctx->in_callback);
    SOKOL_ASSERT(buffer.ptr && (buffer.size > 0));
    _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, h.id);
    if (item) {
        SOKOL_ASSERT((0 == item->buffer.ptr) && (0 == item->buffer.size));
        item->buffer = buffer;
    }
}

SOKOL_API_IMPL void* sfetch_unbind_buffer(sfetch_handle_t h) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    SOKOL_ASSERT(ctx->in_callback);
    _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, h.id);
    if (item) {
        void* prev_buf_ptr = (void*)item->buffer.ptr;
        item->buffer.ptr = 0;
        item->buffer.size = 0;
        return prev_buf_ptr;
    } else {
        return 0;
    }
}

SOKOL_API_IMPL void sfetch_pause(sfetch_handle_t h) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, h.id);
    if (item) {
        item->user.pause = true;
        item->user.cont = false;
    }
}

SOKOL_API_IMPL void sfetch_continue(sfetch_handle_t h) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, h.id);
    if (item) {
        item->user.cont = true;
        item->user.pause = false;
    }
}

SOKOL_API_IMPL void sfetch_cancel(sfetch_handle_t h) {
    _sfetch_t* ctx = _sfetch_ctx();
    SOKOL_ASSERT(ctx && ctx->valid);
    _sfetch_item_t* item = _sfetch_pool_item_lookup(&ctx->pool, h.id);
    if (item) {
        item->user.cont = false;
        item->user.pause = false;
        item->user.cancel = true;
    }
}

#ifdef _MSC_VER
#pragma warning(pop)
#endif

#endif /* SOKOL_FETCH_IMPL */
//FILE_END

#ifndef PK_NO_SAPP

//FILE_START:deps/sokol_app.h
#if defined(SOKOL_IMPL) && !defined(SOKOL_APP_IMPL)
#define SOKOL_APP_IMPL
#endif
#ifndef SOKOL_APP_INCLUDED
/*
    sokol_app.h -- cross-platform application wrapper

    Project URL: https://github.com/floooh/sokol

    Do this:
        #define SOKOL_IMPL or
        #define SOKOL_APP_IMPL
    before you include this file in *one* C or C++ file to create the
    implementation.

    In the same place define one of the following to select the 3D-API
    which should be initialized by sokol_app.h (this must also match
    the backend selected for sokol_gfx.h if both are used in the same
    project):

        #define SOKOL_GLCORE
        #define SOKOL_GLES3
        #define SOKOL_D3D11
        #define SOKOL_METAL
        #define SOKOL_WGPU
        #define SOKOL_NOAPI

    Optionally provide the following defines with your own implementations:

        SOKOL_ASSERT(c)             - your own assert macro (default: assert(c))
        SOKOL_UNREACHABLE()         - a guard macro for unreachable code (default: assert(false))
        SOKOL_WIN32_FORCE_MAIN      - define this on Win32 to add a main() entry point
        SOKOL_WIN32_FORCE_WINMAIN   - define this on Win32 to add a WinMain() entry point (enabled by default unless SOKOL_WIN32_FORCE_MAIN or SOKOL_NO_ENTRY is defined)
        SOKOL_NO_ENTRY              - define this if sokol_app.h shouldn't "hijack" the main() function
        SOKOL_APP_API_DECL          - public function declaration prefix (default: extern)
        SOKOL_API_DECL              - same as SOKOL_APP_API_DECL
        SOKOL_API_IMPL              - public function implementation prefix (default: -)

    Optionally define the following to force debug checks and validations
    even in release mode:

        SOKOL_DEBUG         - by default this is defined if _DEBUG is defined

    If sokol_app.h is compiled as a DLL, define the following before
    including the declaration or implementation:

        SOKOL_DLL

    On Windows, SOKOL_DLL will define SOKOL_APP_API_DECL as __declspec(dllexport)
    or __declspec(dllimport) as needed.

    if SOKOL_WIN32_FORCE_MAIN and SOKOL_WIN32_FORCE_WINMAIN are both defined,
    it is up to the developer to define the desired subsystem.

    On Linux, SOKOL_GLCORE can use either GLX or EGL.
    GLX is default, set SOKOL_FORCE_EGL to override.

    For example code, see https://github.com/floooh/sokol-samples/tree/master/sapp

    Portions of the Windows and Linux GL initialization, event-, icon- etc... code
    have been taken from GLFW (http://www.glfw.org/).

    iOS onscreen keyboard support 'inspired' by libgdx.

    Link with the following system libraries:

    - on macOS with Metal: Cocoa, QuartzCore, Metal, MetalKit
    - on macOS with GL: Cocoa, QuartzCore, OpenGL
    - on iOS with Metal: Foundation, UIKit, Metal, MetalKit
    - on iOS with GL: Foundation, UIKit, OpenGLES, GLKit
    - on Linux with EGL: X11, Xi, Xcursor, EGL, GL (or GLESv2), dl, pthread, m(?)
    - on Linux with GLX: X11, Xi, Xcursor, GL, dl, pthread, m(?)
    - on Android: GLESv3, EGL, log, android
    - on Windows with the MSVC or Clang toolchains: no action needed, libs are defined in-source via pragma-comment-lib
    - on Windows with MINGW/MSYS2 gcc: compile with '-mwin32' so that _WIN32 is defined
        - link with the following libs: -lkernel32 -luser32 -lshell32
        - additionally with the GL backend: -lgdi32
        - additionally with the D3D11 backend: -ld3d11 -ldxgi

    On Linux, you also need to use the -pthread compiler and linker option, otherwise weird
    things will happen, see here for details: https://github.com/floooh/sokol/issues/376

    On macOS and iOS, the implementation must be compiled as Objective-C.

    FEATURE OVERVIEW
    ================
    sokol_app.h provides a minimalistic cross-platform API which
    implements the 'application-wrapper' parts of a 3D application:

    - a common application entry function
    - creates a window and 3D-API context/device with a 'default framebuffer'
    - makes the rendered frame visible
    - provides keyboard-, mouse- and low-level touch-events
    - platforms: MacOS, iOS, HTML5, Win32, Linux/RaspberryPi, Android
    - 3D-APIs: Metal, D3D11, GL4.1, GL4.3, GLES3, WebGL, WebGL2, NOAPI

    FEATURE/PLATFORM MATRIX
    =======================
                        | Windows | macOS | Linux |  iOS  | Android |  HTML5
    --------------------+---------+-------+-------+-------+---------+--------
    gl 4.x              | YES     | YES   | YES   | ---   | ---     |  ---
    gles3/webgl2        | ---     | ---   | YES(2)| YES   | YES     |  YES
    metal               | ---     | YES   | ---   | YES   | ---     |  ---
    d3d11               | YES     | ---   | ---   | ---   | ---     |  ---
    noapi               | YES     | TODO  | TODO  | ---   | TODO    |  ---
    KEY_DOWN            | YES     | YES   | YES   | SOME  | TODO    |  YES
    KEY_UP              | YES     | YES   | YES   | SOME  | TODO    |  YES
    CHAR                | YES     | YES   | YES   | YES   | TODO    |  YES
    MOUSE_DOWN          | YES     | YES   | YES   | ---   | ---     |  YES
    MOUSE_UP            | YES     | YES   | YES   | ---   | ---     |  YES
    MOUSE_SCROLL        | YES     | YES   | YES   | ---   | ---     |  YES
    MOUSE_MOVE          | YES     | YES   | YES   | ---   | ---     |  YES
    MOUSE_ENTER         | YES     | YES   | YES   | ---   | ---     |  YES
    MOUSE_LEAVE         | YES     | YES   | YES   | ---   | ---     |  YES
    TOUCHES_BEGAN       | ---     | ---   | ---   | YES   | YES     |  YES
    TOUCHES_MOVED       | ---     | ---   | ---   | YES   | YES     |  YES
    TOUCHES_ENDED       | ---     | ---   | ---   | YES   | YES     |  YES
    TOUCHES_CANCELLED   | ---     | ---   | ---   | YES   | YES     |  YES
    RESIZED             | YES     | YES   | YES   | YES   | YES     |  YES
    ICONIFIED           | YES     | YES   | YES   | ---   | ---     |  ---
    RESTORED            | YES     | YES   | YES   | ---   | ---     |  ---
    FOCUSED             | YES     | YES   | YES   | ---   | ---     |  YES
    UNFOCUSED           | YES     | YES   | YES   | ---   | ---     |  YES
    SUSPENDED           | ---     | ---   | ---   | YES   | YES     |  TODO
    RESUMED             | ---     | ---   | ---   | YES   | YES     |  TODO
    QUIT_REQUESTED      | YES     | YES   | YES   | ---   | ---     |  YES
    IME                 | TODO    | TODO? | TODO  | ???   | TODO    |  ???
    key repeat flag     | YES     | YES   | YES   | ---   | ---     |  YES
    windowed            | YES     | YES   | YES   | ---   | ---     |  YES
    fullscreen          | YES     | YES   | YES   | YES   | YES     |  ---
    mouse hide          | YES     | YES   | YES   | ---   | ---     |  YES
    mouse lock          | YES     | YES   | YES   | ---   | ---     |  YES
    set cursor type     | YES     | YES   | YES   | ---   | ---     |  YES
    screen keyboard     | ---     | ---   | ---   | YES   | TODO    |  YES
    swap interval       | YES     | YES   | YES   | YES   | TODO    |  YES
    high-dpi            | YES     | YES   | TODO  | YES   | YES     |  YES
    clipboard           | YES     | YES   | YES   | ---   | ---     |  YES
    MSAA                | YES     | YES   | YES   | YES   | YES     |  YES
    drag'n'drop         | YES     | YES   | YES   | ---   | ---     |  YES
    window icon         | YES     | YES(1)| YES   | ---   | ---     |  YES

    (1) macOS has no regular window icons, instead the dock icon is changed
    (2) supported with EGL only (not GLX)

    STEP BY STEP
    ============
    --- Add a sokol_main() function to your code which returns a sapp_desc structure
        with initialization parameters and callback function pointers. This
        function is called very early, usually at the start of the
        platform's entry function (e.g. main or WinMain). You should do as
        little as possible here, since the rest of your code might be called
        from another thread (this depends on the platform):

            sapp_desc sokol_main(int argc, char* argv[]) {
                return (sapp_desc) {
                    .width = 640,
                    .height = 480,
                    .init_cb = my_init_func,
                    .frame_cb = my_frame_func,
                    .cleanup_cb = my_cleanup_func,
                    .event_cb = my_event_func,
                    ...
                };
            }

        To get any logging output in case of errors you need to provide a log
        callback. The easiest way is via sokol_log.h:

            #include "sokol_log.h"

            sapp_desc sokol_main(int argc, char* argv[]) {
                return (sapp_desc) {
                    ...
                    .logger.func = slog_func,
                };
            }

        There are many more setup parameters, but these are the most important.
        For a complete list search for the sapp_desc structure declaration
        below.

        DO NOT call any sokol-app function from inside sokol_main(), since
        sokol-app will not be initialized at this point.

        The .width and .height parameters are the preferred size of the 3D
        rendering canvas. The actual size may differ from this depending on
        platform and other circumstances. Also the canvas size may change at
        any time (for instance when the user resizes the application window,
        or rotates the mobile device). You can just keep .width and .height
        zero-initialized to open a default-sized window (what "default-size"
        exactly means is platform-specific, but usually it's a size that covers
        most of, but not all, of the display).

        All provided function callbacks will be called from the same thread,
        but this may be different from the thread where sokol_main() was called.

        .init_cb (void (*)(void))
            This function is called once after the application window,
            3D rendering context and swap chain have been created. The
            function takes no arguments and has no return value.
        .frame_cb (void (*)(void))
            This is the per-frame callback, which is usually called 60
            times per second. This is where your application would update
            most of its state and perform all rendering.
        .cleanup_cb (void (*)(void))
            The cleanup callback is called once right before the application
            quits.
        .event_cb (void (*)(const sapp_event* event))
            The event callback is mainly for input handling, but is also
            used to communicate other types of events to the application. Keep the
            event_cb struct member zero-initialized if your application doesn't require
            event handling.

        As you can see, those 'standard callbacks' don't have a user_data
        argument, so any data that needs to be preserved between callbacks
        must live in global variables. If keeping state in global variables
        is not an option, there's an alternative set of callbacks with
        an additional user_data pointer argument:

        .user_data (void*)
            The user-data argument for the callbacks below
        .init_userdata_cb (void (*)(void* user_data))
        .frame_userdata_cb (void (*)(void* user_data))
        .cleanup_userdata_cb (void (*)(void* user_data))
        .event_userdata_cb (void(*)(const sapp_event* event, void* user_data))

        The function sapp_userdata() can be used to query the user_data
        pointer provided in the sapp_desc struct.

        You can also call sapp_query_desc() to get a copy of the
        original sapp_desc structure.

        NOTE that there's also an alternative compile mode where sokol_app.h
        doesn't "hijack" the main() function. Search below for SOKOL_NO_ENTRY.

    --- Implement the initialization callback function (init_cb), this is called
        once after the rendering surface, 3D API and swap chain have been
        initialized by sokol_app. All sokol-app functions can be called
        from inside the initialization callback, the most useful functions
        at this point are:

        int sapp_width(void)
        int sapp_height(void)
            Returns the current width and height of the default framebuffer in pixels,
            this may change from one frame to the next, and it may be different
            from the initial size provided in the sapp_desc struct.

        float sapp_widthf(void)
        float sapp_heightf(void)
            These are alternatives to sapp_width() and sapp_height() which return
            the default framebuffer size as float values instead of integer. This
            may help to prevent casting back and forth between int and float
            in more strongly typed languages than C and C++.

        double sapp_frame_duration(void)
            Returns the frame duration in seconds averaged over a number of
            frames to smooth out any jittering spikes.

        int sapp_color_format(void)
        int sapp_depth_format(void)
            The color and depth-stencil pixelformats of the default framebuffer,
            as integer values which are compatible with sokol-gfx's
            sg_pixel_format enum (so that they can be plugged directly in places
            where sg_pixel_format is expected). Possible values are:

                23 == SG_PIXELFORMAT_RGBA8
                28 == SG_PIXELFORMAT_BGRA8
                42 == SG_PIXELFORMAT_DEPTH
                43 == SG_PIXELFORMAT_DEPTH_STENCIL

        int sapp_sample_count(void)
            Return the MSAA sample count of the default framebuffer.

        const void* sapp_metal_get_device(void)
        const void* sapp_metal_get_current_drawable(void)
        const void* sapp_metal_get_depth_stencil_texture(void)
        const void* sapp_metal_get_msaa_color_texture(void)
            If the Metal backend has been selected, these functions return pointers
            to various Metal API objects required for rendering, otherwise
            they return a null pointer. These void pointers are actually
            Objective-C ids converted with a (ARC) __bridge cast so that
            the ids can be tunneled through C code. Also note that the returned
            pointers may change from one frame to the next, only the Metal device
            object is guaranteed to stay the same.

        const void* sapp_macos_get_window(void)
            On macOS, get the NSWindow object pointer, otherwise a null pointer.
            Before being used as Objective-C object, the void* must be converted
            back with a (ARC) __bridge cast.

        const void* sapp_ios_get_window(void)
            On iOS, get the UIWindow object pointer, otherwise a null pointer.
            Before being used as Objective-C object, the void* must be converted
            back with a (ARC) __bridge cast.

        const void* sapp_d3d11_get_device(void)
        const void* sapp_d3d11_get_device_context(void)
        const void* sapp_d3d11_get_render_view(void)
        const void* sapp_d3d11_get_resolve_view(void);
        const void* sapp_d3d11_get_depth_stencil_view(void)
            Similar to the sapp_metal_* functions, the sapp_d3d11_* functions
            return pointers to D3D11 API objects required for rendering,
            only if the D3D11 backend has been selected. Otherwise they
            return a null pointer. Note that the returned pointers to the
            render-target-view and depth-stencil-view may change from one
            frame to the next!

        const void* sapp_win32_get_hwnd(void)
            On Windows, get the window's HWND, otherwise a null pointer. The
            HWND has been cast to a void pointer in order to be tunneled
            through code which doesn't include Windows.h.

        const void* sapp_x11_get_window(void)
            On Linux, get the X11 Window, otherwise a null pointer. The
            Window has been cast to a void pointer in order to be tunneled
            through code which doesn't include X11/Xlib.h.

        const void* sapp_x11_get_display(void)
            On Linux, get the X11 Display, otherwise a null pointer. The
            Display has been cast to a void pointer in order to be tunneled
            through code which doesn't include X11/Xlib.h.

        const void* sapp_wgpu_get_device(void)
        const void* sapp_wgpu_get_render_view(void)
        const void* sapp_wgpu_get_resolve_view(void)
        const void* sapp_wgpu_get_depth_stencil_view(void)
            These are the WebGPU-specific functions to get the WebGPU
            objects and values required for rendering. If sokol_app.h
            is not compiled with SOKOL_WGPU, these functions return null.

        uint32_t sapp_gl_get_framebuffer(void)
            This returns the 'default framebuffer' of the GL context.
            Typically this will be zero.

        int sapp_gl_get_major_version(void)
        int sapp_gl_get_minor_version(void)
        bool sapp_gl_is_gles(void)
            Returns the major and minor version of the GL context and
            whether the GL context is a GLES context

        const void* sapp_android_get_native_activity(void);
            On Android, get the native activity ANativeActivity pointer, otherwise
            a null pointer.

    --- Implement the frame-callback function, this function will be called
        on the same thread as the init callback, but might be on a different
        thread than the sokol_main() function. Note that the size of
        the rendering framebuffer might have changed since the frame callback
        was called last. Call the functions sapp_width() and sapp_height()
        each frame to get the current size.

    --- Optionally implement the event-callback to handle input events.
        sokol-app provides the following type of input events:
            - a 'virtual key' was pressed down or released
            - a single text character was entered (provided as UTF-32 encoded
              UNICODE code point)
            - a mouse button was pressed down or released (left, right, middle)
            - mouse-wheel or 2D scrolling events
            - the mouse was moved
            - the mouse has entered or left the application window boundaries
            - low-level, portable multi-touch events (began, moved, ended, cancelled)
            - the application window was resized, iconified or restored
            - the application was suspended or restored (on mobile platforms)
            - the user or application code has asked to quit the application
            - a string was pasted to the system clipboard
            - one or more files have been dropped onto the application window

        To explicitly 'consume' an event and prevent that the event is
        forwarded for further handling to the operating system, call
        sapp_consume_event() from inside the event handler (NOTE that
        this behaviour is currently only implemented for some HTML5
        events, support for other platforms and event types will
        be added as needed, please open a GitHub ticket and/or provide
        a PR if needed).

        NOTE: Do *not* call any 3D API rendering functions in the event
        callback function, since the 3D API context may not be active when the
        event callback is called (it may work on some platforms and 3D APIs,
        but not others, and the exact behaviour may change between
        sokol-app versions).

    --- Implement the cleanup-callback function, this is called once
        after the user quits the application (see the section
        "APPLICATION QUIT" for detailed information on quitting
        behaviour, and how to intercept a pending quit - for instance to show a
        "Really Quit?" dialog box). Note that the cleanup-callback isn't
        guaranteed to be called on the web and mobile platforms.

    MOUSE CURSOR TYPE AND VISIBILITY
    ================================
    You can show and hide the mouse cursor with

        void sapp_show_mouse(bool show)

    And to get the current shown status:

        bool sapp_mouse_shown(void)

    NOTE that hiding the mouse cursor is different and independent from
    the MOUSE/POINTER LOCK feature which will also hide the mouse pointer when
    active (MOUSE LOCK is described below).

    To change the mouse cursor to one of several predefined types, call
    the function:

        void sapp_set_mouse_cursor(sapp_mouse_cursor cursor)

    Setting the default mouse cursor SAPP_MOUSECURSOR_DEFAULT will restore
    the standard look.

    To get the currently active mouse cursor type, call:

        sapp_mouse_cursor sapp_get_mouse_cursor(void)

    MOUSE LOCK (AKA POINTER LOCK, AKA MOUSE CAPTURE)
    ================================================
    In normal mouse mode, no mouse movement events are reported when the
    mouse leaves the windows client area or hits the screen border (whether
    it's one or the other depends on the platform), and the mouse move events
    (SAPP_EVENTTYPE_MOUSE_MOVE) contain absolute mouse positions in
    framebuffer pixels in the sapp_event items mouse_x and mouse_y, and
    relative movement in framebuffer pixels in the sapp_event items mouse_dx
    and mouse_dy.

    To get continuous mouse movement (also when the mouse leaves the window
    client area or hits the screen border), activate mouse-lock mode
    by calling:

        sapp_lock_mouse(true)

    When mouse lock is activated, the mouse pointer is hidden, the
    reported absolute mouse position (sapp_event.mouse_x/y) appears
    frozen, and the relative mouse movement in sapp_event.mouse_dx/dy
    no longer has a direct relation to framebuffer pixels but instead
    uses "raw mouse input" (what "raw mouse input" exactly means also
    differs by platform).

    To deactivate mouse lock and return to normal mouse mode, call

        sapp_lock_mouse(false)

    And finally, to check if mouse lock is currently active, call

        if (sapp_mouse_locked()) { ... }

    Note that mouse-lock state may not change immediately after sapp_lock_mouse(true/false)
    is called, instead on some platforms the actual state switch may be delayed
    to the end of the current frame or even to a later frame.

    The mouse may also be unlocked automatically without calling sapp_lock_mouse(false),
    most notably when the application window becomes inactive.

    On the web platform there are further restrictions to be aware of, caused
    by the limitations of the HTML5 Pointer Lock API:

        - sapp_lock_mouse(true) can be called at any time, but it will
          only take effect in a 'short-lived input event handler of a specific
          type', meaning when one of the following events happens:
            - SAPP_EVENTTYPE_MOUSE_DOWN
            - SAPP_EVENTTYPE_MOUSE_UP
            - SAPP_EVENTTYPE_MOUSE_SCROLL
            - SAPP_EVENTTYPE_KEY_UP
            - SAPP_EVENTTYPE_KEY_DOWN
        - The mouse lock/unlock action on the web platform is asynchronous,
          this means that sapp_mouse_locked() won't immediately return
          the new status after calling sapp_lock_mouse(), instead the
          reported status will only change when the pointer lock has actually
          been activated or deactivated in the browser.
        - On the web, mouse lock can be deactivated by the user at any time
          by pressing the Esc key. When this happens, sokol_app.h behaves
          the same as if sapp_lock_mouse(false) is called.

    For things like camera manipulation it's most straightforward to lock
    and unlock the mouse right from the sokol_app.h event handler, for
    instance the following code enters and leaves mouse lock when the
    left mouse button is pressed and released, and then uses the relative
    movement information to manipulate a camera (taken from the
    cgltf-sapp.c sample in the sokol-samples repository
    at https://github.com/floooh/sokol-samples):

        static void input(const sapp_event* ev) {
            switch (ev->type) {
                case SAPP_EVENTTYPE_MOUSE_DOWN:
                    if (ev->mouse_button == SAPP_MOUSEBUTTON_LEFT) {
                        sapp_lock_mouse(true);
                    }
                    break;

                case SAPP_EVENTTYPE_MOUSE_UP:
                    if (ev->mouse_button == SAPP_MOUSEBUTTON_LEFT) {
                        sapp_lock_mouse(false);
                    }
                    break;

                case SAPP_EVENTTYPE_MOUSE_MOVE:
                    if (sapp_mouse_locked()) {
                        cam_orbit(&state.camera, ev->mouse_dx * 0.25f, ev->mouse_dy * 0.25f);
                    }
                    break;

                default:
                    break;
            }
        }

    For a 'first person shooter mouse' the following code inside the sokol-app event handler
    is recommended somewhere in your frame callback:

        if (!sapp_mouse_locked()) {
            sapp_lock_mouse(true);
        }

    CLIPBOARD SUPPORT
    =================
    Applications can send and receive UTF-8 encoded text data from and to the
    system clipboard. By default, clipboard support is disabled and
    must be enabled at startup via the following sapp_desc struct
    members:

        sapp_desc.enable_clipboard  - set to true to enable clipboard support
        sapp_desc.clipboard_size    - size of the internal clipboard buffer in bytes

    Enabling the clipboard will dynamically allocate a clipboard buffer
    for UTF-8 encoded text data of the requested size in bytes, the default
    size is 8 KBytes. Strings that don't fit into the clipboard buffer
    (including the terminating zero) will be silently clipped, so it's
    important that you provide a big enough clipboard size for your
    use case.

    To send data to the clipboard, call sapp_set_clipboard_string() with
    a pointer to an UTF-8 encoded, null-terminated C-string.

    NOTE that on the HTML5 platform, sapp_set_clipboard_string() must be
    called from inside a 'short-lived event handler', and there are a few
    other HTML5-specific caveats to workaround. You'll basically have to
    tinker until it works in all browsers :/ (maybe the situation will
    improve when all browsers agree on and implement the new
    HTML5 navigator.clipboard API).

    To get data from the clipboard, check for the SAPP_EVENTTYPE_CLIPBOARD_PASTED
    event in your event handler function, and then call sapp_get_clipboard_string()
    to obtain the pasted UTF-8 encoded text.

    NOTE that behaviour of sapp_get_clipboard_string() is slightly different
    depending on platform:

        - on the HTML5 platform, the internal clipboard buffer will only be updated
          right before the SAPP_EVENTTYPE_CLIPBOARD_PASTED event is sent,
          and sapp_get_clipboard_string() will simply return the current content
          of the clipboard buffer
        - on 'native' platforms, the call to sapp_get_clipboard_string() will
          update the internal clipboard buffer with the most recent data
          from the system clipboard

    Portable code should check for the SAPP_EVENTTYPE_CLIPBOARD_PASTED event,
    and then call sapp_get_clipboard_string() right in the event handler.

    The SAPP_EVENTTYPE_CLIPBOARD_PASTED event will be generated by sokol-app
    as follows:

        - on macOS: when the Cmd+V key is pressed down
        - on HTML5: when the browser sends a 'paste' event to the global 'window' object
        - on all other platforms: when the Ctrl+V key is pressed down

    DRAG AND DROP SUPPORT
    =====================
    PLEASE NOTE: the drag'n'drop feature works differently on WASM/HTML5
    and on the native desktop platforms (Win32, Linux and macOS) because
    of security-related restrictions in the HTML5 drag'n'drop API. The
    WASM/HTML5 specifics are described at the end of this documentation
    section:

    Like clipboard support, drag'n'drop support must be explicitly enabled
    at startup in the sapp_desc struct.

        sapp_desc sokol_main(void) {
            return (sapp_desc) {
                .enable_dragndrop = true,   // default is false
                ...
            };
        }

    You can also adjust the maximum number of files that are accepted
    in a drop operation, and the maximum path length in bytes if needed:

        sapp_desc sokol_main(void) {
            return (sapp_desc) {
                .enable_dragndrop = true,               // default is false
                .max_dropped_files = 8,                 // default is 1
                .max_dropped_file_path_length = 8192,   // in bytes, default is 2048
                ...
            };
        }

    When drag'n'drop is enabled, the event callback will be invoked with an
    event of type SAPP_EVENTTYPE_FILES_DROPPED whenever the user drops files on
    the application window.

    After the SAPP_EVENTTYPE_FILES_DROPPED is received, you can query the
    number of dropped files, and their absolute paths by calling separate
    functions:

        void on_event(const sapp_event* ev) {
            if (ev->type == SAPP_EVENTTYPE_FILES_DROPPED) {

                // the mouse position where the drop happened
                float x = ev->mouse_x;
                float y = ev->mouse_y;

                // get the number of files and their paths like this:
                const int num_dropped_files = sapp_get_num_dropped_files();
                for (int i = 0; i < num_dropped_files; i++) {
                    const char* path = sapp_get_dropped_file_path(i);
                    ...
                }
            }
        }

    The returned file paths are UTF-8 encoded strings.

    You can call sapp_get_num_dropped_files() and sapp_get_dropped_file_path()
    anywhere, also outside the event handler callback, but be aware that the
    file path strings will be overwritten with the next drop operation.

    In any case, sapp_get_dropped_file_path() will never return a null pointer,
    instead an empty string "" will be returned if the drag'n'drop feature
    hasn't been enabled, the last drop-operation failed, or the file path index
    is out of range.

    Drag'n'drop caveats:

        - if more files are dropped in a single drop-action
          than sapp_desc.max_dropped_files, the additional
          files will be silently ignored
        - if any of the file paths is longer than
          sapp_desc.max_dropped_file_path_length (in number of bytes, after UTF-8
          encoding) the entire drop operation will be silently ignored (this
          needs some sort of error feedback in the future)
        - no mouse positions are reported while the drag is in
          process, this may change in the future

    Drag'n'drop on HTML5/WASM:

    The HTML5 drag'n'drop API doesn't return file paths, but instead
    black-box 'file objects' which must be used to load the content
    of dropped files. This is the reason why sokol_app.h adds two
    HTML5-specific functions to the drag'n'drop API:

        uint32_t sapp_html5_get_dropped_file_size(int index)
            Returns the size in bytes of a dropped file.

        void sapp_html5_fetch_dropped_file(const sapp_html5_fetch_request* request)
            Asynchronously loads the content of a dropped file into a
            provided memory buffer (which must be big enough to hold
            the file content)

    To start loading the first dropped file after an SAPP_EVENTTYPE_FILES_DROPPED
    event is received:

        sapp_html5_fetch_dropped_file(&(sapp_html5_fetch_request){
            .dropped_file_index = 0,
            .callback = fetch_cb
            .buffer = {
                .ptr = buf,
                .size = sizeof(buf)
            },
            .user_data = ...
        });

    Make sure that the memory pointed to by 'buf' stays valid until the
    callback function is called!

    As result of the asynchronous loading operation (no matter if succeeded or
    failed) the 'fetch_cb' function will be called:

        void fetch_cb(const sapp_html5_fetch_response* response) {
            // IMPORTANT: check if the loading operation actually succeeded:
            if (response->succeeded) {
                // the size of the loaded file:
                const size_t num_bytes = response->data.size;
                // and the pointer to the data (same as 'buf' in the fetch-call):
                const void* ptr = response->data.ptr;
            }
            else {
                // on error check the error code:
                switch (response->error_code) {
                    case SAPP_HTML5_FETCH_ERROR_BUFFER_TOO_SMALL:
                        ...
                        break;
                    case SAPP_HTML5_FETCH_ERROR_OTHER:
                        ...
                        break;
                }
            }
        }

    Check the droptest-sapp example for a real-world example which works
    both on native platforms and the web:

    https://github.com/floooh/sokol-samples/blob/master/sapp/droptest-sapp.c

    HIGH-DPI RENDERING
    ==================
    You can set the sapp_desc.high_dpi flag during initialization to request
    a full-resolution framebuffer on HighDPI displays. The default behaviour
    is sapp_desc.high_dpi=false, this means that the application will
    render to a lower-resolution framebuffer on HighDPI displays and the
    rendered content will be upscaled by the window system composer.

    In a HighDPI scenario, you still request the same window size during
    sokol_main(), but the framebuffer sizes returned by sapp_width()
    and sapp_height() will be scaled up according to the DPI scaling
    ratio.

    Note that on some platforms the DPI scaling factor may change at any
    time (for instance when a window is moved from a high-dpi display
    to a low-dpi display).

    To query the current DPI scaling factor, call the function:

    float sapp_dpi_scale(void);

    For instance on a Retina Mac, returning the following sapp_desc
    struct from sokol_main():

    sapp_desc sokol_main(void) {
        return (sapp_desc) {
            .width = 640,
            .height = 480,
            .high_dpi = true,
            ...
        };
    }

    ...the functions the functions sapp_width(), sapp_height()
    and sapp_dpi_scale() will return the following values:

    sapp_width:     1280
    sapp_height:    960
    sapp_dpi_scale: 2.0

    If the high_dpi flag is false, or you're not running on a Retina display,
    the values would be:

    sapp_width:     640
    sapp_height:    480
    sapp_dpi_scale: 1.0

    If the window is moved from the Retina display to a low-dpi external display,
    the values would change as follows:

    sapp_width:     1280 => 640
    sapp_height:    960  => 480
    sapp_dpi_scale: 2.0  => 1.0

    Currently there is no event associated with a DPI change, but an
    SAPP_EVENTTYPE_RESIZED will be sent as a side effect of the
    framebuffer size changing.

    Per-monitor DPI is currently supported on macOS and Windows.

    APPLICATION QUIT
    ================
    Without special quit handling, a sokol_app.h application will quit
    'gracefully' when the user clicks the window close-button unless a
    platform's application model prevents this (e.g. on web or mobile).
    'Graceful exit' means that the application-provided cleanup callback will
    be called before the application quits.

    On native desktop platforms sokol_app.h provides more control over the
    application-quit-process. It's possible to initiate a 'programmatic quit'
    from the application code, and a quit initiated by the application user can
    be intercepted (for instance to show a custom dialog box).

    This 'programmatic quit protocol' is implemented through 3 functions
    and 1 event:

        - sapp_quit(): This function simply quits the application without
          giving the user a chance to intervene. Usually this might
          be called when the user clicks the 'Ok' button in a 'Really Quit?'
          dialog box
        - sapp_request_quit(): Calling sapp_request_quit() will send the
          event SAPP_EVENTTYPE_QUIT_REQUESTED to the applications event handler
          callback, giving the user code a chance to intervene and cancel the
          pending quit process (for instance to show a 'Really Quit?' dialog
          box). If the event handler callback does nothing, the application
          will be quit as usual. To prevent this, call the function
          sapp_cancel_quit() from inside the event handler.
        - sapp_cancel_quit(): Cancels a pending quit request, either initiated
          by the user clicking the window close button, or programmatically
          by calling sapp_request_quit(). The only place where calling this
          function makes sense is from inside the event handler callback when
          the SAPP_EVENTTYPE_QUIT_REQUESTED event has been received.
        - SAPP_EVENTTYPE_QUIT_REQUESTED: this event is sent when the user
          clicks the window's close button or application code calls the
          sapp_request_quit() function. The event handler callback code can handle
          this event by calling sapp_cancel_quit() to cancel the quit.
          If the event is ignored, the application will quit as usual.

    On the web platform, the quit behaviour differs from native platforms,
    because of web-specific restrictions:

    A `programmatic quit` initiated by calling sapp_quit() or
    sapp_request_quit() will work as described above: the cleanup callback is
    called, platform-specific cleanup is performed (on the web
    this means that JS event handlers are unregistered), and then
    the request-animation-loop will be exited. However that's all. The
    web page itself will continue to exist (e.g. it's not possible to
    programmatically close the browser tab).

    On the web it's also not possible to run custom code when the user
    closes a browser tab, so it's not possible to prevent this with a
    fancy custom dialog box.

    Instead the standard "Leave Site?" dialog box can be activated (or
    deactivated) with the following function:

        sapp_html5_ask_leave_site(bool ask);

    The initial state of the associated internal flag can be provided
    at startup via sapp_desc.html5_ask_leave_site.

    This feature should only be used sparingly in critical situations - for
    instance when the user would loose data - since popping up modal dialog
    boxes is considered quite rude in the web world. Note that there's no way
    to customize the content of this dialog box or run any code as a result
    of the user's decision. Also note that the user must have interacted with
    the site before the dialog box will appear. These are all security measures
    to prevent fishing.

    The Dear ImGui HighDPI sample contains example code of how to
    implement a 'Really Quit?' dialog box with Dear ImGui (native desktop
    platforms only), and for showing the hardwired "Leave Site?" dialog box
    when running on the web platform:

        https://floooh.github.io/sokol-html5/wasm/imgui-highdpi-sapp.html

    FULLSCREEN
    ==========
    If the sapp_desc.fullscreen flag is true, sokol-app will try to create
    a fullscreen window on platforms with a 'proper' window system
    (mobile devices will always use fullscreen). The implementation details
    depend on the target platform, in general sokol-app will use a
    'soft approach' which doesn't interfere too much with the platform's
    window system (for instance borderless fullscreen window instead of
    a 'real' fullscreen mode). Such details might change over time
    as sokol-app is adapted for different needs.

    The most important effect of fullscreen mode to keep in mind is that
    the requested canvas width and height will be ignored for the initial
    window size, calling sapp_width() and sapp_height() will instead return
    the resolution of the fullscreen canvas (however the provided size
    might still be used for the non-fullscreen window, in case the user can
    switch back from fullscreen- to windowed-mode).

    To toggle fullscreen mode programmatically, call sapp_toggle_fullscreen().

    To check if the application window is currently in fullscreen mode,
    call sapp_is_fullscreen().

    WINDOW ICON SUPPORT
    ===================
    Some sokol_app.h backends allow to change the window icon programmatically:

        - on Win32: the small icon in the window's title bar, and the
          bigger icon in the task bar
        - on Linux: highly dependent on the used window manager, but usually
          the window's title bar icon and/or the task bar icon
        - on HTML5: the favicon shown in the page's browser tab
        - on macOS: the application icon shown in the dock, but only
          for currently running applications

    NOTE that it is not possible to set the actual application icon which is
    displayed by the operating system on the desktop or 'home screen'. Those
    icons must be provided 'traditionally' through operating-system-specific
    resources which are associated with the application (sokol_app.h might
    later support setting the window icon from platform specific resource data
    though).

    There are two ways to set the window icon:

        - at application start in the sokol_main() function by initializing
          the sapp_desc.icon nested struct
        - or later by calling the function sapp_set_icon()

    As a convenient shortcut, sokol_app.h comes with a builtin default-icon
    (a rainbow-colored 'S', which at least looks a bit better than the Windows
    default icon for applications), which can be activated like this:

    At startup in sokol_main():

        sapp_desc sokol_main(...) {
            return (sapp_desc){
                ...
                icon.sokol_default = true
            };
        }

    Or later by calling:

        sapp_set_icon(&(sapp_icon_desc){ .sokol_default = true });

    NOTE that a completely zero-initialized sapp_icon_desc struct will not
    update the window icon in any way. This is an 'escape hatch' so that you
    can handle the window icon update yourself (or if you do this already,
    sokol_app.h won't get in your way, in this case just leave the
    sapp_desc.icon struct zero-initialized).

    Providing your own icon images works exactly like in GLFW (down to the
    data format):

    You provide one or more 'candidate images' in different sizes, and the
    sokol_app.h platform backends pick the best match for the specific backend
    and icon type.

    For each candidate image, you need to provide:

        - the width in pixels
        - the height in pixels
        - and the actual pixel data in RGBA8 pixel format (e.g. 0xFFCC8844
          on a little-endian CPU means: alpha=0xFF, blue=0xCC, green=0x88, red=0x44)

    For instance, if you have 3 candidate images (small, medium, big) of
    sizes 16x16, 32x32 and 64x64 the corresponding sapp_icon_desc struct is setup
    like this:

        // the actual pixel data (RGBA8, origin top-left)
        const uint32_t small[16][16]  = { ... };
        const uint32_t medium[32][32] = { ... };
        const uint32_t big[64][64]    = { ... };

        const sapp_icon_desc icon_desc = {
            .images = {
                { .width = 16, .height = 16, .pixels = SAPP_RANGE(small) },
                { .width = 32, .height = 32, .pixels = SAPP_RANGE(medium) },
                // ...or without the SAPP_RANGE helper macro:
                { .width = 64, .height = 64, .pixels = { .ptr=big, .size=sizeof(big) } }
            }
        };

    An sapp_icon_desc struct initialized like this can then either be applied
    at application start in sokol_main:

        sapp_desc sokol_main(...) {
            return (sapp_desc){
                ...
                icon = icon_desc
            };
        }

    ...or later by calling sapp_set_icon():

        sapp_set_icon(&icon_desc);

    Some window icon caveats:

        - once the window icon has been updated, there's no way to go back to
          the platform's default icon, this is because some platforms (Linux
          and HTML5) don't switch the icon visual back to the default even if
          the custom icon is deleted or removed
        - on HTML5, if the sokol_app.h icon doesn't show up in the browser
          tab, check that there's no traditional favicon 'link' element
          is defined in the page's index.html, sokol_app.h will only
          append a new favicon link element, but not delete any manually
          defined favicon in the page

    For an example and test of the window icon feature, check out the
    'icon-sapp' sample on the sokol-samples git repository.

    ONSCREEN KEYBOARD
    =================
    On some platforms which don't provide a physical keyboard, sokol-app
    can display the platform's integrated onscreen keyboard for text
    input. To request that the onscreen keyboard is shown, call

        sapp_show_keyboard(true);

    Likewise, to hide the keyboard call:

        sapp_show_keyboard(false);

    Note that onscreen keyboard functionality is no longer supported
    on the browser platform (the previous hacks and workarounds to make browser
    keyboards work for on web applications that don't use HTML UIs
    never really worked across browsers).

    INPUT EVENT BUBBLING ON THE WEB PLATFORM
    ========================================
    By default, input event bubbling on the web platform is configured in
    a way that makes the most sense for 'full-canvas' apps that cover the
    entire browser client window area:

    - mouse, touch and wheel events do not bubble up, this prevents various
      ugly side events, like:
        - HTML text overlays being selected on double- or triple-click into
          the canvas
        - 'scroll bumping' even when the canvas covers the entire client area
    - key_up/down events for 'character keys' *do* bubble up (otherwise
      the browser will not generate UNICODE character events)
    - all other key events *do not* bubble up by default (this prevents side effects
      like F1 opening help, or F7 starting 'caret browsing')
    - character events do not bubble up (although I haven't noticed any side effects
      otherwise)

    Event bubbling can be enabled for input event categories during initialization
    in the sapp_desc struct:

        sapp_desc sokol_main(int argc, char* argv[]) {
            return (sapp_desc){
                //...
                .html5_bubble_mouse_events = true,
                .html5_bubble_touch_events = true,
                .html5_bubble_wheel_events = true,
                .html5_bubble_key_events = true,
                .html5_bubble_char_events = true,
            };
        }

    This basically opens the floodgates and lets *all* input events bubble up to the browser.

    To prevent individual events from bubbling, call sapp_consume_event() from within
    the sokol_app.h event callback when that specific event is reported.


    SETTING THE CANVAS OBJECT ON THE WEB PLATFORM
    =============================================
    On the web, sokol_app.h and the Emscripten SDK functions need to find
    the WebGL/WebGPU canvas intended for rendering and attaching event
    handlers. This can happen in four ways:

    1. do nothing and just set the id of the canvas object to 'canvas' (preferred)
    2. via a CSS Selector string (preferred)
    3. by setting the `Module.canvas` property to the canvas object
    4. by adding the canvas object to the global variable `specialHTMLTargets[]`
       (this is a special variable used by the Emscripten runtime to lookup
       event target objects for which document.querySelector() cannot be used)

    The easiest way is to just name your canvas object 'canvas':

        <canvas id="canvas" ...></canvas>

    This works because the default css selector string used by sokol_app.h
    is '#canvas'.

    If you name your canvas differently, you need to communicate that name to
    sokol_app.h via `sapp_desc.html5_canvas_selector` as a regular css selector
    string that's compatible with `document.querySelector()`. E.g. if your canvas
    object looks like this:

        <canvas id="bla" ...></canvas>

    The `sapp_desc.html5_canvas_selector` string must be set to '#bla':

        .html5_canvas_selector = "#bla"

    If the canvas object cannot be looked up via `document.querySelector()` you
    need to use one of the alternative methods, both involve the special
    Emscripten runtime `Module` object which is usually setup in the index.html
    like this before the WASM blob is loaded and instantiated:

        <script type='text/javascript'>
            var Module = {
                // ...
            };
        </script>

    The first option is to set the `Module.canvas` property to your canvas object:

        <script type='text/javascript'>
            var Module = {
                canvas: my_canvas_object,
            };
        </script>

    When sokol_app.h initializes, it will check the global Module object whether
    a `Module.canvas` property exists and is an object. This method will add
    a new entry to the `specialHTMLTargets[]` object

    The other option is to add the canvas under a name chosen by you to the
    special `specialHTMLTargets[]` map, which is used by the Emscripten runtime
    to lookup 'event target objects' which are not visible to `document.querySelector()`.
    Note that `specialHTMLTargets[]` must be updated after the Emscripten runtime
    has started but before the WASM code is running. A good place for this is
    the special `Module.preRun` array in index.html:

        <script type='text/javascript'>
            var Module = {
                preRun: [
                    () => {
                        specialHTMLTargets['my_canvas'] = my_canvas_object;
                    }
                ],
            };
        </script>

    In that case, pass the same string to sokol_app.h which is used as key
    in the specialHTMLTargets[] map:

        .html5_canvas_selector = "my_canvas"

    If sokol_app.h can't find your canvas for some reason check for warning
    messages on the browser console.


    OPTIONAL: DON'T HIJACK main() (#define SOKOL_NO_ENTRY)
    ======================================================
    NOTE: SOKOL_NO_ENTRY and sapp_run() is currently not supported on Android.

    In its default configuration, sokol_app.h "hijacks" the platform's
    standard main() function. This was done because different platforms
    have different entry point conventions which are not compatible with
    C's main() (for instance WinMain on Windows has completely different
    arguments). However, this "main hijacking" posed a problem for
    usage scenarios like integrating sokol_app.h with other languages than
    C or C++, so an alternative SOKOL_NO_ENTRY mode has been added
    in which the user code provides the platform's main function:

    - define SOKOL_NO_ENTRY before including the sokol_app.h implementation
    - do *not* provide a sokol_main() function
    - instead provide the standard main() function of the platform
    - from the main function, call the function ```sapp_run()``` which
      takes a pointer to an ```sapp_desc``` structure.
    - from here on```sapp_run()``` takes over control and calls the provided
      init-, frame-, event- and cleanup-callbacks just like in the default model.

    sapp_run() behaves differently across platforms:

        - on some platforms, sapp_run() will return when the application quits
        - on other platforms, sapp_run() will never return, even when the
          application quits (the operating system is free to simply terminate
          the application at any time)
        - on Emscripten specifically, sapp_run() will return immediately while
          the frame callback keeps being called

    This different behaviour of sapp_run() essentially means that there shouldn't
    be any code *after* sapp_run(), because that may either never be called, or in
    case of Emscripten will be called at an unexpected time (at application start).

    An application also should not depend on the cleanup-callback being called
    when cross-platform compatibility is required.

    Since sapp_run() returns immediately on Emscripten you shouldn't activate
    the 'EXIT_RUNTIME' linker option (this is disabled by default when compiling
    for the browser target), since the C/C++ exit runtime would be called immediately at
    application start, causing any global objects to be destroyed and global
    variables to be zeroed.

    WINDOWS CONSOLE OUTPUT
    ======================
    On Windows, regular windowed applications don't show any stdout/stderr text
    output, which can be a bit of a hassle for printf() debugging or generally
    logging text to the console. Also, console output by default uses a local
    codepage setting and thus international UTF-8 encoded text is printed
    as garbage.

    To help with these issues, sokol_app.h can be configured at startup
    via the following Windows-specific sapp_desc flags:

        sapp_desc.win32_console_utf8 (default: false)
            When set to true, the output console codepage will be switched
            to UTF-8 (and restored to the original codepage on exit)

        sapp_desc.win32_console_attach (default: false)
            When set to true, stdout and stderr will be attached to the
            console of the parent process (if the parent process actually
            has a console). This means that if the application was started
            in a command line window, stdout and stderr output will be printed
            to the terminal, just like a regular command line program. But if
            the application is started via double-click, it will behave like
            a regular UI application, and stdout/stderr will not be visible.

        sapp_desc.win32_console_create (default: false)
            When set to true, a new console window will be created and
            stdout/stderr will be redirected to that console window. It
            doesn't matter if the application is started from the command
            line or via double-click.

    MEMORY ALLOCATION OVERRIDE
    ==========================
    You can override the memory allocation functions at initialization time
    like this:

        void* my_alloc(size_t size, void* user_data) {
            return malloc(size);
        }

        void my_free(void* ptr, void* user_data) {
            free(ptr);
        }

        sapp_desc sokol_main(int argc, char* argv[]) {
            return (sapp_desc){
                // ...
                .allocator = {
                    .alloc_fn = my_alloc,
                    .free_fn = my_free,
                    .user_data = ...,
                }
            };
        }

    If no overrides are provided, malloc and free will be used.

    This only affects memory allocation calls done by sokol_app.h
    itself though, not any allocations in OS libraries.


    ERROR REPORTING AND LOGGING
    ===========================
    To get any logging information at all you need to provide a logging callback in the setup call
    the easiest way is to use sokol_log.h:

        #include "sokol_log.h"

        sapp_desc sokol_main(int argc, char* argv[]) {
            return (sapp_desc) {
                ...
                .logger.func = slog_func,
            };
        }

    To override logging with your own callback, first write a logging function like this:

        void my_log(const char* tag,                // e.g. 'sapp'
                    uint32_t log_level,             // 0=panic, 1=error, 2=warn, 3=info
                    uint32_t log_item_id,           // SAPP_LOGITEM_*
                    const char* message_or_null,    // a message string, may be nullptr in release mode
                    uint32_t line_nr,               // line number in sokol_app.h
                    const char* filename_or_null,   // source filename, may be nullptr in release mode
                    void* user_data)
        {
            ...
        }

    ...and then setup sokol-app like this:

        sapp_desc sokol_main(int argc, char* argv[]) {
            return (sapp_desc) {
                ...
                .logger = {
                    .func = my_log,
                    .user_data = my_user_data,
                }
            };
        }

    The provided logging function must be reentrant (e.g. be callable from
    different threads).

    If you don't want to provide your own custom logger it is highly recommended to use
    the standard logger in sokol_log.h instead, otherwise you won't see any warnings or
    errors.

    TEMP NOTE DUMP
    ==============
    - sapp_desc needs a bool whether to initialize depth-stencil surface
    - the Android implementation calls cleanup_cb() and destroys the egl context in onDestroy
      at the latest but should do it earlier, in onStop, as an app is "killable" after onStop
      on Android Honeycomb and later (it can't be done at the moment as the app may be started
      again after onStop and the sokol lifecycle does not yet handle context teardown/bringup)


    LICENSE
    =======
    zlib/libpng license

    Copyright (c) 2018 Andre Weissflog

    This software is provided 'as-is', without any express or implied warranty.
    In no event will the authors be held liable for any damages arising from the
    use of this software.

    Permission is granted to anyone to use this software for any purpose,
    including commercial applications, and to alter it and redistribute it
    freely, subject to the following restrictions:

        1. The origin of this software must not be misrepresented; you must not
        claim that you wrote the original software. If you use this software in a
        product, an acknowledgment in the product documentation would be
        appreciated but is not required.

        2. Altered source versions must be plainly marked as such, and must not
        be misrepresented as being the original software.

        3. This notice may not be removed or altered from any source
        distribution.
*/
#define SOKOL_APP_INCLUDED (1)
#include <stddef.h> // size_t
#include <stdint.h>
#include <stdbool.h>

#if defined(SOKOL_API_DECL) && !defined(SOKOL_APP_API_DECL)
#define SOKOL_APP_API_DECL SOKOL_API_DECL
#endif
#ifndef SOKOL_APP_API_DECL
#if defined(_WIN32) && defined(SOKOL_DLL) && defined(SOKOL_APP_IMPL)
#define SOKOL_APP_API_DECL __declspec(dllexport)
#elif defined(_WIN32) && defined(SOKOL_DLL)
#define SOKOL_APP_API_DECL __declspec(dllimport)
#else
#define SOKOL_APP_API_DECL extern
#endif
#endif

#ifdef __cplusplus
extern "C" {
#endif

/* misc constants */
enum {
    SAPP_MAX_TOUCHPOINTS = 8,
    SAPP_MAX_MOUSEBUTTONS = 3,
    SAPP_MAX_KEYCODES = 512,
    SAPP_MAX_ICONIMAGES = 8,
};

/*
    sapp_event_type

    The type of event that's passed to the event handler callback
    in the sapp_event.type field. These are not just "traditional"
    input events, but also notify the application about state changes
    or other user-invoked actions.
*/
typedef enum sapp_event_type {
    SAPP_EVENTTYPE_INVALID,
    SAPP_EVENTTYPE_KEY_DOWN,
    SAPP_EVENTTYPE_KEY_UP,
    SAPP_EVENTTYPE_CHAR,
    SAPP_EVENTTYPE_MOUSE_DOWN,
    SAPP_EVENTTYPE_MOUSE_UP,
    SAPP_EVENTTYPE_MOUSE_SCROLL,
    SAPP_EVENTTYPE_MOUSE_MOVE,
    SAPP_EVENTTYPE_MOUSE_ENTER,
    SAPP_EVENTTYPE_MOUSE_LEAVE,
    SAPP_EVENTTYPE_TOUCHES_BEGAN,
    SAPP_EVENTTYPE_TOUCHES_MOVED,
    SAPP_EVENTTYPE_TOUCHES_ENDED,
    SAPP_EVENTTYPE_TOUCHES_CANCELLED,
    SAPP_EVENTTYPE_RESIZED,
    SAPP_EVENTTYPE_ICONIFIED,
    SAPP_EVENTTYPE_RESTORED,
    SAPP_EVENTTYPE_FOCUSED,
    SAPP_EVENTTYPE_UNFOCUSED,
    SAPP_EVENTTYPE_SUSPENDED,
    SAPP_EVENTTYPE_RESUMED,
    SAPP_EVENTTYPE_QUIT_REQUESTED,
    SAPP_EVENTTYPE_CLIPBOARD_PASTED,
    SAPP_EVENTTYPE_FILES_DROPPED,
    _SAPP_EVENTTYPE_NUM,
    _SAPP_EVENTTYPE_FORCE_U32 = 0x7FFFFFFF
} sapp_event_type;

/*
    sapp_keycode

    The 'virtual keycode' of a KEY_DOWN or KEY_UP event in the
    struct field sapp_event.key_code.

    Note that the keycode values are identical with GLFW.
*/
typedef enum sapp_keycode {
    SAPP_KEYCODE_INVALID          = 0,
    SAPP_KEYCODE_SPACE            = 32,
    SAPP_KEYCODE_APOSTROPHE       = 39,  /* ' */
    SAPP_KEYCODE_COMMA            = 44,  /* , */
    SAPP_KEYCODE_MINUS            = 45,  /* - */
    SAPP_KEYCODE_PERIOD           = 46,  /* . */
    SAPP_KEYCODE_SLASH            = 47,  /* / */
    SAPP_KEYCODE_0                = 48,
    SAPP_KEYCODE_1                = 49,
    SAPP_KEYCODE_2                = 50,
    SAPP_KEYCODE_3                = 51,
    SAPP_KEYCODE_4                = 52,
    SAPP_KEYCODE_5                = 53,
    SAPP_KEYCODE_6                = 54,
    SAPP_KEYCODE_7                = 55,
    SAPP_KEYCODE_8                = 56,
    SAPP_KEYCODE_9                = 57,
    SAPP_KEYCODE_SEMICOLON        = 59,  /* ; */
    SAPP_KEYCODE_EQUAL            = 61,  /* = */
    SAPP_KEYCODE_A                = 65,
    SAPP_KEYCODE_B                = 66,
    SAPP_KEYCODE_C                = 67,
    SAPP_KEYCODE_D                = 68,
    SAPP_KEYCODE_E                = 69,
    SAPP_KEYCODE_F                = 70,
    SAPP_KEYCODE_G                = 71,
    SAPP_KEYCODE_H                = 72,
    SAPP_KEYCODE_I                = 73,
    SAPP_KEYCODE_J                = 74,
    SAPP_KEYCODE_K                = 75,
    SAPP_KEYCODE_L                = 76,
    SAPP_KEYCODE_M                = 77,
    SAPP_KEYCODE_N                = 78,
    SAPP_KEYCODE_O                = 79,
    SAPP_KEYCODE_P                = 80,
    SAPP_KEYCODE_Q                = 81,
    SAPP_KEYCODE_R                = 82,
    SAPP_KEYCODE_S                = 83,
    SAPP_KEYCODE_T                = 84,
    SAPP_KEYCODE_U                = 85,
    SAPP_KEYCODE_V                = 86,
    SAPP_KEYCODE_W                = 87,
    SAPP_KEYCODE_X                = 88,
    SAPP_KEYCODE_Y                = 89,
    SAPP_KEYCODE_Z                = 90,
    SAPP_KEYCODE_LEFT_BRACKET     = 91,  /* [ */
    SAPP_KEYCODE_BACKSLASH        = 92,  /* \ */
    SAPP_KEYCODE_RIGHT_BRACKET    = 93,  /* ] */
    SAPP_KEYCODE_GRAVE_ACCENT     = 96,  /* ` */
    SAPP_KEYCODE_WORLD_1          = 161, /* non-US #1 */
    SAPP_KEYCODE_WORLD_2          = 162, /* non-US #2 */
    SAPP_KEYCODE_ESCAPE           = 256,
    SAPP_KEYCODE_ENTER            = 257,
    SAPP_KEYCODE_TAB              = 258,
    SAPP_KEYCODE_BACKSPACE        = 259,
    SAPP_KEYCODE_INSERT           = 260,
    SAPP_KEYCODE_DELETE           = 261,
    SAPP_KEYCODE_RIGHT            = 262,
    SAPP_KEYCODE_LEFT             = 263,
    SAPP_KEYCODE_DOWN             = 264,
    SAPP_KEYCODE_UP               = 265,
    SAPP_KEYCODE_PAGE_UP          = 266,
    SAPP_KEYCODE_PAGE_DOWN        = 267,
    SAPP_KEYCODE_HOME             = 268,
    SAPP_KEYCODE_END              = 269,
    SAPP_KEYCODE_CAPS_LOCK        = 280,
    SAPP_KEYCODE_SCROLL_LOCK      = 281,
    SAPP_KEYCODE_NUM_LOCK         = 282,
    SAPP_KEYCODE_PRINT_SCREEN     = 283,
    SAPP_KEYCODE_PAUSE            = 284,
    SAPP_KEYCODE_F1               = 290,
    SAPP_KEYCODE_F2               = 291,
    SAPP_KEYCODE_F3               = 292,
    SAPP_KEYCODE_F4               = 293,
    SAPP_KEYCODE_F5               = 294,
    SAPP_KEYCODE_F6               = 295,
    SAPP_KEYCODE_F7               = 296,
    SAPP_KEYCODE_F8               = 297,
    SAPP_KEYCODE_F9               = 298,
    SAPP_KEYCODE_F10              = 299,
    SAPP_KEYCODE_F11              = 300,
    SAPP_KEYCODE_F12              = 301,
    SAPP_KEYCODE_F13              = 302,
    SAPP_KEYCODE_F14              = 303,
    SAPP_KEYCODE_F15              = 304,
    SAPP_KEYCODE_F16              = 305,
    SAPP_KEYCODE_F17              = 306,
    SAPP_KEYCODE_F18              = 307,
    SAPP_KEYCODE_F19              = 308,
    SAPP_KEYCODE_F20              = 309,
    SAPP_KEYCODE_F21              = 310,
    SAPP_KEYCODE_F22              = 311,
    SAPP_KEYCODE_F23              = 312,
    SAPP_KEYCODE_F24              = 313,
    SAPP_KEYCODE_F25              = 314,
    SAPP_KEYCODE_KP_0             = 320,
    SAPP_KEYCODE_KP_1             = 321,
    SAPP_KEYCODE_KP_2             = 322,
    SAPP_KEYCODE_KP_3             = 323,
    SAPP_KEYCODE_KP_4             = 324,
    SAPP_KEYCODE_KP_5             = 325,
    SAPP_KEYCODE_KP_6             = 326,
    SAPP_KEYCODE_KP_7             = 327,
    SAPP_KEYCODE_KP_8             = 328,
    SAPP_KEYCODE_KP_9             = 329,
    SAPP_KEYCODE_KP_DECIMAL       = 330,
    SAPP_KEYCODE_KP_DIVIDE        = 331,
    SAPP_KEYCODE_KP_MULTIPLY      = 332,
    SAPP_KEYCODE_KP_SUBTRACT      = 333,
    SAPP_KEYCODE_KP_ADD           = 334,
    SAPP_KEYCODE_KP_ENTER         = 335,
    SAPP_KEYCODE_KP_EQUAL         = 336,
    SAPP_KEYCODE_LEFT_SHIFT       = 340,
    SAPP_KEYCODE_LEFT_CONTROL     = 341,
    SAPP_KEYCODE_LEFT_ALT         = 342,
    SAPP_KEYCODE_LEFT_SUPER       = 343,
    SAPP_KEYCODE_RIGHT_SHIFT      = 344,
    SAPP_KEYCODE_RIGHT_CONTROL    = 345,
    SAPP_KEYCODE_RIGHT_ALT        = 346,
    SAPP_KEYCODE_RIGHT_SUPER      = 347,
    SAPP_KEYCODE_MENU             = 348,
} sapp_keycode;

/*
    Android specific 'tool type' enum for touch events. This lets the
    application check what type of input device was used for
    touch events.

    NOTE: the values must remain in sync with the corresponding
    Android SDK type, so don't change those.

    See https://developer.android.com/reference/android/view/MotionEvent#TOOL_TYPE_UNKNOWN
*/
typedef enum sapp_android_tooltype {
    SAPP_ANDROIDTOOLTYPE_UNKNOWN = 0,   // TOOL_TYPE_UNKNOWN
    SAPP_ANDROIDTOOLTYPE_FINGER = 1,    // TOOL_TYPE_FINGER
    SAPP_ANDROIDTOOLTYPE_STYLUS = 2,    // TOOL_TYPE_STYLUS
    SAPP_ANDROIDTOOLTYPE_MOUSE = 3,     // TOOL_TYPE_MOUSE
} sapp_android_tooltype;

/*
    sapp_touchpoint

    Describes a single touchpoint in a multitouch event (TOUCHES_BEGAN,
    TOUCHES_MOVED, TOUCHES_ENDED).

    Touch points are stored in the nested array sapp_event.touches[],
    and the number of touches is stored in sapp_event.num_touches.
*/
typedef struct sapp_touchpoint {
    uintptr_t identifier;
    float pos_x;
    float pos_y;
    sapp_android_tooltype android_tooltype; // only valid on Android
    bool changed;
} sapp_touchpoint;

/*
    sapp_mousebutton

    The currently pressed mouse button in the events MOUSE_DOWN
    and MOUSE_UP, stored in the struct field sapp_event.mouse_button.
*/
typedef enum sapp_mousebutton {
    SAPP_MOUSEBUTTON_LEFT = 0x0,
    SAPP_MOUSEBUTTON_RIGHT = 0x1,
    SAPP_MOUSEBUTTON_MIDDLE = 0x2,
    SAPP_MOUSEBUTTON_INVALID = 0x100,
} sapp_mousebutton;

/*
    These are currently pressed modifier keys (and mouse buttons) which are
    passed in the event struct field sapp_event.modifiers.
*/
enum {
    SAPP_MODIFIER_SHIFT = 0x1,      // left or right shift key
    SAPP_MODIFIER_CTRL  = 0x2,      // left or right control key
    SAPP_MODIFIER_ALT   = 0x4,      // left or right alt key
    SAPP_MODIFIER_SUPER = 0x8,      // left or right 'super' key
    SAPP_MODIFIER_LMB   = 0x100,    // left mouse button
    SAPP_MODIFIER_RMB   = 0x200,    // right mouse button
    SAPP_MODIFIER_MMB   = 0x400,    // middle mouse button
};

/*
    sapp_event

    This is an all-in-one event struct passed to the event handler
    user callback function. Note that it depends on the event
    type what struct fields actually contain useful values, so you
    should first check the event type before reading other struct
    fields.
*/
typedef struct sapp_event {
    uint64_t frame_count;               // current frame counter, always valid, useful for checking if two events were issued in the same frame
    sapp_event_type type;               // the event type, always valid
    sapp_keycode key_code;              // the virtual key code, only valid in KEY_UP, KEY_DOWN
    uint32_t char_code;                 // the UTF-32 character code, only valid in CHAR events
    bool key_repeat;                    // true if this is a key-repeat event, valid in KEY_UP, KEY_DOWN and CHAR
    uint32_t modifiers;                 // current modifier keys, valid in all key-, char- and mouse-events
    sapp_mousebutton mouse_button;      // mouse button that was pressed or released, valid in MOUSE_DOWN, MOUSE_UP
    float mouse_x;                      // current horizontal mouse position in pixels, always valid except during mouse lock
    float mouse_y;                      // current vertical mouse position in pixels, always valid except during mouse lock
    float mouse_dx;                     // relative horizontal mouse movement since last frame, always valid
    float mouse_dy;                     // relative vertical mouse movement since last frame, always valid
    float scroll_x;                     // horizontal mouse wheel scroll distance, valid in MOUSE_SCROLL events
    float scroll_y;                     // vertical mouse wheel scroll distance, valid in MOUSE_SCROLL events
    int num_touches;                    // number of valid items in the touches[] array
    sapp_touchpoint touches[SAPP_MAX_TOUCHPOINTS];  // current touch points, valid in TOUCHES_BEGIN, TOUCHES_MOVED, TOUCHES_ENDED
    int window_width;                   // current window- and framebuffer sizes in pixels, always valid
    int window_height;
    int framebuffer_width;              // = window_width * dpi_scale
    int framebuffer_height;             // = window_height * dpi_scale
} sapp_event;

/*
    sg_range

    A general pointer/size-pair struct and constructor macros for passing binary blobs
    into sokol_app.h.
*/
typedef struct sapp_range {
    const void* ptr;
    size_t size;
} sapp_range;
// disabling this for every includer isn't great, but the warnings are also quite pointless
#if defined(_MSC_VER)
#pragma warning(disable:4221)   /* /W4 only: nonstandard extension used: 'x': cannot be initialized using address of automatic variable 'y' */
#pragma warning(disable:4204)   /* VS2015: nonstandard extension used: non-constant aggregate initializer */
#endif
#if defined(__cplusplus)
#define SAPP_RANGE(x) sapp_range{ &x, sizeof(x) }
#else
#define SAPP_RANGE(x) (sapp_range){ &x, sizeof(x) }
#endif

/*
    sapp_image_desc

    This is used to describe image data to sokol_app.h (at first, window
    icons, later maybe cursor images).

    Note that the actual image pixel format depends on the use case:

    - window icon pixels are RGBA8
*/
typedef struct sapp_image_desc {
    int width;
    int height;
    sapp_range pixels;
} sapp_image_desc;

/*
    sapp_icon_desc

    An icon description structure for use in sapp_desc.icon and
    sapp_set_icon().

    When setting a custom image, the application can provide a number of
    candidates differing in size, and sokol_app.h will pick the image(s)
    closest to the size expected by the platform's window system.

    To set sokol-app's default icon, set .sokol_default to true.

    Otherwise provide candidate images of different sizes in the
    images[] array.

    If both the sokol_default flag is set to true, any image candidates
    will be ignored and the sokol_app.h default icon will be set.
*/
typedef struct sapp_icon_desc {
    bool sokol_default;
    sapp_image_desc images[SAPP_MAX_ICONIMAGES];
} sapp_icon_desc;

/*
    sapp_allocator

    Used in sapp_desc to provide custom memory-alloc and -free functions
    to sokol_app.h. If memory management should be overridden, both the
    alloc_fn and free_fn function must be provided (e.g. it's not valid to
    override one function but not the other).
*/
typedef struct sapp_allocator {
    void* (*alloc_fn)(size_t size, void* user_data);
    void (*free_fn)(void* ptr, void* user_data);
    void* user_data;
} sapp_allocator;

/*
    sapp_log_item

    Log items are defined via X-Macros and expanded to an enum
    'sapp_log_item', and in debug mode to corresponding
    human readable error messages.
*/
#define _SAPP_LOG_ITEMS \
    _SAPP_LOGITEM_XMACRO(OK, "Ok") \
    _SAPP_LOGITEM_XMACRO(MALLOC_FAILED, "memory allocation failed") \
    _SAPP_LOGITEM_XMACRO(MACOS_INVALID_NSOPENGL_PROFILE, "macos: invalid NSOpenGLProfile (valid choices are 1.0 and 4.1)") \
    _SAPP_LOGITEM_XMACRO(WIN32_LOAD_OPENGL32_DLL_FAILED, "failed loading opengl32.dll") \
    _SAPP_LOGITEM_XMACRO(WIN32_CREATE_HELPER_WINDOW_FAILED, "failed to create helper window") \
    _SAPP_LOGITEM_XMACRO(WIN32_HELPER_WINDOW_GETDC_FAILED, "failed to get helper window DC") \
    _SAPP_LOGITEM_XMACRO(WIN32_DUMMY_CONTEXT_SET_PIXELFORMAT_FAILED, "failed to set pixel format for dummy GL context") \
    _SAPP_LOGITEM_XMACRO(WIN32_CREATE_DUMMY_CONTEXT_FAILED, "failed to create dummy GL context") \
    _SAPP_LOGITEM_XMACRO(WIN32_DUMMY_CONTEXT_MAKE_CURRENT_FAILED, "failed to make dummy GL context current") \
    _SAPP_LOGITEM_XMACRO(WIN32_GET_PIXELFORMAT_ATTRIB_FAILED, "failed to get WGL pixel format attribute") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_FIND_PIXELFORMAT_FAILED, "failed to find matching WGL pixel format") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_DESCRIBE_PIXELFORMAT_FAILED, "failed to get pixel format descriptor") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_SET_PIXELFORMAT_FAILED, "failed to set selected pixel format") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_ARB_CREATE_CONTEXT_REQUIRED, "ARB_create_context required") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_ARB_CREATE_CONTEXT_PROFILE_REQUIRED, "ARB_create_context_profile required") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_OPENGL_VERSION_NOT_SUPPORTED, "requested OpenGL version not supported by GL driver (ERROR_INVALID_VERSION_ARB)") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_OPENGL_PROFILE_NOT_SUPPORTED, "requested OpenGL profile not support by GL driver (ERROR_INVALID_PROFILE_ARB)") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_INCOMPATIBLE_DEVICE_CONTEXT, "CreateContextAttribsARB failed with ERROR_INCOMPATIBLE_DEVICE_CONTEXTS_ARB") \
    _SAPP_LOGITEM_XMACRO(WIN32_WGL_CREATE_CONTEXT_ATTRIBS_FAILED_OTHER, "CreateContextAttribsARB failed for other reason") \
    _SAPP_LOGITEM_XMACRO(WIN32_D3D11_CREATE_DEVICE_AND_SWAPCHAIN_WITH_DEBUG_FAILED, "D3D11CreateDeviceAndSwapChain() with D3D11_CREATE_DEVICE_DEBUG failed, retrying without debug flag.") \
    _SAPP_LOGITEM_XMACRO(WIN32_D3D11_GET_IDXGIFACTORY_FAILED, "could not obtain IDXGIFactory object") \
    _SAPP_LOGITEM_XMACRO(WIN32_D3D11_GET_IDXGIADAPTER_FAILED, "could not obtain IDXGIAdapter object") \
    _SAPP_LOGITEM_XMACRO(WIN32_D3D11_QUERY_INTERFACE_IDXGIDEVICE1_FAILED, "could not obtain IDXGIDevice1 interface") \
    _SAPP_LOGITEM_XMACRO(WIN32_REGISTER_RAW_INPUT_DEVICES_FAILED_MOUSE_LOCK, "RegisterRawInputDevices() failed (on mouse lock)") \
    _SAPP_LOGITEM_XMACRO(WIN32_REGISTER_RAW_INPUT_DEVICES_FAILED_MOUSE_UNLOCK, "RegisterRawInputDevices() failed (on mouse unlock)") \
    _SAPP_LOGITEM_XMACRO(WIN32_GET_RAW_INPUT_DATA_FAILED, "GetRawInputData() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_LOAD_LIBGL_FAILED, "failed to load libGL") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_LOAD_ENTRY_POINTS_FAILED, "failed to load GLX entry points") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_EXTENSION_NOT_FOUND, "GLX extension not found") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_QUERY_VERSION_FAILED, "failed to query GLX version") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_VERSION_TOO_LOW, "GLX version too low (need at least 1.3)") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_NO_GLXFBCONFIGS, "glXGetFBConfigs() returned no configs") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_NO_SUITABLE_GLXFBCONFIG, "failed to find a suitable GLXFBConfig") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_GET_VISUAL_FROM_FBCONFIG_FAILED, "glXGetVisualFromFBConfig failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_REQUIRED_EXTENSIONS_MISSING, "GLX extensions ARB_create_context and ARB_create_context_profile missing") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_CREATE_CONTEXT_FAILED, "Failed to create GL context via glXCreateContextAttribsARB") \
    _SAPP_LOGITEM_XMACRO(LINUX_GLX_CREATE_WINDOW_FAILED, "glXCreateWindow() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_X11_CREATE_WINDOW_FAILED, "XCreateWindow() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_BIND_OPENGL_API_FAILED, "eglBindAPI(EGL_OPENGL_API) failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_BIND_OPENGL_ES_API_FAILED, "eglBindAPI(EGL_OPENGL_ES_API) failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_GET_DISPLAY_FAILED, "eglGetDisplay() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_INITIALIZE_FAILED, "eglInitialize() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_NO_CONFIGS, "eglChooseConfig() returned no configs") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_NO_NATIVE_VISUAL, "eglGetConfigAttrib() for EGL_NATIVE_VISUAL_ID failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_GET_VISUAL_INFO_FAILED, "XGetVisualInfo() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_CREATE_WINDOW_SURFACE_FAILED, "eglCreateWindowSurface() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_CREATE_CONTEXT_FAILED, "eglCreateContext() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_EGL_MAKE_CURRENT_FAILED, "eglMakeCurrent() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_X11_OPEN_DISPLAY_FAILED, "XOpenDisplay() failed") \
    _SAPP_LOGITEM_XMACRO(LINUX_X11_QUERY_SYSTEM_DPI_FAILED, "failed to query system dpi value, assuming default 96.0") \
    _SAPP_LOGITEM_XMACRO(LINUX_X11_DROPPED_FILE_URI_WRONG_SCHEME, "dropped file URL doesn't start with 'file://'") \
    _SAPP_LOGITEM_XMACRO(LINUX_X11_FAILED_TO_BECOME_OWNER_OF_CLIPBOARD, "X11: Failed to become owner of clipboard selection") \
    _SAPP_LOGITEM_XMACRO(ANDROID_UNSUPPORTED_INPUT_EVENT_INPUT_CB, "unsupported input event encountered in _sapp_android_input_cb()") \
    _SAPP_LOGITEM_XMACRO(ANDROID_UNSUPPORTED_INPUT_EVENT_MAIN_CB, "unsupported input event encountered in _sapp_android_main_cb()") \
    _SAPP_LOGITEM_XMACRO(ANDROID_READ_MSG_FAILED, "failed to read message in _sapp_android_main_cb()") \
    _SAPP_LOGITEM_XMACRO(ANDROID_WRITE_MSG_FAILED, "failed to write message in _sapp_android_msg") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_CREATE, "MSG_CREATE") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_RESUME, "MSG_RESUME") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_PAUSE, "MSG_PAUSE") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_FOCUS, "MSG_FOCUS") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_NO_FOCUS, "MSG_NO_FOCUS") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_SET_NATIVE_WINDOW, "MSG_SET_NATIVE_WINDOW") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_SET_INPUT_QUEUE, "MSG_SET_INPUT_QUEUE") \
    _SAPP_LOGITEM_XMACRO(ANDROID_MSG_DESTROY, "MSG_DESTROY") \
    _SAPP_LOGITEM_XMACRO(ANDROID_UNKNOWN_MSG, "unknown msg type received") \
    _SAPP_LOGITEM_XMACRO(ANDROID_LOOP_THREAD_STARTED, "loop thread started") \
    _SAPP_LOGITEM_XMACRO(ANDROID_LOOP_THREAD_DONE, "loop thread done") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONSTART, "NativeActivity onStart()") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONRESUME, "NativeActivity onResume") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONSAVEINSTANCESTATE, "NativeActivity onSaveInstanceState") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONWINDOWFOCUSCHANGED, "NativeActivity onWindowFocusChanged") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONPAUSE, "NativeActivity onPause") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONSTOP, "NativeActivity onStop()") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONNATIVEWINDOWCREATED, "NativeActivity onNativeWindowCreated") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONNATIVEWINDOWDESTROYED, "NativeActivity onNativeWindowDestroyed") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONINPUTQUEUECREATED, "NativeActivity onInputQueueCreated") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONINPUTQUEUEDESTROYED, "NativeActivity onInputQueueDestroyed") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONCONFIGURATIONCHANGED, "NativeActivity onConfigurationChanged") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONLOWMEMORY, "NativeActivity onLowMemory") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONDESTROY, "NativeActivity onDestroy") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_DONE, "NativeActivity done") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_ONCREATE, "NativeActivity onCreate") \
    _SAPP_LOGITEM_XMACRO(ANDROID_CREATE_THREAD_PIPE_FAILED, "failed to create thread pipe") \
    _SAPP_LOGITEM_XMACRO(ANDROID_NATIVE_ACTIVITY_CREATE_SUCCESS, "NativeActivity successfully created") \
    _SAPP_LOGITEM_XMACRO(WGPU_SWAPCHAIN_CREATE_SURFACE_FAILED, "wgpu: failed to create surface for swapchain") \
    _SAPP_LOGITEM_XMACRO(WGPU_SWAPCHAIN_CREATE_SWAPCHAIN_FAILED, "wgpu: failed to create swapchain object") \
    _SAPP_LOGITEM_XMACRO(WGPU_SWAPCHAIN_CREATE_DEPTH_STENCIL_TEXTURE_FAILED, "wgpu: failed to create depth-stencil texture for swapchain") \
    _SAPP_LOGITEM_XMACRO(WGPU_SWAPCHAIN_CREATE_DEPTH_STENCIL_VIEW_FAILED, "wgpu: failed to create view object for swapchain depth-stencil texture") \
    _SAPP_LOGITEM_XMACRO(WGPU_SWAPCHAIN_CREATE_MSAA_TEXTURE_FAILED, "wgpu: failed to create msaa texture for swapchain") \
    _SAPP_LOGITEM_XMACRO(WGPU_SWAPCHAIN_CREATE_MSAA_VIEW_FAILED, "wgpu: failed to create view object for swapchain msaa texture") \
    _SAPP_LOGITEM_XMACRO(WGPU_REQUEST_DEVICE_STATUS_ERROR, "wgpu: requesting device failed with status 'error'") \
    _SAPP_LOGITEM_XMACRO(WGPU_REQUEST_DEVICE_STATUS_UNKNOWN, "wgpu: requesting device failed with status 'unknown'") \
    _SAPP_LOGITEM_XMACRO(WGPU_REQUEST_ADAPTER_STATUS_UNAVAILABLE, "wgpu: requesting adapter failed with 'unavailable'") \
    _SAPP_LOGITEM_XMACRO(WGPU_REQUEST_ADAPTER_STATUS_ERROR, "wgpu: requesting adapter failed with status 'error'") \
    _SAPP_LOGITEM_XMACRO(WGPU_REQUEST_ADAPTER_STATUS_UNKNOWN, "wgpu: requesting adapter failed with status 'unknown'") \
    _SAPP_LOGITEM_XMACRO(WGPU_CREATE_INSTANCE_FAILED, "wgpu: failed to create instance") \
    _SAPP_LOGITEM_XMACRO(IMAGE_DATA_SIZE_MISMATCH, "image data size mismatch (must be width*height*4 bytes)") \
    _SAPP_LOGITEM_XMACRO(DROPPED_FILE_PATH_TOO_LONG, "dropped file path too long (sapp_desc.max_dropped_filed_path_length)") \
    _SAPP_LOGITEM_XMACRO(CLIPBOARD_STRING_TOO_BIG, "clipboard string didn't fit into clipboard buffer") \

#define _SAPP_LOGITEM_XMACRO(item,msg) SAPP_LOGITEM_##item,
typedef enum sapp_log_item {
    _SAPP_LOG_ITEMS
} sapp_log_item;
#undef _SAPP_LOGITEM_XMACRO

/*
    sapp_logger

    Used in sapp_desc to provide a logging function. Please be aware that
    without logging function, sokol-app will be completely silent, e.g. it will
    not report errors or warnings. For maximum error verbosity, compile in
    debug mode (e.g. NDEBUG *not* defined) and install a logger (for instance
    the standard logging function from sokol_log.h).
*/
typedef struct sapp_logger {
    void (*func)(
        const char* tag,                // always "sapp"
        uint32_t log_level,             // 0=panic, 1=error, 2=warning, 3=info
        uint32_t log_item_id,           // SAPP_LOGITEM_*
        const char* message_or_null,    // a message string, may be nullptr in release mode
        uint32_t line_nr,               // line number in sokol_app.h
        const char* filename_or_null,   // source filename, may be nullptr in release mode
        void* user_data);
    void* user_data;
} sapp_logger;

/*
    sokol-app initialization options, used as return value of sokol_main()
    or sapp_run() argument.
*/
typedef struct sapp_desc {
    void (*init_cb)(void);                  // these are the user-provided callbacks without user data
    void (*frame_cb)(void);
    void (*cleanup_cb)(void);
    void (*event_cb)(const sapp_event*);

    void* user_data;                        // these are the user-provided callbacks with user data
    void (*init_userdata_cb)(void*);
    void (*frame_userdata_cb)(void*);
    void (*cleanup_userdata_cb)(void*);
    void (*event_userdata_cb)(const sapp_event*, void*);

    int width;                          // the preferred width of the window / canvas
    int height;                         // the preferred height of the window / canvas
    int sample_count;                   // MSAA sample count
    int swap_interval;                  // the preferred swap interval (ignored on some platforms)
    bool high_dpi;                      // whether the rendering canvas is full-resolution on HighDPI displays
    bool fullscreen;                    // whether the window should be created in fullscreen mode
    bool alpha;                         // whether the framebuffer should have an alpha channel (ignored on some platforms)
    const char* window_title;           // the window title as UTF-8 encoded string
    bool enable_clipboard;              // enable clipboard access, default is false
    int clipboard_size;                 // max size of clipboard content in bytes
    bool enable_dragndrop;              // enable file dropping (drag'n'drop), default is false
    int max_dropped_files;              // max number of dropped files to process (default: 1)
    int max_dropped_file_path_length;   // max length in bytes of a dropped UTF-8 file path (default: 2048)
    sapp_icon_desc icon;                // the initial window icon to set
    sapp_allocator allocator;           // optional memory allocation overrides (default: malloc/free)
    sapp_logger logger;                 // logging callback override (default: NO LOGGING!)

    // backend-specific options
    int gl_major_version;               // override GL/GLES major and minor version (defaults: GL4.1 (macOS) or GL4.3, GLES3.1 (Android) or GLES3.0
    int gl_minor_version;
    bool win32_console_utf8;            // if true, set the output console codepage to UTF-8
    bool win32_console_create;          // if true, attach stdout/stderr to a new console window
    bool win32_console_attach;          // if true, attach stdout/stderr to parent process
    const char* html5_canvas_selector;  // css selector of the HTML5 canvas element, default is "#canvas"
    bool html5_canvas_resize;           // if true, the HTML5 canvas size is set to sapp_desc.width/height, otherwise canvas size is tracked
    bool html5_preserve_drawing_buffer; // HTML5 only: whether to preserve default framebuffer content between frames
    bool html5_premultiplied_alpha;     // HTML5 only: whether the rendered pixels use premultiplied alpha convention
    bool html5_ask_leave_site;          // initial state of the internal html5_ask_leave_site flag (see sapp_html5_ask_leave_site())
    bool html5_update_document_title;   // if true, update the HTML document.title with sapp_desc.window_title
    bool html5_bubble_mouse_events;     // if true, mouse events will bubble up to the web page
    bool html5_bubble_touch_events;     // same for touch events
    bool html5_bubble_wheel_events;     // same for wheel events
    bool html5_bubble_key_events;       // if true, bubble up *all* key events to browser, not just key events that represent characters
    bool html5_bubble_char_events;      // if true, bubble up character events to browser
    bool html5_use_emsc_set_main_loop;  // if true, use emscripten_set_main_loop() instead of emscripten_request_animation_frame_loop()
    bool html5_emsc_set_main_loop_simulate_infinite_loop;   // this will be passed as the simulate_infinite_loop arg to emscripten_set_main_loop()
    bool ios_keyboard_resizes_canvas;   // if true, showing the iOS keyboard shrinks the canvas
} sapp_desc;

/* HTML5 specific: request and response structs for
   asynchronously loading dropped-file content.
*/
typedef enum sapp_html5_fetch_error {
    SAPP_HTML5_FETCH_ERROR_NO_ERROR,
    SAPP_HTML5_FETCH_ERROR_BUFFER_TOO_SMALL,
    SAPP_HTML5_FETCH_ERROR_OTHER,
} sapp_html5_fetch_error;

typedef struct sapp_html5_fetch_response {
    bool succeeded;         // true if the loading operation has succeeded
    sapp_html5_fetch_error error_code;
    int file_index;         // index of the dropped file (0..sapp_get_num_dropped_filed()-1)
    sapp_range data;        // pointer and size of the fetched data (data.ptr == buffer.ptr, data.size <= buffer.size)
    sapp_range buffer;      // the user-provided buffer ptr/size pair (buffer.ptr == data.ptr, buffer.size >= data.size)
    void* user_data;        // user-provided user data pointer
} sapp_html5_fetch_response;

typedef struct sapp_html5_fetch_request {
    int dropped_file_index; // 0..sapp_get_num_dropped_files()-1
    void (*callback)(const sapp_html5_fetch_response*);     // response callback function pointer (required)
    sapp_range buffer;      // ptr/size of a memory buffer to load the data into
    void* user_data;        // optional userdata pointer
} sapp_html5_fetch_request;

/*
    sapp_mouse_cursor

    Predefined cursor image definitions, set with sapp_set_mouse_cursor(sapp_mouse_cursor cursor)
*/
typedef enum sapp_mouse_cursor {
    SAPP_MOUSECURSOR_DEFAULT = 0,   // equivalent with system default cursor
    SAPP_MOUSECURSOR_ARROW,
    SAPP_MOUSECURSOR_IBEAM,
    SAPP_MOUSECURSOR_CROSSHAIR,
    SAPP_MOUSECURSOR_POINTING_HAND,
    SAPP_MOUSECURSOR_RESIZE_EW,
    SAPP_MOUSECURSOR_RESIZE_NS,
    SAPP_MOUSECURSOR_RESIZE_NWSE,
    SAPP_MOUSECURSOR_RESIZE_NESW,
    SAPP_MOUSECURSOR_RESIZE_ALL,
    SAPP_MOUSECURSOR_NOT_ALLOWED,
    _SAPP_MOUSECURSOR_NUM,
} sapp_mouse_cursor;

/* user-provided functions */
extern sapp_desc sokol_main(int argc, char* argv[]);

/* returns true after sokol-app has been initialized */
SOKOL_APP_API_DECL bool sapp_isvalid(void);
/* returns the current framebuffer width in pixels */
SOKOL_APP_API_DECL int sapp_width(void);
/* same as sapp_width(), but returns float */
SOKOL_APP_API_DECL float sapp_widthf(void);
/* returns the current framebuffer height in pixels */
SOKOL_APP_API_DECL int sapp_height(void);
/* same as sapp_height(), but returns float */
SOKOL_APP_API_DECL float sapp_heightf(void);
/* get default framebuffer color pixel format */
SOKOL_APP_API_DECL int sapp_color_format(void);
/* get default framebuffer depth pixel format */
SOKOL_APP_API_DECL int sapp_depth_format(void);
/* get default framebuffer sample count */
SOKOL_APP_API_DECL int sapp_sample_count(void);
/* returns true when high_dpi was requested and actually running in a high-dpi scenario */
SOKOL_APP_API_DECL bool sapp_high_dpi(void);
/* returns the dpi scaling factor (window pixels to framebuffer pixels) */
SOKOL_APP_API_DECL float sapp_dpi_scale(void);
/* show or hide the mobile device onscreen keyboard */
SOKOL_APP_API_DECL void sapp_show_keyboard(bool show);
/* return true if the mobile device onscreen keyboard is currently shown */
SOKOL_APP_API_DECL bool sapp_keyboard_shown(void);
/* query fullscreen mode */
SOKOL_APP_API_DECL bool sapp_is_fullscreen(void);
/* toggle fullscreen mode */
SOKOL_APP_API_DECL void sapp_toggle_fullscreen(void);
/* show or hide the mouse cursor */
SOKOL_APP_API_DECL void sapp_show_mouse(bool show);
/* show or hide the mouse cursor */
SOKOL_APP_API_DECL bool sapp_mouse_shown(void);
/* enable/disable mouse-pointer-lock mode */
SOKOL_APP_API_DECL void sapp_lock_mouse(bool lock);
/* return true if in mouse-pointer-lock mode (this may toggle a few frames later) */
SOKOL_APP_API_DECL bool sapp_mouse_locked(void);
/* set mouse cursor type */
SOKOL_APP_API_DECL void sapp_set_mouse_cursor(sapp_mouse_cursor cursor);
/* get current mouse cursor type */
SOKOL_APP_API_DECL sapp_mouse_cursor sapp_get_mouse_cursor(void);
/* return the userdata pointer optionally provided in sapp_desc */
SOKOL_APP_API_DECL void* sapp_userdata(void);
/* return a copy of the sapp_desc structure */
SOKOL_APP_API_DECL sapp_desc sapp_query_desc(void);
/* initiate a "soft quit" (sends SAPP_EVENTTYPE_QUIT_REQUESTED) */
SOKOL_APP_API_DECL void sapp_request_quit(void);
/* cancel a pending quit (when SAPP_EVENTTYPE_QUIT_REQUESTED has been received) */
SOKOL_APP_API_DECL void sapp_cancel_quit(void);
/* initiate a "hard quit" (quit application without sending SAPP_EVENTTYPE_QUIT_REQUESTED) */
SOKOL_APP_API_DECL void sapp_quit(void);
/* call from inside event callback to consume the current event (don't forward to platform) */
SOKOL_APP_API_DECL void sapp_consume_event(void);
/* get the current frame counter (for comparison with sapp_event.frame_count) */
SOKOL_APP_API_DECL uint64_t sapp_frame_count(void);
/* get an averaged/smoothed frame duration in seconds */
SOKOL_APP_API_DECL double sapp_frame_duration(void);
/* write string into clipboard */
SOKOL_APP_API_DECL void sapp_set_clipboard_string(const char* str);
/* read string from clipboard (usually during SAPP_EVENTTYPE_CLIPBOARD_PASTED) */
SOKOL_APP_API_DECL const char* sapp_get_clipboard_string(void);
/* set the window title (only on desktop platforms) */
SOKOL_APP_API_DECL void sapp_set_window_title(const char* str);
/* set the window icon (only on Windows and Linux) */
SOKOL_APP_API_DECL void sapp_set_icon(const sapp_icon_desc* icon_desc);
/* gets the total number of dropped files (after an SAPP_EVENTTYPE_FILES_DROPPED event) */
SOKOL_APP_API_DECL int sapp_get_num_dropped_files(void);
/* gets the dropped file paths */
SOKOL_APP_API_DECL const char* sapp_get_dropped_file_path(int index);

/* special run-function for SOKOL_NO_ENTRY (in standard mode this is an empty stub) */
SOKOL_APP_API_DECL void sapp_run(const sapp_desc* desc);

/* EGL: get EGLDisplay object */
SOKOL_APP_API_DECL const void* sapp_egl_get_display(void);
/* EGL: get EGLContext object */
SOKOL_APP_API_DECL const void* sapp_egl_get_context(void);

/* HTML5: enable or disable the hardwired "Leave Site?" dialog box */
SOKOL_APP_API_DECL void sapp_html5_ask_leave_site(bool ask);
/* HTML5: get byte size of a dropped file */
SOKOL_APP_API_DECL uint32_t sapp_html5_get_dropped_file_size(int index);
/* HTML5: asynchronously load the content of a dropped file */
SOKOL_APP_API_DECL void sapp_html5_fetch_dropped_file(const sapp_html5_fetch_request* request);

/* Metal: get bridged pointer to Metal device object */
SOKOL_APP_API_DECL const void* sapp_metal_get_device(void);
/* Metal: get bridged pointer to MTKView's current drawable of type CAMetalDrawable */
SOKOL_APP_API_DECL const void* sapp_metal_get_current_drawable(void);
/* Metal: get bridged pointer to MTKView's depth-stencil texture of type MTLTexture */
SOKOL_APP_API_DECL const void* sapp_metal_get_depth_stencil_texture(void);
/* Metal: get bridged pointer to MTKView's msaa-color-texture of type MTLTexture (may be null) */
SOKOL_APP_API_DECL const void* sapp_metal_get_msaa_color_texture(void);
/* macOS: get bridged pointer to macOS NSWindow */
SOKOL_APP_API_DECL const void* sapp_macos_get_window(void);
/* iOS: get bridged pointer to iOS UIWindow */
SOKOL_APP_API_DECL const void* sapp_ios_get_window(void);

/* D3D11: get pointer to ID3D11Device object */
SOKOL_APP_API_DECL const void* sapp_d3d11_get_device(void);
/* D3D11: get pointer to ID3D11DeviceContext object */
SOKOL_APP_API_DECL const void* sapp_d3d11_get_device_context(void);
/* D3D11: get pointer to IDXGISwapChain object */
SOKOL_APP_API_DECL const void* sapp_d3d11_get_swap_chain(void);
/* D3D11: get pointer to ID3D11RenderTargetView object for rendering */
SOKOL_APP_API_DECL const void* sapp_d3d11_get_render_view(void);
/* D3D11: get pointer ID3D11RenderTargetView object for msaa-resolve (may return null) */
SOKOL_APP_API_DECL const void* sapp_d3d11_get_resolve_view(void);
/* D3D11: get pointer ID3D11DepthStencilView */
SOKOL_APP_API_DECL const void* sapp_d3d11_get_depth_stencil_view(void);
/* Win32: get the HWND window handle */
SOKOL_APP_API_DECL const void* sapp_win32_get_hwnd(void);

/* WebGPU: get WGPUDevice handle */
SOKOL_APP_API_DECL const void* sapp_wgpu_get_device(void);
/* WebGPU: get swapchain's WGPUTextureView handle for rendering */
SOKOL_APP_API_DECL const void* sapp_wgpu_get_render_view(void);
/* WebGPU: get swapchain's MSAA-resolve WGPUTextureView (may return null) */
SOKOL_APP_API_DECL const void* sapp_wgpu_get_resolve_view(void);
/* WebGPU: get swapchain's WGPUTextureView for the depth-stencil surface */
SOKOL_APP_API_DECL const void* sapp_wgpu_get_depth_stencil_view(void);

/* GL: get framebuffer object */
SOKOL_APP_API_DECL uint32_t sapp_gl_get_framebuffer(void);
/* GL: get major version */
SOKOL_APP_API_DECL int sapp_gl_get_major_version(void);
/* GL: get minor version */
SOKOL_APP_API_DECL int sapp_gl_get_minor_version(void);
/* GL: return true if the context is GLES */
SOKOL_APP_API_DECL bool sapp_gl_is_gles(void);

/* X11: get Window */
SOKOL_APP_API_DECL const void* sapp_x11_get_window(void);
/* X11: get Display */
SOKOL_APP_API_DECL const void* sapp_x11_get_display(void);

/* Android: get native activity handle */
SOKOL_APP_API_DECL const void* sapp_android_get_native_activity(void);

#ifdef __cplusplus
} /* extern "C" */

/* reference-based equivalents for C++ */
inline void sapp_run(const sapp_desc& desc) { return sapp_run(&desc); }

#endif

#endif // SOKOL_APP_INCLUDED

// ██ ███    ███ ██████  ██      ███████ ███    ███ ███████ ███    ██ ████████  █████  ████████ ██  ██████  ███    ██
// ██ ████  ████ ██   ██ ██      ██      ████  ████ ██      ████   ██    ██    ██   ██    ██    ██ ██    ██ ████   ██
// ██ ██ ████ ██ ██████  ██      █████   ██ ████ ██ █████   ██ ██  ██    ██    ███████    ██    ██ ██    ██ ██ ██  ██
// ██ ██  ██  ██ ██      ██      ██      ██  ██  ██ ██      ██  ██ ██    ██    ██   ██    ██    ██ ██    ██ ██  ██ ██
// ██ ██      ██ ██      ███████ ███████ ██      ██ ███████ ██   ████    ██    ██   ██    ██    ██  ██████  ██   ████
//
// >>implementation
#ifdef SOKOL_APP_IMPL
#define SOKOL_APP_IMPL_INCLUDED (1)

#if defined(SOKOL_MALLOC) || defined(SOKOL_CALLOC) || defined(SOKOL_FREE)
#error "SOKOL_MALLOC/CALLOC/FREE macros are no longer supported, please use sapp_desc.allocator to override memory allocation functions"
#endif

#include <stdlib.h> // malloc, free
#include <string.h> // memset, strncmp
#include <stddef.h> // size_t
#include <math.h>   // roundf

// helper macros
#define _sapp_def(val, def) (((val) == 0) ? (def) : (val))
#define _sapp_absf(a) (((a)<0.0f)?-(a):(a))

#define _SAPP_MAX_TITLE_LENGTH (128)
#define _SAPP_FALLBACK_DEFAULT_WINDOW_WIDTH (640)
#define _SAPP_FALLBACK_DEFAULT_WINDOW_HEIGHT (480)
// NOTE: the pixel format values *must* be compatible with sg_pixel_format
#define _SAPP_PIXELFORMAT_RGBA8 (23)
#define _SAPP_PIXELFORMAT_BGRA8 (28)
#define _SAPP_PIXELFORMAT_DEPTH (43)
#define _SAPP_PIXELFORMAT_DEPTH_STENCIL (44)

// check if the config defines are alright
#if defined(__APPLE__)
    // see https://clang.llvm.org/docs/LanguageExtensions.html#automatic-reference-counting
    #if !defined(__cplusplus)
        #if __has_feature(objc_arc) && !__has_feature(objc_arc_fields)
            #error "sokol_app.h requires __has_feature(objc_arc_field) if ARC is enabled (use a more recent compiler version)"
        #endif
    #endif
    #define _SAPP_APPLE (1)
    #include <TargetConditionals.h>
    #if defined(TARGET_OS_IPHONE) && !TARGET_OS_IPHONE
        /* MacOS */
        #define _SAPP_MACOS (1)
        #if !defined(SOKOL_METAL) && !defined(SOKOL_GLCORE)
        #error("sokol_app.h: unknown 3D API selected for MacOS, must be SOKOL_METAL or SOKOL_GLCORE")
        #endif
    #else
        /* iOS or iOS Simulator */
        #define _SAPP_IOS (1)
        #if !defined(SOKOL_METAL) && !defined(SOKOL_GLES3)
        #error("sokol_app.h: unknown 3D API selected for iOS, must be SOKOL_METAL or SOKOL_GLES3")
        #endif
    #endif
#elif defined(__EMSCRIPTEN__)
    /* emscripten (asm.js or wasm) */
    #define _SAPP_EMSCRIPTEN (1)
    #if !defined(SOKOL_GLES3) && !defined(SOKOL_WGPU)
    #error("sokol_app.h: unknown 3D API selected for emscripten, must be SOKOL_GLES3 or SOKOL_WGPU")
    #endif
#elif defined(_WIN32)
    /* Windows (D3D11 or GL) */
    #define _SAPP_WIN32 (1)
    #if !defined(SOKOL_D3D11) && !defined(SOKOL_GLCORE) && !defined(SOKOL_NOAPI)
    #error("sokol_app.h: unknown 3D API selected for Win32, must be SOKOL_D3D11, SOKOL_GLCORE or SOKOL_NOAPI")
    #endif
#elif defined(__ANDROID__)
    /* Android */
    #define _SAPP_ANDROID (1)
    #if !defined(SOKOL_GLES3)
    #error("sokol_app.h: unknown 3D API selected for Android, must be SOKOL_GLES3")
    #endif
    #if defined(SOKOL_NO_ENTRY)
    #error("sokol_app.h: SOKOL_NO_ENTRY is not supported on Android")
    #endif
#elif defined(__linux__) || defined(__unix__)
    /* Linux */
    #define _SAPP_LINUX (1)
    #if defined(SOKOL_GLCORE)
        #if !defined(SOKOL_FORCE_EGL)
            #define _SAPP_GLX (1)
        #endif
        #define GL_GLEXT_PROTOTYPES
        #include <GL/gl.h>
    #elif defined(SOKOL_GLES3)
        #include <GLES3/gl3.h>
        #include <GLES3/gl3ext.h>
    #else
        #error("sokol_app.h: unknown 3D API selected for Linux, must be SOKOL_GLCORE, SOKOL_GLES3")
    #endif
#else
#error "sokol_app.h: Unknown platform"
#endif

#if defined(SOKOL_GLCORE) || defined(SOKOL_GLES3)
    #define _SAPP_ANY_GL (1)
#endif

#ifndef SOKOL_API_IMPL
    #define SOKOL_API_IMPL
#endif
#ifndef SOKOL_DEBUG
    #ifndef NDEBUG
        #define SOKOL_DEBUG
    #endif
#endif
#ifndef SOKOL_ASSERT
    #include <assert.h>
    #define SOKOL_ASSERT(c) assert(c)
#endif
#ifndef SOKOL_UNREACHABLE
    #define SOKOL_UNREACHABLE SOKOL_ASSERT(false)
#endif

#ifndef _SOKOL_PRIVATE
    #if defined(__GNUC__) || defined(__clang__)
        #define _SOKOL_PRIVATE __attribute__((unused)) static
    #else
        #define _SOKOL_PRIVATE static
    #endif
#endif
#ifndef _SOKOL_UNUSED
    #define _SOKOL_UNUSED(x) (void)(x)
#endif

#if defined(_SAPP_APPLE)
    #if defined(SOKOL_METAL)
        #import <Metal/Metal.h>
        #import <MetalKit/MetalKit.h>
    #endif
    #if defined(_SAPP_MACOS)
        #if defined(_SAPP_ANY_GL)
            #ifndef GL_SILENCE_DEPRECATION
            #define GL_SILENCE_DEPRECATION
            #endif
            #include <Cocoa/Cocoa.h>
            #include <OpenGL/gl3.h>
        #endif
    #elif defined(_SAPP_IOS)
        #import <UIKit/UIKit.h>
        #if defined(_SAPP_ANY_GL)
            #import <GLKit/GLKit.h>
            #include <OpenGLES/ES3/gl.h>
        #endif
    #endif
    #include <AvailabilityMacros.h>
    #include <mach/mach_time.h>
#elif defined(_SAPP_EMSCRIPTEN)
    #if defined(SOKOL_WGPU)
        #include <webgpu/webgpu.h>
    #endif
    #if defined(SOKOL_GLES3)
        #include <GLES3/gl3.h>
    #endif
    #include <emscripten/emscripten.h>
    #include <emscripten/html5.h>
#elif defined(_SAPP_WIN32)
    #ifdef _MSC_VER
        #pragma warning(push)
        #pragma warning(disable:4201)   /* nonstandard extension used: nameless struct/union */
        #pragma warning(disable:4204)   /* nonstandard extension used: non-constant aggregate initializer */
        #pragma warning(disable:4054)   /* 'type cast': from function pointer */
        #pragma warning(disable:4055)   /* 'type cast': from data pointer */
        #pragma warning(disable:4505)   /* unreferenced local function has been removed */
        #pragma warning(disable:4115)   /* /W4: 'ID3D11ModuleInstance': named type definition in parentheses (in d3d11.h) */
    #endif
    #ifndef WIN32_LEAN_AND_MEAN
        #define WIN32_LEAN_AND_MEAN
    #endif
    #ifndef NOMINMAX
        #define NOMINMAX
    #endif
    #include <windows.h>
    #include <windowsx.h>
    #include <shellapi.h>
    #if !defined(SOKOL_NO_ENTRY)    // if SOKOL_NO_ENTRY is defined, it's the application's responsibility to use the right subsystem

        #if defined(SOKOL_WIN32_FORCE_MAIN) && defined(SOKOL_WIN32_FORCE_WINMAIN)
            // If both are defined, it's the application's responsibility to use the right subsystem
        #elif defined(SOKOL_WIN32_FORCE_MAIN)
            #pragma comment (linker, "/subsystem:console")
        #else
            #pragma comment (linker, "/subsystem:windows")
        #endif
    #endif
    #include <stdio.h>  /* freopen_s() */
    #include <wchar.h>  /* wcslen() */

    #pragma comment (lib, "kernel32")
    #pragma comment (lib, "user32")
    #pragma comment (lib, "shell32")    /* CommandLineToArgvW, DragQueryFileW, DragFinished */
    #pragma comment (lib, "gdi32")
    #if defined(SOKOL_D3D11)
        #pragma comment (lib, "dxgi")
        #pragma comment (lib, "d3d11")
    #endif

    #if defined(SOKOL_D3D11)
        #ifndef D3D11_NO_HELPERS
            #define D3D11_NO_HELPERS
        #endif
        #include <d3d11.h>
        #include <dxgi.h>
        // DXGI_SWAP_EFFECT_FLIP_DISCARD is only defined in newer Windows SDKs, so don't depend on it
        #define _SAPP_DXGI_SWAP_EFFECT_FLIP_DISCARD (4)
    #endif
    #ifndef WM_MOUSEHWHEEL /* see https://github.com/floooh/sokol/issues/138 */
        #define WM_MOUSEHWHEEL (0x020E)
    #endif
    #ifndef WM_DPICHANGED
        #define WM_DPICHANGED (0x02E0)
    #endif
#elif defined(_SAPP_ANDROID)
    #include <pthread.h>
    #include <unistd.h>
    #include <time.h>
    #include <android/native_activity.h>
    #include <android/looper.h>
    #include <EGL/egl.h>
    #include <GLES3/gl3.h>
#elif defined(_SAPP_LINUX)
    #define GL_GLEXT_PROTOTYPES
    #include <X11/Xlib.h>
    #include <X11/Xutil.h>
    #include <X11/XKBlib.h>
    #include <X11/keysym.h>
    #include <X11/Xresource.h>
    #include <X11/Xatom.h>
    #include <X11/extensions/XInput2.h>
    #include <X11/Xcursor/Xcursor.h>
    #include <X11/cursorfont.h> /* XC_* font cursors */
    #include <X11/Xmd.h> /* CARD32 */
    #if !defined(_SAPP_GLX)
        #include <EGL/egl.h>
    #endif
    #include <dlfcn.h> /* dlopen, dlsym, dlclose */
    #include <limits.h> /* LONG_MAX */
    #include <pthread.h>    /* only used a linker-guard, search for _sapp_linux_run() and see first comment */
    #include <time.h>
    #include <poll.h>
#endif

#if defined(_SAPP_APPLE)
    // this is ARC compatible
    #if defined(__cplusplus)
        #define _SAPP_CLEAR_ARC_STRUCT(type, item) { item = type(); }
    #else
        #define _SAPP_CLEAR_ARC_STRUCT(type, item) { item = (type) { 0 }; }
    #endif
#else
    #define _SAPP_CLEAR_ARC_STRUCT(type, item) { _sapp_clear(&item, sizeof(item)); }
#endif


// ███████ ██████   █████  ███    ███ ███████     ████████ ██ ███    ███ ██ ███    ██  ██████
// ██      ██   ██ ██   ██ ████  ████ ██             ██    ██ ████  ████ ██ ████   ██ ██
// █████   ██████  ███████ ██ ████ ██ █████          ██    ██ ██ ████ ██ ██ ██ ██  ██ ██   ███
// ██      ██   ██ ██   ██ ██  ██  ██ ██             ██    ██ ██  ██  ██ ██ ██  ██ ██ ██    ██
// ██      ██   ██ ██   ██ ██      ██ ███████        ██    ██ ██      ██ ██ ██   ████  ██████
//
// >>frame timing
#define _SAPP_RING_NUM_SLOTS (256)
typedef struct {
    int head;
    int tail;
    double buf[_SAPP_RING_NUM_SLOTS];
} _sapp_ring_t;

_SOKOL_PRIVATE int _sapp_ring_idx(int i) {
    return i % _SAPP_RING_NUM_SLOTS;
}

_SOKOL_PRIVATE void _sapp_ring_init(_sapp_ring_t* ring) {
    ring->head = 0;
    ring->tail = 0;
}

_SOKOL_PRIVATE bool _sapp_ring_full(_sapp_ring_t* ring) {
    return _sapp_ring_idx(ring->head + 1) == ring->tail;
}

_SOKOL_PRIVATE bool _sapp_ring_empty(_sapp_ring_t* ring) {
    return ring->head == ring->tail;
}

_SOKOL_PRIVATE int _sapp_ring_count(_sapp_ring_t* ring) {
    int count;
    if (ring->head >= ring->tail) {
        count = ring->head - ring->tail;
    }
    else {
        count = (ring->head + _SAPP_RING_NUM_SLOTS) - ring->tail;
    }
    SOKOL_ASSERT((count >= 0) && (count < _SAPP_RING_NUM_SLOTS));
    return count;
}

_SOKOL_PRIVATE void _sapp_ring_enqueue(_sapp_ring_t* ring, double val) {
    SOKOL_ASSERT(!_sapp_ring_full(ring));
    ring->buf[ring->head] = val;
    ring->head = _sapp_ring_idx(ring->head + 1);
}

_SOKOL_PRIVATE double _sapp_ring_dequeue(_sapp_ring_t* ring) {
    SOKOL_ASSERT(!_sapp_ring_empty(ring));
    double val = ring->buf[ring->tail];
    ring->tail = _sapp_ring_idx(ring->tail + 1);
    return val;
}

/*
    NOTE:

    Q: Why not use CAMetalDrawable.presentedTime on macOS and iOS?
    A: The value appears to be highly unstable during the first few
    seconds, sometimes several frames are dropped in sequence, or
    switch between 120 and 60 Hz for a few frames. Simply measuring
    and averaging the frame time yielded a more stable frame duration.
    Maybe switching to CVDisplayLink would yield better results.
    Until then just measure the time.
*/
typedef struct {
    #if defined(_SAPP_APPLE)
        struct {
            mach_timebase_info_data_t timebase;
            uint64_t start;
        } mach;
    #elif defined(_SAPP_EMSCRIPTEN)
        // empty
    #elif defined(_SAPP_WIN32)
        struct {
            LARGE_INTEGER freq;
            LARGE_INTEGER start;
        } win;
    #else // Linux, Android, ...
        #ifdef CLOCK_MONOTONIC
        #define _SAPP_CLOCK_MONOTONIC CLOCK_MONOTONIC
        #else
        // on some embedded platforms, CLOCK_MONOTONIC isn't defined
        #define _SAPP_CLOCK_MONOTONIC (1)
        #endif
        struct {
            uint64_t start;
        } posix;
    #endif
} _sapp_timestamp_t;

_SOKOL_PRIVATE int64_t _sapp_int64_muldiv(int64_t value, int64_t numer, int64_t denom) {
    int64_t q = value / denom;
    int64_t r = value % denom;
    return q * numer + r * numer / denom;
}

_SOKOL_PRIVATE void _sapp_timestamp_init(_sapp_timestamp_t* ts) {
    #if defined(_SAPP_APPLE)
        mach_timebase_info(&ts->mach.timebase);
        ts->mach.start = mach_absolute_time();
    #elif defined(_SAPP_EMSCRIPTEN)
        (void)ts;
    #elif defined(_SAPP_WIN32)
        QueryPerformanceFrequency(&ts->win.freq);
        QueryPerformanceCounter(&ts->win.start);
    #else
        struct timespec tspec;
        clock_gettime(_SAPP_CLOCK_MONOTONIC, &tspec);
        ts->posix.start = (uint64_t)tspec.tv_sec*1000000000 + (uint64_t)tspec.tv_nsec;
    #endif
}

_SOKOL_PRIVATE double _sapp_timestamp_now(_sapp_timestamp_t* ts) {
    #if defined(_SAPP_APPLE)
        const uint64_t traw = mach_absolute_time() - ts->mach.start;
        const uint64_t now = (uint64_t) _sapp_int64_muldiv((int64_t)traw, (int64_t)ts->mach.timebase.numer, (int64_t)ts->mach.timebase.denom);
        return (double)now / 1000000000.0;
    #elif defined(_SAPP_EMSCRIPTEN)
        (void)ts;
        SOKOL_ASSERT(false);
        return 0.0;
    #elif defined(_SAPP_WIN32)
        LARGE_INTEGER qpc;
        QueryPerformanceCounter(&qpc);
        const uint64_t now = (uint64_t)_sapp_int64_muldiv(qpc.QuadPart - ts->win.start.QuadPart, 1000000000, ts->win.freq.QuadPart);
        return (double)now / 1000000000.0;
    #else
        struct timespec tspec;
        clock_gettime(_SAPP_CLOCK_MONOTONIC, &tspec);
        const uint64_t now = ((uint64_t)tspec.tv_sec*1000000000 + (uint64_t)tspec.tv_nsec) - ts->posix.start;
        return (double)now / 1000000000.0;
    #endif
}

typedef struct {
    double last;
    double accum;
    double avg;
    int spike_count;
    int num;
    _sapp_timestamp_t timestamp;
    _sapp_ring_t ring;
} _sapp_timing_t;

_SOKOL_PRIVATE void _sapp_timing_reset(_sapp_timing_t* t) {
    t->last = 0.0;
    t->accum = 0.0;
    t->spike_count = 0;
    t->num = 0;
    _sapp_ring_init(&t->ring);
}

_SOKOL_PRIVATE void _sapp_timing_init(_sapp_timing_t* t) {
    t->avg = 1.0 / 60.0;    // dummy value until first actual value is available
    _sapp_timing_reset(t);
    _sapp_timestamp_init(&t->timestamp);
}

_SOKOL_PRIVATE void _sapp_timing_put(_sapp_timing_t* t, double dur) {
    // arbitrary upper limit to ignore outliers (e.g. during window resizing, or debugging)
    double min_dur = 0.0;
    double max_dur = 0.1;
    // if we have enough samples for a useful average, use a much tighter 'valid window'
    if (_sapp_ring_full(&t->ring)) {
        min_dur = t->avg * 0.8;
        max_dur = t->avg * 1.2;
    }
    if ((dur < min_dur) || (dur > max_dur)) {
        t->spike_count++;
        // if there have been many spikes in a row, the display refresh rate
        // might have changed, so a timing reset is needed
        if (t->spike_count > 20) {
            _sapp_timing_reset(t);
        }
        return;
    }
    if (_sapp_ring_full(&t->ring)) {
        double old_val = _sapp_ring_dequeue(&t->ring);
        t->accum -= old_val;
        t->num -= 1;
    }
    _sapp_ring_enqueue(&t->ring, dur);
    t->accum += dur;
    t->num += 1;
    SOKOL_ASSERT(t->num > 0);
    t->avg = t->accum / t->num;
    t->spike_count = 0;
}

_SOKOL_PRIVATE void _sapp_timing_discontinuity(_sapp_timing_t* t) {
    t->last = 0.0;
}

_SOKOL_PRIVATE void _sapp_timing_measure(_sapp_timing_t* t) {
    const double now = _sapp_timestamp_now(&t->timestamp);
    if (t->last > 0.0) {
        double dur = now - t->last;
        _sapp_timing_put(t, dur);
    }
    t->last = now;
}

_SOKOL_PRIVATE void _sapp_timing_external(_sapp_timing_t* t, double now) {
    if (t->last > 0.0) {
        double dur = now - t->last;
        _sapp_timing_put(t, dur);
    }
    t->last = now;
}

_SOKOL_PRIVATE double _sapp_timing_get_avg(_sapp_timing_t* t) {
    return t->avg;
}

// ███████ ████████ ██████  ██    ██  ██████ ████████ ███████
// ██         ██    ██   ██ ██    ██ ██         ██    ██
// ███████    ██    ██████  ██    ██ ██         ██    ███████
//      ██    ██    ██   ██ ██    ██ ██         ██         ██
// ███████    ██    ██   ██  ██████   ██████    ██    ███████
//
// >> structs
#if defined(_SAPP_MACOS)
@interface _sapp_macos_app_delegate : NSObject<NSApplicationDelegate>
@end
@interface _sapp_macos_window : NSWindow
@end
@interface _sapp_macos_window_delegate : NSObject<NSWindowDelegate>
@end
#if defined(SOKOL_METAL)
    @interface _sapp_macos_view : MTKView
    @end
#elif defined(SOKOL_GLCORE)
    @interface _sapp_macos_view : NSOpenGLView
    - (void)timerFired:(id)sender;
    @end
#endif // SOKOL_GLCORE

typedef struct {
    uint32_t flags_changed_store;
    uint8_t mouse_buttons;
    NSWindow* window;
    NSTrackingArea* tracking_area;
    id keyup_monitor;
    _sapp_macos_app_delegate* app_dlg;
    _sapp_macos_window_delegate* win_dlg;
    _sapp_macos_view* view;
    NSCursor* cursors[_SAPP_MOUSECURSOR_NUM];
    #if defined(SOKOL_METAL)
        id<MTLDevice> mtl_device;
    #endif
} _sapp_macos_t;

#endif // _SAPP_MACOS

#if defined(_SAPP_IOS)

@interface _sapp_app_delegate : NSObject<UIApplicationDelegate>
@end
@interface _sapp_textfield_dlg : NSObject<UITextFieldDelegate>
- (void)keyboardWasShown:(NSNotification*)notif;
- (void)keyboardWillBeHidden:(NSNotification*)notif;
- (void)keyboardDidChangeFrame:(NSNotification*)notif;
@end
#if defined(SOKOL_METAL)
    @interface _sapp_ios_view : MTKView;
    @end
#else
    @interface _sapp_ios_view : GLKView
    @end
#endif

typedef struct {
    UIWindow* window;
    _sapp_ios_view* view;
    UITextField* textfield;
    _sapp_textfield_dlg* textfield_dlg;
    #if defined(SOKOL_METAL)
        UIViewController* view_ctrl;
        id<MTLDevice> mtl_device;
    #else
        GLKViewController* view_ctrl;
        EAGLContext* eagl_ctx;
    #endif
    bool suspended;
} _sapp_ios_t;

#endif // _SAPP_IOS

#if defined(_SAPP_EMSCRIPTEN)

#if defined(SOKOL_WGPU)
typedef struct {
    WGPUInstance instance;
    WGPUAdapter adapter;
    WGPUDevice device;
    WGPUTextureFormat render_format;
    WGPUSurface surface;
    WGPUSwapChain swapchain;
    WGPUTexture msaa_tex;
    WGPUTextureView msaa_view;
    WGPUTexture depth_stencil_tex;
    WGPUTextureView depth_stencil_view;
    WGPUTextureView swapchain_view;
    bool async_init_done;
} _sapp_wgpu_t;
#endif

typedef struct {
    bool mouse_lock_requested;
    uint16_t mouse_buttons;
} _sapp_emsc_t;
#endif // _SAPP_EMSCRIPTEN

#if defined(SOKOL_D3D11) && defined(_SAPP_WIN32)
typedef struct {
    ID3D11Device* device;
    ID3D11DeviceContext* device_context;
    ID3D11Texture2D* rt;
    ID3D11RenderTargetView* rtv;
    ID3D11Texture2D* msaa_rt;
    ID3D11RenderTargetView* msaa_rtv;
    ID3D11Texture2D* ds;
    ID3D11DepthStencilView* dsv;
    DXGI_SWAP_CHAIN_DESC swap_chain_desc;
    IDXGISwapChain* swap_chain;
    IDXGIDevice1* dxgi_device;
    bool use_dxgi_frame_stats;
    UINT sync_refresh_count;
} _sapp_d3d11_t;
#endif

#if defined(_SAPP_WIN32)

#ifndef DPI_ENUMS_DECLARED
typedef enum PROCESS_DPI_AWARENESS
{
    PROCESS_DPI_UNAWARE = 0,
    PROCESS_SYSTEM_DPI_AWARE = 1,
    PROCESS_PER_MONITOR_DPI_AWARE = 2
} PROCESS_DPI_AWARENESS;
typedef enum MONITOR_DPI_TYPE {
    MDT_EFFECTIVE_DPI = 0,
    MDT_ANGULAR_DPI = 1,
    MDT_RAW_DPI = 2,
    MDT_DEFAULT = MDT_EFFECTIVE_DPI
} MONITOR_DPI_TYPE;
#endif // DPI_ENUMS_DECLARED

typedef struct {
    bool aware;
    float content_scale;
    float window_scale;
    float mouse_scale;
} _sapp_win32_dpi_t;

typedef struct {
    HWND hwnd;
    HMONITOR hmonitor;
    HDC dc;
    HICON big_icon;
    HICON small_icon;
    HCURSOR cursors[_SAPP_MOUSECURSOR_NUM];
    UINT orig_codepage;
    RECT stored_window_rect;    // used to restore window pos/size when toggling fullscreen => windowed
    bool is_win10_or_greater;
    bool in_create_window;
    bool iconified;
    _sapp_win32_dpi_t dpi;
    struct {
        struct {
            LONG pos_x, pos_y;
            bool pos_valid;
        } lock;
        struct {
            LONG pos_x, pos_y;
            bool pos_valid;
        } raw_input;
        bool requested_lock;
        bool tracked;
        uint8_t capture_mask;
    } mouse;
    struct {
        size_t size;
        void* ptr;
    } raw_input_data;
} _sapp_win32_t;

#if defined(SOKOL_GLCORE)
#define WGL_NUMBER_PIXEL_FORMATS_ARB 0x2000
#define WGL_SUPPORT_OPENGL_ARB 0x2010
#define WGL_DRAW_TO_WINDOW_ARB 0x2001
#define WGL_PIXEL_TYPE_ARB 0x2013
#define WGL_TYPE_RGBA_ARB 0x202b
#define WGL_ACCELERATION_ARB 0x2003
#define WGL_NO_ACCELERATION_ARB 0x2025
#define WGL_RED_BITS_ARB 0x2015
#define WGL_GREEN_BITS_ARB 0x2017
#define WGL_BLUE_BITS_ARB 0x2019
#define WGL_ALPHA_BITS_ARB 0x201b
#define WGL_DEPTH_BITS_ARB 0x2022
#define WGL_STENCIL_BITS_ARB 0x2023
#define WGL_DOUBLE_BUFFER_ARB 0x2011
#define WGL_SAMPLES_ARB 0x2042
#define WGL_CONTEXT_DEBUG_BIT_ARB 0x00000001
#define WGL_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB 0x00000002
#define WGL_CONTEXT_PROFILE_MASK_ARB 0x9126
#define WGL_CONTEXT_CORE_PROFILE_BIT_ARB 0x00000001
#define WGL_CONTEXT_MAJOR_VERSION_ARB 0x2091
#define WGL_CONTEXT_MINOR_VERSION_ARB 0x2092
#define WGL_CONTEXT_FLAGS_ARB 0x2094
#define ERROR_INVALID_VERSION_ARB 0x2095
#define ERROR_INVALID_PROFILE_ARB 0x2096
#define ERROR_INCOMPATIBLE_DEVICE_CONTEXTS_ARB 0x2054
typedef BOOL (WINAPI * PFNWGLSWAPINTERVALEXTPROC)(int);
typedef BOOL (WINAPI * PFNWGLGETPIXELFORMATATTRIBIVARBPROC)(HDC,int,int,UINT,const int*,int*);
typedef const char* (WINAPI * PFNWGLGETEXTENSIONSSTRINGEXTPROC)(void);
typedef const char* (WINAPI * PFNWGLGETEXTENSIONSSTRINGARBPROC)(HDC);
typedef HGLRC (WINAPI * PFNWGLCREATECONTEXTATTRIBSARBPROC)(HDC,HGLRC,const int*);
typedef HGLRC (WINAPI * PFN_wglCreateContext)(HDC);
typedef BOOL (WINAPI * PFN_wglDeleteContext)(HGLRC);
typedef PROC (WINAPI * PFN_wglGetProcAddress)(LPCSTR);
typedef HDC (WINAPI * PFN_wglGetCurrentDC)(void);
typedef BOOL (WINAPI * PFN_wglMakeCurrent)(HDC,HGLRC);

typedef struct {
    HINSTANCE opengl32;
    HGLRC gl_ctx;
    PFN_wglCreateContext CreateContext;
    PFN_wglDeleteContext DeleteContext;
    PFN_wglGetProcAddress GetProcAddress;
    PFN_wglGetCurrentDC GetCurrentDC;
    PFN_wglMakeCurrent MakeCurrent;
    PFNWGLSWAPINTERVALEXTPROC SwapIntervalEXT;
    PFNWGLGETPIXELFORMATATTRIBIVARBPROC GetPixelFormatAttribivARB;
    PFNWGLGETEXTENSIONSSTRINGEXTPROC GetExtensionsStringEXT;
    PFNWGLGETEXTENSIONSSTRINGARBPROC GetExtensionsStringARB;
    PFNWGLCREATECONTEXTATTRIBSARBPROC CreateContextAttribsARB;
    // special case glGetIntegerv
    void (WINAPI *GetIntegerv)(uint32_t pname, int32_t* data);
    bool ext_swap_control;
    bool arb_multisample;
    bool arb_pixel_format;
    bool arb_create_context;
    bool arb_create_context_profile;
    HWND msg_hwnd;
    HDC msg_dc;
} _sapp_wgl_t;
#endif // SOKOL_GLCORE

#endif // _SAPP_WIN32

#if defined(_SAPP_ANDROID)
typedef enum {
    _SOKOL_ANDROID_MSG_CREATE,
    _SOKOL_ANDROID_MSG_RESUME,
    _SOKOL_ANDROID_MSG_PAUSE,
    _SOKOL_ANDROID_MSG_FOCUS,
    _SOKOL_ANDROID_MSG_NO_FOCUS,
    _SOKOL_ANDROID_MSG_SET_NATIVE_WINDOW,
    _SOKOL_ANDROID_MSG_SET_INPUT_QUEUE,
    _SOKOL_ANDROID_MSG_DESTROY,
} _sapp_android_msg_t;

typedef struct {
    pthread_t thread;
    pthread_mutex_t mutex;
    pthread_cond_t cond;
    int read_from_main_fd;
    int write_from_main_fd;
} _sapp_android_pt_t;

typedef struct {
    ANativeWindow* window;
    AInputQueue* input;
} _sapp_android_resources_t;

typedef struct {
    ANativeActivity* activity;
    _sapp_android_pt_t pt;
    _sapp_android_resources_t pending;
    _sapp_android_resources_t current;
    ALooper* looper;
    bool is_thread_started;
    bool is_thread_stopping;
    bool is_thread_stopped;
    bool has_created;
    bool has_resumed;
    bool has_focus;
    EGLConfig config;
    EGLDisplay display;
    EGLContext context;
    EGLSurface surface;
} _sapp_android_t;

#endif // _SAPP_ANDROID

#if defined(_SAPP_LINUX)

#define _SAPP_X11_XDND_VERSION (5)
#define _SAPP_X11_MAX_X11_KEYCODES (256)

#define GLX_VENDOR 1
#define GLX_RGBA_BIT 0x00000001
#define GLX_WINDOW_BIT 0x00000001
#define GLX_DRAWABLE_TYPE 0x8010
#define GLX_RENDER_TYPE	0x8011
#define GLX_DOUBLEBUFFER 5
#define GLX_RED_SIZE 8
#define GLX_GREEN_SIZE 9
#define GLX_BLUE_SIZE 10
#define GLX_ALPHA_SIZE 11
#define GLX_DEPTH_SIZE 12
#define GLX_STENCIL_SIZE 13
#define GLX_SAMPLES 0x186a1
#define GLX_CONTEXT_CORE_PROFILE_BIT_ARB 0x00000001
#define GLX_CONTEXT_PROFILE_MASK_ARB 0x9126
#define GLX_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB 0x00000002
#define GLX_CONTEXT_MAJOR_VERSION_ARB 0x2091
#define GLX_CONTEXT_MINOR_VERSION_ARB 0x2092
#define GLX_CONTEXT_FLAGS_ARB 0x2094

typedef XID GLXWindow;
typedef XID GLXDrawable;
typedef struct __GLXFBConfig* GLXFBConfig;
typedef struct __GLXcontext* GLXContext;
typedef void (*__GLXextproc)(void);

typedef int (*PFNGLXGETFBCONFIGATTRIBPROC)(Display*,GLXFBConfig,int,int*);
typedef const char* (*PFNGLXGETCLIENTSTRINGPROC)(Display*,int);
typedef Bool (*PFNGLXQUERYEXTENSIONPROC)(Display*,int*,int*);
typedef Bool (*PFNGLXQUERYVERSIONPROC)(Display*,int*,int*);
typedef void (*PFNGLXDESTROYCONTEXTPROC)(Display*,GLXContext);
typedef Bool (*PFNGLXMAKECURRENTPROC)(Display*,GLXDrawable,GLXContext);
typedef void (*PFNGLXSWAPBUFFERSPROC)(Display*,GLXDrawable);
typedef const char* (*PFNGLXQUERYEXTENSIONSSTRINGPROC)(Display*,int);
typedef GLXFBConfig* (*PFNGLXGETFBCONFIGSPROC)(Display*,int,int*);
typedef __GLXextproc (* PFNGLXGETPROCADDRESSPROC)(const char *procName);
typedef void (*PFNGLXSWAPINTERVALEXTPROC)(Display*,GLXDrawable,int);
typedef XVisualInfo* (*PFNGLXGETVISUALFROMFBCONFIGPROC)(Display*,GLXFBConfig);
typedef GLXWindow (*PFNGLXCREATEWINDOWPROC)(Display*,GLXFBConfig,Window,const int*);
typedef void (*PFNGLXDESTROYWINDOWPROC)(Display*,GLXWindow);

typedef int (*PFNGLXSWAPINTERVALMESAPROC)(int);
typedef GLXContext (*PFNGLXCREATECONTEXTATTRIBSARBPROC)(Display*,GLXFBConfig,GLXContext,Bool,const int*);

typedef struct {
    bool available;
    int major_opcode;
    int event_base;
    int error_base;
    int major;
    int minor;
} _sapp_xi_t;

typedef struct {
    int version;
    Window source;
    Atom format;
    Atom XdndAware;
    Atom XdndEnter;
    Atom XdndPosition;
    Atom XdndStatus;
    Atom XdndActionCopy;
    Atom XdndDrop;
    Atom XdndFinished;
    Atom XdndSelection;
    Atom XdndTypeList;
    Atom text_uri_list;
} _sapp_xdnd_t;

typedef struct {
    uint8_t mouse_buttons;
    Display* display;
    int screen;
    Window root;
    Colormap colormap;
    Window window;
    Cursor hidden_cursor;
    Cursor cursors[_SAPP_MOUSECURSOR_NUM];
    int window_state;
    float dpi;
    unsigned char error_code;
    Atom UTF8_STRING;
    Atom CLIPBOARD;
    Atom TARGETS;
    Atom WM_PROTOCOLS;
    Atom WM_DELETE_WINDOW;
    Atom WM_STATE;
    Atom NET_WM_NAME;
    Atom NET_WM_ICON_NAME;
    Atom NET_WM_ICON;
    Atom NET_WM_STATE;
    Atom NET_WM_STATE_FULLSCREEN;
    _sapp_xi_t xi;
    _sapp_xdnd_t xdnd;
    // XLib manual says keycodes are in the range [8, 255] inclusive.
    // https://tronche.com/gui/x/xlib/input/keyboard-encoding.html
    bool key_repeat[_SAPP_X11_MAX_X11_KEYCODES];
} _sapp_x11_t;

#if defined(_SAPP_GLX)

typedef struct {
    void* libgl;
    int major;
    int minor;
    int event_base;
    int error_base;
    GLXContext ctx;
    GLXWindow window;

    // GLX 1.3 functions
    PFNGLXGETFBCONFIGSPROC GetFBConfigs;
    PFNGLXGETFBCONFIGATTRIBPROC GetFBConfigAttrib;
    PFNGLXGETCLIENTSTRINGPROC GetClientString;
    PFNGLXQUERYEXTENSIONPROC QueryExtension;
    PFNGLXQUERYVERSIONPROC QueryVersion;
    PFNGLXDESTROYCONTEXTPROC DestroyContext;
    PFNGLXMAKECURRENTPROC MakeCurrent;
    PFNGLXSWAPBUFFERSPROC SwapBuffers;
    PFNGLXQUERYEXTENSIONSSTRINGPROC QueryExtensionsString;
    PFNGLXGETVISUALFROMFBCONFIGPROC GetVisualFromFBConfig;
    PFNGLXCREATEWINDOWPROC CreateWindow;
    PFNGLXDESTROYWINDOWPROC DestroyWindow;

    // GLX 1.4 and extension functions
    PFNGLXGETPROCADDRESSPROC GetProcAddress;
    PFNGLXGETPROCADDRESSPROC GetProcAddressARB;
    PFNGLXSWAPINTERVALEXTPROC SwapIntervalEXT;
    PFNGLXSWAPINTERVALMESAPROC SwapIntervalMESA;
    PFNGLXCREATECONTEXTATTRIBSARBPROC CreateContextAttribsARB;

    // special case glGetIntegerv
    void (*GetIntegerv)(uint32_t pname, int32_t* data);

    // extension availability
    bool EXT_swap_control;
    bool MESA_swap_control;
    bool ARB_multisample;
    bool ARB_create_context;
    bool ARB_create_context_profile;
} _sapp_glx_t;

#else

typedef struct {
    EGLDisplay display;
    EGLContext context;
    EGLSurface surface;
} _sapp_egl_t;

#endif // _SAPP_GLX
#endif // _SAPP_LINUX

#if defined(_SAPP_ANY_GL)
typedef struct {
    uint32_t framebuffer;
} _sapp_gl_t;
#endif

typedef struct {
    bool enabled;
    int buf_size;
    char* buffer;
} _sapp_clipboard_t;

typedef struct {
    bool enabled;
    int max_files;
    int max_path_length;
    int num_files;
    int buf_size;
    char* buffer;
} _sapp_drop_t;

typedef struct {
    float x, y;
    float dx, dy;
    bool shown;
    bool locked;
    bool pos_valid;
    sapp_mouse_cursor current_cursor;
} _sapp_mouse_t;

typedef struct {
    sapp_desc desc;
    bool valid;
    bool fullscreen;
    bool first_frame;
    bool init_called;
    bool cleanup_called;
    bool quit_requested;
    bool quit_ordered;
    bool event_consumed;
    bool html5_ask_leave_site;
    bool onscreen_keyboard_shown;
    int window_width;
    int window_height;
    int framebuffer_width;
    int framebuffer_height;
    int sample_count;
    int swap_interval;
    float dpi_scale;
    uint64_t frame_count;
    _sapp_timing_t timing;
    sapp_event event;
    _sapp_mouse_t mouse;
    _sapp_clipboard_t clipboard;
    _sapp_drop_t drop;
    sapp_icon_desc default_icon_desc;
    uint32_t* default_icon_pixels;
    #if defined(_SAPP_MACOS)
        _sapp_macos_t macos;
    #elif defined(_SAPP_IOS)
        _sapp_ios_t ios;
    #elif defined(_SAPP_EMSCRIPTEN)
        _sapp_emsc_t emsc;
        #if defined(SOKOL_WGPU)
            _sapp_wgpu_t wgpu;
        #endif
    #elif defined(_SAPP_WIN32)
        _sapp_win32_t win32;
        #if defined(SOKOL_D3D11)
            _sapp_d3d11_t d3d11;
        #elif defined(SOKOL_GLCORE)
            _sapp_wgl_t wgl;
        #endif
    #elif defined(_SAPP_ANDROID)
        _sapp_android_t android;
    #elif defined(_SAPP_LINUX)
        _sapp_x11_t x11;
        #if defined(_SAPP_GLX)
            _sapp_glx_t glx;
        #else
            _sapp_egl_t egl;
        #endif
    #endif
    #if defined(_SAPP_ANY_GL)
        _sapp_gl_t gl;
    #endif
    char html5_canvas_selector[_SAPP_MAX_TITLE_LENGTH];
    char window_title[_SAPP_MAX_TITLE_LENGTH];      // UTF-8
    wchar_t window_title_wide[_SAPP_MAX_TITLE_LENGTH];   // UTF-32 or UCS-2 */
    sapp_keycode keycodes[SAPP_MAX_KEYCODES];
} _sapp_t;
static _sapp_t _sapp;

// ██       ██████   ██████   ██████  ██ ███    ██  ██████
// ██      ██    ██ ██       ██       ██ ████   ██ ██
// ██      ██    ██ ██   ███ ██   ███ ██ ██ ██  ██ ██   ███
// ██      ██    ██ ██    ██ ██    ██ ██ ██  ██ ██ ██    ██
// ███████  ██████   ██████   ██████  ██ ██   ████  ██████
//
// >>logging
#if defined(SOKOL_DEBUG)
#define _SAPP_LOGITEM_XMACRO(item,msg) #item ": " msg,
static const char* _sapp_log_messages[] = {
    _SAPP_LOG_ITEMS
};
#undef _SAPP_LOGITEM_XMACRO
#endif // SOKOL_DEBUG

#define _SAPP_PANIC(code) _sapp_log(SAPP_LOGITEM_ ##code, 0, 0, __LINE__)
#define _SAPP_ERROR(code) _sapp_log(SAPP_LOGITEM_ ##code, 1, 0, __LINE__)
#define _SAPP_WARN(code) _sapp_log(SAPP_LOGITEM_ ##code, 2, 0, __LINE__)
#define _SAPP_INFO(code) _sapp_log(SAPP_LOGITEM_ ##code, 3, 0, __LINE__)

static void _sapp_log(sapp_log_item log_item, uint32_t log_level, const char* msg, uint32_t line_nr) {
    if (_sapp.desc.logger.func) {
        const char* filename = 0;
        #if defined(SOKOL_DEBUG)
            filename = __FILE__;
            if (0 == msg) {
                msg = _sapp_log_messages[log_item];
            }
        #endif
        _sapp.desc.logger.func("sapp", log_level, (uint32_t)log_item, msg, line_nr, filename, _sapp.desc.logger.user_data);
    }
    else {
        // for log level PANIC it would be 'undefined behaviour' to continue
        if (log_level == 0) {
            abort();
        }
    }
}

// ███    ███ ███████ ███    ███  ██████  ██████  ██    ██
// ████  ████ ██      ████  ████ ██    ██ ██   ██  ██  ██
// ██ ████ ██ █████   ██ ████ ██ ██    ██ ██████    ████
// ██  ██  ██ ██      ██  ██  ██ ██    ██ ██   ██    ██
// ██      ██ ███████ ██      ██  ██████  ██   ██    ██
//
// >>memory
_SOKOL_PRIVATE void _sapp_clear(void* ptr, size_t size) {
    SOKOL_ASSERT(ptr && (size > 0));
    memset(ptr, 0, size);
}

_SOKOL_PRIVATE void* _sapp_malloc(size_t size) {
    SOKOL_ASSERT(size > 0);
    void* ptr;
    if (_sapp.desc.allocator.alloc_fn) {
        ptr = _sapp.desc.allocator.alloc_fn(size, _sapp.desc.allocator.user_data);
    } else {
        ptr = malloc(size);
    }
    if (0 == ptr) {
        _SAPP_PANIC(MALLOC_FAILED);
    }
    return ptr;
}

_SOKOL_PRIVATE void* _sapp_malloc_clear(size_t size) {
    void* ptr = _sapp_malloc(size);
    _sapp_clear(ptr, size);
    return ptr;
}

_SOKOL_PRIVATE void _sapp_free(void* ptr) {
    if (_sapp.desc.allocator.free_fn) {
        _sapp.desc.allocator.free_fn(ptr, _sapp.desc.allocator.user_data);
    }
    else {
        free(ptr);
    }
}

// ██   ██ ███████ ██      ██████  ███████ ██████  ███████
// ██   ██ ██      ██      ██   ██ ██      ██   ██ ██
// ███████ █████   ██      ██████  █████   ██████  ███████
// ██   ██ ██      ██      ██      ██      ██   ██      ██
// ██   ██ ███████ ███████ ██      ███████ ██   ██ ███████
//
// >>helpers
_SOKOL_PRIVATE void _sapp_call_init(void) {
    if (_sapp.desc.init_cb) {
        _sapp.desc.init_cb();
    }
    else if (_sapp.desc.init_userdata_cb) {
        _sapp.desc.init_userdata_cb(_sapp.desc.user_data);
    }
    _sapp.init_called = true;
}

_SOKOL_PRIVATE void _sapp_call_frame(void) {
    if (_sapp.init_called && !_sapp.cleanup_called) {
        if (_sapp.desc.frame_cb) {
            _sapp.desc.frame_cb();
        }
        else if (_sapp.desc.frame_userdata_cb) {
            _sapp.desc.frame_userdata_cb(_sapp.desc.user_data);
        }
    }
}

_SOKOL_PRIVATE void _sapp_call_cleanup(void) {
    if (!_sapp.cleanup_called) {
        if (_sapp.desc.cleanup_cb) {
            _sapp.desc.cleanup_cb();
        }
        else if (_sapp.desc.cleanup_userdata_cb) {
            _sapp.desc.cleanup_userdata_cb(_sapp.desc.user_data);
        }
        _sapp.cleanup_called = true;
    }
}

_SOKOL_PRIVATE bool _sapp_call_event(const sapp_event* e) {
    if (!_sapp.cleanup_called) {
        if (_sapp.desc.event_cb) {
            _sapp.desc.event_cb(e);
        }
        else if (_sapp.desc.event_userdata_cb) {
            _sapp.desc.event_userdata_cb(e, _sapp.desc.user_data);
        }
    }
    if (_sapp.event_consumed) {
        _sapp.event_consumed = false;
        return true;
    }
    else {
        return false;
    }
}

_SOKOL_PRIVATE char* _sapp_dropped_file_path_ptr(int index) {
    SOKOL_ASSERT(_sapp.drop.buffer);
    SOKOL_ASSERT((index >= 0) && (index <= _sapp.drop.max_files));
    int offset = index * _sapp.drop.max_path_length;
    SOKOL_ASSERT(offset < _sapp.drop.buf_size);
    return &_sapp.drop.buffer[offset];
}

/* Copy a string into a fixed size buffer with guaranteed zero-
   termination.

   Return false if the string didn't fit into the buffer and had to be clamped.

   FIXME: Currently UTF-8 strings might become invalid if the string
   is clamped, because the last zero-byte might be written into
   the middle of a multi-byte sequence.
*/
_SOKOL_PRIVATE bool _sapp_strcpy(const char* src, char* dst, int max_len) {
    SOKOL_ASSERT(src && dst && (max_len > 0));
    char* const end = &(dst[max_len-1]);
    char c = 0;
    for (int i = 0; i < max_len; i++) {
        c = *src;
        if (c != 0) {
            src++;
        }
        *dst++ = c;
    }
    /* truncated? */
    if (c != 0) {
        *end = 0;
        return false;
    }
    else {
        return true;
    }
}

_SOKOL_PRIVATE sapp_desc _sapp_desc_defaults(const sapp_desc* desc) {
    SOKOL_ASSERT((desc->allocator.alloc_fn && desc->allocator.free_fn) || (!desc->allocator.alloc_fn && !desc->allocator.free_fn));
    sapp_desc res = *desc;
    res.sample_count = _sapp_def(res.sample_count, 1);
    res.swap_interval = _sapp_def(res.swap_interval, 1);
    if (0 == res.gl_major_version) {
        #if defined(SOKOL_GLCORE)
            res.gl_major_version = 4;
            #if defined(_SAPP_APPLE)
                res.gl_minor_version = 1;
            #else
                res.gl_minor_version = 3;
            #endif
        #elif defined(SOKOL_GLES3)
            res.gl_major_version = 3;
            #if defined(_SAPP_ANDROID) || defined(_SAPP_LINUX)
                res.gl_minor_version = 1;
            #else
                res.gl_minor_version = 0;
            #endif
        #endif
    }
    res.html5_canvas_selector = _sapp_def(res.html5_canvas_selector, "#canvas");
    res.clipboard_size = _sapp_def(res.clipboard_size, 8192);
    res.max_dropped_files = _sapp_def(res.max_dropped_files, 1);
    res.max_dropped_file_path_length = _sapp_def(res.max_dropped_file_path_length, 2048);
    res.window_title = _sapp_def(res.window_title, "sokol");
    return res;
}

_SOKOL_PRIVATE void _sapp_init_state(const sapp_desc* desc) {
    SOKOL_ASSERT(desc);
    SOKOL_ASSERT(desc->width >= 0);
    SOKOL_ASSERT(desc->height >= 0);
    SOKOL_ASSERT(desc->sample_count >= 0);
    SOKOL_ASSERT(desc->swap_interval >= 0);
    SOKOL_ASSERT(desc->clipboard_size >= 0);
    SOKOL_ASSERT(desc->max_dropped_files >= 0);
    SOKOL_ASSERT(desc->max_dropped_file_path_length >= 0);
    _SAPP_CLEAR_ARC_STRUCT(_sapp_t, _sapp);
    _sapp.desc = _sapp_desc_defaults(desc);
    _sapp.first_frame = true;
    // NOTE: _sapp.desc.width/height may be 0! Platform backends need to deal with this
    _sapp.window_width = _sapp.desc.width;
    _sapp.window_height = _sapp.desc.height;
    _sapp.framebuffer_width = _sapp.window_width;
    _sapp.framebuffer_height = _sapp.window_height;
    _sapp.sample_count = _sapp.desc.sample_count;
    _sapp.swap_interval = _sapp.desc.swap_interval;
    _sapp_strcpy(_sapp.desc.html5_canvas_selector, _sapp.html5_canvas_selector, sizeof(_sapp.html5_canvas_selector));
    _sapp.desc.html5_canvas_selector = _sapp.html5_canvas_selector;
    _sapp.html5_ask_leave_site = _sapp.desc.html5_ask_leave_site;
    _sapp.clipboard.enabled = _sapp.desc.enable_clipboard;
    if (_sapp.clipboard.enabled) {
        _sapp.clipboard.buf_size = _sapp.desc.clipboard_size;
        _sapp.clipboard.buffer = (char*) _sapp_malloc_clear((size_t)_sapp.clipboard.buf_size);
    }
    _sapp.drop.enabled = _sapp.desc.enable_dragndrop;
    if (_sapp.drop.enabled) {
        _sapp.drop.max_files = _sapp.desc.max_dropped_files;
        _sapp.drop.max_path_length = _sapp.desc.max_dropped_file_path_length;
        _sapp.drop.buf_size = _sapp.drop.max_files * _sapp.drop.max_path_length;
        _sapp.drop.buffer = (char*) _sapp_malloc_clear((size_t)_sapp.drop.buf_size);
    }
    _sapp_strcpy(_sapp.desc.window_title, _sapp.window_title, sizeof(_sapp.window_title));
    _sapp.desc.window_title = _sapp.window_title;
    _sapp.dpi_scale = 1.0f;
    _sapp.fullscreen = _sapp.desc.fullscreen;
    _sapp.mouse.shown = true;
    _sapp_timing_init(&_sapp.timing);
}

_SOKOL_PRIVATE void _sapp_discard_state(void) {
    if (_sapp.clipboard.enabled) {
        SOKOL_ASSERT(_sapp.clipboard.buffer);
        _sapp_free((void*)_sapp.clipboard.buffer);
    }
    if (_sapp.drop.enabled) {
        SOKOL_ASSERT(_sapp.drop.buffer);
        _sapp_free((void*)_sapp.drop.buffer);
    }
    if (_sapp.default_icon_pixels) {
        _sapp_free((void*)_sapp.default_icon_pixels);
    }
    _SAPP_CLEAR_ARC_STRUCT(_sapp_t, _sapp);
}

_SOKOL_PRIVATE void _sapp_init_event(sapp_event_type type) {
    _sapp_clear(&_sapp.event, sizeof(_sapp.event));
    _sapp.event.type = type;
    _sapp.event.frame_count = _sapp.frame_count;
    _sapp.event.mouse_button = SAPP_MOUSEBUTTON_INVALID;
    _sapp.event.window_width = _sapp.window_width;
    _sapp.event.window_height = _sapp.window_height;
    _sapp.event.framebuffer_width = _sapp.framebuffer_width;
    _sapp.event.framebuffer_height = _sapp.framebuffer_height;
    _sapp.event.mouse_x = _sapp.mouse.x;
    _sapp.event.mouse_y = _sapp.mouse.y;
    _sapp.event.mouse_dx = _sapp.mouse.dx;
    _sapp.event.mouse_dy = _sapp.mouse.dy;
}

_SOKOL_PRIVATE bool _sapp_events_enabled(void) {
    /* only send events when an event callback is set, and the init function was called */
    return (_sapp.desc.event_cb || _sapp.desc.event_userdata_cb) && _sapp.init_called;
}

_SOKOL_PRIVATE sapp_keycode _sapp_translate_key(int scan_code) {
    if ((scan_code >= 0) && (scan_code < SAPP_MAX_KEYCODES)) {
        return _sapp.keycodes[scan_code];
    }
    else {
        return SAPP_KEYCODE_INVALID;
    }
}

_SOKOL_PRIVATE void _sapp_clear_drop_buffer(void) {
    if (_sapp.drop.enabled) {
        SOKOL_ASSERT(_sapp.drop.buffer);
        _sapp_clear(_sapp.drop.buffer, (size_t)_sapp.drop.buf_size);
    }
}

_SOKOL_PRIVATE void _sapp_frame(void) {
    if (_sapp.first_frame) {
        _sapp.first_frame = false;
        _sapp_call_init();
    }
    _sapp_call_frame();
    _sapp.frame_count++;
}

_SOKOL_PRIVATE bool _sapp_image_validate(const sapp_image_desc* desc) {
    SOKOL_ASSERT(desc->width > 0);
    SOKOL_ASSERT(desc->height > 0);
    SOKOL_ASSERT(desc->pixels.ptr != 0);
    SOKOL_ASSERT(desc->pixels.size > 0);
    const size_t wh_size = (size_t)(desc->width * desc->height) * sizeof(uint32_t);
    if (wh_size != desc->pixels.size) {
        _SAPP_ERROR(IMAGE_DATA_SIZE_MISMATCH);
        return false;
    }
    return true;
}

_SOKOL_PRIVATE int _sapp_image_bestmatch(const sapp_image_desc image_descs[], int num_images, int width, int height) {
    int least_diff = 0x7FFFFFFF;
    int least_index = 0;
    for (int i = 0; i < num_images; i++) {
        int diff = (image_descs[i].width * image_descs[i].height) - (width * height);
        if (diff < 0) {
            diff = -diff;
        }
        if (diff < least_diff) {
            least_diff = diff;
            least_index = i;
        }
    }
    return least_index;
}

_SOKOL_PRIVATE int _sapp_icon_num_images(const sapp_icon_desc* desc) {
    int index = 0;
    for (; index < SAPP_MAX_ICONIMAGES; index++) {
        if (0 == desc->images[index].pixels.ptr) {
            break;
        }
    }
    return index;
}

_SOKOL_PRIVATE bool _sapp_validate_icon_desc(const sapp_icon_desc* desc, int num_images) {
    SOKOL_ASSERT(num_images <= SAPP_MAX_ICONIMAGES);
    for (int i = 0; i < num_images; i++) {
        const sapp_image_desc* img_desc = &desc->images[i];
        if (!_sapp_image_validate(img_desc)) {
            return false;
        }
    }
    return true;
}

_SOKOL_PRIVATE void _sapp_setup_default_icon(void) {
    SOKOL_ASSERT(0 == _sapp.default_icon_pixels);

    const int num_icons = 3;
    const int icon_sizes[3] = { 16, 32, 64 };   // must be multiple of 8!

    // allocate a pixel buffer for all icon pixels
    int all_num_pixels = 0;
    for (int i = 0; i < num_icons; i++) {
        all_num_pixels += icon_sizes[i] * icon_sizes[i];
    }
    _sapp.default_icon_pixels = (uint32_t*) _sapp_malloc_clear((size_t)all_num_pixels * sizeof(uint32_t));

    // initialize default_icon_desc struct
    uint32_t* dst = _sapp.default_icon_pixels;
    const uint32_t* dst_end = dst + all_num_pixels;
    (void)dst_end; // silence unused warning in release mode
    for (int i = 0; i < num_icons; i++) {
        const int dim = (int) icon_sizes[i];
        const int num_pixels = dim * dim;
        sapp_image_desc* img_desc = &_sapp.default_icon_desc.images[i];
        img_desc->width = dim;
        img_desc->height = dim;
        img_desc->pixels.ptr = dst;
        img_desc->pixels.size = (size_t)num_pixels * sizeof(uint32_t);
        dst += num_pixels;
    }
    SOKOL_ASSERT(dst == dst_end);

    // Amstrad CPC font 'S'
    const uint8_t tile[8] = {
        0x3C,
        0x66,
        0x60,
        0x3C,
        0x06,
        0x66,
        0x3C,
        0x00,
    };
    // rainbow colors
    const uint32_t colors[8] = {
        0xFF4370FF,
        0xFF26A7FF,
        0xFF58EEFF,
        0xFF57E1D4,
        0xFF65CC9C,
        0xFF6ABB66,
        0xFFF5A542,
        0xFFC2577E,
    };
    dst = _sapp.default_icon_pixels;
    const uint32_t blank = 0x00FFFFFF;
    const uint32_t shadow = 0xFF000000;
    for (int i = 0; i < num_icons; i++) {
        const int dim = icon_sizes[i];
        SOKOL_ASSERT((dim % 8) == 0);
        const int scale = dim / 8;
        for (int ty = 0, y = 0; ty < 8; ty++) {
            const uint32_t color = colors[ty];
            for (int sy = 0; sy < scale; sy++, y++) {
                uint8_t bits = tile[ty];
                for (int tx = 0, x = 0; tx < 8; tx++, bits<<=1) {
                    uint32_t pixel = (0 == (bits & 0x80)) ? blank : color;
                    for (int sx = 0; sx < scale; sx++, x++) {
                        SOKOL_ASSERT(dst < dst_end);
                        *dst++ = pixel;
                    }
                }
            }
        }
    }
    SOKOL_ASSERT(dst == dst_end);

    // right shadow
    dst = _sapp.default_icon_pixels;
    for (int i = 0; i < num_icons; i++) {
        const int dim = icon_sizes[i];
        for (int y = 0; y < dim; y++) {
            uint32_t prev_color = blank;
            for (int x = 0; x < dim; x++) {
                const int dst_index = y * dim + x;
                const uint32_t cur_color = dst[dst_index];
                if ((cur_color == blank) && (prev_color != blank)) {
                    dst[dst_index] = shadow;
                }
                prev_color = cur_color;
            }
        }
        dst += dim * dim;
    }
    SOKOL_ASSERT(dst == dst_end);

    // bottom shadow
    dst = _sapp.default_icon_pixels;
    for (int i = 0; i < num_icons; i++) {
        const int dim = icon_sizes[i];
        for (int x = 0; x < dim; x++) {
            uint32_t prev_color = blank;
            for (int y = 0; y < dim; y++) {
                const int dst_index = y * dim + x;
                const uint32_t cur_color = dst[dst_index];
                if ((cur_color == blank) && (prev_color != blank)) {
                    dst[dst_index] = shadow;
                }
                prev_color = cur_color;
            }
        }
        dst += dim * dim;
    }
    SOKOL_ASSERT(dst == dst_end);
}

//  █████  ██████  ██████  ██      ███████
// ██   ██ ██   ██ ██   ██ ██      ██
// ███████ ██████  ██████  ██      █████
// ██   ██ ██      ██      ██      ██
// ██   ██ ██      ██      ███████ ███████
//
// >>apple
#if defined(_SAPP_APPLE)

#if __has_feature(objc_arc)
#define _SAPP_OBJC_RELEASE(obj) { obj = nil; }
#else
#define _SAPP_OBJC_RELEASE(obj) { [obj release]; obj = nil; }
#endif

// ███    ███  █████   ██████  ██████  ███████
// ████  ████ ██   ██ ██      ██    ██ ██
// ██ ████ ██ ███████ ██      ██    ██ ███████
// ██  ██  ██ ██   ██ ██      ██    ██      ██
// ██      ██ ██   ██  ██████  ██████  ███████
//
// >>macos
#if defined(_SAPP_MACOS)

_SOKOL_PRIVATE void _sapp_macos_init_keytable(void) {
    _sapp.keycodes[0x1D] = SAPP_KEYCODE_0;
    _sapp.keycodes[0x12] = SAPP_KEYCODE_1;
    _sapp.keycodes[0x13] = SAPP_KEYCODE_2;
    _sapp.keycodes[0x14] = SAPP_KEYCODE_3;
    _sapp.keycodes[0x15] = SAPP_KEYCODE_4;
    _sapp.keycodes[0x17] = SAPP_KEYCODE_5;
    _sapp.keycodes[0x16] = SAPP_KEYCODE_6;
    _sapp.keycodes[0x1A] = SAPP_KEYCODE_7;
    _sapp.keycodes[0x1C] = SAPP_KEYCODE_8;
    _sapp.keycodes[0x19] = SAPP_KEYCODE_9;
    _sapp.keycodes[0x00] = SAPP_KEYCODE_A;
    _sapp.keycodes[0x0B] = SAPP_KEYCODE_B;
    _sapp.keycodes[0x08] = SAPP_KEYCODE_C;
    _sapp.keycodes[0x02] = SAPP_KEYCODE_D;
    _sapp.keycodes[0x0E] = SAPP_KEYCODE_E;
    _sapp.keycodes[0x03] = SAPP_KEYCODE_F;
    _sapp.keycodes[0x05] = SAPP_KEYCODE_G;
    _sapp.keycodes[0x04] = SAPP_KEYCODE_H;
    _sapp.keycodes[0x22] = SAPP_KEYCODE_I;
    _sapp.keycodes[0x26] = SAPP_KEYCODE_J;
    _sapp.keycodes[0x28] = SAPP_KEYCODE_K;
    _sapp.keycodes[0x25] = SAPP_KEYCODE_L;
    _sapp.keycodes[0x2E] = SAPP_KEYCODE_M;
    _sapp.keycodes[0x2D] = SAPP_KEYCODE_N;
    _sapp.keycodes[0x1F] = SAPP_KEYCODE_O;
    _sapp.keycodes[0x23] = SAPP_KEYCODE_P;
    _sapp.keycodes[0x0C] = SAPP_KEYCODE_Q;
    _sapp.keycodes[0x0F] = SAPP_KEYCODE_R;
    _sapp.keycodes[0x01] = SAPP_KEYCODE_S;
    _sapp.keycodes[0x11] = SAPP_KEYCODE_T;
    _sapp.keycodes[0x20] = SAPP_KEYCODE_U;
    _sapp.keycodes[0x09] = SAPP_KEYCODE_V;
    _sapp.keycodes[0x0D] = SAPP_KEYCODE_W;
    _sapp.keycodes[0x07] = SAPP_KEYCODE_X;
    _sapp.keycodes[0x10] = SAPP_KEYCODE_Y;
    _sapp.keycodes[0x06] = SAPP_KEYCODE_Z;
    _sapp.keycodes[0x27] = SAPP_KEYCODE_APOSTROPHE;
    _sapp.keycodes[0x2A] = SAPP_KEYCODE_BACKSLASH;
    _sapp.keycodes[0x2B] = SAPP_KEYCODE_COMMA;
    _sapp.keycodes[0x18] = SAPP_KEYCODE_EQUAL;
    _sapp.keycodes[0x32] = SAPP_KEYCODE_GRAVE_ACCENT;
    _sapp.keycodes[0x21] = SAPP_KEYCODE_LEFT_BRACKET;
    _sapp.keycodes[0x1B] = SAPP_KEYCODE_MINUS;
    _sapp.keycodes[0x2F] = SAPP_KEYCODE_PERIOD;
    _sapp.keycodes[0x1E] = SAPP_KEYCODE_RIGHT_BRACKET;
    _sapp.keycodes[0x29] = SAPP_KEYCODE_SEMICOLON;
    _sapp.keycodes[0x2C] = SAPP_KEYCODE_SLASH;
    _sapp.keycodes[0x0A] = SAPP_KEYCODE_WORLD_1;
    _sapp.keycodes[0x33] = SAPP_KEYCODE_BACKSPACE;
    _sapp.keycodes[0x39] = SAPP_KEYCODE_CAPS_LOCK;
    _sapp.keycodes[0x75] = SAPP_KEYCODE_DELETE;
    _sapp.keycodes[0x7D] = SAPP_KEYCODE_DOWN;
    _sapp.keycodes[0x77] = SAPP_KEYCODE_END;
    _sapp.keycodes[0x24] = SAPP_KEYCODE_ENTER;
    _sapp.keycodes[0x35] = SAPP_KEYCODE_ESCAPE;
    _sapp.keycodes[0x7A] = SAPP_KEYCODE_F1;
    _sapp.keycodes[0x78] = SAPP_KEYCODE_F2;
    _sapp.keycodes[0x63] = SAPP_KEYCODE_F3;
    _sapp.keycodes[0x76] = SAPP_KEYCODE_F4;
    _sapp.keycodes[0x60] = SAPP_KEYCODE_F5;
    _sapp.keycodes[0x61] = SAPP_KEYCODE_F6;
    _sapp.keycodes[0x62] = SAPP_KEYCODE_F7;
    _sapp.keycodes[0x64] = SAPP_KEYCODE_F8;
    _sapp.keycodes[0x65] = SAPP_KEYCODE_F9;
    _sapp.keycodes[0x6D] = SAPP_KEYCODE_F10;
    _sapp.keycodes[0x67] = SAPP_KEYCODE_F11;
    _sapp.keycodes[0x6F] = SAPP_KEYCODE_F12;
    _sapp.keycodes[0x69] = SAPP_KEYCODE_F13;
    _sapp.keycodes[0x6B] = SAPP_KEYCODE_F14;
    _sapp.keycodes[0x71] = SAPP_KEYCODE_F15;
    _sapp.keycodes[0x6A] = SAPP_KEYCODE_F16;
    _sapp.keycodes[0x40] = SAPP_KEYCODE_F17;
    _sapp.keycodes[0x4F] = SAPP_KEYCODE_F18;
    _sapp.keycodes[0x50] = SAPP_KEYCODE_F19;
    _sapp.keycodes[0x5A] = SAPP_KEYCODE_F20;
    _sapp.keycodes[0x73] = SAPP_KEYCODE_HOME;
    _sapp.keycodes[0x72] = SAPP_KEYCODE_INSERT;
    _sapp.keycodes[0x7B] = SAPP_KEYCODE_LEFT;
    _sapp.keycodes[0x3A] = SAPP_KEYCODE_LEFT_ALT;
    _sapp.keycodes[0x3B] = SAPP_KEYCODE_LEFT_CONTROL;
    _sapp.keycodes[0x38] = SAPP_KEYCODE_LEFT_SHIFT;
    _sapp.keycodes[0x37] = SAPP_KEYCODE_LEFT_SUPER;
    _sapp.keycodes[0x6E] = SAPP_KEYCODE_MENU;
    _sapp.keycodes[0x47] = SAPP_KEYCODE_NUM_LOCK;
    _sapp.keycodes[0x79] = SAPP_KEYCODE_PAGE_DOWN;
    _sapp.keycodes[0x74] = SAPP_KEYCODE_PAGE_UP;
    _sapp.keycodes[0x7C] = SAPP_KEYCODE_RIGHT;
    _sapp.keycodes[0x3D] = SAPP_KEYCODE_RIGHT_ALT;
    _sapp.keycodes[0x3E] = SAPP_KEYCODE_RIGHT_CONTROL;
    _sapp.keycodes[0x3C] = SAPP_KEYCODE_RIGHT_SHIFT;
    _sapp.keycodes[0x36] = SAPP_KEYCODE_RIGHT_SUPER;
    _sapp.keycodes[0x31] = SAPP_KEYCODE_SPACE;
    _sapp.keycodes[0x30] = SAPP_KEYCODE_TAB;
    _sapp.keycodes[0x7E] = SAPP_KEYCODE_UP;
    _sapp.keycodes[0x52] = SAPP_KEYCODE_KP_0;
    _sapp.keycodes[0x53] = SAPP_KEYCODE_KP_1;
    _sapp.keycodes[0x54] = SAPP_KEYCODE_KP_2;
    _sapp.keycodes[0x55] = SAPP_KEYCODE_KP_3;
    _sapp.keycodes[0x56] = SAPP_KEYCODE_KP_4;
    _sapp.keycodes[0x57] = SAPP_KEYCODE_KP_5;
    _sapp.keycodes[0x58] = SAPP_KEYCODE_KP_6;
    _sapp.keycodes[0x59] = SAPP_KEYCODE_KP_7;
    _sapp.keycodes[0x5B] = SAPP_KEYCODE_KP_8;
    _sapp.keycodes[0x5C] = SAPP_KEYCODE_KP_9;
    _sapp.keycodes[0x45] = SAPP_KEYCODE_KP_ADD;
    _sapp.keycodes[0x41] = SAPP_KEYCODE_KP_DECIMAL;
    _sapp.keycodes[0x4B] = SAPP_KEYCODE_KP_DIVIDE;
    _sapp.keycodes[0x4C] = SAPP_KEYCODE_KP_ENTER;
    _sapp.keycodes[0x51] = SAPP_KEYCODE_KP_EQUAL;
    _sapp.keycodes[0x43] = SAPP_KEYCODE_KP_MULTIPLY;
    _sapp.keycodes[0x4E] = SAPP_KEYCODE_KP_SUBTRACT;
}

_SOKOL_PRIVATE void _sapp_macos_discard_state(void) {
    // NOTE: it's safe to call [release] on a nil object
    if (_sapp.macos.keyup_monitor != nil) {
        [NSEvent removeMonitor:_sapp.macos.keyup_monitor];
        // NOTE: removeMonitor also releases the object
        _sapp.macos.keyup_monitor = nil;
    }
    _SAPP_OBJC_RELEASE(_sapp.macos.tracking_area);
    _SAPP_OBJC_RELEASE(_sapp.macos.app_dlg);
    _SAPP_OBJC_RELEASE(_sapp.macos.win_dlg);
    _SAPP_OBJC_RELEASE(_sapp.macos.view);
    #if defined(SOKOL_METAL)
        _SAPP_OBJC_RELEASE(_sapp.macos.mtl_device);
    #endif
    _SAPP_OBJC_RELEASE(_sapp.macos.window);
}

// undocumented methods for creating cursors (see GLFW 3.4 and imgui_impl_osx.mm)
@interface NSCursor()
+ (id)_windowResizeNorthWestSouthEastCursor;
+ (id)_windowResizeNorthEastSouthWestCursor;
+ (id)_windowResizeNorthSouthCursor;
+ (id)_windowResizeEastWestCursor;
@end

_SOKOL_PRIVATE void _sapp_macos_init_cursors(void) {
    _sapp.macos.cursors[SAPP_MOUSECURSOR_DEFAULT] = nil; // not a bug
    _sapp.macos.cursors[SAPP_MOUSECURSOR_ARROW] = [NSCursor arrowCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_IBEAM] = [NSCursor IBeamCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_CROSSHAIR] = [NSCursor crosshairCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_POINTING_HAND] = [NSCursor pointingHandCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_RESIZE_EW] = [NSCursor respondsToSelector:@selector(_windowResizeEastWestCursor)] ? [NSCursor _windowResizeEastWestCursor] : [NSCursor resizeLeftRightCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_RESIZE_NS] = [NSCursor respondsToSelector:@selector(_windowResizeNorthSouthCursor)] ? [NSCursor _windowResizeNorthSouthCursor] : [NSCursor resizeUpDownCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_RESIZE_NWSE] = [NSCursor respondsToSelector:@selector(_windowResizeNorthWestSouthEastCursor)] ? [NSCursor _windowResizeNorthWestSouthEastCursor] : [NSCursor closedHandCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_RESIZE_NESW] = [NSCursor respondsToSelector:@selector(_windowResizeNorthEastSouthWestCursor)] ? [NSCursor _windowResizeNorthEastSouthWestCursor] : [NSCursor closedHandCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_RESIZE_ALL] = [NSCursor closedHandCursor];
    _sapp.macos.cursors[SAPP_MOUSECURSOR_NOT_ALLOWED] = [NSCursor operationNotAllowedCursor];
}

_SOKOL_PRIVATE void _sapp_macos_run(const sapp_desc* desc) {
    _sapp_init_state(desc);
    _sapp_macos_init_keytable();
    [NSApplication sharedApplication];

    // set the application dock icon as early as possible, otherwise
    // the dummy icon will be visible for a short time
    sapp_set_icon(&_sapp.desc.icon);
    _sapp.macos.app_dlg = [[_sapp_macos_app_delegate alloc] init];
    NSApp.delegate = _sapp.macos.app_dlg;

    // workaround for "no key-up sent while Cmd is pressed" taken from GLFW:
    NSEvent* (^keyup_monitor)(NSEvent*) = ^NSEvent* (NSEvent* event) {
        if ([event modifierFlags] & NSEventModifierFlagCommand) {
            [[NSApp keyWindow] sendEvent:event];
        }
        return event;
    };
    _sapp.macos.keyup_monitor = [NSEvent addLocalMonitorForEventsMatchingMask:NSEventMaskKeyUp handler:keyup_monitor];

    [NSApp run];
    // NOTE: [NSApp run] never returns, instead cleanup code
    // must be put into applicationWillTerminate
}

/* MacOS entry function */
#if !defined(SOKOL_NO_ENTRY)
int main(int argc, char* argv[]) {
    sapp_desc desc = sokol_main(argc, argv);
    _sapp_macos_run(&desc);
    return 0;
}
#endif /* SOKOL_NO_ENTRY */

_SOKOL_PRIVATE uint32_t _sapp_macos_mods(NSEvent* ev) {
    const NSEventModifierFlags f = (ev == nil) ? NSEvent.modifierFlags : ev.modifierFlags;
    const NSUInteger b = NSEvent.pressedMouseButtons;
    uint32_t m = 0;
    if (f & NSEventModifierFlagShift) {
        m |= SAPP_MODIFIER_SHIFT;
    }
    if (f & NSEventModifierFlagControl) {
        m |= SAPP_MODIFIER_CTRL;
    }
    if (f & NSEventModifierFlagOption) {
        m |= SAPP_MODIFIER_ALT;
    }
    if (f & NSEventModifierFlagCommand) {
        m |= SAPP_MODIFIER_SUPER;
    }
    if (0 != (b & (1<<0))) {
        m |= SAPP_MODIFIER_LMB;
    }
    if (0 != (b & (1<<1))) {
        m |= SAPP_MODIFIER_RMB;
    }
    if (0 != (b & (1<<2))) {
        m |= SAPP_MODIFIER_MMB;
    }
    return m;
}

_SOKOL_PRIVATE void _sapp_macos_mouse_event(sapp_event_type type, sapp_mousebutton btn, uint32_t mod) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp.event.mouse_button = btn;
        _sapp.event.modifiers = mod;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_macos_key_event(sapp_event_type type, sapp_keycode key, bool repeat, uint32_t mod) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp.event.key_code = key;
        _sapp.event.key_repeat = repeat;
        _sapp.event.modifiers = mod;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_macos_app_event(sapp_event_type type) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp_call_event(&_sapp.event);
    }
}

/* NOTE: unlike the iOS version of this function, the macOS version
    can dynamically update the DPI scaling factor when a window is moved
    between HighDPI / LowDPI screens.
*/
_SOKOL_PRIVATE void _sapp_macos_update_dimensions(void) {
    if (_sapp.desc.high_dpi) {
        _sapp.dpi_scale = [_sapp.macos.window screen].backingScaleFactor;
    }
    else {
        _sapp.dpi_scale = 1.0f;
    }
    _sapp.macos.view.layer.contentsScale = _sapp.dpi_scale; // NOTE: needed because we set layerContentsPlacement to a non-scaling value in windowWillStartLiveResize.
    const NSRect bounds = [_sapp.macos.view bounds];
    _sapp.window_width = (int)roundf(bounds.size.width);
    _sapp.window_height = (int)roundf(bounds.size.height);
    #if defined(SOKOL_METAL)
        _sapp.framebuffer_width = (int)roundf(bounds.size.width * _sapp.dpi_scale);
        _sapp.framebuffer_height = (int)roundf(bounds.size.height * _sapp.dpi_scale);
        const CGSize fb_size = _sapp.macos.view.drawableSize;
        const int cur_fb_width = (int)roundf(fb_size.width);
        const int cur_fb_height = (int)roundf(fb_size.height);
        const bool dim_changed = (_sapp.framebuffer_width != cur_fb_width) ||
                                 (_sapp.framebuffer_height != cur_fb_height);
    #elif defined(SOKOL_GLCORE)
        const int cur_fb_width = (int)roundf(bounds.size.width * _sapp.dpi_scale);
        const int cur_fb_height = (int)roundf(bounds.size.height * _sapp.dpi_scale);
        const bool dim_changed = (_sapp.framebuffer_width != cur_fb_width) ||
                                 (_sapp.framebuffer_height != cur_fb_height);
        _sapp.framebuffer_width = cur_fb_width;
        _sapp.framebuffer_height = cur_fb_height;
    #endif
    if (_sapp.framebuffer_width == 0) {
        _sapp.framebuffer_width = 1;
    }
    if (_sapp.framebuffer_height == 0) {
        _sapp.framebuffer_height = 1;
    }
    if (_sapp.window_width == 0) {
        _sapp.window_width = 1;
    }
    if (_sapp.window_height == 0) {
        _sapp.window_height = 1;
    }
    if (dim_changed) {
        #if defined(SOKOL_METAL)
            CGSize drawable_size = { (CGFloat) _sapp.framebuffer_width, (CGFloat) _sapp.framebuffer_height };
            _sapp.macos.view.drawableSize = drawable_size;
        #else
            // nothing to do for GL?
        #endif
        if (!_sapp.first_frame) {
            _sapp_macos_app_event(SAPP_EVENTTYPE_RESIZED);
        }
    }
}

_SOKOL_PRIVATE void _sapp_macos_toggle_fullscreen(void) {
    /* NOTE: the _sapp.fullscreen flag is also notified by the
       windowDidEnterFullscreen / windowDidExitFullscreen
       event handlers
    */
    _sapp.fullscreen = !_sapp.fullscreen;
    [_sapp.macos.window toggleFullScreen:nil];
}

_SOKOL_PRIVATE void _sapp_macos_set_clipboard_string(const char* str) {
    @autoreleasepool {
        NSPasteboard* pasteboard = [NSPasteboard generalPasteboard];
        [pasteboard declareTypes:@[NSPasteboardTypeString] owner:nil];
        [pasteboard setString:@(str) forType:NSPasteboardTypeString];
    }
}

_SOKOL_PRIVATE const char* _sapp_macos_get_clipboard_string(void) {
    SOKOL_ASSERT(_sapp.clipboard.buffer);
    @autoreleasepool {
        _sapp.clipboard.buffer[0] = 0;
        NSPasteboard* pasteboard = [NSPasteboard generalPasteboard];
        if (![[pasteboard types] containsObject:NSPasteboardTypeString]) {
            return _sapp.clipboard.buffer;
        }
        NSString* str = [pasteboard stringForType:NSPasteboardTypeString];
        if (!str) {
            return _sapp.clipboard.buffer;
        }
        _sapp_strcpy([str UTF8String], _sapp.clipboard.buffer, _sapp.clipboard.buf_size);
    }
    return _sapp.clipboard.buffer;
}

_SOKOL_PRIVATE void _sapp_macos_update_window_title(void) {
    [_sapp.macos.window setTitle: [NSString stringWithUTF8String:_sapp.window_title]];
}

_SOKOL_PRIVATE void _sapp_macos_mouse_update_from_nspoint(NSPoint mouse_pos, bool clear_dxdy) {
    if (!_sapp.mouse.locked) {
        float new_x = mouse_pos.x * _sapp.dpi_scale;
        float new_y = _sapp.framebuffer_height - (mouse_pos.y * _sapp.dpi_scale) - 1;
        if (clear_dxdy) {
            _sapp.mouse.dx = 0.0f;
            _sapp.mouse.dy = 0.0f;
        }
        else if (_sapp.mouse.pos_valid) {
            // don't update dx/dy in the very first update
            _sapp.mouse.dx = new_x - _sapp.mouse.x;
            _sapp.mouse.dy = new_y - _sapp.mouse.y;
        }
        _sapp.mouse.x = new_x;
        _sapp.mouse.y = new_y;
        _sapp.mouse.pos_valid = true;
    }
}

_SOKOL_PRIVATE void _sapp_macos_mouse_update_from_nsevent(NSEvent* event, bool clear_dxdy) {
    _sapp_macos_mouse_update_from_nspoint(event.locationInWindow, clear_dxdy);
}

_SOKOL_PRIVATE void _sapp_macos_show_mouse(bool visible) {
    /* NOTE: this function is only called when the mouse visibility actually changes */
    if (visible) {
        CGDisplayShowCursor(kCGDirectMainDisplay);
    }
    else {
        CGDisplayHideCursor(kCGDirectMainDisplay);
    }
}

_SOKOL_PRIVATE void _sapp_macos_lock_mouse(bool lock) {
    if (lock == _sapp.mouse.locked) {
        return;
    }
    _sapp.mouse.dx = 0.0f;
    _sapp.mouse.dy = 0.0f;
    _sapp.mouse.locked = lock;
    /*
        NOTE that this code doesn't warp the mouse cursor to the window
        center as everybody else does it. This lead to a spike in the
        *second* mouse-moved event after the warp happened. The
        mouse centering doesn't seem to be required (mouse-moved events
        are reported correctly even when the cursor is at an edge of the screen).

        NOTE also that the hide/show of the mouse cursor should properly
        stack with calls to sapp_show_mouse()
    */
    if (_sapp.mouse.locked) {
        CGAssociateMouseAndMouseCursorPosition(NO);
        [NSCursor hide];
    }
    else {
        [NSCursor unhide];
        CGAssociateMouseAndMouseCursorPosition(YES);
    }
}

_SOKOL_PRIVATE void _sapp_macos_update_cursor(sapp_mouse_cursor cursor, bool shown) {
    // show/hide cursor only if visibility status has changed (required because show/hide stacks)
    if (shown != _sapp.mouse.shown) {
        if (shown) {
            [NSCursor unhide];
        }
        else {
            [NSCursor hide];
        }
    }
    // update cursor type
    SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
    if (_sapp.macos.cursors[cursor]) {
        [_sapp.macos.cursors[cursor] set];
    }
    else {
        [[NSCursor arrowCursor] set];
    }
}

_SOKOL_PRIVATE void _sapp_macos_set_icon(const sapp_icon_desc* icon_desc, int num_images) {
    NSDockTile* dock_tile = NSApp.dockTile;
    const int wanted_width = (int) dock_tile.size.width;
    const int wanted_height = (int) dock_tile.size.height;
    const int img_index = _sapp_image_bestmatch(icon_desc->images, num_images, wanted_width, wanted_height);
    const sapp_image_desc* img_desc = &icon_desc->images[img_index];

    CGColorSpaceRef cg_color_space = CGColorSpaceCreateDeviceRGB();
    CFDataRef cf_data = CFDataCreate(kCFAllocatorDefault, (const UInt8*)img_desc->pixels.ptr, (CFIndex)img_desc->pixels.size);
    CGDataProviderRef cg_data_provider = CGDataProviderCreateWithCFData(cf_data);
    CGImageRef cg_img = CGImageCreate(
        (size_t)img_desc->width,    // width
        (size_t)img_desc->height,   // height
        8,                          // bitsPerComponent
        32,                         // bitsPerPixel
        (size_t)img_desc->width * 4,// bytesPerRow
        cg_color_space,             // space
        kCGImageAlphaLast | kCGImageByteOrderDefault,  // bitmapInfo
        cg_data_provider,           // provider
        NULL,                       // decode
        false,                      // shouldInterpolate
        kCGRenderingIntentDefault);
    CFRelease(cf_data);
    CGDataProviderRelease(cg_data_provider);
    CGColorSpaceRelease(cg_color_space);

    NSImage* ns_image = [[NSImage alloc] initWithCGImage:cg_img size:dock_tile.size];
    dock_tile.contentView = [NSImageView imageViewWithImage:ns_image];
    [dock_tile display];
    _SAPP_OBJC_RELEASE(ns_image);
    CGImageRelease(cg_img);
}

_SOKOL_PRIVATE void _sapp_macos_frame(void) {
    _sapp_frame();
    if (_sapp.quit_requested || _sapp.quit_ordered) {
        [_sapp.macos.window performClose:nil];
    }
}

@implementation _sapp_macos_app_delegate
- (void)applicationDidFinishLaunching:(NSNotification*)aNotification {
    _SOKOL_UNUSED(aNotification);
    _sapp_macos_init_cursors();
    if ((_sapp.window_width == 0) || (_sapp.window_height == 0)) {
        // use 4/5 of screen size as default size
        NSRect screen_rect = NSScreen.mainScreen.frame;
        if (_sapp.window_width == 0) {
            _sapp.window_width = (int)roundf((screen_rect.size.width * 4.0f) / 5.0f);
        }
        if (_sapp.window_height == 0) {
            _sapp.window_height = (int)roundf((screen_rect.size.height * 4.0f) / 5.0f);
        }
    }
    const NSUInteger style =
        NSWindowStyleMaskTitled |
        NSWindowStyleMaskClosable |
        NSWindowStyleMaskMiniaturizable |
        NSWindowStyleMaskResizable;
    NSRect window_rect = NSMakeRect(0, 0, _sapp.window_width, _sapp.window_height);
    _sapp.macos.window = [[_sapp_macos_window alloc]
        initWithContentRect:window_rect
        styleMask:style
        backing:NSBackingStoreBuffered
        defer:NO];
    _sapp.macos.window.releasedWhenClosed = NO; // this is necessary for proper cleanup in applicationWillTerminate
    _sapp.macos.window.title = [NSString stringWithUTF8String:_sapp.window_title];
    _sapp.macos.window.acceptsMouseMovedEvents = YES;
    _sapp.macos.window.restorable = YES;

    _sapp.macos.win_dlg = [[_sapp_macos_window_delegate alloc] init];
    _sapp.macos.window.delegate = _sapp.macos.win_dlg;
    #if defined(SOKOL_METAL)
        NSInteger max_fps = 60;
        #if (__MAC_OS_X_VERSION_MAX_ALLOWED >= 120000)
        if (@available(macOS 12.0, *)) {
            max_fps = [NSScreen.mainScreen maximumFramesPerSecond];
        }
        #endif
        _sapp.macos.mtl_device = MTLCreateSystemDefaultDevice();
        _sapp.macos.view = [[_sapp_macos_view alloc] init];
        [_sapp.macos.view updateTrackingAreas];
        _sapp.macos.view.preferredFramesPerSecond = max_fps / _sapp.swap_interval;
        _sapp.macos.view.device = _sapp.macos.mtl_device;
        _sapp.macos.view.colorPixelFormat = MTLPixelFormatBGRA8Unorm;
        _sapp.macos.view.depthStencilPixelFormat = MTLPixelFormatDepth32Float_Stencil8;
        _sapp.macos.view.sampleCount = (NSUInteger) _sapp.sample_count;
        _sapp.macos.view.autoResizeDrawable = false;
        _sapp.macos.window.contentView = _sapp.macos.view;
        [_sapp.macos.window makeFirstResponder:_sapp.macos.view];
        _sapp.macos.view.layer.magnificationFilter = kCAFilterNearest;
    #elif defined(SOKOL_GLCORE)
        NSOpenGLPixelFormatAttribute attrs[32];
        int i = 0;
        attrs[i++] = NSOpenGLPFAAccelerated;
        attrs[i++] = NSOpenGLPFADoubleBuffer;
        attrs[i++] = NSOpenGLPFAOpenGLProfile;
        const int glVersion = _sapp.desc.gl_major_version * 10 + _sapp.desc.gl_minor_version;
        switch(glVersion) {
            case 10: attrs[i++] = NSOpenGLProfileVersionLegacy;  break;
            case 32: attrs[i++] = NSOpenGLProfileVersion3_2Core; break;
            case 41: attrs[i++] = NSOpenGLProfileVersion4_1Core; break;
            default:
                _SAPP_PANIC(MACOS_INVALID_NSOPENGL_PROFILE);
        }
        attrs[i++] = NSOpenGLPFAColorSize; attrs[i++] = 24;
        attrs[i++] = NSOpenGLPFAAlphaSize; attrs[i++] = 8;
        attrs[i++] = NSOpenGLPFADepthSize; attrs[i++] = 24;
        attrs[i++] = NSOpenGLPFAStencilSize; attrs[i++] = 8;
        if (_sapp.sample_count > 1) {
            attrs[i++] = NSOpenGLPFAMultisample;
            attrs[i++] = NSOpenGLPFASampleBuffers; attrs[i++] = 1;
            attrs[i++] = NSOpenGLPFASamples; attrs[i++] = (NSOpenGLPixelFormatAttribute)_sapp.sample_count;
        }
        else {
            attrs[i++] = NSOpenGLPFASampleBuffers; attrs[i++] = 0;
        }
        attrs[i++] = 0;
        NSOpenGLPixelFormat* glpixelformat_obj = [[NSOpenGLPixelFormat alloc] initWithAttributes:attrs];
        SOKOL_ASSERT(glpixelformat_obj != nil);

        _sapp.macos.view = [[_sapp_macos_view alloc]
            initWithFrame:window_rect
            pixelFormat:glpixelformat_obj];
        _SAPP_OBJC_RELEASE(glpixelformat_obj);
        [_sapp.macos.view updateTrackingAreas];
        if (_sapp.desc.high_dpi) {
            [_sapp.macos.view setWantsBestResolutionOpenGLSurface:YES];
        }
        else {
            [_sapp.macos.view setWantsBestResolutionOpenGLSurface:NO];
        }

        _sapp.macos.window.contentView = _sapp.macos.view;
        [_sapp.macos.window makeFirstResponder:_sapp.macos.view];

        NSTimer* timer_obj = [NSTimer timerWithTimeInterval:0.001
            target:_sapp.macos.view
            selector:@selector(timerFired:)
            userInfo:nil
            repeats:YES];
        [[NSRunLoop currentRunLoop] addTimer:timer_obj forMode:NSDefaultRunLoopMode];
        timer_obj = nil;
    #endif
    [_sapp.macos.window center];
    _sapp.valid = true;
    NSApp.activationPolicy = NSApplicationActivationPolicyRegular;
    if (_sapp.fullscreen) {
        /* ^^^ on GL, this already toggles a rendered frame, so set the valid flag before */
        [_sapp.macos.window toggleFullScreen:self];
    }
    [NSApp activateIgnoringOtherApps:YES];
    [_sapp.macos.window makeKeyAndOrderFront:nil];
    _sapp_macos_update_dimensions();
    [NSEvent setMouseCoalescingEnabled:NO];

    // workaround for window not being focused during a long init callback
    // for details see: https://github.com/floooh/sokol/pull/982
    // also see: https://gitlab.gnome.org/GNOME/gtk/-/issues/2342
    NSEvent *focusevent = [NSEvent otherEventWithType:NSEventTypeAppKitDefined
        location:NSZeroPoint
        modifierFlags:0x40
        timestamp:0
        windowNumber:0
        context:nil
        subtype:NSEventSubtypeApplicationActivated
        data1:0
        data2:0];
    [NSApp postEvent:focusevent atStart:YES];
}

- (BOOL)applicationShouldTerminateAfterLastWindowClosed:(NSApplication*)sender {
    _SOKOL_UNUSED(sender);
    return YES;
}

- (void)applicationWillTerminate:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_call_cleanup();
    _sapp_macos_discard_state();
    _sapp_discard_state();
}
@end

@implementation _sapp_macos_window_delegate
- (BOOL)windowShouldClose:(id)sender {
    _SOKOL_UNUSED(sender);
    /* only give user-code a chance to intervene when sapp_quit() wasn't already called */
    if (!_sapp.quit_ordered) {
        /* if window should be closed and event handling is enabled, give user code
           a chance to intervene via sapp_cancel_quit()
        */
        _sapp.quit_requested = true;
        _sapp_macos_app_event(SAPP_EVENTTYPE_QUIT_REQUESTED);
        /* user code hasn't intervened, quit the app */
        if (_sapp.quit_requested) {
            _sapp.quit_ordered = true;
        }
    }
    if (_sapp.quit_ordered) {
        return YES;
    }
    else {
        return NO;
    }
}

#if defined(SOKOL_METAL)
- (void)windowWillStartLiveResize:(NSNotification *)notification {
    // Work around the MTKView resizing glitch by "anchoring" the layer to the window corner opposite
    // to the currently manipulated corner (or edge). This prevents the content stretching back and
    // forth during resizing. This is a workaround for this issue: https://github.com/floooh/sokol/issues/700
    // Can be removed if/when migrating to CAMetalLayer: https://github.com/floooh/sokol/issues/727
    bool resizing_from_left = _sapp.mouse.x < _sapp.window_width/2;
    bool resizing_from_top = _sapp.mouse.y < _sapp.window_height/2;
    NSViewLayerContentsPlacement placement;
    if (resizing_from_left) {
        placement = resizing_from_top ? NSViewLayerContentsPlacementBottomRight : NSViewLayerContentsPlacementTopRight;
    } else {
        placement = resizing_from_top ? NSViewLayerContentsPlacementBottomLeft : NSViewLayerContentsPlacementTopLeft;
    }
    _sapp.macos.view.layerContentsPlacement = placement;
}
#endif

- (void)windowDidResize:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_macos_update_dimensions();
}

- (void)windowDidChangeScreen:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_timing_reset(&_sapp.timing);
    _sapp_macos_update_dimensions();
}

- (void)windowDidMiniaturize:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_macos_app_event(SAPP_EVENTTYPE_ICONIFIED);
}

- (void)windowDidDeminiaturize:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_macos_app_event(SAPP_EVENTTYPE_RESTORED);
}

- (void)windowDidBecomeKey:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_macos_app_event(SAPP_EVENTTYPE_FOCUSED);
}

- (void)windowDidResignKey:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp_macos_app_event(SAPP_EVENTTYPE_UNFOCUSED);
}

- (void)windowDidEnterFullScreen:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp.fullscreen = true;
}

- (void)windowDidExitFullScreen:(NSNotification*)notification {
    _SOKOL_UNUSED(notification);
    _sapp.fullscreen = false;
}
@end

@implementation _sapp_macos_window
- (instancetype)initWithContentRect:(NSRect)contentRect
                          styleMask:(NSWindowStyleMask)style
                            backing:(NSBackingStoreType)backingStoreType
                              defer:(BOOL)flag {
    if (self = [super initWithContentRect:contentRect styleMask:style backing:backingStoreType defer:flag]) {
        #if __MAC_OS_X_VERSION_MAX_ALLOWED >= 101300
            [self registerForDraggedTypes:[NSArray arrayWithObject:NSPasteboardTypeFileURL]];
        #endif
    }
    return self;
}

- (NSDragOperation)draggingEntered:(id<NSDraggingInfo>)sender {
    return NSDragOperationCopy;
}

- (NSDragOperation)draggingUpdated:(id<NSDraggingInfo>)sender {
    return NSDragOperationCopy;
}

- (BOOL)performDragOperation:(id<NSDraggingInfo>)sender {
    #if __MAC_OS_X_VERSION_MAX_ALLOWED >= 101300
    NSPasteboard *pboard = [sender draggingPasteboard];
    if ([pboard.types containsObject:NSPasteboardTypeFileURL]) {
        _sapp_clear_drop_buffer();
        _sapp.drop.num_files = ((int)pboard.pasteboardItems.count > _sapp.drop.max_files) ? _sapp.drop.max_files : (int)pboard.pasteboardItems.count;
        bool drop_failed = false;
        for (int i = 0; i < _sapp.drop.num_files; i++) {
            NSURL *fileUrl = [NSURL fileURLWithPath:[pboard.pasteboardItems[(NSUInteger)i] stringForType:NSPasteboardTypeFileURL]];
            if (!_sapp_strcpy(fileUrl.standardizedURL.path.UTF8String, _sapp_dropped_file_path_ptr(i), _sapp.drop.max_path_length)) {
                _SAPP_ERROR(DROPPED_FILE_PATH_TOO_LONG);
                drop_failed = true;
                break;
            }
        }
        if (!drop_failed) {
            if (_sapp_events_enabled()) {
                _sapp_macos_mouse_update_from_nspoint(sender.draggingLocation, true);
                _sapp_init_event(SAPP_EVENTTYPE_FILES_DROPPED);
                _sapp.event.modifiers = _sapp_macos_mods(nil);
                _sapp_call_event(&_sapp.event);
            }
        }
        else {
            _sapp_clear_drop_buffer();
            _sapp.drop.num_files = 0;
        }
        return YES;
    }
    #endif
    return NO;
}
@end

@implementation _sapp_macos_view
#if defined(SOKOL_GLCORE)
- (void)timerFired:(id)sender {
    _SOKOL_UNUSED(sender);
    [self setNeedsDisplay:YES];
}
- (void)prepareOpenGL {
    [super prepareOpenGL];
    GLint swapInt = 1;
    NSOpenGLContext* ctx = [_sapp.macos.view openGLContext];
    [ctx setValues:&swapInt forParameter:NSOpenGLContextParameterSwapInterval];
    [ctx makeCurrentContext];
}
#endif

_SOKOL_PRIVATE void _sapp_macos_poll_input_events(void) {
    /*

    NOTE: late event polling temporarily out-commented to check if this
    causes infrequent and almost impossible to reproduce problems with the
    window close events, see:
    https://github.com/floooh/sokol/pull/483#issuecomment-805148815


    const NSEventMask mask = NSEventMaskLeftMouseDown |
                             NSEventMaskLeftMouseUp|
                             NSEventMaskRightMouseDown |
                             NSEventMaskRightMouseUp |
                             NSEventMaskMouseMoved |
                             NSEventMaskLeftMouseDragged |
                             NSEventMaskRightMouseDragged |
                             NSEventMaskMouseEntered |
                             NSEventMaskMouseExited |
                             NSEventMaskKeyDown |
                             NSEventMaskKeyUp |
                             NSEventMaskCursorUpdate |
                             NSEventMaskScrollWheel |
                             NSEventMaskTabletPoint |
                             NSEventMaskTabletProximity |
                             NSEventMaskOtherMouseDown |
                             NSEventMaskOtherMouseUp |
                             NSEventMaskOtherMouseDragged |
                             NSEventMaskPressure |
                             NSEventMaskDirectTouch;
    @autoreleasepool {
        for (;;) {
            // NOTE: using NSDefaultRunLoopMode here causes stuttering in the GL backend,
            // see: https://github.com/floooh/sokol/issues/486
            NSEvent* event = [NSApp nextEventMatchingMask:mask untilDate:nil inMode:NSEventTrackingRunLoopMode dequeue:YES];
            if (event == nil) {
                break;
            }
            [NSApp sendEvent:event];
        }
    }
    */
}

- (void)drawRect:(NSRect)rect {
    _SOKOL_UNUSED(rect);
    #if defined(_SAPP_ANY_GL)
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&_sapp.gl.framebuffer);
    #endif
    _sapp_timing_measure(&_sapp.timing);
    /* Catch any last-moment input events */
    _sapp_macos_poll_input_events();
    @autoreleasepool {
        _sapp_macos_frame();
    }
    #if defined(_SAPP_ANY_GL)
    [[_sapp.macos.view openGLContext] flushBuffer];
    #endif
}

- (BOOL)isOpaque {
    return YES;
}
- (BOOL)canBecomeKeyView {
    return YES;
}
- (BOOL)acceptsFirstResponder {
    return YES;
}
- (void)updateTrackingAreas {
    if (_sapp.macos.tracking_area != nil) {
        [self removeTrackingArea:_sapp.macos.tracking_area];
        _SAPP_OBJC_RELEASE(_sapp.macos.tracking_area);
    }
    const NSTrackingAreaOptions options = NSTrackingMouseEnteredAndExited |
                                          NSTrackingActiveInKeyWindow |
                                          NSTrackingEnabledDuringMouseDrag |
                                          NSTrackingCursorUpdate |
                                          NSTrackingInVisibleRect |
                                          NSTrackingAssumeInside;
    _sapp.macos.tracking_area = [[NSTrackingArea alloc] initWithRect:[self bounds] options:options owner:self userInfo:nil];
    [self addTrackingArea:_sapp.macos.tracking_area];
    [super updateTrackingAreas];
}

// helper function to make GL context active
static void _sapp_gl_make_current(void) {
    #if defined(SOKOL_GLCORE)
    [[_sapp.macos.view openGLContext] makeCurrentContext];
    #endif
}

- (void)mouseEntered:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, true);
    /* don't send mouse enter/leave while dragging (so that it behaves the same as
       on Windows while SetCapture is active
    */
    if (0 == _sapp.macos.mouse_buttons) {
        _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_ENTER, SAPP_MOUSEBUTTON_INVALID, _sapp_macos_mods(event));
    }
}
- (void)mouseExited:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, true);
    if (0 == _sapp.macos.mouse_buttons) {
        _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_LEAVE, SAPP_MOUSEBUTTON_INVALID, _sapp_macos_mods(event));
    }
}
- (void)mouseDown:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, SAPP_MOUSEBUTTON_LEFT, _sapp_macos_mods(event));
    _sapp.macos.mouse_buttons |= (1<<SAPP_MOUSEBUTTON_LEFT);
}
- (void)mouseUp:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, SAPP_MOUSEBUTTON_LEFT, _sapp_macos_mods(event));
    _sapp.macos.mouse_buttons &= ~(1<<SAPP_MOUSEBUTTON_LEFT);
}
- (void)rightMouseDown:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, SAPP_MOUSEBUTTON_RIGHT, _sapp_macos_mods(event));
    _sapp.macos.mouse_buttons |= (1<<SAPP_MOUSEBUTTON_RIGHT);
}
- (void)rightMouseUp:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, SAPP_MOUSEBUTTON_RIGHT, _sapp_macos_mods(event));
    _sapp.macos.mouse_buttons &= ~(1<<SAPP_MOUSEBUTTON_RIGHT);
}
- (void)otherMouseDown:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    if (2 == event.buttonNumber) {
        _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, SAPP_MOUSEBUTTON_MIDDLE, _sapp_macos_mods(event));
        _sapp.macos.mouse_buttons |= (1<<SAPP_MOUSEBUTTON_MIDDLE);
    }
}
- (void)otherMouseUp:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    if (2 == event.buttonNumber) {
        _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, SAPP_MOUSEBUTTON_MIDDLE, _sapp_macos_mods(event));
        _sapp.macos.mouse_buttons &= (1<<SAPP_MOUSEBUTTON_MIDDLE);
    }
}
- (void)otherMouseDragged:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    if (2 == event.buttonNumber) {
        if (_sapp.mouse.locked) {
            _sapp.mouse.dx = [event deltaX];
            _sapp.mouse.dy = [event deltaY];
        }
        _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID, _sapp_macos_mods(event));
    }
}
- (void)mouseMoved:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    if (_sapp.mouse.locked) {
        _sapp.mouse.dx = [event deltaX];
        _sapp.mouse.dy = [event deltaY];
    }
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID , _sapp_macos_mods(event));
}
- (void)mouseDragged:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    if (_sapp.mouse.locked) {
        _sapp.mouse.dx = [event deltaX];
        _sapp.mouse.dy = [event deltaY];
    }
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID , _sapp_macos_mods(event));
}
- (void)rightMouseDragged:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, false);
    if (_sapp.mouse.locked) {
        _sapp.mouse.dx = [event deltaX];
        _sapp.mouse.dy = [event deltaY];
    }
    _sapp_macos_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID, _sapp_macos_mods(event));
}
- (void)scrollWheel:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_mouse_update_from_nsevent(event, true);
    if (_sapp_events_enabled()) {
        float dx = (float) event.scrollingDeltaX;
        float dy = (float) event.scrollingDeltaY;
        if (event.hasPreciseScrollingDeltas) {
            dx *= 0.1;
            dy *= 0.1;
        }
        if ((_sapp_absf(dx) > 0.0f) || (_sapp_absf(dy) > 0.0f)) {
            _sapp_init_event(SAPP_EVENTTYPE_MOUSE_SCROLL);
            _sapp.event.modifiers = _sapp_macos_mods(event);
            _sapp.event.scroll_x = dx;
            _sapp.event.scroll_y = dy;
            _sapp_call_event(&_sapp.event);
        }
    }
}
- (void)keyDown:(NSEvent*)event {
    if (_sapp_events_enabled()) {
        _sapp_gl_make_current();
        const uint32_t mods = _sapp_macos_mods(event);
        const sapp_keycode key_code = _sapp_translate_key(event.keyCode);
        _sapp_macos_key_event(SAPP_EVENTTYPE_KEY_DOWN, key_code, event.isARepeat, mods);
        const NSString* chars = event.characters;
        const NSUInteger len = chars.length;
        if (len > 0) {
            _sapp_init_event(SAPP_EVENTTYPE_CHAR);
            _sapp.event.modifiers = mods;
            for (NSUInteger i = 0; i < len; i++) {
                const unichar codepoint = [chars characterAtIndex:i];
                if ((codepoint & 0xFF00) == 0xF700) {
                    continue;
                }
                _sapp.event.char_code = codepoint;
                _sapp.event.key_repeat = event.isARepeat;
                _sapp_call_event(&_sapp.event);
            }
        }
        /* if this is a Cmd+V (paste), also send a CLIPBOARD_PASTE event */
        if (_sapp.clipboard.enabled && (mods == SAPP_MODIFIER_SUPER) && (key_code == SAPP_KEYCODE_V)) {
            _sapp_init_event(SAPP_EVENTTYPE_CLIPBOARD_PASTED);
            _sapp_call_event(&_sapp.event);
        }
    }
}

- (BOOL)performKeyEquivalent:(NSEvent*)event {
    // fixes Ctrl-Tab keydown not triggering a keyDown event
    //
    // NOTE: it seems that Ctrl-F1 cannot be intercepted the same way, but since
    // this enabled critical accessibility features that's probably a good thing.
    switch (_sapp_translate_key(event.keyCode)) {
        case SAPP_KEYCODE_TAB:
            [_sapp.macos.view keyDown:event];
            return YES;
        default:
            return NO;
    }
}

- (void)keyUp:(NSEvent*)event {
    _sapp_gl_make_current();
    _sapp_macos_key_event(SAPP_EVENTTYPE_KEY_UP,
        _sapp_translate_key(event.keyCode),
        event.isARepeat,
        _sapp_macos_mods(event));
}
- (void)flagsChanged:(NSEvent*)event {
    const uint32_t old_f = _sapp.macos.flags_changed_store;
    const uint32_t new_f = (uint32_t)event.modifierFlags;
    _sapp.macos.flags_changed_store = new_f;
    sapp_keycode key_code = SAPP_KEYCODE_INVALID;
    bool down = false;
    if ((new_f ^ old_f) & NSEventModifierFlagShift) {
        key_code = SAPP_KEYCODE_LEFT_SHIFT;
        down = 0 != (new_f & NSEventModifierFlagShift);
    }
    if ((new_f ^ old_f) & NSEventModifierFlagControl) {
        key_code = SAPP_KEYCODE_LEFT_CONTROL;
        down = 0 != (new_f & NSEventModifierFlagControl);
    }
    if ((new_f ^ old_f) & NSEventModifierFlagOption) {
        key_code = SAPP_KEYCODE_LEFT_ALT;
        down = 0 != (new_f & NSEventModifierFlagOption);
    }
    if ((new_f ^ old_f) & NSEventModifierFlagCommand) {
        key_code = SAPP_KEYCODE_LEFT_SUPER;
        down = 0 != (new_f & NSEventModifierFlagCommand);
    }
    if (key_code != SAPP_KEYCODE_INVALID) {
        _sapp_macos_key_event(down ? SAPP_EVENTTYPE_KEY_DOWN : SAPP_EVENTTYPE_KEY_UP,
            key_code,
            false,
            _sapp_macos_mods(event));
    }
}
@end

#endif // macOS

// ██  ██████  ███████
// ██ ██    ██ ██
// ██ ██    ██ ███████
// ██ ██    ██      ██
// ██  ██████  ███████
//
// >>ios
#if defined(_SAPP_IOS)

_SOKOL_PRIVATE void _sapp_ios_discard_state(void) {
    // NOTE: it's safe to call [release] on a nil object
    _SAPP_OBJC_RELEASE(_sapp.ios.textfield_dlg);
    _SAPP_OBJC_RELEASE(_sapp.ios.textfield);
    #if defined(SOKOL_METAL)
        _SAPP_OBJC_RELEASE(_sapp.ios.view_ctrl);
        _SAPP_OBJC_RELEASE(_sapp.ios.mtl_device);
    #else
        _SAPP_OBJC_RELEASE(_sapp.ios.view_ctrl);
        _SAPP_OBJC_RELEASE(_sapp.ios.eagl_ctx);
    #endif
    _SAPP_OBJC_RELEASE(_sapp.ios.view);
    _SAPP_OBJC_RELEASE(_sapp.ios.window);
}

_SOKOL_PRIVATE void _sapp_ios_run(const sapp_desc* desc) {
    _sapp_init_state(desc);
    static int argc = 1;
    static char* argv[] = { (char*)"sokol_app" };
    UIApplicationMain(argc, argv, nil, NSStringFromClass([_sapp_app_delegate class]));
}

/* iOS entry function */
#if !defined(SOKOL_NO_ENTRY)
int main(int argc, char* argv[]) {
    sapp_desc desc = sokol_main(argc, argv);
    _sapp_ios_run(&desc);
    return 0;
}
#endif /* SOKOL_NO_ENTRY */

_SOKOL_PRIVATE void _sapp_ios_app_event(sapp_event_type type) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_ios_touch_event(sapp_event_type type, NSSet<UITouch *>* touches, UIEvent* event) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        NSEnumerator* enumerator = event.allTouches.objectEnumerator;
        UITouch* ios_touch;
        while ((ios_touch = [enumerator nextObject])) {
            if ((_sapp.event.num_touches + 1) < SAPP_MAX_TOUCHPOINTS) {
                CGPoint ios_pos = [ios_touch locationInView:_sapp.ios.view];
                sapp_touchpoint* cur_point = &_sapp.event.touches[_sapp.event.num_touches++];
                cur_point->identifier = (uintptr_t) ios_touch;
                cur_point->pos_x = ios_pos.x * _sapp.dpi_scale;
                cur_point->pos_y = ios_pos.y * _sapp.dpi_scale;
                cur_point->changed = [touches containsObject:ios_touch];
            }
        }
        if (_sapp.event.num_touches > 0) {
            _sapp_call_event(&_sapp.event);
        }
    }
}

_SOKOL_PRIVATE void _sapp_ios_update_dimensions(void) {
    CGRect screen_rect = UIScreen.mainScreen.bounds;
    _sapp.framebuffer_width = (int)roundf(screen_rect.size.width * _sapp.dpi_scale);
    _sapp.framebuffer_height = (int)roundf(screen_rect.size.height * _sapp.dpi_scale);
    _sapp.window_width = (int)roundf(screen_rect.size.width);
    _sapp.window_height = (int)roundf(screen_rect.size.height);
    int cur_fb_width, cur_fb_height;
    #if defined(SOKOL_METAL)
        const CGSize fb_size = _sapp.ios.view.drawableSize;
        cur_fb_width = (int)roundf(fb_size.width);
        cur_fb_height = (int)roundf(fb_size.height);
    #else
        cur_fb_width = (int)roundf(_sapp.ios.view.drawableWidth);
        cur_fb_height = (int)roundf(_sapp.ios.view.drawableHeight);
    #endif
    const bool dim_changed = (_sapp.framebuffer_width != cur_fb_width) ||
                             (_sapp.framebuffer_height != cur_fb_height);
    if (dim_changed) {
        #if defined(SOKOL_METAL)
            const CGSize drawable_size = { (CGFloat) _sapp.framebuffer_width, (CGFloat) _sapp.framebuffer_height };
            _sapp.ios.view.drawableSize = drawable_size;
        #else
            // nothing to do here, GLKView correctly respects the view's contentScaleFactor
        #endif
        if (!_sapp.first_frame) {
            _sapp_ios_app_event(SAPP_EVENTTYPE_RESIZED);
        }
    }
}

_SOKOL_PRIVATE void _sapp_ios_frame(void) {
    _sapp_ios_update_dimensions();
    _sapp_frame();
}

_SOKOL_PRIVATE void _sapp_ios_show_keyboard(bool shown) {
    /* if not happened yet, create an invisible text field */
    if (nil == _sapp.ios.textfield) {
        _sapp.ios.textfield_dlg = [[_sapp_textfield_dlg alloc] init];
        _sapp.ios.textfield = [[UITextField alloc] initWithFrame:CGRectMake(10, 10, 100, 50)];
        _sapp.ios.textfield.keyboardType = UIKeyboardTypeDefault;
        _sapp.ios.textfield.returnKeyType = UIReturnKeyDefault;
        _sapp.ios.textfield.autocapitalizationType = UITextAutocapitalizationTypeNone;
        _sapp.ios.textfield.autocorrectionType = UITextAutocorrectionTypeNo;
        _sapp.ios.textfield.spellCheckingType = UITextSpellCheckingTypeNo;
        _sapp.ios.textfield.hidden = YES;
        _sapp.ios.textfield.text = @"x";
        _sapp.ios.textfield.delegate = _sapp.ios.textfield_dlg;
        [_sapp.ios.view_ctrl.view addSubview:_sapp.ios.textfield];

        [[NSNotificationCenter defaultCenter] addObserver:_sapp.ios.textfield_dlg
            selector:@selector(keyboardWasShown:)
            name:UIKeyboardDidShowNotification object:nil];
        [[NSNotificationCenter defaultCenter] addObserver:_sapp.ios.textfield_dlg
            selector:@selector(keyboardWillBeHidden:)
            name:UIKeyboardWillHideNotification object:nil];
        [[NSNotificationCenter defaultCenter] addObserver:_sapp.ios.textfield_dlg
            selector:@selector(keyboardDidChangeFrame:)
            name:UIKeyboardDidChangeFrameNotification object:nil];
    }
    if (shown) {
        /* setting the text field as first responder brings up the onscreen keyboard */
        [_sapp.ios.textfield becomeFirstResponder];
    }
    else {
        [_sapp.ios.textfield resignFirstResponder];
    }
}

@implementation _sapp_app_delegate
- (BOOL)application:(UIApplication*)application didFinishLaunchingWithOptions:(NSDictionary*)launchOptions {
    CGRect screen_rect = UIScreen.mainScreen.bounds;
    _sapp.ios.window = [[UIWindow alloc] initWithFrame:screen_rect];
    _sapp.window_width = (int)roundf(screen_rect.size.width);
    _sapp.window_height = (int)roundf(screen_rect.size.height);
    if (_sapp.desc.high_dpi) {
        _sapp.dpi_scale = (float) UIScreen.mainScreen.nativeScale;
    }
    else {
        _sapp.dpi_scale = 1.0f;
    }
    _sapp.framebuffer_width = (int)roundf(_sapp.window_width * _sapp.dpi_scale);
    _sapp.framebuffer_height = (int)roundf(_sapp.window_height * _sapp.dpi_scale);
    NSInteger max_fps = UIScreen.mainScreen.maximumFramesPerSecond;
    #if defined(SOKOL_METAL)
        _sapp.ios.mtl_device = MTLCreateSystemDefaultDevice();
        _sapp.ios.view = [[_sapp_ios_view alloc] init];
        _sapp.ios.view.preferredFramesPerSecond = max_fps / _sapp.swap_interval;
        _sapp.ios.view.device = _sapp.ios.mtl_device;
        _sapp.ios.view.colorPixelFormat = MTLPixelFormatBGRA8Unorm;
        _sapp.ios.view.depthStencilPixelFormat = MTLPixelFormatDepth32Float_Stencil8;
        _sapp.ios.view.sampleCount = (NSUInteger)_sapp.sample_count;
        /* NOTE: iOS MTKView seems to ignore thew view's contentScaleFactor
            and automatically renders at Retina resolution. We'll disable
            autoResize and instead do the resizing in _sapp_ios_update_dimensions()
        */
        _sapp.ios.view.autoResizeDrawable = false;
        _sapp.ios.view.userInteractionEnabled = YES;
        _sapp.ios.view.multipleTouchEnabled = YES;
        _sapp.ios.view_ctrl = [[UIViewController alloc] init];
        _sapp.ios.view_ctrl.modalPresentationStyle = UIModalPresentationFullScreen;
        _sapp.ios.view_ctrl.view = _sapp.ios.view;
        _sapp.ios.window.rootViewController = _sapp.ios.view_ctrl;
    #else
        _sapp.ios.eagl_ctx = [[EAGLContext alloc] initWithAPI:kEAGLRenderingAPIOpenGLES3];
        _sapp.ios.view = [[_sapp_ios_view alloc] initWithFrame:screen_rect];
        _sapp.ios.view.drawableColorFormat = GLKViewDrawableColorFormatRGBA8888;
        _sapp.ios.view.drawableDepthFormat = GLKViewDrawableDepthFormat24;
        _sapp.ios.view.drawableStencilFormat = GLKViewDrawableStencilFormatNone;
        GLKViewDrawableMultisample msaa = _sapp.sample_count > 1 ? GLKViewDrawableMultisample4X : GLKViewDrawableMultisampleNone;
        _sapp.ios.view.drawableMultisample = msaa;
        _sapp.ios.view.context = _sapp.ios.eagl_ctx;
        _sapp.ios.view.enableSetNeedsDisplay = NO;
        _sapp.ios.view.userInteractionEnabled = YES;
        _sapp.ios.view.multipleTouchEnabled = YES;
        // on GLKView, contentScaleFactor appears to work just fine!
        if (_sapp.desc.high_dpi) {
            _sapp.ios.view.contentScaleFactor = _sapp.dpi_scale;
        }
        else {
            _sapp.ios.view.contentScaleFactor = 1.0;
        }
        _sapp.ios.view_ctrl = [[GLKViewController alloc] init];
        _sapp.ios.view_ctrl.view = _sapp.ios.view;
        _sapp.ios.view_ctrl.preferredFramesPerSecond = max_fps / _sapp.swap_interval;
        _sapp.ios.window.rootViewController = _sapp.ios.view_ctrl;
    #endif
    [_sapp.ios.window makeKeyAndVisible];

    _sapp.valid = true;
    return YES;
}

- (void)applicationWillResignActive:(UIApplication *)application {
    if (!_sapp.ios.suspended) {
        _sapp.ios.suspended = true;
        _sapp_ios_app_event(SAPP_EVENTTYPE_SUSPENDED);
    }
}

- (void)applicationDidBecomeActive:(UIApplication *)application {
    if (_sapp.ios.suspended) {
        _sapp.ios.suspended = false;
        _sapp_ios_app_event(SAPP_EVENTTYPE_RESUMED);
    }
}

/* NOTE: this method will rarely ever be called, iOS application
    which are terminated by the user are usually killed via signal 9
    by the operating system.
*/
- (void)applicationWillTerminate:(UIApplication *)application {
    _SOKOL_UNUSED(application);
    _sapp_call_cleanup();
    _sapp_ios_discard_state();
    _sapp_discard_state();
}
@end

@implementation _sapp_textfield_dlg
- (void)keyboardWasShown:(NSNotification*)notif {
    _sapp.onscreen_keyboard_shown = true;
    /* query the keyboard's size, and modify the content view's size */
    if (_sapp.desc.ios_keyboard_resizes_canvas) {
        NSDictionary* info = notif.userInfo;
        CGFloat kbd_h = [[info objectForKey:UIKeyboardFrameEndUserInfoKey] CGRectValue].size.height;
        CGRect view_frame = UIScreen.mainScreen.bounds;
        view_frame.size.height -= kbd_h;
        _sapp.ios.view.frame = view_frame;
    }
}
- (void)keyboardWillBeHidden:(NSNotification*)notif {
    _sapp.onscreen_keyboard_shown = false;
    if (_sapp.desc.ios_keyboard_resizes_canvas) {
        _sapp.ios.view.frame = UIScreen.mainScreen.bounds;
    }
}
- (void)keyboardDidChangeFrame:(NSNotification*)notif {
    /* this is for the case when the screen rotation changes while the keyboard is open */
    if (_sapp.onscreen_keyboard_shown && _sapp.desc.ios_keyboard_resizes_canvas) {
        NSDictionary* info = notif.userInfo;
        CGFloat kbd_h = [[info objectForKey:UIKeyboardFrameEndUserInfoKey] CGRectValue].size.height;
        CGRect view_frame = UIScreen.mainScreen.bounds;
        view_frame.size.height -= kbd_h;
        _sapp.ios.view.frame = view_frame;
    }
}
- (BOOL)textField:(UITextField*)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString*)string {
    if (_sapp_events_enabled()) {
        const NSUInteger len = string.length;
        if (len > 0) {
            for (NSUInteger i = 0; i < len; i++) {
                unichar c = [string characterAtIndex:i];
                if (c >= 32) {
                    /* ignore surrogates for now */
                    if ((c < 0xD800) || (c > 0xDFFF)) {
                        _sapp_init_event(SAPP_EVENTTYPE_CHAR);
                        _sapp.event.char_code = c;
                        _sapp_call_event(&_sapp.event);
                    }
                }
                if (c <= 32) {
                    sapp_keycode k = SAPP_KEYCODE_INVALID;
                    switch (c) {
                        case 10: k = SAPP_KEYCODE_ENTER; break;
                        case 32: k = SAPP_KEYCODE_SPACE; break;
                        default: break;
                    }
                    if (k != SAPP_KEYCODE_INVALID) {
                        _sapp_init_event(SAPP_EVENTTYPE_KEY_DOWN);
                        _sapp.event.key_code = k;
                        _sapp_call_event(&_sapp.event);
                        _sapp_init_event(SAPP_EVENTTYPE_KEY_UP);
                        _sapp.event.key_code = k;
                        _sapp_call_event(&_sapp.event);
                    }
                }
            }
        }
        else {
            /* this was a backspace */
            _sapp_init_event(SAPP_EVENTTYPE_KEY_DOWN);
            _sapp.event.key_code = SAPP_KEYCODE_BACKSPACE;
            _sapp_call_event(&_sapp.event);
            _sapp_init_event(SAPP_EVENTTYPE_KEY_UP);
            _sapp.event.key_code = SAPP_KEYCODE_BACKSPACE;
            _sapp_call_event(&_sapp.event);
        }
    }
    return NO;
}
@end

@implementation _sapp_ios_view
- (void)drawRect:(CGRect)rect {
    _SOKOL_UNUSED(rect);
    #if defined(_SAPP_ANY_GL)
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&_sapp.gl.framebuffer);
    #endif
    _sapp_timing_measure(&_sapp.timing);
    @autoreleasepool {
        _sapp_ios_frame();
    }
}
- (BOOL)isOpaque {
    return YES;
}
- (void)touchesBegan:(NSSet<UITouch *> *)touches withEvent:(UIEvent*)event {
    _sapp_ios_touch_event(SAPP_EVENTTYPE_TOUCHES_BEGAN, touches, event);
}
- (void)touchesMoved:(NSSet<UITouch *> *)touches withEvent:(UIEvent*)event {
    _sapp_ios_touch_event(SAPP_EVENTTYPE_TOUCHES_MOVED, touches, event);
}
- (void)touchesEnded:(NSSet<UITouch *> *)touches withEvent:(UIEvent*)event {
    _sapp_ios_touch_event(SAPP_EVENTTYPE_TOUCHES_ENDED, touches, event);
}
- (void)touchesCancelled:(NSSet<UITouch *> *)touches withEvent:(UIEvent*)event {
    _sapp_ios_touch_event(SAPP_EVENTTYPE_TOUCHES_CANCELLED, touches, event);
}
@end
#endif /* TARGET_OS_IPHONE */

#endif /* _SAPP_APPLE */

// ███████ ███    ███ ███████  ██████ ██████  ██ ██████  ████████ ███████ ███    ██
// ██      ████  ████ ██      ██      ██   ██ ██ ██   ██    ██    ██      ████   ██
// █████   ██ ████ ██ ███████ ██      ██████  ██ ██████     ██    █████   ██ ██  ██
// ██      ██  ██  ██      ██ ██      ██   ██ ██ ██         ██    ██      ██  ██ ██
// ███████ ██      ██ ███████  ██████ ██   ██ ██ ██         ██    ███████ ██   ████
//
// >>emscripten
#if defined(_SAPP_EMSCRIPTEN)

#if defined(EM_JS_DEPS)
EM_JS_DEPS(sokol_app, "$withStackSave,$stringToUTF8OnStack,$findCanvasEventTarget")
#endif

#ifdef __cplusplus
extern "C" {
#endif

typedef void (*_sapp_html5_fetch_callback) (const sapp_html5_fetch_response*);

EMSCRIPTEN_KEEPALIVE void _sapp_emsc_onpaste(const char* str) {
    if (_sapp.clipboard.enabled) {
        _sapp_strcpy(str, _sapp.clipboard.buffer, _sapp.clipboard.buf_size);
        if (_sapp_events_enabled()) {
            _sapp_init_event(SAPP_EVENTTYPE_CLIPBOARD_PASTED);
            _sapp_call_event(&_sapp.event);
        }
    }
}

/*  https://developer.mozilla.org/en-US/docs/Web/API/WindowEventHandlers/onbeforeunload */
EMSCRIPTEN_KEEPALIVE int _sapp_html5_get_ask_leave_site(void) {
    return _sapp.html5_ask_leave_site ? 1 : 0;
}

EMSCRIPTEN_KEEPALIVE void _sapp_emsc_begin_drop(int num) {
    if (!_sapp.drop.enabled) {
        return;
    }
    if (num < 0) {
        num = 0;
    }
    if (num > _sapp.drop.max_files) {
        num = _sapp.drop.max_files;
    }
    _sapp.drop.num_files = num;
    _sapp_clear_drop_buffer();
}

EMSCRIPTEN_KEEPALIVE void _sapp_emsc_drop(int i, const char* name) {
    /* NOTE: name is only the filename part, not a path */
    if (!_sapp.drop.enabled) {
        return;
    }
    if (0 == name) {
        return;
    }
    SOKOL_ASSERT(_sapp.drop.num_files <= _sapp.drop.max_files);
    if ((i < 0) || (i >= _sapp.drop.num_files)) {
        return;
    }
    if (!_sapp_strcpy(name, _sapp_dropped_file_path_ptr(i), _sapp.drop.max_path_length)) {
        _SAPP_ERROR(DROPPED_FILE_PATH_TOO_LONG);
        _sapp.drop.num_files = 0;
    }
}

EMSCRIPTEN_KEEPALIVE void _sapp_emsc_end_drop(int x, int y, int mods) {
    if (!_sapp.drop.enabled) {
        return;
    }
    if (0 == _sapp.drop.num_files) {
        /* there was an error copying the filenames */
        _sapp_clear_drop_buffer();
        return;

    }
    if (_sapp_events_enabled()) {
        _sapp.mouse.x = (float)x * _sapp.dpi_scale;
        _sapp.mouse.y = (float)y * _sapp.dpi_scale;
        _sapp.mouse.dx = 0.0f;
        _sapp.mouse.dy = 0.0f;
        _sapp_init_event(SAPP_EVENTTYPE_FILES_DROPPED);
        // see sapp_js_add_dragndrop_listeners for mods constants
        if (mods & 1) { _sapp.event.modifiers |= SAPP_MODIFIER_SHIFT; }
        if (mods & 2) { _sapp.event.modifiers |= SAPP_MODIFIER_CTRL; }
        if (mods & 4) { _sapp.event.modifiers |= SAPP_MODIFIER_ALT; }
        if (mods & 8) { _sapp.event.modifiers |= SAPP_MODIFIER_SUPER; }
        _sapp_call_event(&_sapp.event);
    }
}

EMSCRIPTEN_KEEPALIVE void _sapp_emsc_invoke_fetch_cb(int index, int success, int error_code, _sapp_html5_fetch_callback callback, uint32_t fetched_size, void* buf_ptr, uint32_t buf_size, void* user_data) {
    sapp_html5_fetch_response response;
    _sapp_clear(&response, sizeof(response));
    response.succeeded = (0 != success);
    response.error_code = (sapp_html5_fetch_error) error_code;
    response.file_index = index;
    response.data.ptr = buf_ptr;
    response.data.size = fetched_size;
    response.buffer.ptr = buf_ptr;
    response.buffer.size = buf_size;
    response.user_data = user_data;
    callback(&response);
}

#ifdef __cplusplus
} /* extern "C" */
#endif

EM_JS(void, sapp_js_add_beforeunload_listener, (void), {
    Module.sokol_beforeunload = (event) => {
        if (__sapp_html5_get_ask_leave_site() != 0) {
            event.preventDefault();
            event.returnValue = ' ';
        }
    };
    window.addEventListener('beforeunload', Module.sokol_beforeunload);
})

EM_JS(void, sapp_js_remove_beforeunload_listener, (void), {
    window.removeEventListener('beforeunload', Module.sokol_beforeunload);
})

EM_JS(void, sapp_js_add_clipboard_listener, (void), {
    Module.sokol_paste = (event) => {
        const pasted_str = event.clipboardData.getData('text');
        withStackSave(() => {
            const cstr = stringToUTF8OnStack(pasted_str);
            __sapp_emsc_onpaste(cstr);
        });
    };
    window.addEventListener('paste', Module.sokol_paste);
})

EM_JS(void, sapp_js_remove_clipboard_listener, (void), {
    window.removeEventListener('paste', Module.sokol_paste);
})

EM_JS(void, sapp_js_write_clipboard, (const char* c_str), {
    const str = UTF8ToString(c_str);
    const ta = document.createElement('textarea');
    ta.setAttribute('autocomplete', 'off');
    ta.setAttribute('autocorrect', 'off');
    ta.setAttribute('autocapitalize', 'off');
    ta.setAttribute('spellcheck', 'false');
    ta.style.left = -100 + 'px';
    ta.style.top = -100 + 'px';
    ta.style.height = 1;
    ta.style.width = 1;
    ta.value = str;
    document.body.appendChild(ta);
    ta.select();
    document.execCommand('copy');
    document.body.removeChild(ta);
})

_SOKOL_PRIVATE void _sapp_emsc_set_clipboard_string(const char* str) {
    sapp_js_write_clipboard(str);
}

EM_JS(void, sapp_js_add_dragndrop_listeners, (void), {
    Module.sokol_drop_files = [];
    Module.sokol_dragenter = (event) => {
        event.stopPropagation();
        event.preventDefault();
    };
    Module.sokol_dragleave = (event) => {
        event.stopPropagation();
        event.preventDefault();
    };
    Module.sokol_dragover = (event) => {
        event.stopPropagation();
        event.preventDefault();
    };
    Module.sokol_drop = (event) => {
        event.stopPropagation();
        event.preventDefault();
        const files = event.dataTransfer.files;
        Module.sokol_dropped_files = files;
        __sapp_emsc_begin_drop(files.length);
        for (let i = 0; i < files.length; i++) {
            withStackSave(() => {
                const cstr = stringToUTF8OnStack(files[i].name);
                __sapp_emsc_drop(i, cstr);
            });
        }
        let mods = 0;
        if (event.shiftKey) { mods |= 1; }
        if (event.ctrlKey) { mods |= 2; }
        if (event.altKey) { mods |= 4; }
        if (event.metaKey) { mods |= 8; }
        // FIXME? see computation of targetX/targetY in emscripten via getClientBoundingRect
        __sapp_emsc_end_drop(event.clientX, event.clientY, mods);
    };
    \x2F\x2A\x2A @suppress {missingProperties} \x2A\x2F
    const canvas = Module.sapp_emsc_target;
    canvas.addEventListener('dragenter', Module.sokol_dragenter, false);
    canvas.addEventListener('dragleave', Module.sokol_dragleave, false);
    canvas.addEventListener('dragover',  Module.sokol_dragover, false);
    canvas.addEventListener('drop',      Module.sokol_drop, false);
})

EM_JS(uint32_t, sapp_js_dropped_file_size, (int index), {
    \x2F\x2A\x2A @suppress {missingProperties} \x2A\x2F
    const files = Module.sokol_dropped_files;
    if ((index < 0) || (index >= files.length)) {
        return 0;
    }
    else {
        return files[index].size;
    }
})

EM_JS(void, sapp_js_fetch_dropped_file, (int index, _sapp_html5_fetch_callback callback, void* buf_ptr, uint32_t buf_size, void* user_data), {
    const reader = new FileReader();
    reader.onload = (loadEvent) => {
        const content = loadEvent.target.result;
        if (content.byteLength > buf_size) {
            // SAPP_HTML5_FETCH_ERROR_BUFFER_TOO_SMALL
            __sapp_emsc_invoke_fetch_cb(index, 0, 1, callback, 0, buf_ptr, buf_size, user_data);
        }
        else {
            HEAPU8.set(new Uint8Array(content), buf_ptr);
            __sapp_emsc_invoke_fetch_cb(index, 1, 0, callback, content.byteLength, buf_ptr, buf_size, user_data);
        }
    };
    reader.onerror = () => {
        // SAPP_HTML5_FETCH_ERROR_OTHER
        __sapp_emsc_invoke_fetch_cb(index, 0, 2, callback, 0, buf_ptr, buf_size, user_data);
    };
    \x2F\x2A\x2A @suppress {missingProperties} \x2A\x2F
    const files = Module.sokol_dropped_files;
    reader.readAsArrayBuffer(files[index]);
})

EM_JS(void, sapp_js_remove_dragndrop_listeners, (void), {
    \x2F\x2A\x2A @suppress {missingProperties} \x2A\x2F
    const canvas = Module.sapp_emsc_target;
    canvas.removeEventListener('dragenter', Module.sokol_dragenter);
    canvas.removeEventListener('dragleave', Module.sokol_dragleave);
    canvas.removeEventListener('dragover',  Module.sokol_dragover);
    canvas.removeEventListener('drop',      Module.sokol_drop);
})

EM_JS(void, sapp_js_init, (const char* c_str_target_selector, const char* c_str_document_title), {
    if (c_str_document_title !== 0) {
        document.title = UTF8ToString(c_str_document_title);
    }
    const target_selector_str = UTF8ToString(c_str_target_selector);
    if (Module['canvas'] !== undefined) {
        if (typeof Module['canvas'] === 'object') {
            specialHTMLTargets[target_selector_str] = Module['canvas'];
        } else {
            console.warn("sokol_app.h: Module['canvas'] is set but is not an object");
        }
    }
    Module.sapp_emsc_target = findCanvasEventTarget(target_selector_str);
    if (!Module.sapp_emsc_target) {
        console.warn("sokol_app.h: can't find html5_canvas_selector ", target_selector_str);
    }
    if (!Module.sapp_emsc_target.requestPointerLock) {
        console.warn("sokol_app.h: target doesn't support requestPointerLock: ", target_selector_str);
    }
})

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_pointerlockchange_cb(int emsc_type, const EmscriptenPointerlockChangeEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(emsc_type);
    _SOKOL_UNUSED(user_data);
    _sapp.mouse.locked = emsc_event->isActive;
    return EM_TRUE;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_pointerlockerror_cb(int emsc_type, const void* reserved, void* user_data) {
    _SOKOL_UNUSED(emsc_type);
    _SOKOL_UNUSED(reserved);
    _SOKOL_UNUSED(user_data);
    _sapp.mouse.locked = false;
    _sapp.emsc.mouse_lock_requested = false;
    return true;
}

EM_JS(void, sapp_js_request_pointerlock, (void), {
    if (Module.sapp_emsc_target) {
        if (Module.sapp_emsc_target.requestPointerLock) {
            Module.sapp_emsc_target.requestPointerLock();
        }
    }
})

EM_JS(void, sapp_js_exit_pointerlock, (void), {
    if (document.exitPointerLock) {
        document.exitPointerLock();
    }
})

_SOKOL_PRIVATE void _sapp_emsc_lock_mouse(bool lock) {
    if (lock) {
        /* request mouse-lock during event handler invocation (see _sapp_emsc_update_mouse_lock_state) */
        _sapp.emsc.mouse_lock_requested = true;
    }
    else {
        /* NOTE: the _sapp.mouse_locked state will be set in the pointerlockchange callback */
        _sapp.emsc.mouse_lock_requested = false;
        sapp_js_exit_pointerlock();
    }
}

/* called from inside event handlers to check if mouse lock had been requested,
   and if yes, actually enter mouse lock.
*/
_SOKOL_PRIVATE void _sapp_emsc_update_mouse_lock_state(void) {
    if (_sapp.emsc.mouse_lock_requested) {
        _sapp.emsc.mouse_lock_requested = false;
        sapp_js_request_pointerlock();
    }
}

// set mouse cursor type
EM_JS(void, sapp_js_set_cursor, (int cursor_type, int shown), {
    if (Module.sapp_emsc_target) {
        let cursor;
        if (shown === 0) {
            cursor = "none";
        }
        else switch (cursor_type) {
            case 0: cursor = "auto"; break;         // SAPP_MOUSECURSOR_DEFAULT
            case 1: cursor = "default"; break;      // SAPP_MOUSECURSOR_ARROW
            case 2: cursor = "text"; break;         // SAPP_MOUSECURSOR_IBEAM
            case 3: cursor = "crosshair"; break;    // SAPP_MOUSECURSOR_CROSSHAIR
            case 4: cursor = "pointer"; break;      // SAPP_MOUSECURSOR_POINTING_HAND
            case 5: cursor = "ew-resize"; break;    // SAPP_MOUSECURSOR_RESIZE_EW
            case 6: cursor = "ns-resize"; break;    // SAPP_MOUSECURSOR_RESIZE_NS
            case 7: cursor = "nwse-resize"; break;  // SAPP_MOUSECURSOR_RESIZE_NWSE
            case 8: cursor = "nesw-resize"; break;  // SAPP_MOUSECURSOR_RESIZE_NESW
            case 9: cursor = "all-scroll"; break;   // SAPP_MOUSECURSOR_RESIZE_ALL
            case 10: cursor = "not-allowed"; break; // SAPP_MOUSECURSOR_NOT_ALLOWED
            default: cursor = "auto"; break;
        }
        Module.sapp_emsc_target.style.cursor = cursor;
    }
})

_SOKOL_PRIVATE void _sapp_emsc_update_cursor(sapp_mouse_cursor cursor, bool shown) {
    SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
    sapp_js_set_cursor((int)cursor, shown ? 1 : 0);
}

/* JS helper functions to update browser tab favicon */
EM_JS(void, sapp_js_clear_favicon, (void), {
    const link = document.getElementById('sokol-app-favicon');
    if (link) {
        document.head.removeChild(link);
    }
})

EM_JS(void, sapp_js_set_favicon, (int w, int h, const uint8_t* pixels), {
    const canvas = document.createElement('canvas');
    canvas.width = w;
    canvas.height = h;
    const ctx = canvas.getContext('2d');
    const img_data = ctx.createImageData(w, h);
    img_data.data.set(HEAPU8.subarray(pixels, pixels + w*h*4));
    ctx.putImageData(img_data, 0, 0);
    const new_link = document.createElement('link');
    new_link.id = 'sokol-app-favicon';
    new_link.rel = 'shortcut icon';
    new_link.href = canvas.toDataURL();
    document.head.appendChild(new_link);
})

_SOKOL_PRIVATE void _sapp_emsc_set_icon(const sapp_icon_desc* icon_desc, int num_images) {
    SOKOL_ASSERT((num_images > 0) && (num_images <= SAPP_MAX_ICONIMAGES));
    sapp_js_clear_favicon();
    // find the best matching image candidate for 16x16 pixels
    int img_index = _sapp_image_bestmatch(icon_desc->images, num_images, 16, 16);
    const sapp_image_desc* img_desc = &icon_desc->images[img_index];
    sapp_js_set_favicon(img_desc->width, img_desc->height, (const uint8_t*) img_desc->pixels.ptr);
}

_SOKOL_PRIVATE uint32_t _sapp_emsc_mouse_button_mods(uint16_t buttons) {
    uint32_t m = 0;
    if (0 != (buttons & (1<<0))) { m |= SAPP_MODIFIER_LMB; }
    if (0 != (buttons & (1<<1))) { m |= SAPP_MODIFIER_RMB; } // not a bug
    if (0 != (buttons & (1<<2))) { m |= SAPP_MODIFIER_MMB; } // not a bug
    return m;
}

_SOKOL_PRIVATE uint32_t _sapp_emsc_mouse_event_mods(const EmscriptenMouseEvent* ev) {
    uint32_t m = 0;
    if (ev->ctrlKey)    { m |= SAPP_MODIFIER_CTRL; }
    if (ev->shiftKey)   { m |= SAPP_MODIFIER_SHIFT; }
    if (ev->altKey)     { m |= SAPP_MODIFIER_ALT; }
    if (ev->metaKey)    { m |= SAPP_MODIFIER_SUPER; }
    m |= _sapp_emsc_mouse_button_mods(_sapp.emsc.mouse_buttons);
    return m;
}

_SOKOL_PRIVATE uint32_t _sapp_emsc_key_event_mods(const EmscriptenKeyboardEvent* ev) {
    uint32_t m = 0;
    if (ev->ctrlKey)    { m |= SAPP_MODIFIER_CTRL; }
    if (ev->shiftKey)   { m |= SAPP_MODIFIER_SHIFT; }
    if (ev->altKey)     { m |= SAPP_MODIFIER_ALT; }
    if (ev->metaKey)    { m |= SAPP_MODIFIER_SUPER; }
    m |= _sapp_emsc_mouse_button_mods(_sapp.emsc.mouse_buttons);
    return m;
}

_SOKOL_PRIVATE uint32_t _sapp_emsc_touch_event_mods(const EmscriptenTouchEvent* ev) {
    uint32_t m = 0;
    if (ev->ctrlKey)    { m |= SAPP_MODIFIER_CTRL; }
    if (ev->shiftKey)   { m |= SAPP_MODIFIER_SHIFT; }
    if (ev->altKey)     { m |= SAPP_MODIFIER_ALT; }
    if (ev->metaKey)    { m |= SAPP_MODIFIER_SUPER; }
    m |= _sapp_emsc_mouse_button_mods(_sapp.emsc.mouse_buttons);
    return m;
}

#if defined(SOKOL_WGPU)
_SOKOL_PRIVATE void _sapp_emsc_wgpu_size_changed(void);
#endif

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_size_changed(int event_type, const EmscriptenUiEvent* ui_event, void* user_data) {
    _SOKOL_UNUSED(event_type);
    _SOKOL_UNUSED(user_data);
    double w, h;
    emscripten_get_element_css_size(_sapp.html5_canvas_selector, &w, &h);
    /* The above method might report zero when toggling HTML5 fullscreen,
       in that case use the window's inner width reported by the
       emscripten event. This works ok when toggling *into* fullscreen
       but doesn't properly restore the previous canvas size when switching
       back from fullscreen.

       In general, due to the HTML5's fullscreen API's flaky nature it is
       recommended to use 'soft fullscreen' (stretching the WebGL canvas
       over the browser windows client rect) with a CSS definition like this:

            position: absolute;
            top: 0px;
            left: 0px;
            margin: 0px;
            border: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            display: block;
    */
    if (w < 1.0) {
        w = ui_event->windowInnerWidth;
    }
    else {
        _sapp.window_width = (int)roundf(w);
    }
    if (h < 1.0) {
        h = ui_event->windowInnerHeight;
    }
    else {
        _sapp.window_height = (int)roundf(h);
    }
    if (_sapp.desc.high_dpi) {
        _sapp.dpi_scale = emscripten_get_device_pixel_ratio();
    }
    _sapp.framebuffer_width = (int)roundf(w * _sapp.dpi_scale);
    _sapp.framebuffer_height = (int)roundf(h * _sapp.dpi_scale);
    SOKOL_ASSERT((_sapp.framebuffer_width > 0) && (_sapp.framebuffer_height > 0));
    emscripten_set_canvas_element_size(_sapp.html5_canvas_selector, _sapp.framebuffer_width, _sapp.framebuffer_height);
    #if defined(SOKOL_WGPU)
        // on WebGPU: recreate size-dependent rendering surfaces
        _sapp_emsc_wgpu_size_changed();
    #endif
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_RESIZED);
        _sapp_call_event(&_sapp.event);
    }
    return true;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_mouse_cb(int emsc_type, const EmscriptenMouseEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(user_data);
    bool consume_event = !_sapp.desc.html5_bubble_mouse_events;
    _sapp.emsc.mouse_buttons = emsc_event->buttons;
    if (_sapp.mouse.locked) {
        _sapp.mouse.dx = (float) emsc_event->movementX;
        _sapp.mouse.dy = (float) emsc_event->movementY;
    } else {
        float new_x = emsc_event->targetX * _sapp.dpi_scale;
        float new_y = emsc_event->targetY * _sapp.dpi_scale;
        if (_sapp.mouse.pos_valid) {
            _sapp.mouse.dx = new_x - _sapp.mouse.x;
            _sapp.mouse.dy = new_y - _sapp.mouse.y;
        }
        _sapp.mouse.x = new_x;
        _sapp.mouse.y = new_y;
        _sapp.mouse.pos_valid = true;
    }
    if (_sapp_events_enabled() && (emsc_event->button >= 0) && (emsc_event->button < SAPP_MAX_MOUSEBUTTONS)) {
        sapp_event_type type;
        bool is_button_event = false;
        bool clear_dxdy = false;
        switch (emsc_type) {
            case EMSCRIPTEN_EVENT_MOUSEDOWN:
                type = SAPP_EVENTTYPE_MOUSE_DOWN;
                is_button_event = true;
                break;
            case EMSCRIPTEN_EVENT_MOUSEUP:
                type = SAPP_EVENTTYPE_MOUSE_UP;
                is_button_event = true;
                break;
            case EMSCRIPTEN_EVENT_MOUSEMOVE:
                type = SAPP_EVENTTYPE_MOUSE_MOVE;
                break;
            case EMSCRIPTEN_EVENT_MOUSEENTER:
                type = SAPP_EVENTTYPE_MOUSE_ENTER;
                clear_dxdy = true;
                break;
            case EMSCRIPTEN_EVENT_MOUSELEAVE:
                type = SAPP_EVENTTYPE_MOUSE_LEAVE;
                clear_dxdy = true;
                break;
            default:
                type = SAPP_EVENTTYPE_INVALID;
                break;
        }
        if (clear_dxdy) {
            _sapp.mouse.dx = 0.0f;
            _sapp.mouse.dy = 0.0f;
        }
        if (type != SAPP_EVENTTYPE_INVALID) {
            _sapp_init_event(type);
            _sapp.event.modifiers = _sapp_emsc_mouse_event_mods(emsc_event);
            if (is_button_event) {
                switch (emsc_event->button) {
                    case 0: _sapp.event.mouse_button = SAPP_MOUSEBUTTON_LEFT; break;
                    case 1: _sapp.event.mouse_button = SAPP_MOUSEBUTTON_MIDDLE; break;
                    case 2: _sapp.event.mouse_button = SAPP_MOUSEBUTTON_RIGHT; break;
                    default: _sapp.event.mouse_button = (sapp_mousebutton)emsc_event->button; break;
                }
            } else {
                _sapp.event.mouse_button = SAPP_MOUSEBUTTON_INVALID;
            }
            consume_event |= _sapp_call_event(&_sapp.event);
        }
        // mouse lock can only be activated in mouse button events (not in move, enter or leave)
        if (is_button_event) {
            _sapp_emsc_update_mouse_lock_state();
        }
    }
    return consume_event;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_wheel_cb(int emsc_type, const EmscriptenWheelEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(emsc_type);
    _SOKOL_UNUSED(user_data);
    bool consume_event = !_sapp.desc.html5_bubble_wheel_events;
    _sapp.emsc.mouse_buttons = emsc_event->mouse.buttons;
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_MOUSE_SCROLL);
        _sapp.event.modifiers = _sapp_emsc_mouse_event_mods(&emsc_event->mouse);
        /* see https://github.com/floooh/sokol/issues/339 */
        float scale;
        switch (emsc_event->deltaMode) {
            case DOM_DELTA_PIXEL: scale = -0.04f; break;
            case DOM_DELTA_LINE:  scale = -1.33f; break;
            case DOM_DELTA_PAGE:  scale = -10.0f; break; // FIXME: this is a guess
            default:              scale = -0.1f; break;  // shouldn't happen
        }
        _sapp.event.scroll_x = scale * (float)emsc_event->deltaX;
        _sapp.event.scroll_y = scale * (float)emsc_event->deltaY;
        consume_event |= _sapp_call_event(&_sapp.event);
    }
    _sapp_emsc_update_mouse_lock_state();
    return consume_event;
}

static struct {
    const char* str;
    sapp_keycode code;
} _sapp_emsc_keymap[] = {
    { "Backspace",      SAPP_KEYCODE_BACKSPACE },
    { "Tab",            SAPP_KEYCODE_TAB },
    { "Enter",          SAPP_KEYCODE_ENTER },
    { "ShiftLeft",      SAPP_KEYCODE_LEFT_SHIFT },
    { "ShiftRight",     SAPP_KEYCODE_RIGHT_SHIFT },
    { "ControlLeft",    SAPP_KEYCODE_LEFT_CONTROL },
    { "ControlRight",   SAPP_KEYCODE_RIGHT_CONTROL },
    { "AltLeft",        SAPP_KEYCODE_LEFT_ALT },
    { "AltRight",       SAPP_KEYCODE_RIGHT_ALT },
    { "Pause",          SAPP_KEYCODE_PAUSE },
    { "CapsLock",       SAPP_KEYCODE_CAPS_LOCK },
    { "Escape",         SAPP_KEYCODE_ESCAPE },
    { "Space",          SAPP_KEYCODE_SPACE },
    { "PageUp",         SAPP_KEYCODE_PAGE_UP },
    { "PageDown",       SAPP_KEYCODE_PAGE_DOWN },
    { "End",            SAPP_KEYCODE_END },
    { "Home",           SAPP_KEYCODE_HOME },
    { "ArrowLeft",      SAPP_KEYCODE_LEFT },
    { "ArrowUp",        SAPP_KEYCODE_UP },
    { "ArrowRight",     SAPP_KEYCODE_RIGHT },
    { "ArrowDown",      SAPP_KEYCODE_DOWN },
    { "PrintScreen",    SAPP_KEYCODE_PRINT_SCREEN },
    { "Insert",         SAPP_KEYCODE_INSERT },
    { "Delete",         SAPP_KEYCODE_DELETE },
    { "Digit0",         SAPP_KEYCODE_0 },
    { "Digit1",         SAPP_KEYCODE_1 },
    { "Digit2",         SAPP_KEYCODE_2 },
    { "Digit3",         SAPP_KEYCODE_3 },
    { "Digit4",         SAPP_KEYCODE_4 },
    { "Digit5",         SAPP_KEYCODE_5 },
    { "Digit6",         SAPP_KEYCODE_6 },
    { "Digit7",         SAPP_KEYCODE_7 },
    { "Digit8",         SAPP_KEYCODE_8 },
    { "Digit9",         SAPP_KEYCODE_9 },
    { "KeyA",           SAPP_KEYCODE_A },
    { "KeyB",           SAPP_KEYCODE_B },
    { "KeyC",           SAPP_KEYCODE_C },
    { "KeyD",           SAPP_KEYCODE_D },
    { "KeyE",           SAPP_KEYCODE_E },
    { "KeyF",           SAPP_KEYCODE_F },
    { "KeyG",           SAPP_KEYCODE_G },
    { "KeyH",           SAPP_KEYCODE_H },
    { "KeyI",           SAPP_KEYCODE_I },
    { "KeyJ",           SAPP_KEYCODE_J },
    { "KeyK",           SAPP_KEYCODE_K },
    { "KeyL",           SAPP_KEYCODE_L },
    { "KeyM",           SAPP_KEYCODE_M },
    { "KeyN",           SAPP_KEYCODE_N },
    { "KeyO",           SAPP_KEYCODE_O },
    { "KeyP",           SAPP_KEYCODE_P },
    { "KeyQ",           SAPP_KEYCODE_Q },
    { "KeyR",           SAPP_KEYCODE_R },
    { "KeyS",           SAPP_KEYCODE_S },
    { "KeyT",           SAPP_KEYCODE_T },
    { "KeyU",           SAPP_KEYCODE_U },
    { "KeyV",           SAPP_KEYCODE_V },
    { "KeyW",           SAPP_KEYCODE_W },
    { "KeyX",           SAPP_KEYCODE_X },
    { "KeyY",           SAPP_KEYCODE_Y },
    { "KeyZ",           SAPP_KEYCODE_Z },
    { "MetaLeft",       SAPP_KEYCODE_LEFT_SUPER },
    { "MetaRight",      SAPP_KEYCODE_RIGHT_SUPER },
    { "Numpad0",        SAPP_KEYCODE_KP_0 },
    { "Numpad1",        SAPP_KEYCODE_KP_1 },
    { "Numpad2",        SAPP_KEYCODE_KP_2 },
    { "Numpad3",        SAPP_KEYCODE_KP_3 },
    { "Numpad4",        SAPP_KEYCODE_KP_4 },
    { "Numpad5",        SAPP_KEYCODE_KP_5 },
    { "Numpad6",        SAPP_KEYCODE_KP_6 },
    { "Numpad7",        SAPP_KEYCODE_KP_7 },
    { "Numpad8",        SAPP_KEYCODE_KP_8 },
    { "Numpad9",        SAPP_KEYCODE_KP_9 },
    { "NumpadMultiply", SAPP_KEYCODE_KP_MULTIPLY },
    { "NumpadAdd",      SAPP_KEYCODE_KP_ADD },
    { "NumpadSubtract", SAPP_KEYCODE_KP_SUBTRACT },
    { "NumpadDecimal",  SAPP_KEYCODE_KP_DECIMAL },
    { "NumpadDivide",   SAPP_KEYCODE_KP_DIVIDE },
    { "F1",             SAPP_KEYCODE_F1 },
    { "F2",             SAPP_KEYCODE_F2 },
    { "F3",             SAPP_KEYCODE_F3 },
    { "F4",             SAPP_KEYCODE_F4 },
    { "F5",             SAPP_KEYCODE_F5 },
    { "F6",             SAPP_KEYCODE_F6 },
    { "F7",             SAPP_KEYCODE_F7 },
    { "F8",             SAPP_KEYCODE_F8 },
    { "F9",             SAPP_KEYCODE_F9 },
    { "F10",            SAPP_KEYCODE_F10 },
    { "F11",            SAPP_KEYCODE_F11 },
    { "F12",            SAPP_KEYCODE_F12 },
    { "NumLock",        SAPP_KEYCODE_NUM_LOCK },
    { "ScrollLock",     SAPP_KEYCODE_SCROLL_LOCK },
    { "Semicolon",      SAPP_KEYCODE_SEMICOLON },
    { "Equal",          SAPP_KEYCODE_EQUAL },
    { "Comma",          SAPP_KEYCODE_COMMA },
    { "Minus",          SAPP_KEYCODE_MINUS },
    { "Period",         SAPP_KEYCODE_PERIOD },
    { "Slash",          SAPP_KEYCODE_SLASH },
    { "Backquote",      SAPP_KEYCODE_GRAVE_ACCENT },
    { "BracketLeft",    SAPP_KEYCODE_LEFT_BRACKET },
    { "Backslash",      SAPP_KEYCODE_BACKSLASH },
    { "BracketRight",   SAPP_KEYCODE_RIGHT_BRACKET },
    { "Quote",          SAPP_KEYCODE_GRAVE_ACCENT },    // FIXME: ???
    { 0, SAPP_KEYCODE_INVALID },
};

_SOKOL_PRIVATE sapp_keycode _sapp_emsc_translate_key(const char* str) {
    int i = 0;
    const char* keystr;
    while (( keystr = _sapp_emsc_keymap[i].str )) {
        if (0 == strcmp(str, keystr)) {
            return _sapp_emsc_keymap[i].code;
        }
        i += 1;
    }
    return SAPP_KEYCODE_INVALID;
}

// returns true if the key code is a 'character key', this is used to decide
// if a key event needs to bubble up to create a char event
_SOKOL_PRIVATE bool _sapp_emsc_is_char_key(sapp_keycode key_code) {
    return key_code < SAPP_KEYCODE_WORLD_1;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_key_cb(int emsc_type, const EmscriptenKeyboardEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(user_data);
    bool consume_event = false;
    if (_sapp_events_enabled()) {
        sapp_event_type type;
        switch (emsc_type) {
            case EMSCRIPTEN_EVENT_KEYDOWN:
                type = SAPP_EVENTTYPE_KEY_DOWN;
                break;
            case EMSCRIPTEN_EVENT_KEYUP:
                type = SAPP_EVENTTYPE_KEY_UP;
                break;
            case EMSCRIPTEN_EVENT_KEYPRESS:
                type = SAPP_EVENTTYPE_CHAR;
                break;
            default:
                type = SAPP_EVENTTYPE_INVALID;
                break;
        }
        if (type != SAPP_EVENTTYPE_INVALID) {
            bool send_keyup_followup = false;
            _sapp_init_event(type);
            _sapp.event.key_repeat = emsc_event->repeat;
            _sapp.event.modifiers = _sapp_emsc_key_event_mods(emsc_event);
            if (type == SAPP_EVENTTYPE_CHAR) {
                // NOTE: charCode doesn't appear to be supported on Android Chrome
                _sapp.event.char_code = emsc_event->charCode;
                consume_event |= !_sapp.desc.html5_bubble_char_events;
            } else {
                if (0 != emsc_event->code[0]) {
                    // This code path is for desktop browsers which send untranslated 'physical' key code strings
                    // (which is what we actually want for key events)
                    _sapp.event.key_code = _sapp_emsc_translate_key(emsc_event->code);
                } else {
                    // This code path is for mobile browsers which only send localized key code
                    // strings. Note that the translation will only work for a small subset
                    // of localization-agnostic keys (like Enter, arrow keys, etc...), but
                    // regular alpha-numeric keys will all result in an SAPP_KEYCODE_INVALID)
                    _sapp.event.key_code = _sapp_emsc_translate_key(emsc_event->key);
                }

                // Special hack for macOS: if the Super key is pressed, macOS doesn't
                //  send keyUp events. As a workaround, to prevent keys from
                //  "sticking", we'll send a keyup event following a keydown
                //  when the SUPER key is pressed
                if ((type == SAPP_EVENTTYPE_KEY_DOWN) &&
                    (_sapp.event.key_code != SAPP_KEYCODE_LEFT_SUPER) &&
                    (_sapp.event.key_code != SAPP_KEYCODE_RIGHT_SUPER) &&
                    (_sapp.event.modifiers & SAPP_MODIFIER_SUPER))
                {
                    send_keyup_followup = true;
                }

                // 'character key events' will always need to bubble up, otherwise the browser
                // wouldn't be able to generate character events.
                if (!_sapp_emsc_is_char_key(_sapp.event.key_code)) {
                    consume_event |= !_sapp.desc.html5_bubble_key_events;
                }
            }
            consume_event |= _sapp_call_event(&_sapp.event);
            if (send_keyup_followup) {
                _sapp.event.type = SAPP_EVENTTYPE_KEY_UP;
                consume_event |= _sapp_call_event(&_sapp.event);
            }
        }
    }
    _sapp_emsc_update_mouse_lock_state();
    return consume_event;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_touch_cb(int emsc_type, const EmscriptenTouchEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(user_data);
    bool consume_event = !_sapp.desc.html5_bubble_touch_events;
    if (_sapp_events_enabled()) {
        sapp_event_type type;
        switch (emsc_type) {
            case EMSCRIPTEN_EVENT_TOUCHSTART:
                type = SAPP_EVENTTYPE_TOUCHES_BEGAN;
                break;
            case EMSCRIPTEN_EVENT_TOUCHMOVE:
                type = SAPP_EVENTTYPE_TOUCHES_MOVED;
                break;
            case EMSCRIPTEN_EVENT_TOUCHEND:
                type = SAPP_EVENTTYPE_TOUCHES_ENDED;
                break;
            case EMSCRIPTEN_EVENT_TOUCHCANCEL:
                type = SAPP_EVENTTYPE_TOUCHES_CANCELLED;
                break;
            default:
                type = SAPP_EVENTTYPE_INVALID;
                break;
        }
        if (type != SAPP_EVENTTYPE_INVALID) {
            _sapp_init_event(type);
            _sapp.event.modifiers = _sapp_emsc_touch_event_mods(emsc_event);
            _sapp.event.num_touches = emsc_event->numTouches;
            if (_sapp.event.num_touches > SAPP_MAX_TOUCHPOINTS) {
                _sapp.event.num_touches = SAPP_MAX_TOUCHPOINTS;
            }
            for (int i = 0; i < _sapp.event.num_touches; i++) {
                const EmscriptenTouchPoint* src = &emsc_event->touches[i];
                sapp_touchpoint* dst = &_sapp.event.touches[i];
                dst->identifier = (uintptr_t)src->identifier;
                dst->pos_x = src->targetX * _sapp.dpi_scale;
                dst->pos_y = src->targetY * _sapp.dpi_scale;
                dst->changed = src->isChanged;
            }
            consume_event |= _sapp_call_event(&_sapp.event);
        }
    }
    return consume_event;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_focus_cb(int emsc_type, const EmscriptenFocusEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(emsc_type);
    _SOKOL_UNUSED(emsc_event);
    _SOKOL_UNUSED(user_data);
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_FOCUSED);
        _sapp_call_event(&_sapp.event);
    }
    return true;
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_blur_cb(int emsc_type, const EmscriptenFocusEvent* emsc_event, void* user_data) {
    _SOKOL_UNUSED(emsc_type);
    _SOKOL_UNUSED(emsc_event);
    _SOKOL_UNUSED(user_data);
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_UNFOCUSED);
        _sapp_call_event(&_sapp.event);
    }
    return true;
}

#if defined(SOKOL_GLES3)
_SOKOL_PRIVATE EM_BOOL _sapp_emsc_webgl_context_cb(int emsc_type, const void* reserved, void* user_data) {
    _SOKOL_UNUSED(reserved);
    _SOKOL_UNUSED(user_data);
    sapp_event_type type;
    switch (emsc_type) {
        case EMSCRIPTEN_EVENT_WEBGLCONTEXTLOST:     type = SAPP_EVENTTYPE_SUSPENDED; break;
        case EMSCRIPTEN_EVENT_WEBGLCONTEXTRESTORED: type = SAPP_EVENTTYPE_RESUMED; break;
        default:                                    type = SAPP_EVENTTYPE_INVALID; break;
    }
    if (_sapp_events_enabled() && (SAPP_EVENTTYPE_INVALID != type)) {
        _sapp_init_event(type);
        _sapp_call_event(&_sapp.event);
    }
    return true;
}

_SOKOL_PRIVATE void _sapp_emsc_webgl_init(void) {
    EmscriptenWebGLContextAttributes attrs;
    emscripten_webgl_init_context_attributes(&attrs);
    attrs.alpha = _sapp.desc.alpha;
    attrs.depth = true;
    attrs.stencil = true;
    attrs.antialias = _sapp.sample_count > 1;
    attrs.premultipliedAlpha = _sapp.desc.html5_premultiplied_alpha;
    attrs.preserveDrawingBuffer = _sapp.desc.html5_preserve_drawing_buffer;
    attrs.enableExtensionsByDefault = true;
    attrs.majorVersion = 2;
    EMSCRIPTEN_WEBGL_CONTEXT_HANDLE ctx = emscripten_webgl_create_context(_sapp.html5_canvas_selector, &attrs);
    // FIXME: error message?
    emscripten_webgl_make_context_current(ctx);
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&_sapp.gl.framebuffer);
}
#endif

#if defined(SOKOL_WGPU)

_SOKOL_PRIVATE void _sapp_emsc_wgpu_create_swapchain(void) {
    SOKOL_ASSERT(_sapp.wgpu.instance);
    SOKOL_ASSERT(_sapp.wgpu.device);
    SOKOL_ASSERT(0 == _sapp.wgpu.surface);
    SOKOL_ASSERT(0 == _sapp.wgpu.swapchain);
    SOKOL_ASSERT(0 == _sapp.wgpu.msaa_tex);
    SOKOL_ASSERT(0 == _sapp.wgpu.msaa_view);
    SOKOL_ASSERT(0 == _sapp.wgpu.depth_stencil_tex);
    SOKOL_ASSERT(0 == _sapp.wgpu.depth_stencil_view);
    SOKOL_ASSERT(0 == _sapp.wgpu.swapchain_view);

    WGPUSurfaceDescriptorFromCanvasHTMLSelector canvas_desc;
    _sapp_clear(&canvas_desc, sizeof(canvas_desc));
    canvas_desc.chain.sType = WGPUSType_SurfaceDescriptorFromCanvasHTMLSelector;
    canvas_desc.selector = _sapp.html5_canvas_selector;
    WGPUSurfaceDescriptor surf_desc;
    _sapp_clear(&surf_desc, sizeof(surf_desc));
    surf_desc.nextInChain = &canvas_desc.chain;
    _sapp.wgpu.surface = wgpuInstanceCreateSurface(_sapp.wgpu.instance, &surf_desc);
    if (0 == _sapp.wgpu.surface) {
        _SAPP_PANIC(WGPU_SWAPCHAIN_CREATE_SURFACE_FAILED);
    }
    _sapp.wgpu.render_format = wgpuSurfaceGetPreferredFormat(_sapp.wgpu.surface, _sapp.wgpu.adapter);

    WGPUSwapChainDescriptor sc_desc;
    _sapp_clear(&sc_desc, sizeof(sc_desc));
    sc_desc.usage = WGPUTextureUsage_RenderAttachment;
    sc_desc.format = _sapp.wgpu.render_format;
    sc_desc.width = (uint32_t)_sapp.framebuffer_width;
    sc_desc.height = (uint32_t)_sapp.framebuffer_height;
    sc_desc.presentMode = WGPUPresentMode_Fifo;
    _sapp.wgpu.swapchain = wgpuDeviceCreateSwapChain(_sapp.wgpu.device, _sapp.wgpu.surface, &sc_desc);
    if (0 == _sapp.wgpu.swapchain) {
        _SAPP_PANIC(WGPU_SWAPCHAIN_CREATE_SWAPCHAIN_FAILED);
    }

    WGPUTextureDescriptor ds_desc;
    _sapp_clear(&ds_desc, sizeof(ds_desc));
    ds_desc.usage = WGPUTextureUsage_RenderAttachment;
    ds_desc.dimension = WGPUTextureDimension_2D;
    ds_desc.size.width = (uint32_t)_sapp.framebuffer_width;
    ds_desc.size.height = (uint32_t)_sapp.framebuffer_height;
    ds_desc.size.depthOrArrayLayers = 1;
    ds_desc.format = WGPUTextureFormat_Depth32FloatStencil8;
    ds_desc.mipLevelCount = 1;
    ds_desc.sampleCount = (uint32_t)_sapp.sample_count;
    _sapp.wgpu.depth_stencil_tex = wgpuDeviceCreateTexture(_sapp.wgpu.device, &ds_desc);
    if (0 == _sapp.wgpu.depth_stencil_tex) {
        _SAPP_PANIC(WGPU_SWAPCHAIN_CREATE_DEPTH_STENCIL_TEXTURE_FAILED);
    }
    _sapp.wgpu.depth_stencil_view = wgpuTextureCreateView(_sapp.wgpu.depth_stencil_tex, 0);
    if (0 == _sapp.wgpu.depth_stencil_view) {
        _SAPP_PANIC(WGPU_SWAPCHAIN_CREATE_DEPTH_STENCIL_VIEW_FAILED);
    }

    if (_sapp.sample_count > 1) {
        WGPUTextureDescriptor msaa_desc;
        _sapp_clear(&msaa_desc, sizeof(msaa_desc));
        msaa_desc.usage = WGPUTextureUsage_RenderAttachment;
        msaa_desc.dimension = WGPUTextureDimension_2D;
        msaa_desc.size.width = (uint32_t)_sapp.framebuffer_width;
        msaa_desc.size.height = (uint32_t)_sapp.framebuffer_height;
        msaa_desc.size.depthOrArrayLayers = 1;
        msaa_desc.format = _sapp.wgpu.render_format;
        msaa_desc.mipLevelCount = 1;
        msaa_desc.sampleCount = (uint32_t)_sapp.sample_count;
        _sapp.wgpu.msaa_tex = wgpuDeviceCreateTexture(_sapp.wgpu.device, &msaa_desc);
        if (0 == _sapp.wgpu.msaa_tex) {
            _SAPP_PANIC(WGPU_SWAPCHAIN_CREATE_MSAA_TEXTURE_FAILED);
        }
        _sapp.wgpu.msaa_view = wgpuTextureCreateView(_sapp.wgpu.msaa_tex, 0);
        if (0 == _sapp.wgpu.msaa_view) {
            _SAPP_PANIC(WGPU_SWAPCHAIN_CREATE_MSAA_VIEW_FAILED);
        }
    }
}

_SOKOL_PRIVATE void _sapp_emsc_wgpu_discard_swapchain(void) {
    if (_sapp.wgpu.msaa_view) {
        wgpuTextureViewRelease(_sapp.wgpu.msaa_view);
        _sapp.wgpu.msaa_view = 0;
    }
    if (_sapp.wgpu.msaa_tex) {
        wgpuTextureRelease(_sapp.wgpu.msaa_tex);
        _sapp.wgpu.msaa_tex = 0;
    }
    if (_sapp.wgpu.depth_stencil_view) {
        wgpuTextureViewRelease(_sapp.wgpu.depth_stencil_view);
        _sapp.wgpu.depth_stencil_view = 0;
    }
    if (_sapp.wgpu.depth_stencil_tex) {
        wgpuTextureRelease(_sapp.wgpu.depth_stencil_tex);
        _sapp.wgpu.depth_stencil_tex = 0;
    }
    if (_sapp.wgpu.swapchain) {
        wgpuSwapChainRelease(_sapp.wgpu.swapchain);
        _sapp.wgpu.swapchain = 0;
    }
    if (_sapp.wgpu.surface) {
        wgpuSurfaceRelease(_sapp.wgpu.surface);
        _sapp.wgpu.surface = 0;
    }
}

_SOKOL_PRIVATE void _sapp_emsc_wgpu_size_changed(void) {
    _sapp_emsc_wgpu_discard_swapchain();
    _sapp_emsc_wgpu_create_swapchain();
}

_SOKOL_PRIVATE void _sapp_emsc_wgpu_request_device_cb(WGPURequestDeviceStatus status, WGPUDevice device, const char* msg, void* userdata) {
    _SOKOL_UNUSED(msg);
    _SOKOL_UNUSED(userdata);
    SOKOL_ASSERT(!_sapp.wgpu.async_init_done);
    if (status != WGPURequestDeviceStatus_Success) {
        if (status == WGPURequestDeviceStatus_Error) {
            _SAPP_PANIC(WGPU_REQUEST_DEVICE_STATUS_ERROR);
        } else {
            _SAPP_PANIC(WGPU_REQUEST_DEVICE_STATUS_UNKNOWN);
        }
    }
    SOKOL_ASSERT(device);
    _sapp.wgpu.device = device;
    _sapp_emsc_wgpu_create_swapchain();
    _sapp.wgpu.async_init_done = true;
}

_SOKOL_PRIVATE void _sapp_emsc_wgpu_request_adapter_cb(WGPURequestAdapterStatus status, WGPUAdapter adapter, const char* msg, void* userdata) {
    _SOKOL_UNUSED(msg);
    _SOKOL_UNUSED(userdata);
    if (status != WGPURequestAdapterStatus_Success) {
        switch (status) {
            case WGPURequestAdapterStatus_Unavailable: _SAPP_PANIC(WGPU_REQUEST_ADAPTER_STATUS_UNAVAILABLE); break;
            case WGPURequestAdapterStatus_Error: _SAPP_PANIC(WGPU_REQUEST_ADAPTER_STATUS_ERROR); break;
            default: _SAPP_PANIC(WGPU_REQUEST_ADAPTER_STATUS_UNKNOWN); break;
        }
    }
    SOKOL_ASSERT(adapter);
    _sapp.wgpu.adapter = adapter;
    size_t cur_feature_index = 1;
    #define _SAPP_WGPU_MAX_REQUESTED_FEATURES (8)
    WGPUFeatureName requiredFeatures[_SAPP_WGPU_MAX_REQUESTED_FEATURES] = {
        WGPUFeatureName_Depth32FloatStencil8,
    };
    // check for optional features we're interested in
    if (wgpuAdapterHasFeature(adapter, WGPUFeatureName_TextureCompressionBC)) {
        SOKOL_ASSERT(cur_feature_index < _SAPP_WGPU_MAX_REQUESTED_FEATURES);
        requiredFeatures[cur_feature_index++] = WGPUFeatureName_TextureCompressionBC;
    }
    if (wgpuAdapterHasFeature(adapter, WGPUFeatureName_TextureCompressionETC2)) {
        SOKOL_ASSERT(cur_feature_index < _SAPP_WGPU_MAX_REQUESTED_FEATURES);
        requiredFeatures[cur_feature_index++] = WGPUFeatureName_TextureCompressionETC2;
    }
    if (wgpuAdapterHasFeature(adapter, WGPUFeatureName_TextureCompressionASTC)) {
        SOKOL_ASSERT(cur_feature_index < _SAPP_WGPU_MAX_REQUESTED_FEATURES);
        requiredFeatures[cur_feature_index++] = WGPUFeatureName_TextureCompressionASTC;
    }
    if (wgpuAdapterHasFeature(adapter, WGPUFeatureName_Float32Filterable)) {
        SOKOL_ASSERT(cur_feature_index < _SAPP_WGPU_MAX_REQUESTED_FEATURES);
        requiredFeatures[cur_feature_index++] = WGPUFeatureName_Float32Filterable;
    }
    #undef _SAPP_WGPU_MAX_REQUESTED_FEATURES

    WGPUDeviceDescriptor dev_desc;
    _sapp_clear(&dev_desc, sizeof(dev_desc));
    dev_desc.requiredFeatureCount = cur_feature_index;
    dev_desc.requiredFeatures = requiredFeatures,
    wgpuAdapterRequestDevice(adapter, &dev_desc, _sapp_emsc_wgpu_request_device_cb, 0);
}

_SOKOL_PRIVATE void _sapp_emsc_wgpu_init(void) {
    SOKOL_ASSERT(0 == _sapp.wgpu.instance);
    SOKOL_ASSERT(!_sapp.wgpu.async_init_done);
    _sapp.wgpu.instance = wgpuCreateInstance(0);
    if (0 == _sapp.wgpu.instance) {
        _SAPP_PANIC(WGPU_CREATE_INSTANCE_FAILED);
    }
    // FIXME: power preference?
    wgpuInstanceRequestAdapter(_sapp.wgpu.instance, 0, _sapp_emsc_wgpu_request_adapter_cb, 0);
}

_SOKOL_PRIVATE void _sapp_emsc_wgpu_frame(void) {
    if (_sapp.wgpu.async_init_done) {
        _sapp.wgpu.swapchain_view = wgpuSwapChainGetCurrentTextureView(_sapp.wgpu.swapchain);
        _sapp_frame();
        wgpuTextureViewRelease(_sapp.wgpu.swapchain_view);
        _sapp.wgpu.swapchain_view = 0;
    }
}
#endif // SOKOL_WGPU

_SOKOL_PRIVATE void _sapp_emsc_register_eventhandlers(void) {
    // NOTE: HTML canvas doesn't receive input focus, this is why key event handlers are added
    // to the window object (this could be worked around by adding a "tab index" to the
    // canvas)
    emscripten_set_mousedown_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_mouse_cb);
    emscripten_set_mouseup_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_mouse_cb);
    emscripten_set_mousemove_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_mouse_cb);
    emscripten_set_mouseenter_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_mouse_cb);
    emscripten_set_mouseleave_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_mouse_cb);
    emscripten_set_wheel_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_wheel_cb);
    emscripten_set_keydown_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, _sapp_emsc_key_cb);
    emscripten_set_keyup_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, _sapp_emsc_key_cb);
    emscripten_set_keypress_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, _sapp_emsc_key_cb);
    emscripten_set_touchstart_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_touch_cb);
    emscripten_set_touchmove_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_touch_cb);
    emscripten_set_touchend_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_touch_cb);
    emscripten_set_touchcancel_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_touch_cb);
    emscripten_set_pointerlockchange_callback(EMSCRIPTEN_EVENT_TARGET_DOCUMENT, 0, true, _sapp_emsc_pointerlockchange_cb);
    emscripten_set_pointerlockerror_callback(EMSCRIPTEN_EVENT_TARGET_DOCUMENT, 0, true, _sapp_emsc_pointerlockerror_cb);
    emscripten_set_focus_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, _sapp_emsc_focus_cb);
    emscripten_set_blur_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, _sapp_emsc_blur_cb);
    sapp_js_add_beforeunload_listener();
    if (_sapp.clipboard.enabled) {
        sapp_js_add_clipboard_listener();
    }
    if (_sapp.drop.enabled) {
        sapp_js_add_dragndrop_listeners();
    }
    #if defined(SOKOL_GLES3)
        emscripten_set_webglcontextlost_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_webgl_context_cb);
        emscripten_set_webglcontextrestored_callback(_sapp.html5_canvas_selector, 0, true, _sapp_emsc_webgl_context_cb);
    #endif
}

_SOKOL_PRIVATE void _sapp_emsc_unregister_eventhandlers(void) {
    emscripten_set_mousedown_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_mouseup_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_mousemove_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_mouseenter_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_mouseleave_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_wheel_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_keydown_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, 0);
    emscripten_set_keyup_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, 0);
    emscripten_set_keypress_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, 0);
    emscripten_set_touchstart_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_touchmove_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_touchend_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_touchcancel_callback(_sapp.html5_canvas_selector, 0, true, 0);
    emscripten_set_pointerlockchange_callback(EMSCRIPTEN_EVENT_TARGET_DOCUMENT, 0, true, 0);
    emscripten_set_pointerlockerror_callback(EMSCRIPTEN_EVENT_TARGET_DOCUMENT, 0, true, 0);
    emscripten_set_focus_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, 0);
    emscripten_set_blur_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, 0);
    if (!_sapp.desc.html5_canvas_resize) {
        emscripten_set_resize_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, true, 0);
    }
    sapp_js_remove_beforeunload_listener();
    if (_sapp.clipboard.enabled) {
        sapp_js_remove_clipboard_listener();
    }
    if (_sapp.drop.enabled) {
        sapp_js_remove_dragndrop_listeners();
    }
    #if defined(SOKOL_GLES3)
        emscripten_set_webglcontextlost_callback(_sapp.html5_canvas_selector, 0, true, 0);
        emscripten_set_webglcontextrestored_callback(_sapp.html5_canvas_selector, 0, true, 0);
    #endif
}

_SOKOL_PRIVATE EM_BOOL _sapp_emsc_frame_animation_loop(double time, void* userData) {
    _SOKOL_UNUSED(userData);
    _sapp_timing_external(&_sapp.timing, time / 1000.0);

    #if defined(SOKOL_WGPU)
        _sapp_emsc_wgpu_frame();
    #else
        _sapp_frame();
    #endif

    // quit-handling
    if (_sapp.quit_requested) {
        _sapp_init_event(SAPP_EVENTTYPE_QUIT_REQUESTED);
        _sapp_call_event(&_sapp.event);
        if (_sapp.quit_requested) {
            _sapp.quit_ordered = true;
        }
    }
    if (_sapp.quit_ordered) {
        _sapp_emsc_unregister_eventhandlers();
        _sapp_call_cleanup();
        _sapp_discard_state();
        return EM_FALSE;
    }
    return EM_TRUE;
}

_SOKOL_PRIVATE void _sapp_emsc_frame_main_loop(void) {
    const double time = emscripten_performance_now();
    if (!_sapp_emsc_frame_animation_loop(time, 0)) {
        emscripten_cancel_main_loop();
    }
}

_SOKOL_PRIVATE void _sapp_emsc_run(const sapp_desc* desc) {
    _sapp_init_state(desc);
    const char* document_title = desc->html5_update_document_title ? _sapp.window_title : 0;
    sapp_js_init(_sapp.html5_canvas_selector, document_title);
    double w, h;
    if (_sapp.desc.html5_canvas_resize) {
        w = (double) _sapp_def(_sapp.desc.width, _SAPP_FALLBACK_DEFAULT_WINDOW_WIDTH);
        h = (double) _sapp_def(_sapp.desc.height, _SAPP_FALLBACK_DEFAULT_WINDOW_HEIGHT);
    }
    else {
        emscripten_get_element_css_size(_sapp.html5_canvas_selector, &w, &h);
        emscripten_set_resize_callback(EMSCRIPTEN_EVENT_TARGET_WINDOW, 0, false, _sapp_emsc_size_changed);
    }
    if (_sapp.desc.high_dpi) {
        _sapp.dpi_scale = emscripten_get_device_pixel_ratio();
    }
    _sapp.window_width = (int)roundf(w);
    _sapp.window_height = (int)roundf(h);
    _sapp.framebuffer_width = (int)roundf(w * _sapp.dpi_scale);
    _sapp.framebuffer_height = (int)roundf(h * _sapp.dpi_scale);
    emscripten_set_canvas_element_size(_sapp.html5_canvas_selector, _sapp.framebuffer_width, _sapp.framebuffer_height);
    #if defined(SOKOL_GLES3)
        _sapp_emsc_webgl_init();
    #elif defined(SOKOL_WGPU)
        _sapp_emsc_wgpu_init();
    #endif
    _sapp.valid = true;
    _sapp_emsc_register_eventhandlers();
    sapp_set_icon(&desc->icon);

    // start the frame loop
    if (_sapp.desc.html5_use_emsc_set_main_loop) {
        emscripten_set_main_loop(_sapp_emsc_frame_main_loop, 0, _sapp.desc.html5_emsc_set_main_loop_simulate_infinite_loop);
    } else {
        emscripten_request_animation_frame_loop(_sapp_emsc_frame_animation_loop, 0);
    }
    // NOT A BUG: do not call _sapp_discard_state() here, instead this is
    // called in _sapp_emsc_frame() when the application is ordered to quit
}

#if !defined(SOKOL_NO_ENTRY)
int main(int argc, char* argv[]) {
    sapp_desc desc = sokol_main(argc, argv);
    _sapp_emsc_run(&desc);
    return 0;
}
#endif /* SOKOL_NO_ENTRY */
#endif /* _SAPP_EMSCRIPTEN */

//  ██████  ██          ██   ██ ███████ ██      ██████  ███████ ██████  ███████
// ██       ██          ██   ██ ██      ██      ██   ██ ██      ██   ██ ██
// ██   ███ ██          ███████ █████   ██      ██████  █████   ██████  ███████
// ██    ██ ██          ██   ██ ██      ██      ██      ██      ██   ██      ██
//  ██████  ███████     ██   ██ ███████ ███████ ██      ███████ ██   ██ ███████
//
// >>gl helpers
#if defined(SOKOL_GLCORE)
typedef struct {
    int         red_bits;
    int         green_bits;
    int         blue_bits;
    int         alpha_bits;
    int         depth_bits;
    int         stencil_bits;
    int         samples;
    bool        doublebuffer;
    uintptr_t   handle;
} _sapp_gl_fbconfig;

_SOKOL_PRIVATE void _sapp_gl_init_fbconfig(_sapp_gl_fbconfig* fbconfig) {
    _sapp_clear(fbconfig, sizeof(_sapp_gl_fbconfig));
    /* -1 means "don't care" */
    fbconfig->red_bits = -1;
    fbconfig->green_bits = -1;
    fbconfig->blue_bits = -1;
    fbconfig->alpha_bits = -1;
    fbconfig->depth_bits = -1;
    fbconfig->stencil_bits = -1;
    fbconfig->samples = -1;
}

typedef struct {
    int least_missing;
    int least_color_diff;
    int least_extra_diff;
    bool best_match;
} _sapp_gl_fbselect;

_SOKOL_PRIVATE void _sapp_gl_init_fbselect(_sapp_gl_fbselect* fbselect) {
    _sapp_clear(fbselect, sizeof(_sapp_gl_fbselect));
    fbselect->least_missing = 1000000;
    fbselect->least_color_diff = 10000000;
    fbselect->least_extra_diff = 10000000;
    fbselect->best_match = false;
}

// NOTE: this is used only in the WGL code path
_SOKOL_PRIVATE bool _sapp_gl_select_fbconfig(_sapp_gl_fbselect* fbselect, const _sapp_gl_fbconfig* desired, const _sapp_gl_fbconfig* current) {
    int missing = 0;
    if (desired->doublebuffer != current->doublebuffer) {
        return false;
    }

    if ((desired->alpha_bits > 0) && (current->alpha_bits == 0)) {
        missing++;
    }
    if ((desired->depth_bits > 0) && (current->depth_bits == 0)) {
        missing++;
    }
    if ((desired->stencil_bits > 0) && (current->stencil_bits == 0)) {
        missing++;
    }
    if ((desired->samples > 0) && (current->samples == 0)) {
        /* Technically, several multisampling buffers could be
            involved, but that's a lower level implementation detail and
            not important to us here, so we count them as one
        */
        missing++;
    }

    /* These polynomials make many small channel size differences matter
        less than one large channel size difference
        Calculate color channel size difference value
    */
    int color_diff = 0;
    if (desired->red_bits != -1) {
        color_diff += (desired->red_bits - current->red_bits) * (desired->red_bits - current->red_bits);
    }
    if (desired->green_bits != -1) {
        color_diff += (desired->green_bits - current->green_bits) * (desired->green_bits - current->green_bits);
    }
    if (desired->blue_bits != -1) {
        color_diff += (desired->blue_bits - current->blue_bits) * (desired->blue_bits - current->blue_bits);
    }

    /* Calculate non-color channel size difference value */
    int extra_diff = 0;
    if (desired->alpha_bits != -1) {
        extra_diff += (desired->alpha_bits - current->alpha_bits) * (desired->alpha_bits - current->alpha_bits);
    }
    if (desired->depth_bits != -1) {
        extra_diff += (desired->depth_bits - current->depth_bits) * (desired->depth_bits - current->depth_bits);
    }
    if (desired->stencil_bits != -1) {
        extra_diff += (desired->stencil_bits - current->stencil_bits) * (desired->stencil_bits - current->stencil_bits);
    }
    if (desired->samples != -1) {
        extra_diff += (desired->samples - current->samples) * (desired->samples - current->samples);
    }

    /* Figure out if the current one is better than the best one found so far
        Least number of missing buffers is the most important heuristic,
        then color buffer size match and lastly size match for other buffers
    */
    bool new_closest = false;
    if (missing < fbselect->least_missing) {
        new_closest = true;
    } else if (missing == fbselect->least_missing) {
        if ((color_diff < fbselect->least_color_diff) ||
            ((color_diff == fbselect->least_color_diff) && (extra_diff < fbselect->least_extra_diff)))
        {
            new_closest = true;
        }
    }
    if (new_closest) {
        fbselect->least_missing = missing;
        fbselect->least_color_diff = color_diff;
        fbselect->least_extra_diff = extra_diff;
        fbselect->best_match = (missing | color_diff | extra_diff) == 0;
    }
    return new_closest;
}

// NOTE: this is used only in the GLX code path
_SOKOL_PRIVATE const _sapp_gl_fbconfig* _sapp_gl_choose_fbconfig(const _sapp_gl_fbconfig* desired, const _sapp_gl_fbconfig* alternatives, int count) {
    int missing, least_missing = 1000000;
    int color_diff, least_color_diff = 10000000;
    int extra_diff, least_extra_diff = 10000000;
    const _sapp_gl_fbconfig* current;
    const _sapp_gl_fbconfig* closest = 0;
    for (int i = 0;  i < count;  i++) {
        current = alternatives + i;
        if (desired->doublebuffer != current->doublebuffer) {
            continue;
        }
        missing = 0;
        if (desired->alpha_bits > 0 && current->alpha_bits == 0) {
            missing++;
        }
        if (desired->depth_bits > 0 && current->depth_bits == 0) {
            missing++;
        }
        if (desired->stencil_bits > 0 && current->stencil_bits == 0) {
            missing++;
        }
        if (desired->samples > 0 && current->samples == 0) {
            /* Technically, several multisampling buffers could be
                involved, but that's a lower level implementation detail and
                not important to us here, so we count them as one
            */
            missing++;
        }

        /* These polynomials make many small channel size differences matter
            less than one large channel size difference
            Calculate color channel size difference value
        */
        color_diff = 0;
        if (desired->red_bits != -1) {
            color_diff += (desired->red_bits - current->red_bits) * (desired->red_bits - current->red_bits);
        }
        if (desired->green_bits != -1) {
            color_diff += (desired->green_bits - current->green_bits) * (desired->green_bits - current->green_bits);
        }
        if (desired->blue_bits != -1) {
            color_diff += (desired->blue_bits - current->blue_bits) * (desired->blue_bits - current->blue_bits);
        }

        /* Calculate non-color channel size difference value */
        extra_diff = 0;
        if (desired->alpha_bits != -1) {
            extra_diff += (desired->alpha_bits - current->alpha_bits) * (desired->alpha_bits - current->alpha_bits);
        }
        if (desired->depth_bits != -1) {
            extra_diff += (desired->depth_bits - current->depth_bits) * (desired->depth_bits - current->depth_bits);
        }
        if (desired->stencil_bits != -1) {
            extra_diff += (desired->stencil_bits - current->stencil_bits) * (desired->stencil_bits - current->stencil_bits);
        }
        if (desired->samples != -1) {
            extra_diff += (desired->samples - current->samples) * (desired->samples - current->samples);
        }

        /* Figure out if the current one is better than the best one found so far
            Least number of missing buffers is the most important heuristic,
            then color buffer size match and lastly size match for other buffers
        */
        if (missing < least_missing) {
            closest = current;
        }
        else if (missing == least_missing) {
            if ((color_diff < least_color_diff) ||
                (color_diff == least_color_diff && extra_diff < least_extra_diff))
            {
                closest = current;
            }
        }
        if (current == closest) {
            least_missing = missing;
            least_color_diff = color_diff;
            least_extra_diff = extra_diff;
        }
    }
    return closest;
}
#endif

// ██     ██ ██ ███    ██ ██████   ██████  ██     ██ ███████
// ██     ██ ██ ████   ██ ██   ██ ██    ██ ██     ██ ██
// ██  █  ██ ██ ██ ██  ██ ██   ██ ██    ██ ██  █  ██ ███████
// ██ ███ ██ ██ ██  ██ ██ ██   ██ ██    ██ ██ ███ ██      ██
//  ███ ███  ██ ██   ████ ██████   ██████   ███ ███  ███████
//
// >>windows
#if defined(_SAPP_WIN32)
_SOKOL_PRIVATE bool _sapp_win32_utf8_to_wide(const char* src, wchar_t* dst, int dst_num_bytes) {
    SOKOL_ASSERT(src && dst && (dst_num_bytes > 1));
    _sapp_clear(dst, (size_t)dst_num_bytes);
    const int dst_chars = dst_num_bytes / (int)sizeof(wchar_t);
    const int dst_needed = MultiByteToWideChar(CP_UTF8, 0, src, -1, 0, 0);
    if ((dst_needed > 0) && (dst_needed < dst_chars)) {
        MultiByteToWideChar(CP_UTF8, 0, src, -1, dst, dst_chars);
        return true;
    }
    else {
        /* input string doesn't fit into destination buffer */
        return false;
    }
}

_SOKOL_PRIVATE void _sapp_win32_app_event(sapp_event_type type) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_win32_init_keytable(void) {
    /* same as GLFW */
    _sapp.keycodes[0x00B] = SAPP_KEYCODE_0;
    _sapp.keycodes[0x002] = SAPP_KEYCODE_1;
    _sapp.keycodes[0x003] = SAPP_KEYCODE_2;
    _sapp.keycodes[0x004] = SAPP_KEYCODE_3;
    _sapp.keycodes[0x005] = SAPP_KEYCODE_4;
    _sapp.keycodes[0x006] = SAPP_KEYCODE_5;
    _sapp.keycodes[0x007] = SAPP_KEYCODE_6;
    _sapp.keycodes[0x008] = SAPP_KEYCODE_7;
    _sapp.keycodes[0x009] = SAPP_KEYCODE_8;
    _sapp.keycodes[0x00A] = SAPP_KEYCODE_9;
    _sapp.keycodes[0x01E] = SAPP_KEYCODE_A;
    _sapp.keycodes[0x030] = SAPP_KEYCODE_B;
    _sapp.keycodes[0x02E] = SAPP_KEYCODE_C;
    _sapp.keycodes[0x020] = SAPP_KEYCODE_D;
    _sapp.keycodes[0x012] = SAPP_KEYCODE_E;
    _sapp.keycodes[0x021] = SAPP_KEYCODE_F;
    _sapp.keycodes[0x022] = SAPP_KEYCODE_G;
    _sapp.keycodes[0x023] = SAPP_KEYCODE_H;
    _sapp.keycodes[0x017] = SAPP_KEYCODE_I;
    _sapp.keycodes[0x024] = SAPP_KEYCODE_J;
    _sapp.keycodes[0x025] = SAPP_KEYCODE_K;
    _sapp.keycodes[0x026] = SAPP_KEYCODE_L;
    _sapp.keycodes[0x032] = SAPP_KEYCODE_M;
    _sapp.keycodes[0x031] = SAPP_KEYCODE_N;
    _sapp.keycodes[0x018] = SAPP_KEYCODE_O;
    _sapp.keycodes[0x019] = SAPP_KEYCODE_P;
    _sapp.keycodes[0x010] = SAPP_KEYCODE_Q;
    _sapp.keycodes[0x013] = SAPP_KEYCODE_R;
    _sapp.keycodes[0x01F] = SAPP_KEYCODE_S;
    _sapp.keycodes[0x014] = SAPP_KEYCODE_T;
    _sapp.keycodes[0x016] = SAPP_KEYCODE_U;
    _sapp.keycodes[0x02F] = SAPP_KEYCODE_V;
    _sapp.keycodes[0x011] = SAPP_KEYCODE_W;
    _sapp.keycodes[0x02D] = SAPP_KEYCODE_X;
    _sapp.keycodes[0x015] = SAPP_KEYCODE_Y;
    _sapp.keycodes[0x02C] = SAPP_KEYCODE_Z;
    _sapp.keycodes[0x028] = SAPP_KEYCODE_APOSTROPHE;
    _sapp.keycodes[0x02B] = SAPP_KEYCODE_BACKSLASH;
    _sapp.keycodes[0x033] = SAPP_KEYCODE_COMMA;
    _sapp.keycodes[0x00D] = SAPP_KEYCODE_EQUAL;
    _sapp.keycodes[0x029] = SAPP_KEYCODE_GRAVE_ACCENT;
    _sapp.keycodes[0x01A] = SAPP_KEYCODE_LEFT_BRACKET;
    _sapp.keycodes[0x00C] = SAPP_KEYCODE_MINUS;
    _sapp.keycodes[0x034] = SAPP_KEYCODE_PERIOD;
    _sapp.keycodes[0x01B] = SAPP_KEYCODE_RIGHT_BRACKET;
    _sapp.keycodes[0x027] = SAPP_KEYCODE_SEMICOLON;
    _sapp.keycodes[0x035] = SAPP_KEYCODE_SLASH;
    _sapp.keycodes[0x056] = SAPP_KEYCODE_WORLD_2;
    _sapp.keycodes[0x00E] = SAPP_KEYCODE_BACKSPACE;
    _sapp.keycodes[0x153] = SAPP_KEYCODE_DELETE;
    _sapp.keycodes[0x14F] = SAPP_KEYCODE_END;
    _sapp.keycodes[0x01C] = SAPP_KEYCODE_ENTER;
    _sapp.keycodes[0x001] = SAPP_KEYCODE_ESCAPE;
    _sapp.keycodes[0x147] = SAPP_KEYCODE_HOME;
    _sapp.keycodes[0x152] = SAPP_KEYCODE_INSERT;
    _sapp.keycodes[0x15D] = SAPP_KEYCODE_MENU;
    _sapp.keycodes[0x151] = SAPP_KEYCODE_PAGE_DOWN;
    _sapp.keycodes[0x149] = SAPP_KEYCODE_PAGE_UP;
    _sapp.keycodes[0x045] = SAPP_KEYCODE_PAUSE;
    _sapp.keycodes[0x146] = SAPP_KEYCODE_PAUSE;
    _sapp.keycodes[0x039] = SAPP_KEYCODE_SPACE;
    _sapp.keycodes[0x00F] = SAPP_KEYCODE_TAB;
    _sapp.keycodes[0x03A] = SAPP_KEYCODE_CAPS_LOCK;
    _sapp.keycodes[0x145] = SAPP_KEYCODE_NUM_LOCK;
    _sapp.keycodes[0x046] = SAPP_KEYCODE_SCROLL_LOCK;
    _sapp.keycodes[0x03B] = SAPP_KEYCODE_F1;
    _sapp.keycodes[0x03C] = SAPP_KEYCODE_F2;
    _sapp.keycodes[0x03D] = SAPP_KEYCODE_F3;
    _sapp.keycodes[0x03E] = SAPP_KEYCODE_F4;
    _sapp.keycodes[0x03F] = SAPP_KEYCODE_F5;
    _sapp.keycodes[0x040] = SAPP_KEYCODE_F6;
    _sapp.keycodes[0x041] = SAPP_KEYCODE_F7;
    _sapp.keycodes[0x042] = SAPP_KEYCODE_F8;
    _sapp.keycodes[0x043] = SAPP_KEYCODE_F9;
    _sapp.keycodes[0x044] = SAPP_KEYCODE_F10;
    _sapp.keycodes[0x057] = SAPP_KEYCODE_F11;
    _sapp.keycodes[0x058] = SAPP_KEYCODE_F12;
    _sapp.keycodes[0x064] = SAPP_KEYCODE_F13;
    _sapp.keycodes[0x065] = SAPP_KEYCODE_F14;
    _sapp.keycodes[0x066] = SAPP_KEYCODE_F15;
    _sapp.keycodes[0x067] = SAPP_KEYCODE_F16;
    _sapp.keycodes[0x068] = SAPP_KEYCODE_F17;
    _sapp.keycodes[0x069] = SAPP_KEYCODE_F18;
    _sapp.keycodes[0x06A] = SAPP_KEYCODE_F19;
    _sapp.keycodes[0x06B] = SAPP_KEYCODE_F20;
    _sapp.keycodes[0x06C] = SAPP_KEYCODE_F21;
    _sapp.keycodes[0x06D] = SAPP_KEYCODE_F22;
    _sapp.keycodes[0x06E] = SAPP_KEYCODE_F23;
    _sapp.keycodes[0x076] = SAPP_KEYCODE_F24;
    _sapp.keycodes[0x038] = SAPP_KEYCODE_LEFT_ALT;
    _sapp.keycodes[0x01D] = SAPP_KEYCODE_LEFT_CONTROL;
    _sapp.keycodes[0x02A] = SAPP_KEYCODE_LEFT_SHIFT;
    _sapp.keycodes[0x15B] = SAPP_KEYCODE_LEFT_SUPER;
    _sapp.keycodes[0x137] = SAPP_KEYCODE_PRINT_SCREEN;
    _sapp.keycodes[0x138] = SAPP_KEYCODE_RIGHT_ALT;
    _sapp.keycodes[0x11D] = SAPP_KEYCODE_RIGHT_CONTROL;
    _sapp.keycodes[0x036] = SAPP_KEYCODE_RIGHT_SHIFT;
    _sapp.keycodes[0x136] = SAPP_KEYCODE_RIGHT_SHIFT;
    _sapp.keycodes[0x15C] = SAPP_KEYCODE_RIGHT_SUPER;
    _sapp.keycodes[0x150] = SAPP_KEYCODE_DOWN;
    _sapp.keycodes[0x14B] = SAPP_KEYCODE_LEFT;
    _sapp.keycodes[0x14D] = SAPP_KEYCODE_RIGHT;
    _sapp.keycodes[0x148] = SAPP_KEYCODE_UP;
    _sapp.keycodes[0x052] = SAPP_KEYCODE_KP_0;
    _sapp.keycodes[0x04F] = SAPP_KEYCODE_KP_1;
    _sapp.keycodes[0x050] = SAPP_KEYCODE_KP_2;
    _sapp.keycodes[0x051] = SAPP_KEYCODE_KP_3;
    _sapp.keycodes[0x04B] = SAPP_KEYCODE_KP_4;
    _sapp.keycodes[0x04C] = SAPP_KEYCODE_KP_5;
    _sapp.keycodes[0x04D] = SAPP_KEYCODE_KP_6;
    _sapp.keycodes[0x047] = SAPP_KEYCODE_KP_7;
    _sapp.keycodes[0x048] = SAPP_KEYCODE_KP_8;
    _sapp.keycodes[0x049] = SAPP_KEYCODE_KP_9;
    _sapp.keycodes[0x04E] = SAPP_KEYCODE_KP_ADD;
    _sapp.keycodes[0x053] = SAPP_KEYCODE_KP_DECIMAL;
    _sapp.keycodes[0x135] = SAPP_KEYCODE_KP_DIVIDE;
    _sapp.keycodes[0x11C] = SAPP_KEYCODE_KP_ENTER;
    _sapp.keycodes[0x037] = SAPP_KEYCODE_KP_MULTIPLY;
    _sapp.keycodes[0x04A] = SAPP_KEYCODE_KP_SUBTRACT;
}
#endif // _SAPP_WIN32

#if defined(_SAPP_WIN32)

#if defined(SOKOL_D3D11)

#if defined(__cplusplus)
#define _sapp_d3d11_Release(self) (self)->Release()
#define _sapp_win32_refiid(iid) iid
#else
#define _sapp_d3d11_Release(self) (self)->lpVtbl->Release(self)
#define _sapp_win32_refiid(iid) &iid
#endif

#define _SAPP_SAFE_RELEASE(obj) if (obj) { _sapp_d3d11_Release(obj); obj=0; }


static const IID _sapp_IID_ID3D11Texture2D = { 0x6f15aaf2,0xd208,0x4e89, {0x9a,0xb4,0x48,0x95,0x35,0xd3,0x4f,0x9c} };
static const IID _sapp_IID_IDXGIDevice1    = { 0x77db970f,0x6276,0x48ba, {0xba,0x28,0x07,0x01,0x43,0xb4,0x39,0x2c} };
static const IID _sapp_IID_IDXGIFactory    = { 0x7b7166ec,0x21c7,0x44ae, {0xb2,0x1a,0xc9,0xae,0x32,0x1a,0xe3,0x69} };

static inline HRESULT _sapp_dxgi_GetBuffer(IDXGISwapChain* self, UINT buffer_t, REFIID riid, void** ppSurface) {
    #if defined(__cplusplus)
        return self->GetBuffer(buffer_t, riid, ppSurface);
    #else
        return self->lpVtbl->GetBuffer(self, buffer_t, riid, ppSurface);
    #endif
}

static inline HRESULT _sapp_d3d11_QueryInterface(ID3D11Device* self, REFIID riid, void** ppvObject) {
    #if defined(__cplusplus)
        return self->QueryInterface(riid, ppvObject);
    #else
        return self->lpVtbl->QueryInterface(self, riid, ppvObject);
    #endif
}

static inline HRESULT _sapp_d3d11_CreateRenderTargetView(ID3D11Device* self, ID3D11Resource *pResource, const D3D11_RENDER_TARGET_VIEW_DESC* pDesc, ID3D11RenderTargetView** ppRTView) {
    #if defined(__cplusplus)
        return self->CreateRenderTargetView(pResource, pDesc, ppRTView);
    #else
        return self->lpVtbl->CreateRenderTargetView(self, pResource, pDesc, ppRTView);
    #endif
}

static inline HRESULT _sapp_d3d11_CreateTexture2D(ID3D11Device* self, const D3D11_TEXTURE2D_DESC* pDesc, const D3D11_SUBRESOURCE_DATA* pInitialData, ID3D11Texture2D** ppTexture2D) {
    #if defined(__cplusplus)
        return self->CreateTexture2D(pDesc, pInitialData, ppTexture2D);
    #else
        return self->lpVtbl->CreateTexture2D(self, pDesc, pInitialData, ppTexture2D);
    #endif
}

static inline HRESULT _sapp_d3d11_CreateDepthStencilView(ID3D11Device* self, ID3D11Resource* pResource, const D3D11_DEPTH_STENCIL_VIEW_DESC* pDesc, ID3D11DepthStencilView** ppDepthStencilView) {
    #if defined(__cplusplus)
        return self->CreateDepthStencilView(pResource, pDesc, ppDepthStencilView);
    #else
        return self->lpVtbl->CreateDepthStencilView(self, pResource, pDesc, ppDepthStencilView);
    #endif
}

static inline HRESULT _sapp_dxgi_ResizeBuffers(IDXGISwapChain* self, UINT BufferCount, UINT Width, UINT Height, DXGI_FORMAT NewFormat, UINT SwapChainFlags) {
    #if defined(__cplusplus)
        return self->ResizeBuffers(BufferCount, Width, Height, NewFormat, SwapChainFlags);
    #else
        return self->lpVtbl->ResizeBuffers(self, BufferCount, Width, Height, NewFormat, SwapChainFlags);
    #endif
}

static inline HRESULT _sapp_dxgi_Present(IDXGISwapChain* self, UINT SyncInterval, UINT Flags) {
    #if defined(__cplusplus)
        return self->Present(SyncInterval, Flags);
    #else
        return self->lpVtbl->Present(self, SyncInterval, Flags);
    #endif
}

static inline HRESULT _sapp_dxgi_GetFrameStatistics(IDXGISwapChain* self, DXGI_FRAME_STATISTICS* pStats) {
    #if defined(__cplusplus)
        return self->GetFrameStatistics(pStats);
    #else
        return self->lpVtbl->GetFrameStatistics(self, pStats);
    #endif
}

static inline HRESULT _sapp_dxgi_SetMaximumFrameLatency(IDXGIDevice1* self, UINT MaxLatency) {
    #if defined(__cplusplus)
        return self->SetMaximumFrameLatency(MaxLatency);
    #else
        return self->lpVtbl->SetMaximumFrameLatency(self, MaxLatency);
    #endif
}

static inline HRESULT _sapp_dxgi_GetAdapter(IDXGIDevice1* self, IDXGIAdapter** pAdapter) {
    #if defined(__cplusplus)
        return self->GetAdapter(pAdapter);
    #else
        return self->lpVtbl->GetAdapter(self, pAdapter);
    #endif
}

static inline HRESULT _sapp_dxgi_GetParent(IDXGIObject* self, REFIID riid, void** ppParent) {
    #if defined(__cplusplus)
        return self->GetParent(riid, ppParent);
    #else
        return self->lpVtbl->GetParent(self, riid, ppParent);
    #endif
}

static inline HRESULT _sapp_dxgi_MakeWindowAssociation(IDXGIFactory* self, HWND WindowHandle, UINT Flags) {
    #if defined(__cplusplus)
        return self->MakeWindowAssociation(WindowHandle, Flags);
    #else
        return self->lpVtbl->MakeWindowAssociation(self, WindowHandle, Flags);
    #endif
}

_SOKOL_PRIVATE void _sapp_d3d11_create_device_and_swapchain(void) {
    DXGI_SWAP_CHAIN_DESC* sc_desc = &_sapp.d3d11.swap_chain_desc;
    sc_desc->BufferDesc.Width = (UINT)_sapp.framebuffer_width;
    sc_desc->BufferDesc.Height = (UINT)_sapp.framebuffer_height;
    sc_desc->BufferDesc.Format = DXGI_FORMAT_B8G8R8A8_UNORM;
    sc_desc->BufferDesc.RefreshRate.Numerator = 60;
    sc_desc->BufferDesc.RefreshRate.Denominator = 1;
    sc_desc->OutputWindow = _sapp.win32.hwnd;
    sc_desc->Windowed = true;
    if (_sapp.win32.is_win10_or_greater) {
        sc_desc->BufferCount = 2;
        sc_desc->SwapEffect = (DXGI_SWAP_EFFECT) _SAPP_DXGI_SWAP_EFFECT_FLIP_DISCARD;
        _sapp.d3d11.use_dxgi_frame_stats = true;
    }
    else {
        sc_desc->BufferCount = 1;
        sc_desc->SwapEffect = DXGI_SWAP_EFFECT_DISCARD;
        _sapp.d3d11.use_dxgi_frame_stats = false;
    }
    sc_desc->SampleDesc.Count = 1;
    sc_desc->SampleDesc.Quality = 0;
    sc_desc->BufferUsage = DXGI_USAGE_RENDER_TARGET_OUTPUT;
    UINT create_flags = D3D11_CREATE_DEVICE_SINGLETHREADED | D3D11_CREATE_DEVICE_BGRA_SUPPORT;
    #if defined(SOKOL_DEBUG)
        create_flags |= D3D11_CREATE_DEVICE_DEBUG;
    #endif
    D3D_FEATURE_LEVEL requested_feature_levels[] = { D3D_FEATURE_LEVEL_11_1, D3D_FEATURE_LEVEL_11_0 };
    D3D_FEATURE_LEVEL result_feature_level;
    HRESULT hr = D3D11CreateDeviceAndSwapChain(
        NULL,                           /* pAdapter (use default) */
        D3D_DRIVER_TYPE_HARDWARE,       /* DriverType */
        NULL,                           /* Software */
        create_flags,                   /* Flags */
        requested_feature_levels,       /* pFeatureLevels */
        2,                              /* FeatureLevels */
        D3D11_SDK_VERSION,              /* SDKVersion */
        sc_desc,                        /* pSwapChainDesc */
        &_sapp.d3d11.swap_chain,        /* ppSwapChain */
        &_sapp.d3d11.device,            /* ppDevice */
        &result_feature_level,          /* pFeatureLevel */
        &_sapp.d3d11.device_context);   /* ppImmediateContext */
    _SOKOL_UNUSED(hr);
    #if defined(SOKOL_DEBUG)
    if (!SUCCEEDED(hr)) {
        // if initialization with D3D11_CREATE_DEVICE_DEBUG fails, this could be because the
        // 'D3D11 debug layer' stopped working, indicated by the error message:
        // ===
        // D3D11CreateDevice: Flags (0x2) were specified which require the D3D11 SDK Layers for Windows 10, but they are not present on the system.
        // These flags must be removed, or the Windows 10 SDK must be installed.
        // Flags include: D3D11_CREATE_DEVICE_DEBUG
        // ===
        //
        // ...just retry with the DEBUG flag switched off
        _SAPP_ERROR(WIN32_D3D11_CREATE_DEVICE_AND_SWAPCHAIN_WITH_DEBUG_FAILED);
        create_flags &= ~(UINT)D3D11_CREATE_DEVICE_DEBUG;
        hr = D3D11CreateDeviceAndSwapChain(
            NULL,                           /* pAdapter (use default) */
            D3D_DRIVER_TYPE_HARDWARE,       /* DriverType */
            NULL,                           /* Software */
            create_flags,                   /* Flags */
            requested_feature_levels,       /* pFeatureLevels */
            2,                              /* FeatureLevels */
            D3D11_SDK_VERSION,              /* SDKVersion */
            sc_desc,                        /* pSwapChainDesc */
            &_sapp.d3d11.swap_chain,        /* ppSwapChain */
            &_sapp.d3d11.device,            /* ppDevice */
            &result_feature_level,          /* pFeatureLevel */
            &_sapp.d3d11.device_context);   /* ppImmediateContext */
    }
    #endif
    SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.swap_chain && _sapp.d3d11.device && _sapp.d3d11.device_context);

    // minimize frame latency, disable Alt-Enter
    hr = _sapp_d3d11_QueryInterface(_sapp.d3d11.device, _sapp_win32_refiid(_sapp_IID_IDXGIDevice1), (void**)&_sapp.d3d11.dxgi_device);
    if (SUCCEEDED(hr) && _sapp.d3d11.dxgi_device) {
        _sapp_dxgi_SetMaximumFrameLatency(_sapp.d3d11.dxgi_device, 1);
        IDXGIAdapter* dxgi_adapter = 0;
        hr = _sapp_dxgi_GetAdapter(_sapp.d3d11.dxgi_device, &dxgi_adapter);
        if (SUCCEEDED(hr) && dxgi_adapter) {
            IDXGIFactory* dxgi_factory = 0;
            hr = _sapp_dxgi_GetParent((IDXGIObject*)dxgi_adapter, _sapp_win32_refiid(_sapp_IID_IDXGIFactory), (void**)&dxgi_factory);
            if (SUCCEEDED(hr)) {
                _sapp_dxgi_MakeWindowAssociation(dxgi_factory, _sapp.win32.hwnd, DXGI_MWA_NO_ALT_ENTER|DXGI_MWA_NO_PRINT_SCREEN);
                _SAPP_SAFE_RELEASE(dxgi_factory);
            }
            else {
                _SAPP_ERROR(WIN32_D3D11_GET_IDXGIFACTORY_FAILED);
            }
            _SAPP_SAFE_RELEASE(dxgi_adapter);
        }
        else {
            _SAPP_ERROR(WIN32_D3D11_GET_IDXGIADAPTER_FAILED);
        }
    }
    else {
        _SAPP_PANIC(WIN32_D3D11_QUERY_INTERFACE_IDXGIDEVICE1_FAILED);
    }
}

_SOKOL_PRIVATE void _sapp_d3d11_destroy_device_and_swapchain(void) {
    _SAPP_SAFE_RELEASE(_sapp.d3d11.swap_chain);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.dxgi_device);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.device_context);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.device);
}

_SOKOL_PRIVATE void _sapp_d3d11_create_default_render_target(void) {
    SOKOL_ASSERT(0 == _sapp.d3d11.rt);
    SOKOL_ASSERT(0 == _sapp.d3d11.rtv);
    SOKOL_ASSERT(0 == _sapp.d3d11.msaa_rt);
    SOKOL_ASSERT(0 == _sapp.d3d11.msaa_rtv);
    SOKOL_ASSERT(0 == _sapp.d3d11.ds);
    SOKOL_ASSERT(0 == _sapp.d3d11.dsv);

    HRESULT hr; _SOKOL_UNUSED(hr);

    /* view for the swapchain-created framebuffer */
    hr = _sapp_dxgi_GetBuffer(_sapp.d3d11.swap_chain, 0, _sapp_win32_refiid(_sapp_IID_ID3D11Texture2D), (void**)&_sapp.d3d11.rt);
    SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.rt);
    hr = _sapp_d3d11_CreateRenderTargetView(_sapp.d3d11.device, (ID3D11Resource*)_sapp.d3d11.rt, NULL, &_sapp.d3d11.rtv);
    SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.rtv);

    /* common desc for MSAA and depth-stencil texture */
    D3D11_TEXTURE2D_DESC tex_desc;
    _sapp_clear(&tex_desc, sizeof(tex_desc));
    tex_desc.Width = (UINT)_sapp.framebuffer_width;
    tex_desc.Height = (UINT)_sapp.framebuffer_height;
    tex_desc.MipLevels = 1;
    tex_desc.ArraySize = 1;
    tex_desc.Usage = D3D11_USAGE_DEFAULT;
    tex_desc.BindFlags = D3D11_BIND_RENDER_TARGET;
    tex_desc.SampleDesc.Count = (UINT) _sapp.sample_count;
    tex_desc.SampleDesc.Quality = (UINT) (_sapp.sample_count > 1 ? D3D11_STANDARD_MULTISAMPLE_PATTERN : 0);

    /* create MSAA texture and view if antialiasing requested */
    if (_sapp.sample_count > 1) {
        tex_desc.Format = DXGI_FORMAT_B8G8R8A8_UNORM;
        hr = _sapp_d3d11_CreateTexture2D(_sapp.d3d11.device, &tex_desc, NULL, &_sapp.d3d11.msaa_rt);
        SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.msaa_rt);
        hr = _sapp_d3d11_CreateRenderTargetView(_sapp.d3d11.device, (ID3D11Resource*)_sapp.d3d11.msaa_rt, NULL, &_sapp.d3d11.msaa_rtv);
        SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.msaa_rtv);
    }

    /* texture and view for the depth-stencil-surface */
    tex_desc.Format = DXGI_FORMAT_D24_UNORM_S8_UINT;
    tex_desc.BindFlags = D3D11_BIND_DEPTH_STENCIL;
    hr = _sapp_d3d11_CreateTexture2D(_sapp.d3d11.device, &tex_desc, NULL, &_sapp.d3d11.ds);
    SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.ds);
    hr = _sapp_d3d11_CreateDepthStencilView(_sapp.d3d11.device, (ID3D11Resource*)_sapp.d3d11.ds, NULL, &_sapp.d3d11.dsv);
    SOKOL_ASSERT(SUCCEEDED(hr) && _sapp.d3d11.dsv);
}

_SOKOL_PRIVATE void _sapp_d3d11_destroy_default_render_target(void) {
    _SAPP_SAFE_RELEASE(_sapp.d3d11.rt);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.rtv);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.msaa_rt);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.msaa_rtv);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.ds);
    _SAPP_SAFE_RELEASE(_sapp.d3d11.dsv);
}

_SOKOL_PRIVATE void _sapp_d3d11_resize_default_render_target(void) {
    if (_sapp.d3d11.swap_chain) {
        _sapp_d3d11_destroy_default_render_target();
        _sapp_dxgi_ResizeBuffers(_sapp.d3d11.swap_chain, _sapp.d3d11.swap_chain_desc.BufferCount, (UINT)_sapp.framebuffer_width, (UINT)_sapp.framebuffer_height, DXGI_FORMAT_B8G8R8A8_UNORM, 0);
        _sapp_d3d11_create_default_render_target();
    }
}

_SOKOL_PRIVATE void _sapp_d3d11_present(bool do_not_wait) {
    UINT flags = 0;
    if (_sapp.win32.is_win10_or_greater && do_not_wait) {
        /* this hack/workaround somewhat improves window-movement and -sizing
            responsiveness when rendering is controlled via WM_TIMER during window
            move and resize on NVIDIA cards on Win10 with recent drivers.
        */
        flags = DXGI_PRESENT_DO_NOT_WAIT;
    }
    _sapp_dxgi_Present(_sapp.d3d11.swap_chain, (UINT)_sapp.swap_interval, flags);
}

#endif /* SOKOL_D3D11 */

#if defined(SOKOL_GLCORE)
_SOKOL_PRIVATE void _sapp_wgl_init(void) {
    _sapp.wgl.opengl32 = LoadLibraryA("opengl32.dll");
    if (!_sapp.wgl.opengl32) {
        _SAPP_PANIC(WIN32_LOAD_OPENGL32_DLL_FAILED);
    }
    SOKOL_ASSERT(_sapp.wgl.opengl32);
    _sapp.wgl.CreateContext = (PFN_wglCreateContext)(void*) GetProcAddress(_sapp.wgl.opengl32, "wglCreateContext");
    SOKOL_ASSERT(_sapp.wgl.CreateContext);
    _sapp.wgl.DeleteContext = (PFN_wglDeleteContext)(void*) GetProcAddress(_sapp.wgl.opengl32, "wglDeleteContext");
    SOKOL_ASSERT(_sapp.wgl.DeleteContext);
    _sapp.wgl.GetProcAddress = (PFN_wglGetProcAddress)(void*) GetProcAddress(_sapp.wgl.opengl32, "wglGetProcAddress");
    SOKOL_ASSERT(_sapp.wgl.GetProcAddress);
    _sapp.wgl.GetCurrentDC = (PFN_wglGetCurrentDC)(void*) GetProcAddress(_sapp.wgl.opengl32, "wglGetCurrentDC");
    SOKOL_ASSERT(_sapp.wgl.GetCurrentDC);
    _sapp.wgl.MakeCurrent = (PFN_wglMakeCurrent)(void*) GetProcAddress(_sapp.wgl.opengl32, "wglMakeCurrent");
    SOKOL_ASSERT(_sapp.wgl.MakeCurrent);
    _sapp.wgl.GetIntegerv = (void(WINAPI*)(uint32_t, int32_t*)) GetProcAddress(_sapp.wgl.opengl32, "glGetIntegerv");
    SOKOL_ASSERT(_sapp.wgl.GetIntegerv);

    _sapp.wgl.msg_hwnd = CreateWindowExW(WS_EX_OVERLAPPEDWINDOW,
        L"SOKOLAPP",
        L"sokol-app message window",
        WS_CLIPSIBLINGS|WS_CLIPCHILDREN,
        0, 0, 1, 1,
        NULL, NULL,
        GetModuleHandleW(NULL),
        NULL);
    if (!_sapp.wgl.msg_hwnd) {
        _SAPP_PANIC(WIN32_CREATE_HELPER_WINDOW_FAILED);
    }
    SOKOL_ASSERT(_sapp.wgl.msg_hwnd);
    ShowWindow(_sapp.wgl.msg_hwnd, SW_HIDE);
    MSG msg;
    while (PeekMessageW(&msg, _sapp.wgl.msg_hwnd, 0, 0, PM_REMOVE)) {
        TranslateMessage(&msg);
        DispatchMessageW(&msg);
    }
    _sapp.wgl.msg_dc = GetDC(_sapp.wgl.msg_hwnd);
    if (!_sapp.wgl.msg_dc) {
        _SAPP_PANIC(WIN32_HELPER_WINDOW_GETDC_FAILED);
    }
}

_SOKOL_PRIVATE void _sapp_wgl_shutdown(void) {
    SOKOL_ASSERT(_sapp.wgl.opengl32 && _sapp.wgl.msg_hwnd);
    DestroyWindow(_sapp.wgl.msg_hwnd); _sapp.wgl.msg_hwnd = 0;
    FreeLibrary(_sapp.wgl.opengl32); _sapp.wgl.opengl32 = 0;
}

_SOKOL_PRIVATE bool _sapp_wgl_has_ext(const char* ext, const char* extensions) {
    SOKOL_ASSERT(ext && extensions);
    const char* start = extensions;
    while (true) {
        const char* where = strstr(start, ext);
        if (!where) {
            return false;
        }
        const char* terminator = where + strlen(ext);
        if ((where == start) || (*(where - 1) == ' ')) {
            if (*terminator == ' ' || *terminator == '\0') {
                break;
            }
        }
        start = terminator;
    }
    return true;
}

_SOKOL_PRIVATE bool _sapp_wgl_ext_supported(const char* ext) {
    SOKOL_ASSERT(ext);
    if (_sapp.wgl.GetExtensionsStringEXT) {
        const char* extensions = _sapp.wgl.GetExtensionsStringEXT();
        if (extensions) {
            if (_sapp_wgl_has_ext(ext, extensions)) {
                return true;
            }
        }
    }
    if (_sapp.wgl.GetExtensionsStringARB) {
        const char* extensions = _sapp.wgl.GetExtensionsStringARB(_sapp.wgl.GetCurrentDC());
        if (extensions) {
            if (_sapp_wgl_has_ext(ext, extensions)) {
                return true;
            }
        }
    }
    return false;
}

_SOKOL_PRIVATE void _sapp_wgl_load_extensions(void) {
    SOKOL_ASSERT(_sapp.wgl.msg_dc);
    PIXELFORMATDESCRIPTOR pfd;
    _sapp_clear(&pfd, sizeof(pfd));
    pfd.nSize = sizeof(pfd);
    pfd.nVersion = 1;
    pfd.dwFlags = PFD_DRAW_TO_WINDOW | PFD_SUPPORT_OPENGL | PFD_DOUBLEBUFFER;
    pfd.iPixelType = PFD_TYPE_RGBA;
    pfd.cColorBits = 24;
    if (!SetPixelFormat(_sapp.wgl.msg_dc, ChoosePixelFormat(_sapp.wgl.msg_dc, &pfd), &pfd)) {
        _SAPP_PANIC(WIN32_DUMMY_CONTEXT_SET_PIXELFORMAT_FAILED);
    }
    HGLRC rc = _sapp.wgl.CreateContext(_sapp.wgl.msg_dc);
    if (!rc) {
        _SAPP_PANIC(WIN32_CREATE_DUMMY_CONTEXT_FAILED);
    }
    if (!_sapp.wgl.MakeCurrent(_sapp.wgl.msg_dc, rc)) {
        _SAPP_PANIC(WIN32_DUMMY_CONTEXT_MAKE_CURRENT_FAILED);
    }
    _sapp.wgl.GetExtensionsStringEXT = (PFNWGLGETEXTENSIONSSTRINGEXTPROC)(void*) _sapp.wgl.GetProcAddress("wglGetExtensionsStringEXT");
    _sapp.wgl.GetExtensionsStringARB = (PFNWGLGETEXTENSIONSSTRINGARBPROC)(void*) _sapp.wgl.GetProcAddress("wglGetExtensionsStringARB");
    _sapp.wgl.CreateContextAttribsARB = (PFNWGLCREATECONTEXTATTRIBSARBPROC)(void*) _sapp.wgl.GetProcAddress("wglCreateContextAttribsARB");
    _sapp.wgl.SwapIntervalEXT = (PFNWGLSWAPINTERVALEXTPROC)(void*) _sapp.wgl.GetProcAddress("wglSwapIntervalEXT");
    _sapp.wgl.GetPixelFormatAttribivARB = (PFNWGLGETPIXELFORMATATTRIBIVARBPROC)(void*) _sapp.wgl.GetProcAddress("wglGetPixelFormatAttribivARB");
    _sapp.wgl.arb_multisample = _sapp_wgl_ext_supported("WGL_ARB_multisample");
    _sapp.wgl.arb_create_context = _sapp_wgl_ext_supported("WGL_ARB_create_context");
    _sapp.wgl.arb_create_context_profile = _sapp_wgl_ext_supported("WGL_ARB_create_context_profile");
    _sapp.wgl.ext_swap_control = _sapp_wgl_ext_supported("WGL_EXT_swap_control");
    _sapp.wgl.arb_pixel_format = _sapp_wgl_ext_supported("WGL_ARB_pixel_format");
    _sapp.wgl.MakeCurrent(_sapp.wgl.msg_dc, 0);
    _sapp.wgl.DeleteContext(rc);
}

_SOKOL_PRIVATE int _sapp_wgl_attrib(int pixel_format, int attrib) {
    SOKOL_ASSERT(_sapp.wgl.arb_pixel_format);
    int value = 0;
    if (!_sapp.wgl.GetPixelFormatAttribivARB(_sapp.win32.dc, pixel_format, 0, 1, &attrib, &value)) {
        _SAPP_PANIC(WIN32_GET_PIXELFORMAT_ATTRIB_FAILED);
    }
    return value;
}

_SOKOL_PRIVATE void _sapp_wgl_attribiv(int pixel_format, int num_attribs, const int* attribs, int* results) {
    SOKOL_ASSERT(_sapp.wgl.arb_pixel_format);
    if (!_sapp.wgl.GetPixelFormatAttribivARB(_sapp.win32.dc, pixel_format, 0, num_attribs, attribs, results)) {
        _SAPP_PANIC(WIN32_GET_PIXELFORMAT_ATTRIB_FAILED);
    }
}

_SOKOL_PRIVATE int _sapp_wgl_find_pixel_format(void) {
    SOKOL_ASSERT(_sapp.win32.dc);
    SOKOL_ASSERT(_sapp.wgl.arb_pixel_format);

    #define _sapp_wgl_num_query_tags (12)
    const int query_tags[_sapp_wgl_num_query_tags] = {
        WGL_SUPPORT_OPENGL_ARB,
        WGL_DRAW_TO_WINDOW_ARB,
        WGL_PIXEL_TYPE_ARB,
        WGL_ACCELERATION_ARB,
        WGL_DOUBLE_BUFFER_ARB,
        WGL_RED_BITS_ARB,
        WGL_GREEN_BITS_ARB,
        WGL_BLUE_BITS_ARB,
        WGL_ALPHA_BITS_ARB,
        WGL_DEPTH_BITS_ARB,
        WGL_STENCIL_BITS_ARB,
        WGL_SAMPLES_ARB,
    };
    const int result_support_opengl_index = 0;
    const int result_draw_to_window_index = 1;
    const int result_pixel_type_index = 2;
    const int result_acceleration_index = 3;
    const int result_double_buffer_index = 4;
    const int result_red_bits_index = 5;
    const int result_green_bits_index = 6;
    const int result_blue_bits_index = 7;
    const int result_alpha_bits_index = 8;
    const int result_depth_bits_index = 9;
    const int result_stencil_bits_index = 10;
    const int result_samples_index = 11;

    int query_results[_sapp_wgl_num_query_tags] = {0};
    // Drop the last item if multisample extension is not supported.
    //  If in future querying with multiple extensions, will have to shuffle index values to have active extensions on the end.
    int query_count = _sapp_wgl_num_query_tags;
    if (!_sapp.wgl.arb_multisample) {
        query_count = _sapp_wgl_num_query_tags - 1;
    }

    int native_count = _sapp_wgl_attrib(1, WGL_NUMBER_PIXEL_FORMATS_ARB);

    _sapp_gl_fbconfig desired;
    _sapp_gl_init_fbconfig(&desired);
    desired.red_bits = 8;
    desired.green_bits = 8;
    desired.blue_bits = 8;
    desired.alpha_bits = 8;
    desired.depth_bits = 24;
    desired.stencil_bits = 8;
    desired.doublebuffer = true;
    desired.samples = (_sapp.sample_count > 1) ? _sapp.sample_count : 0;

    int pixel_format = 0;

    _sapp_gl_fbselect fbselect;
    _sapp_gl_init_fbselect(&fbselect);
    for (int i = 0; i < native_count; i++) {
        const int n = i + 1;
        _sapp_wgl_attribiv(n, query_count, query_tags, query_results);

        if (query_results[result_support_opengl_index] == 0
            || query_results[result_draw_to_window_index] == 0
            || query_results[result_pixel_type_index] != WGL_TYPE_RGBA_ARB
            || query_results[result_acceleration_index] == WGL_NO_ACCELERATION_ARB)
        {
            continue;
        }

        _sapp_gl_fbconfig u;
        _sapp_clear(&u, sizeof(u));
        u.red_bits     = query_results[result_red_bits_index];
        u.green_bits   = query_results[result_green_bits_index];
        u.blue_bits    = query_results[result_blue_bits_index];
        u.alpha_bits   = query_results[result_alpha_bits_index];
        u.depth_bits   = query_results[result_depth_bits_index];
        u.stencil_bits = query_results[result_stencil_bits_index];
        u.doublebuffer = 0 != query_results[result_double_buffer_index];
        u.samples = query_results[result_samples_index]; // NOTE: If arb_multisample is not supported  - just takes the default 0

        // Test if this pixel format is better than the previous one
        if (_sapp_gl_select_fbconfig(&fbselect, &desired, &u)) {
            pixel_format = (uintptr_t)n;

            // Early exit if matching as good as possible
            if (fbselect.best_match) {
                break;
            }
        }
    }

    return pixel_format;
}

_SOKOL_PRIVATE void _sapp_wgl_create_context(void) {
    int pixel_format = _sapp_wgl_find_pixel_format();
    if (0 == pixel_format) {
        _SAPP_PANIC(WIN32_WGL_FIND_PIXELFORMAT_FAILED);
    }
    PIXELFORMATDESCRIPTOR pfd;
    if (!DescribePixelFormat(_sapp.win32.dc, pixel_format, sizeof(pfd), &pfd)) {
        _SAPP_PANIC(WIN32_WGL_DESCRIBE_PIXELFORMAT_FAILED);
    }
    if (!SetPixelFormat(_sapp.win32.dc, pixel_format, &pfd)) {
        _SAPP_PANIC(WIN32_WGL_SET_PIXELFORMAT_FAILED);
    }
    if (!_sapp.wgl.arb_create_context) {
        _SAPP_PANIC(WIN32_WGL_ARB_CREATE_CONTEXT_REQUIRED);
    }
    if (!_sapp.wgl.arb_create_context_profile) {
        _SAPP_PANIC(WIN32_WGL_ARB_CREATE_CONTEXT_PROFILE_REQUIRED);
    }
    const int attrs[] = {
        WGL_CONTEXT_MAJOR_VERSION_ARB, _sapp.desc.gl_major_version,
        WGL_CONTEXT_MINOR_VERSION_ARB, _sapp.desc.gl_minor_version,
#if defined(SOKOL_DEBUG)
        WGL_CONTEXT_FLAGS_ARB, WGL_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB | WGL_CONTEXT_DEBUG_BIT_ARB,
#else
        WGL_CONTEXT_FLAGS_ARB, WGL_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB,
#endif
        WGL_CONTEXT_PROFILE_MASK_ARB, WGL_CONTEXT_CORE_PROFILE_BIT_ARB,
        0, 0
    };
    _sapp.wgl.gl_ctx = _sapp.wgl.CreateContextAttribsARB(_sapp.win32.dc, 0, attrs);
    if (!_sapp.wgl.gl_ctx) {
        const DWORD err = GetLastError();
        if (err == (0xc0070000 | ERROR_INVALID_VERSION_ARB)) {
            _SAPP_PANIC(WIN32_WGL_OPENGL_VERSION_NOT_SUPPORTED);
        }
        else if (err == (0xc0070000 | ERROR_INVALID_PROFILE_ARB)) {
            _SAPP_PANIC(WIN32_WGL_OPENGL_PROFILE_NOT_SUPPORTED);
        }
        else if (err == (0xc0070000 | ERROR_INCOMPATIBLE_DEVICE_CONTEXTS_ARB)) {
            _SAPP_PANIC(WIN32_WGL_INCOMPATIBLE_DEVICE_CONTEXT);
        }
        else {
            _SAPP_PANIC(WIN32_WGL_CREATE_CONTEXT_ATTRIBS_FAILED_OTHER);
        }
    }
    _sapp.wgl.MakeCurrent(_sapp.win32.dc, _sapp.wgl.gl_ctx);
    if (_sapp.wgl.ext_swap_control) {
        /* FIXME: DwmIsCompositionEnabled() (see GLFW) */
        _sapp.wgl.SwapIntervalEXT(_sapp.swap_interval);
    }
    const uint32_t gl_framebuffer_binding = 0x8CA6;
    _sapp.wgl.GetIntegerv(gl_framebuffer_binding, (int32_t*)&_sapp.gl.framebuffer);
}

_SOKOL_PRIVATE void _sapp_wgl_destroy_context(void) {
    SOKOL_ASSERT(_sapp.wgl.gl_ctx);
    _sapp.wgl.DeleteContext(_sapp.wgl.gl_ctx);
    _sapp.wgl.gl_ctx = 0;
}

_SOKOL_PRIVATE void _sapp_wgl_swap_buffers(void) {
    SOKOL_ASSERT(_sapp.win32.dc);
    /* FIXME: DwmIsCompositionEnabled? (see GLFW) */
    SwapBuffers(_sapp.win32.dc);
}
#endif /* SOKOL_GLCORE */

_SOKOL_PRIVATE bool _sapp_win32_wide_to_utf8(const wchar_t* src, char* dst, int dst_num_bytes) {
    SOKOL_ASSERT(src && dst && (dst_num_bytes > 1));
    _sapp_clear(dst, (size_t)dst_num_bytes);
    const int bytes_needed = WideCharToMultiByte(CP_UTF8, 0, src, -1, NULL, 0, NULL, NULL);
    if (bytes_needed <= dst_num_bytes) {
        WideCharToMultiByte(CP_UTF8, 0, src, -1, dst, dst_num_bytes, NULL, NULL);
        return true;
    }
    else {
        return false;
    }
}

/* updates current window and framebuffer size from the window's client rect, returns true if size has changed */
_SOKOL_PRIVATE bool _sapp_win32_update_dimensions(void) {
    RECT rect;
    if (GetClientRect(_sapp.win32.hwnd, &rect)) {
        float window_width = (float)(rect.right - rect.left) / _sapp.win32.dpi.window_scale;
        float window_height = (float)(rect.bottom - rect.top) / _sapp.win32.dpi.window_scale;
        _sapp.window_width = (int)roundf(window_width);
        _sapp.window_height = (int)roundf(window_height);
        int fb_width = (int)roundf(window_width * _sapp.win32.dpi.content_scale);
        int fb_height = (int)roundf(window_height * _sapp.win32.dpi.content_scale);
        /* prevent a framebuffer size of 0 when window is minimized */
        if (0 == fb_width) {
            fb_width = 1;
        }
        if (0 == fb_height) {
            fb_height = 1;
        }
        if ((fb_width != _sapp.framebuffer_width) || (fb_height != _sapp.framebuffer_height)) {
            _sapp.framebuffer_width = fb_width;
            _sapp.framebuffer_height = fb_height;
            return true;
        }
    }
    else {
        _sapp.window_width = _sapp.window_height = 1;
        _sapp.framebuffer_width = _sapp.framebuffer_height = 1;
    }
    return false;
}

_SOKOL_PRIVATE void _sapp_win32_set_fullscreen(bool fullscreen, UINT swp_flags) {
    HMONITOR monitor = MonitorFromWindow(_sapp.win32.hwnd, MONITOR_DEFAULTTONEAREST);
    MONITORINFO minfo;
    _sapp_clear(&minfo, sizeof(minfo));
    minfo.cbSize = sizeof(MONITORINFO);
    GetMonitorInfo(monitor, &minfo);
    const RECT mr = minfo.rcMonitor;
    const int monitor_w = mr.right - mr.left;
    const int monitor_h = mr.bottom - mr.top;

    const DWORD win_ex_style = WS_EX_APPWINDOW | WS_EX_WINDOWEDGE;
    DWORD win_style;
    RECT rect = { 0, 0, 0, 0 };

    _sapp.fullscreen = fullscreen;
    if (!_sapp.fullscreen) {
        win_style = WS_CLIPSIBLINGS | WS_CLIPCHILDREN | WS_CAPTION | WS_SYSMENU | WS_MINIMIZEBOX | WS_MAXIMIZEBOX | WS_SIZEBOX;
        rect = _sapp.win32.stored_window_rect;
    }
    else {
        GetWindowRect(_sapp.win32.hwnd, &_sapp.win32.stored_window_rect);
        win_style = WS_POPUP | WS_SYSMENU | WS_VISIBLE;
        rect.left = mr.left;
        rect.top = mr.top;
        rect.right = rect.left + monitor_w;
        rect.bottom = rect.top + monitor_h;
        AdjustWindowRectEx(&rect, win_style, FALSE, win_ex_style);
    }
    const int win_w = rect.right - rect.left;
    const int win_h = rect.bottom - rect.top;
    const int win_x = rect.left;
    const int win_y = rect.top;
    SetWindowLongPtr(_sapp.win32.hwnd, GWL_STYLE, win_style);
    SetWindowPos(_sapp.win32.hwnd, HWND_TOP, win_x, win_y, win_w, win_h, swp_flags | SWP_FRAMECHANGED);
}

_SOKOL_PRIVATE void _sapp_win32_toggle_fullscreen(void) {
    _sapp_win32_set_fullscreen(!_sapp.fullscreen, SWP_SHOWWINDOW);
}

_SOKOL_PRIVATE void _sapp_win32_init_cursor(sapp_mouse_cursor cursor) {
    SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
    // NOTE: the OCR_* constants are only defined if OEMRESOURCE is defined
    // before windows.h is included, but we can't guarantee that because
    // the sokol_app.h implementation may be included with other implementations
    // in the same compilation unit
    int id = 0;
    switch (cursor) {
        case SAPP_MOUSECURSOR_ARROW:            id = 32512; break;  // OCR_NORMAL
        case SAPP_MOUSECURSOR_IBEAM:            id = 32513; break;  // OCR_IBEAM
        case SAPP_MOUSECURSOR_CROSSHAIR:        id = 32515; break;  // OCR_CROSS
        case SAPP_MOUSECURSOR_POINTING_HAND:    id = 32649; break;  // OCR_HAND
        case SAPP_MOUSECURSOR_RESIZE_EW:        id = 32644; break;  // OCR_SIZEWE
        case SAPP_MOUSECURSOR_RESIZE_NS:        id = 32645; break;  // OCR_SIZENS
        case SAPP_MOUSECURSOR_RESIZE_NWSE:      id = 32642; break;  // OCR_SIZENWSE
        case SAPP_MOUSECURSOR_RESIZE_NESW:      id = 32643; break;  // OCR_SIZENESW
        case SAPP_MOUSECURSOR_RESIZE_ALL:       id = 32646; break;  // OCR_SIZEALL
        case SAPP_MOUSECURSOR_NOT_ALLOWED:      id = 32648; break;  // OCR_NO
        default: break;
    }
    if (id != 0) {
        _sapp.win32.cursors[cursor] = (HCURSOR)LoadImageW(NULL, MAKEINTRESOURCEW(id), IMAGE_CURSOR, 0, 0, LR_DEFAULTSIZE|LR_SHARED);
    }
    // fallback: default cursor
    if (0 == _sapp.win32.cursors[cursor]) {
        // 32512 => IDC_ARROW
        _sapp.win32.cursors[cursor] = LoadCursorW(NULL, MAKEINTRESOURCEW(32512));
    }
    SOKOL_ASSERT(0 != _sapp.win32.cursors[cursor]);
}

_SOKOL_PRIVATE void _sapp_win32_init_cursors(void) {
    for (int i = 0; i < _SAPP_MOUSECURSOR_NUM; i++) {
        _sapp_win32_init_cursor((sapp_mouse_cursor)i);
    }
}

_SOKOL_PRIVATE bool _sapp_win32_cursor_in_content_area(void) {
    POINT pos;
    if (!GetCursorPos(&pos)) {
        return false;
    }
    if (WindowFromPoint(pos) != _sapp.win32.hwnd) {
        return false;
    }
    RECT area;
    GetClientRect(_sapp.win32.hwnd, &area);
    ClientToScreen(_sapp.win32.hwnd, (POINT*)&area.left);
    ClientToScreen(_sapp.win32.hwnd, (POINT*)&area.right);
    return PtInRect(&area, pos) == TRUE;
}

_SOKOL_PRIVATE void _sapp_win32_update_cursor(sapp_mouse_cursor cursor, bool shown, bool skip_area_test) {
    // NOTE: when called from WM_SETCURSOR, the area test would be redundant
    if (!skip_area_test) {
        if (!_sapp_win32_cursor_in_content_area()) {
            return;
        }
    }
    if (!shown) {
        SetCursor(NULL);
    }
    else {
        SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
        SOKOL_ASSERT(0 != _sapp.win32.cursors[cursor]);
        SetCursor(_sapp.win32.cursors[cursor]);
    }
}

_SOKOL_PRIVATE void _sapp_win32_capture_mouse(uint8_t btn_mask) {
    if (0 == _sapp.win32.mouse.capture_mask) {
        SetCapture(_sapp.win32.hwnd);
    }
    _sapp.win32.mouse.capture_mask |= btn_mask;
}

_SOKOL_PRIVATE void _sapp_win32_release_mouse(uint8_t btn_mask) {
    if (0 != _sapp.win32.mouse.capture_mask) {
        _sapp.win32.mouse.capture_mask &= ~btn_mask;
        if (0 == _sapp.win32.mouse.capture_mask) {
            ReleaseCapture();
        }
    }
}

_SOKOL_PRIVATE bool _sapp_win32_is_foreground_window(void) {
    return _sapp.win32.hwnd == GetForegroundWindow();
}

_SOKOL_PRIVATE void _sapp_win32_lock_mouse(bool lock) {
    _sapp.win32.mouse.requested_lock = lock;
}

_SOKOL_PRIVATE void _sapp_win32_free_raw_input_data(void) {
    if (_sapp.win32.raw_input_data.ptr) {
        _sapp_free(_sapp.win32.raw_input_data.ptr);
        _sapp.win32.raw_input_data.ptr = 0;
        _sapp.win32.raw_input_data.size = 0;
    }
}

_SOKOL_PRIVATE void _sapp_win32_alloc_raw_input_data(size_t size) {
    SOKOL_ASSERT(!_sapp.win32.raw_input_data.ptr);
    SOKOL_ASSERT(size > 0);
    _sapp.win32.raw_input_data.ptr = _sapp_malloc(size);
    _sapp.win32.raw_input_data.size = size;
    SOKOL_ASSERT(_sapp.win32.raw_input_data.ptr);
}

_SOKOL_PRIVATE void* _sapp_win32_ensure_raw_input_data(size_t required_size) {
    if (required_size > _sapp.win32.raw_input_data.size) {
        _sapp_win32_free_raw_input_data();
        _sapp_win32_alloc_raw_input_data(required_size);
    }
    // we expect that malloc() returns at least 8-byte aligned memory
    SOKOL_ASSERT((((uintptr_t)_sapp.win32.raw_input_data.ptr) & 7) == 0);
    return _sapp.win32.raw_input_data.ptr;
}

_SOKOL_PRIVATE void _sapp_win32_do_lock_mouse(void) {
    _sapp.mouse.locked = true;

    // hide mouse cursor (NOTE: this maintains a hidden counter, but since
    // only mouse-lock uses ShowCursor this doesn't matter)
    ShowCursor(FALSE);

    // reset dx/dy and release any active mouse capture
    _sapp.mouse.dx = 0.0f;
    _sapp.mouse.dy = 0.0f;
    _sapp_win32_release_mouse(0xFF);

    // store current mouse position so that it can be restored when unlocked
    POINT pos;
    if (GetCursorPos(&pos)) {
        _sapp.win32.mouse.lock.pos_valid = true;
        _sapp.win32.mouse.lock.pos_x = pos.x;
        _sapp.win32.mouse.lock.pos_y = pos.y;
    } else {
        _sapp.win32.mouse.lock.pos_valid = false;
    }

    // while mouse is locked, restrict cursor movement to the client
    // rectangle so that we don't loose any mouse movement events
    RECT client_rect;
    GetClientRect(_sapp.win32.hwnd, &client_rect);
    POINT mid_point;
    mid_point.x = (client_rect.right - client_rect.left) / 2;
    mid_point.y = (client_rect.bottom - client_rect.top) / 2;
    ClientToScreen(_sapp.win32.hwnd, &mid_point);
    RECT clip_rect;
    clip_rect.left = clip_rect.right = mid_point.x;
    clip_rect.top = clip_rect.bottom = mid_point.y;
    ClipCursor(&clip_rect);

    // enable raw input for mouse, starts sending WM_INPUT messages to WinProc (see GLFW)
    const RAWINPUTDEVICE rid = {
        0x01,   // usUsagePage: HID_USAGE_PAGE_GENERIC
        0x02,   // usUsage: HID_USAGE_GENERIC_MOUSE
        0,      // dwFlags
        _sapp.win32.hwnd    // hwndTarget
    };
    if (!RegisterRawInputDevices(&rid, 1, sizeof(rid))) {
        _SAPP_ERROR(WIN32_REGISTER_RAW_INPUT_DEVICES_FAILED_MOUSE_LOCK);
    }
    // in case the raw mouse device only supports absolute position reporting,
    // we need to skip the dx/dy compution for the first WM_INPUT event
    _sapp.win32.mouse.raw_input.pos_valid = false;
}

_SOKOL_PRIVATE void _sapp_win32_do_unlock_mouse(void) {
    _sapp.mouse.locked = false;

    // make mouse cursor visible
    ShowCursor(TRUE);

    // reset dx/dy and release any active mouse capture
    _sapp.mouse.dx = 0.0f;
    _sapp.mouse.dy = 0.0f;
    _sapp_win32_release_mouse(0xFF);

    // disable raw input for mouse
    const RAWINPUTDEVICE rid = { 0x01, 0x02, RIDEV_REMOVE, NULL };
    if (!RegisterRawInputDevices(&rid, 1, sizeof(rid))) {
        _SAPP_ERROR(WIN32_REGISTER_RAW_INPUT_DEVICES_FAILED_MOUSE_UNLOCK);
    }

    // unrestrict mouse movement
    ClipCursor(NULL);

    // restore the 'pre-locked' mouse position
    if (_sapp.win32.mouse.lock.pos_valid) {
        SetCursorPos(_sapp.win32.mouse.lock.pos_x, _sapp.win32.mouse.lock.pos_y);
        _sapp.win32.mouse.lock.pos_valid = false;
    }
}

_SOKOL_PRIVATE void _sapp_win32_update_mouse_lock(void) {
    // mouse lock can only be active when we're the active window
    if (!_sapp_win32_is_foreground_window()) {
        // unlock mouse if currently locked
        if (_sapp.mouse.locked) {
            _sapp_win32_do_unlock_mouse();
        }
        return;
    }

    // nothing to do if requested lock state matches current lock state
    const bool lock = _sapp.win32.mouse.requested_lock;
    if (lock == _sapp.mouse.locked) {
        return;
    }

    // otherwise change into desired state
    if (lock) {
        _sapp_win32_do_lock_mouse();
    } else {
        _sapp_win32_do_unlock_mouse();
    }
}

_SOKOL_PRIVATE bool _sapp_win32_update_monitor(void) {
    const HMONITOR cur_monitor = MonitorFromWindow(_sapp.win32.hwnd, MONITOR_DEFAULTTONULL);
    if (cur_monitor != _sapp.win32.hmonitor) {
        _sapp.win32.hmonitor = cur_monitor;
        return true;
    }
    else {
        return false;
    }
}

_SOKOL_PRIVATE uint32_t _sapp_win32_mods(void) {
    uint32_t mods = 0;
    if (GetKeyState(VK_SHIFT) & (1<<15)) {
        mods |= SAPP_MODIFIER_SHIFT;
    }
    if (GetKeyState(VK_CONTROL) & (1<<15)) {
        mods |= SAPP_MODIFIER_CTRL;
    }
    if (GetKeyState(VK_MENU) & (1<<15)) {
        mods |= SAPP_MODIFIER_ALT;
    }
    if ((GetKeyState(VK_LWIN) | GetKeyState(VK_RWIN)) & (1<<15)) {
        mods |= SAPP_MODIFIER_SUPER;
    }
    const bool swapped = (TRUE == GetSystemMetrics(SM_SWAPBUTTON));
    if (GetAsyncKeyState(VK_LBUTTON)) {
        mods |= swapped ? SAPP_MODIFIER_RMB : SAPP_MODIFIER_LMB;
    }
    if (GetAsyncKeyState(VK_RBUTTON)) {
        mods |= swapped ? SAPP_MODIFIER_LMB : SAPP_MODIFIER_RMB;
    }
    if (GetAsyncKeyState(VK_MBUTTON)) {
        mods |= SAPP_MODIFIER_MMB;
    }
    return mods;
}

_SOKOL_PRIVATE void _sapp_win32_mouse_update(LPARAM lParam) {
    if (!_sapp.mouse.locked) {
        const float new_x  = (float)GET_X_LPARAM(lParam) * _sapp.win32.dpi.mouse_scale;
        const float new_y = (float)GET_Y_LPARAM(lParam) * _sapp.win32.dpi.mouse_scale;
        if (_sapp.mouse.pos_valid) {
            // don't update dx/dy in the very first event
            _sapp.mouse.dx = new_x - _sapp.mouse.x;
            _sapp.mouse.dy = new_y - _sapp.mouse.y;
        }
        _sapp.mouse.x = new_x;
        _sapp.mouse.y = new_y;
        _sapp.mouse.pos_valid = true;
    }
}

_SOKOL_PRIVATE void _sapp_win32_mouse_event(sapp_event_type type, sapp_mousebutton btn) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp.event.modifiers = _sapp_win32_mods();
        _sapp.event.mouse_button = btn;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_win32_scroll_event(float x, float y) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_MOUSE_SCROLL);
        _sapp.event.modifiers = _sapp_win32_mods();
        _sapp.event.scroll_x = -x / 30.0f;
        _sapp.event.scroll_y = y / 30.0f;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_win32_key_event(sapp_event_type type, int vk, bool repeat) {
    if (_sapp_events_enabled() && (vk < SAPP_MAX_KEYCODES)) {
        _sapp_init_event(type);
        _sapp.event.modifiers = _sapp_win32_mods();
        _sapp.event.key_code = _sapp.keycodes[vk];
        _sapp.event.key_repeat = repeat;
        _sapp_call_event(&_sapp.event);
        /* check if a CLIPBOARD_PASTED event must be sent too */
        if (_sapp.clipboard.enabled &&
            (type == SAPP_EVENTTYPE_KEY_DOWN) &&
            (_sapp.event.modifiers == SAPP_MODIFIER_CTRL) &&
            (_sapp.event.key_code == SAPP_KEYCODE_V))
        {
            _sapp_init_event(SAPP_EVENTTYPE_CLIPBOARD_PASTED);
            _sapp_call_event(&_sapp.event);
        }
    }
}

_SOKOL_PRIVATE void _sapp_win32_char_event(uint32_t c, bool repeat) {
    if (_sapp_events_enabled() && (c >= 32)) {
        _sapp_init_event(SAPP_EVENTTYPE_CHAR);
        _sapp.event.modifiers = _sapp_win32_mods();
        _sapp.event.char_code = c;
        _sapp.event.key_repeat = repeat;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_win32_dpi_changed(HWND hWnd, LPRECT proposed_win_rect) {
    /* called on WM_DPICHANGED, which will only be sent to the application
        if sapp_desc.high_dpi is true and the Windows version is recent enough
        to support DPI_AWARENESS_CONTEXT_PER_MONITOR_AWARE_V2
    */
    SOKOL_ASSERT(_sapp.desc.high_dpi);
    HINSTANCE user32 = LoadLibraryA("user32.dll");
    if (!user32) {
        return;
    }
    typedef UINT(WINAPI * GETDPIFORWINDOW_T)(HWND hwnd);
    GETDPIFORWINDOW_T fn_getdpiforwindow = (GETDPIFORWINDOW_T)(void*)GetProcAddress(user32, "GetDpiForWindow");
    if (fn_getdpiforwindow) {
        UINT dpix = fn_getdpiforwindow(_sapp.win32.hwnd);
        // NOTE: for high-dpi apps, mouse_scale remains one
        _sapp.win32.dpi.window_scale = (float)dpix / 96.0f;
        _sapp.win32.dpi.content_scale = _sapp.win32.dpi.window_scale;
        _sapp.dpi_scale = _sapp.win32.dpi.window_scale;
        SetWindowPos(hWnd, 0,
            proposed_win_rect->left,
            proposed_win_rect->top,
            proposed_win_rect->right - proposed_win_rect->left,
            proposed_win_rect->bottom - proposed_win_rect->top,
            SWP_NOZORDER | SWP_NOACTIVATE);
    }
    FreeLibrary(user32);
}

_SOKOL_PRIVATE void _sapp_win32_files_dropped(HDROP hdrop) {
    if (!_sapp.drop.enabled) {
        return;
    }
    _sapp_clear_drop_buffer();
    bool drop_failed = false;
    const int count = (int) DragQueryFileW(hdrop, 0xffffffff, NULL, 0);
    _sapp.drop.num_files = (count > _sapp.drop.max_files) ? _sapp.drop.max_files : count;
    for (UINT i = 0;  i < (UINT)_sapp.drop.num_files;  i++) {
        const UINT num_chars = DragQueryFileW(hdrop, i, NULL, 0) + 1;
        WCHAR* buffer = (WCHAR*) _sapp_malloc_clear(num_chars * sizeof(WCHAR));
        DragQueryFileW(hdrop, i, buffer, num_chars);
        if (!_sapp_win32_wide_to_utf8(buffer, _sapp_dropped_file_path_ptr((int)i), _sapp.drop.max_path_length)) {
            _SAPP_ERROR(DROPPED_FILE_PATH_TOO_LONG);
            drop_failed = true;
        }
        _sapp_free(buffer);
    }
    DragFinish(hdrop);
    if (!drop_failed) {
        if (_sapp_events_enabled()) {
            _sapp_init_event(SAPP_EVENTTYPE_FILES_DROPPED);
            _sapp.event.modifiers = _sapp_win32_mods();
            _sapp_call_event(&_sapp.event);
        }
    }
    else {
        _sapp_clear_drop_buffer();
        _sapp.drop.num_files = 0;
    }
}

_SOKOL_PRIVATE void _sapp_win32_timing_measure(void) {
    #if defined(SOKOL_D3D11)
        // on D3D11, use the more precise DXGI timestamp
        if (_sapp.d3d11.use_dxgi_frame_stats) {
            DXGI_FRAME_STATISTICS dxgi_stats;
            _sapp_clear(&dxgi_stats, sizeof(dxgi_stats));
            HRESULT hr = _sapp_dxgi_GetFrameStatistics(_sapp.d3d11.swap_chain, &dxgi_stats);
            if (SUCCEEDED(hr)) {
                if (dxgi_stats.SyncRefreshCount != _sapp.d3d11.sync_refresh_count) {
                    if ((_sapp.d3d11.sync_refresh_count + 1) != dxgi_stats.SyncRefreshCount) {
                        _sapp_timing_discontinuity(&_sapp.timing);
                    }
                    _sapp.d3d11.sync_refresh_count = dxgi_stats.SyncRefreshCount;
                    LARGE_INTEGER qpc = dxgi_stats.SyncQPCTime;
                    const uint64_t now = (uint64_t)_sapp_int64_muldiv(qpc.QuadPart - _sapp.timing.timestamp.win.start.QuadPart, 1000000000, _sapp.timing.timestamp.win.freq.QuadPart);
                    _sapp_timing_external(&_sapp.timing, (double)now / 1000000000.0);
                }
                return;
            }
        }
        // fallback if swap model isn't "flip-discard" or GetFrameStatistics failed for another reason
        _sapp_timing_measure(&_sapp.timing);
    #endif
    #if defined(SOKOL_GLCORE)
        _sapp_timing_measure(&_sapp.timing);
    #endif
    #if defined(SOKOL_NOAPI)
        _sapp_timing_measure(&_sapp.timing);
    #endif
}

_SOKOL_PRIVATE LRESULT CALLBACK _sapp_win32_wndproc(HWND hWnd, UINT uMsg, WPARAM wParam, LPARAM lParam) {
    if (!_sapp.win32.in_create_window) {
        switch (uMsg) {
            case WM_CLOSE:
                /* only give user a chance to intervene when sapp_quit() wasn't already called */
                if (!_sapp.quit_ordered) {
                    /* if window should be closed and event handling is enabled, give user code
                        a change to intervene via sapp_cancel_quit()
                    */
                    _sapp.quit_requested = true;
                    _sapp_win32_app_event(SAPP_EVENTTYPE_QUIT_REQUESTED);
                    /* if user code hasn't intervened, quit the app */
                    if (_sapp.quit_requested) {
                        _sapp.quit_ordered = true;
                    }
                }
                if (_sapp.quit_ordered) {
                    PostQuitMessage(0);
                }
                return 0;
            case WM_SYSCOMMAND:
                switch (wParam & 0xFFF0) {
                    case SC_SCREENSAVE:
                    case SC_MONITORPOWER:
                        if (_sapp.fullscreen) {
                            /* disable screen saver and blanking in fullscreen mode */
                            return 0;
                        }
                        break;
                    case SC_KEYMENU:
                        /* user trying to access menu via ALT */
                        return 0;
                }
                break;
            case WM_ERASEBKGND:
                return 1;
            case WM_SIZE:
                {
                    const bool iconified = wParam == SIZE_MINIMIZED;
                    if (iconified != _sapp.win32.iconified) {
                        _sapp.win32.iconified = iconified;
                        if (iconified) {
                            _sapp_win32_app_event(SAPP_EVENTTYPE_ICONIFIED);
                        }
                        else {
                            _sapp_win32_app_event(SAPP_EVENTTYPE_RESTORED);
                        }
                    }
                }
                break;
            case WM_SETFOCUS:
                _sapp_win32_app_event(SAPP_EVENTTYPE_FOCUSED);
                break;
            case WM_KILLFOCUS:
                _sapp_win32_app_event(SAPP_EVENTTYPE_UNFOCUSED);
                break;
            case WM_SETCURSOR:
                if (LOWORD(lParam) == HTCLIENT) {
                    _sapp_win32_update_cursor(_sapp.mouse.current_cursor, _sapp.mouse.shown, true);
                    return TRUE;
                }
                break;
            case WM_DPICHANGED:
            {
                /* Update window's DPI and size if its moved to another monitor with a different DPI
                   Only sent if DPI_AWARENESS_CONTEXT_PER_MONITOR_AWARE_V2 is used.
                */
                _sapp_win32_dpi_changed(hWnd, (LPRECT)lParam);
                break;
            }
            case WM_LBUTTONDOWN:
                _sapp_win32_mouse_update(lParam);
                _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, SAPP_MOUSEBUTTON_LEFT);
                _sapp_win32_capture_mouse(1<<SAPP_MOUSEBUTTON_LEFT);
                break;
            case WM_RBUTTONDOWN:
                _sapp_win32_mouse_update(lParam);
                _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, SAPP_MOUSEBUTTON_RIGHT);
                _sapp_win32_capture_mouse(1<<SAPP_MOUSEBUTTON_RIGHT);
                break;
            case WM_MBUTTONDOWN:
                _sapp_win32_mouse_update(lParam);
                _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, SAPP_MOUSEBUTTON_MIDDLE);
                _sapp_win32_capture_mouse(1<<SAPP_MOUSEBUTTON_MIDDLE);
                break;
            case WM_LBUTTONUP:
                _sapp_win32_mouse_update(lParam);
                _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, SAPP_MOUSEBUTTON_LEFT);
                _sapp_win32_release_mouse(1<<SAPP_MOUSEBUTTON_LEFT);
                break;
            case WM_RBUTTONUP:
                _sapp_win32_mouse_update(lParam);
                _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, SAPP_MOUSEBUTTON_RIGHT);
                _sapp_win32_release_mouse(1<<SAPP_MOUSEBUTTON_RIGHT);
                break;
            case WM_MBUTTONUP:
                _sapp_win32_mouse_update(lParam);
                _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, SAPP_MOUSEBUTTON_MIDDLE);
                _sapp_win32_release_mouse(1<<SAPP_MOUSEBUTTON_MIDDLE);
                break;
            case WM_MOUSEMOVE:
                if (!_sapp.mouse.locked) {
                    _sapp_win32_mouse_update(lParam);
                    if (!_sapp.win32.mouse.tracked) {
                        _sapp.win32.mouse.tracked = true;
                        TRACKMOUSEEVENT tme;
                        _sapp_clear(&tme, sizeof(tme));
                        tme.cbSize = sizeof(tme);
                        tme.dwFlags = TME_LEAVE;
                        tme.hwndTrack = _sapp.win32.hwnd;
                        TrackMouseEvent(&tme);
                        _sapp.mouse.dx = 0.0f;
                        _sapp.mouse.dy = 0.0f;
                        _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_ENTER, SAPP_MOUSEBUTTON_INVALID);
                    }
                    _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID);
                }
                break;
            case WM_INPUT:
                /* raw mouse input during mouse-lock */
                if (_sapp.mouse.locked) {
                    HRAWINPUT ri = (HRAWINPUT) lParam;
                    // see: https://docs.microsoft.com/en-us/windows/win32/api/winuser/nf-winuser-getrawinputdata
                    // also see: https://github.com/glfw/glfw/blob/e7ea71be039836da3a98cea55ae5569cb5eb885c/src/win32_window.c#L912-L924

                    // first poll for required size to alloc/grow input buffer, then get the actual data
                    UINT size = 0;
                    GetRawInputData(ri, RID_INPUT, NULL, &size, sizeof(RAWINPUTHEADER));
                    void* raw_input_data_ptr = _sapp_win32_ensure_raw_input_data(size);
                    if ((UINT)-1 == GetRawInputData(ri, RID_INPUT, raw_input_data_ptr, &size, sizeof(RAWINPUTHEADER))) {
                        _SAPP_ERROR(WIN32_GET_RAW_INPUT_DATA_FAILED);
                        break;
                    }
                    const RAWINPUT* raw_mouse_data = (const RAWINPUT*) raw_input_data_ptr;
                    if (raw_mouse_data->data.mouse.usFlags & MOUSE_MOVE_ABSOLUTE) {
                        /* mouse only reports absolute position
                           NOTE: This code is untested and will most likely behave wrong in Remote Desktop sessions.
                           (such remote desktop sessions are setting the MOUSE_MOVE_ABSOLUTE flag).
                           See: https://github.com/floooh/sokol/issues/806 and
                           https://github.com/microsoft/DirectXTK/commit/ef56b63f3739381e451f7a5a5bd2c9779d2a7555)
                        */
                        LONG new_x = raw_mouse_data->data.mouse.lLastX;
                        LONG new_y = raw_mouse_data->data.mouse.lLastY;
                        if (_sapp.win32.mouse.raw_input.pos_valid) {
                            _sapp.mouse.dx = (float) (new_x - _sapp.win32.mouse.raw_input.pos_x);
                            _sapp.mouse.dy = (float) (new_y - _sapp.win32.mouse.raw_input.pos_y);
                        }
                        _sapp.win32.mouse.raw_input.pos_x = new_x;
                        _sapp.win32.mouse.raw_input.pos_y = new_y;
                        _sapp.win32.mouse.raw_input.pos_valid = true;
                    }
                    else {
                        /* mouse reports movement delta (this seems to be the common case) */
                        _sapp.mouse.dx = (float) raw_mouse_data->data.mouse.lLastX;
                        _sapp.mouse.dy = (float) raw_mouse_data->data.mouse.lLastY;
                    }
                    _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID);
                }
                break;

            case WM_MOUSELEAVE:
                if (!_sapp.mouse.locked) {
                    _sapp.mouse.dx = 0.0f;
                    _sapp.mouse.dy = 0.0f;
                    _sapp.win32.mouse.tracked = false;
                    _sapp_win32_mouse_event(SAPP_EVENTTYPE_MOUSE_LEAVE, SAPP_MOUSEBUTTON_INVALID);
                }
                break;
            case WM_MOUSEWHEEL:
                _sapp_win32_scroll_event(0.0f, (float)((SHORT)HIWORD(wParam)));
                break;
            case WM_MOUSEHWHEEL:
                _sapp_win32_scroll_event((float)((SHORT)HIWORD(wParam)), 0.0f);
                break;
            case WM_CHAR:
                _sapp_win32_char_event((uint32_t)wParam, !!(lParam&0x40000000));
                break;
            case WM_KEYDOWN:
            case WM_SYSKEYDOWN:
                _sapp_win32_key_event(SAPP_EVENTTYPE_KEY_DOWN, (int)(HIWORD(lParam)&0x1FF), !!(lParam&0x40000000));
                break;
            case WM_KEYUP:
            case WM_SYSKEYUP:
                _sapp_win32_key_event(SAPP_EVENTTYPE_KEY_UP, (int)(HIWORD(lParam)&0x1FF), false);
                break;
            case WM_ENTERSIZEMOVE:
                SetTimer(_sapp.win32.hwnd, 1, USER_TIMER_MINIMUM, NULL);
                break;
            case WM_EXITSIZEMOVE:
                KillTimer(_sapp.win32.hwnd, 1);
                break;
            case WM_TIMER:
                _sapp_win32_timing_measure();
                _sapp_frame();
                #if defined(SOKOL_D3D11)
                    // present with DXGI_PRESENT_DO_NOT_WAIT
                    _sapp_d3d11_present(true);
                #endif
                #if defined(SOKOL_GLCORE)
                    _sapp_wgl_swap_buffers();
                #endif
                /* NOTE: resizing the swap-chain during resize leads to a substantial
                   memory spike (hundreds of megabytes for a few seconds).

                if (_sapp_win32_update_dimensions()) {
                    #if defined(SOKOL_D3D11)
                    _sapp_d3d11_resize_default_render_target();
                    #endif
                    _sapp_win32_app_event(SAPP_EVENTTYPE_RESIZED);
                }
                */
                break;
            case WM_NCLBUTTONDOWN:
                /* workaround for half-second pause when starting to move window
                    see: https://gamedev.net/forums/topic/672094-keeping-things-moving-during-win32-moveresize-events/5254386/
                */
                if (SendMessage(_sapp.win32.hwnd, WM_NCHITTEST, wParam, lParam) == HTCAPTION) {
                    POINT point = { 0, 0 };
                    if (GetCursorPos(&point)) {
                        ScreenToClient(_sapp.win32.hwnd, &point);
                        PostMessage(_sapp.win32.hwnd, WM_MOUSEMOVE, 0, ((uint32_t)point.x)|(((uint32_t)point.y) << 16));
                    }
                }
                break;
            case WM_DROPFILES:
                _sapp_win32_files_dropped((HDROP)wParam);
                break;
            case WM_DISPLAYCHANGE:
                // refresh rate might have changed
                _sapp_timing_reset(&_sapp.timing);
                break;

            default:
                break;
        }
    }
    return DefWindowProcW(hWnd, uMsg, wParam, lParam);
}

_SOKOL_PRIVATE void _sapp_win32_create_window(void) {
    WNDCLASSW wndclassw;
    _sapp_clear(&wndclassw, sizeof(wndclassw));
    wndclassw.style = CS_HREDRAW | CS_VREDRAW | CS_OWNDC;
    wndclassw.lpfnWndProc = (WNDPROC) _sapp_win32_wndproc;
    wndclassw.hInstance = GetModuleHandleW(NULL);
    wndclassw.hCursor = LoadCursor(NULL, IDC_ARROW);
    wndclassw.hIcon = LoadIcon(NULL, IDI_WINLOGO);
    wndclassw.lpszClassName = L"SOKOLAPP";
    RegisterClassW(&wndclassw);

    /* NOTE: regardless whether fullscreen is requested or not, a regular
       windowed-mode window will always be created first (however in hidden
       mode, so that no windowed-mode window pops up before the fullscreen window)
    */
    const DWORD win_ex_style = WS_EX_APPWINDOW | WS_EX_WINDOWEDGE;
    RECT rect = { 0, 0, 0, 0 };
    DWORD win_style = WS_CLIPSIBLINGS | WS_CLIPCHILDREN | WS_CAPTION | WS_SYSMENU | WS_MINIMIZEBOX | WS_MAXIMIZEBOX | WS_SIZEBOX;
    rect.right = (int) ((float)_sapp.window_width * _sapp.win32.dpi.window_scale);
    rect.bottom = (int) ((float)_sapp.window_height * _sapp.win32.dpi.window_scale);
    const bool use_default_width = 0 == _sapp.window_width;
    const bool use_default_height = 0 == _sapp.window_height;
    AdjustWindowRectEx(&rect, win_style, FALSE, win_ex_style);
    const int win_width = rect.right - rect.left;
    const int win_height = rect.bottom - rect.top;
    _sapp.win32.in_create_window = true;
    _sapp.win32.hwnd = CreateWindowExW(
        win_ex_style,               // dwExStyle
        L"SOKOLAPP",                // lpClassName
        _sapp.window_title_wide,    // lpWindowName
        win_style,                  // dwStyle
        CW_USEDEFAULT,              // X
        SW_HIDE,                    // Y (NOTE: CW_USEDEFAULT is not used for position here, but internally calls ShowWindow!
        use_default_width ? CW_USEDEFAULT : win_width, // nWidth
        use_default_height ? CW_USEDEFAULT : win_height, // nHeight (NOTE: if width is CW_USEDEFAULT, height is actually ignored)
        NULL,                       // hWndParent
        NULL,                       // hMenu
        GetModuleHandle(NULL),      // hInstance
        NULL);                      // lParam
    _sapp.win32.in_create_window = false;
    _sapp.win32.dc = GetDC(_sapp.win32.hwnd);
    _sapp.win32.hmonitor = MonitorFromWindow(_sapp.win32.hwnd, MONITOR_DEFAULTTONULL);
    SOKOL_ASSERT(_sapp.win32.dc);

    /* this will get the actual windowed-mode window size, if fullscreen
       is requested, the set_fullscreen function will then capture the
       current window rectangle, which then might be used later to
       restore the window position when switching back to windowed
    */
    _sapp_win32_update_dimensions();
    if (_sapp.fullscreen) {
        _sapp_win32_set_fullscreen(_sapp.fullscreen, SWP_HIDEWINDOW);
        _sapp_win32_update_dimensions();
    }
    ShowWindow(_sapp.win32.hwnd, SW_SHOW);
    DragAcceptFiles(_sapp.win32.hwnd, 1);
}

_SOKOL_PRIVATE void _sapp_win32_destroy_window(void) {
    DestroyWindow(_sapp.win32.hwnd); _sapp.win32.hwnd = 0;
    UnregisterClassW(L"SOKOLAPP", GetModuleHandleW(NULL));
}

_SOKOL_PRIVATE void _sapp_win32_destroy_icons(void) {
    if (_sapp.win32.big_icon) {
        DestroyIcon(_sapp.win32.big_icon);
        _sapp.win32.big_icon = 0;
    }
    if (_sapp.win32.small_icon) {
        DestroyIcon(_sapp.win32.small_icon);
        _sapp.win32.small_icon = 0;
    }
}

_SOKOL_PRIVATE void _sapp_win32_init_console(void) {
    if (_sapp.desc.win32_console_create || _sapp.desc.win32_console_attach) {
        BOOL con_valid = FALSE;
        if (_sapp.desc.win32_console_create) {
            con_valid = AllocConsole();
        }
        else if (_sapp.desc.win32_console_attach) {
            con_valid = AttachConsole(ATTACH_PARENT_PROCESS);
        }
        if (con_valid) {
            FILE* res_fp = 0;
            errno_t err;
            err = freopen_s(&res_fp, "CON", "w", stdout);
            (void)err;
            err = freopen_s(&res_fp, "CON", "w", stderr);
            (void)err;
        }
    }
    if (_sapp.desc.win32_console_utf8) {
        _sapp.win32.orig_codepage = GetConsoleOutputCP();
        SetConsoleOutputCP(CP_UTF8);
    }
}

_SOKOL_PRIVATE void _sapp_win32_restore_console(void) {
    if (_sapp.desc.win32_console_utf8) {
        SetConsoleOutputCP(_sapp.win32.orig_codepage);
    }
}

_SOKOL_PRIVATE void _sapp_win32_init_dpi(void) {

    DECLARE_HANDLE(DPI_AWARENESS_CONTEXT_T);
    typedef BOOL(WINAPI * SETPROCESSDPIAWARE_T)(void);
    typedef bool (WINAPI * SETPROCESSDPIAWARENESSCONTEXT_T)(DPI_AWARENESS_CONTEXT_T); // since Windows 10, version 1703
    typedef HRESULT(WINAPI * SETPROCESSDPIAWARENESS_T)(PROCESS_DPI_AWARENESS);
    typedef HRESULT(WINAPI * GETDPIFORMONITOR_T)(HMONITOR, MONITOR_DPI_TYPE, UINT*, UINT*);

    SETPROCESSDPIAWARE_T fn_setprocessdpiaware = 0;
    SETPROCESSDPIAWARENESS_T fn_setprocessdpiawareness = 0;
    GETDPIFORMONITOR_T fn_getdpiformonitor = 0;
    SETPROCESSDPIAWARENESSCONTEXT_T fn_setprocessdpiawarenesscontext =0;

    HINSTANCE user32 = LoadLibraryA("user32.dll");
    if (user32) {
        fn_setprocessdpiaware = (SETPROCESSDPIAWARE_T)(void*) GetProcAddress(user32, "SetProcessDPIAware");
        fn_setprocessdpiawarenesscontext = (SETPROCESSDPIAWARENESSCONTEXT_T)(void*) GetProcAddress(user32, "SetProcessDpiAwarenessContext");
    }
    HINSTANCE shcore = LoadLibraryA("shcore.dll");
    if (shcore) {
        fn_setprocessdpiawareness = (SETPROCESSDPIAWARENESS_T)(void*) GetProcAddress(shcore, "SetProcessDpiAwareness");
        fn_getdpiformonitor = (GETDPIFORMONITOR_T)(void*) GetProcAddress(shcore, "GetDpiForMonitor");
    }
    /*
        NOTE on SetProcessDpiAware() vs SetProcessDpiAwareness() vs SetProcessDpiAwarenessContext():

        These are different attempts to get DPI handling on Windows right, from oldest
        to newest. SetProcessDpiAwarenessContext() is required for the new
        DPI_AWARENESS_CONTEXT_PER_MONITOR_AWARE_V2 method.
    */
    if (fn_setprocessdpiawareness) {
        if (_sapp.desc.high_dpi) {
            /* app requests HighDPI rendering, first try the Win10 Creator Update per-monitor-dpi awareness,
               if that fails, fall back to system-dpi-awareness
            */
            _sapp.win32.dpi.aware = true;
            DPI_AWARENESS_CONTEXT_T per_monitor_aware_v2 = (DPI_AWARENESS_CONTEXT_T)-4;
            if (!(fn_setprocessdpiawarenesscontext && fn_setprocessdpiawarenesscontext(per_monitor_aware_v2))) {
                // fallback to system-dpi-aware
                fn_setprocessdpiawareness(PROCESS_SYSTEM_DPI_AWARE);
            }
        }
        else {
            /* if the app didn't request HighDPI rendering, let Windows do the upscaling */
            _sapp.win32.dpi.aware = false;
            fn_setprocessdpiawareness(PROCESS_DPI_UNAWARE);
        }
    }
    else if (fn_setprocessdpiaware) {
        // fallback for Windows 7
        _sapp.win32.dpi.aware = true;
        fn_setprocessdpiaware();
    }
    /* get dpi scale factor for main monitor */
    if (fn_getdpiformonitor && _sapp.win32.dpi.aware) {
        POINT pt = { 1, 1 };
        HMONITOR hm = MonitorFromPoint(pt, MONITOR_DEFAULTTONEAREST);
        UINT dpix, dpiy;
        HRESULT hr = fn_getdpiformonitor(hm, MDT_EFFECTIVE_DPI, &dpix, &dpiy);
        _SOKOL_UNUSED(hr);
        SOKOL_ASSERT(SUCCEEDED(hr));
        /* clamp window scale to an integer factor */
        _sapp.win32.dpi.window_scale = (float)dpix / 96.0f;
    }
    else {
        _sapp.win32.dpi.window_scale = 1.0f;
    }
    if (_sapp.desc.high_dpi) {
        _sapp.win32.dpi.content_scale = _sapp.win32.dpi.window_scale;
        _sapp.win32.dpi.mouse_scale = 1.0f;
    }
    else {
        _sapp.win32.dpi.content_scale = 1.0f;
        _sapp.win32.dpi.mouse_scale = 1.0f / _sapp.win32.dpi.window_scale;
    }
    _sapp.dpi_scale = _sapp.win32.dpi.content_scale;
    if (user32) {
        FreeLibrary(user32);
    }
    if (shcore) {
        FreeLibrary(shcore);
    }
}

_SOKOL_PRIVATE bool _sapp_win32_set_clipboard_string(const char* str) {
    SOKOL_ASSERT(str);
    SOKOL_ASSERT(_sapp.win32.hwnd);
    SOKOL_ASSERT(_sapp.clipboard.enabled && (_sapp.clipboard.buf_size > 0));

    if (!OpenClipboard(_sapp.win32.hwnd)) {
        return false;
    }

    HANDLE object = 0;
    wchar_t* wchar_buf = 0;

    const SIZE_T wchar_buf_size = (SIZE_T)_sapp.clipboard.buf_size * sizeof(wchar_t);
    object = GlobalAlloc(GMEM_MOVEABLE, wchar_buf_size);
    if (NULL == object) {
        goto error;
    }
    wchar_buf = (wchar_t*) GlobalLock(object);
    if (NULL == wchar_buf) {
        goto error;
    }
    if (!_sapp_win32_utf8_to_wide(str, wchar_buf, (int)wchar_buf_size)) {
        goto error;
    }
    GlobalUnlock(object);
    wchar_buf = 0;
    EmptyClipboard();
    // NOTE: when successful, SetClipboardData() takes ownership of memory object!
    if (NULL == SetClipboardData(CF_UNICODETEXT, object)) {
        goto error;
    }
    CloseClipboard();
    return true;

error:
    if (wchar_buf) {
        GlobalUnlock(object);
    }
    if (object) {
        GlobalFree(object);
    }
    CloseClipboard();
    return false;
}

_SOKOL_PRIVATE const char* _sapp_win32_get_clipboard_string(void) {
    SOKOL_ASSERT(_sapp.clipboard.enabled && _sapp.clipboard.buffer);
    SOKOL_ASSERT(_sapp.win32.hwnd);
    if (!OpenClipboard(_sapp.win32.hwnd)) {
        /* silently ignore any errors and just return the current
           content of the local clipboard buffer
        */
        return _sapp.clipboard.buffer;
    }
    HANDLE object = GetClipboardData(CF_UNICODETEXT);
    if (!object) {
        CloseClipboard();
        return _sapp.clipboard.buffer;
    }
    const wchar_t* wchar_buf = (const wchar_t*) GlobalLock(object);
    if (!wchar_buf) {
        CloseClipboard();
        return _sapp.clipboard.buffer;
    }
    if (!_sapp_win32_wide_to_utf8(wchar_buf, _sapp.clipboard.buffer, _sapp.clipboard.buf_size)) {
        _SAPP_ERROR(CLIPBOARD_STRING_TOO_BIG);
    }
    GlobalUnlock(object);
    CloseClipboard();
    return _sapp.clipboard.buffer;
}

_SOKOL_PRIVATE void _sapp_win32_update_window_title(void) {
    _sapp_win32_utf8_to_wide(_sapp.window_title, _sapp.window_title_wide, sizeof(_sapp.window_title_wide));
    SetWindowTextW(_sapp.win32.hwnd, _sapp.window_title_wide);
}

_SOKOL_PRIVATE HICON _sapp_win32_create_icon_from_image(const sapp_image_desc* desc) {
    BITMAPV5HEADER bi;
    _sapp_clear(&bi, sizeof(bi));
    bi.bV5Size = sizeof(bi);
    bi.bV5Width = desc->width;
    bi.bV5Height = -desc->height;   // NOTE the '-' here to indicate that origin is top-left
    bi.bV5Planes = 1;
    bi.bV5BitCount = 32;
    bi.bV5Compression = BI_BITFIELDS;
    bi.bV5RedMask = 0x00FF0000;
    bi.bV5GreenMask = 0x0000FF00;
    bi.bV5BlueMask = 0x000000FF;
    bi.bV5AlphaMask = 0xFF000000;

    uint8_t* target = 0;
    const uint8_t* source = (const uint8_t*)desc->pixels.ptr;

    HDC dc = GetDC(NULL);
    HBITMAP color = CreateDIBSection(dc, (BITMAPINFO*)&bi, DIB_RGB_COLORS, (void**)&target, NULL, (DWORD)0);
    ReleaseDC(NULL, dc);
    if (0 == color) {
        return NULL;
    }
    SOKOL_ASSERT(target);

    HBITMAP mask = CreateBitmap(desc->width, desc->height, 1, 1, NULL);
    if (0 == mask) {
        DeleteObject(color);
        return NULL;
    }

    for (int i = 0; i < (desc->width*desc->height); i++) {
        target[0] = source[2];
        target[1] = source[1];
        target[2] = source[0];
        target[3] = source[3];
        target += 4;
        source += 4;
    }

    ICONINFO icon_info;
    _sapp_clear(&icon_info, sizeof(icon_info));
    icon_info.fIcon = true;
    icon_info.xHotspot = 0;
    icon_info.yHotspot = 0;
    icon_info.hbmMask = mask;
    icon_info.hbmColor = color;
    HICON icon_handle = CreateIconIndirect(&icon_info);
    DeleteObject(color);
    DeleteObject(mask);

    return icon_handle;
}

_SOKOL_PRIVATE void _sapp_win32_set_icon(const sapp_icon_desc* icon_desc, int num_images) {
    SOKOL_ASSERT((num_images > 0) && (num_images <= SAPP_MAX_ICONIMAGES));

    int big_img_index = _sapp_image_bestmatch(icon_desc->images, num_images, GetSystemMetrics(SM_CXICON), GetSystemMetrics(SM_CYICON));
    int sml_img_index = _sapp_image_bestmatch(icon_desc->images, num_images, GetSystemMetrics(SM_CXSMICON), GetSystemMetrics(SM_CYSMICON));
    HICON big_icon = _sapp_win32_create_icon_from_image(&icon_desc->images[big_img_index]);
    HICON sml_icon = _sapp_win32_create_icon_from_image(&icon_desc->images[sml_img_index]);

    // if icon creation or lookup has failed for some reason, leave the currently set icon untouched
    if (0 != big_icon) {
        SendMessage(_sapp.win32.hwnd, WM_SETICON, ICON_BIG, (LPARAM) big_icon);
        if (0 != _sapp.win32.big_icon) {
            DestroyIcon(_sapp.win32.big_icon);
        }
        _sapp.win32.big_icon = big_icon;
    }
    if (0 != sml_icon) {
        SendMessage(_sapp.win32.hwnd, WM_SETICON, ICON_SMALL, (LPARAM) sml_icon);
        if (0 != _sapp.win32.small_icon) {
            DestroyIcon(_sapp.win32.small_icon);
        }
        _sapp.win32.small_icon = sml_icon;
    }
}

/* don't laugh, but this seems to be the easiest and most robust
   way to check if we're running on Win10

   From: https://github.com/videolan/vlc/blob/232fb13b0d6110c4d1b683cde24cf9a7f2c5c2ea/modules/video_output/win32/d3d11_swapchain.c#L263
*/
_SOKOL_PRIVATE bool _sapp_win32_is_win10_or_greater(void) {
    HMODULE h = GetModuleHandleW(L"kernel32.dll");
    if (NULL != h) {
        return (NULL != GetProcAddress(h, "GetSystemCpuSetInformation"));
    }
    else {
        return false;
    }
}

_SOKOL_PRIVATE void _sapp_win32_run(const sapp_desc* desc) {
    _sapp_init_state(desc);
    _sapp_win32_init_console();
    _sapp.win32.is_win10_or_greater = _sapp_win32_is_win10_or_greater();
    _sapp_win32_init_keytable();
    _sapp_win32_utf8_to_wide(_sapp.window_title, _sapp.window_title_wide, sizeof(_sapp.window_title_wide));
    _sapp_win32_init_dpi();
    _sapp_win32_init_cursors();
    _sapp_win32_create_window();
    sapp_set_icon(&desc->icon);
    #if defined(SOKOL_D3D11)
        _sapp_d3d11_create_device_and_swapchain();
        _sapp_d3d11_create_default_render_target();
    #endif
    #if defined(SOKOL_GLCORE)
        _sapp_wgl_init();
        _sapp_wgl_load_extensions();
        _sapp_wgl_create_context();
    #endif
    _sapp.valid = true;

    bool done = false;
    while (!(done || _sapp.quit_ordered)) {
        _sapp_win32_timing_measure();
        MSG msg;
        while (PeekMessageW(&msg, NULL, 0, 0, PM_REMOVE)) {
            if (WM_QUIT == msg.message) {
                done = true;
                continue;
            }
            else {
                TranslateMessage(&msg);
                DispatchMessageW(&msg);
            }
        }
        _sapp_frame();
        #if defined(SOKOL_D3D11)
            _sapp_d3d11_present(false);
            if (IsIconic(_sapp.win32.hwnd)) {
                Sleep((DWORD)(16 * _sapp.swap_interval));
            }
        #endif
        #if defined(SOKOL_GLCORE)
            _sapp_wgl_swap_buffers();
        #endif
        /* check for window resized, this cannot happen in WM_SIZE as it explodes memory usage */
        if (_sapp_win32_update_dimensions()) {
            #if defined(SOKOL_D3D11)
            _sapp_d3d11_resize_default_render_target();
            #endif
            _sapp_win32_app_event(SAPP_EVENTTYPE_RESIZED);
        }
        /* check if the window monitor has changed, need to reset timing because
           the new monitor might have a different refresh rate
        */
        if (_sapp_win32_update_monitor()) {
            _sapp_timing_reset(&_sapp.timing);
        }
        if (_sapp.quit_requested) {
            PostMessage(_sapp.win32.hwnd, WM_CLOSE, 0, 0);
        }
        // update mouse-lock state
        _sapp_win32_update_mouse_lock();
    }
    _sapp_call_cleanup();

    #if defined(SOKOL_D3D11)
        _sapp_d3d11_destroy_default_render_target();
        _sapp_d3d11_destroy_device_and_swapchain();
    #elif defined(SOKOL_GLCORE)
        _sapp_wgl_destroy_context();
        _sapp_wgl_shutdown();
    #endif
    _sapp_win32_destroy_window();
    _sapp_win32_destroy_icons();
    _sapp_win32_restore_console();
    _sapp_win32_free_raw_input_data();
    _sapp_discard_state();
}

_SOKOL_PRIVATE char** _sapp_win32_command_line_to_utf8_argv(LPWSTR w_command_line, int* o_argc) {
    int argc = 0;
    char** argv = 0;
    char* args;

    LPWSTR* w_argv = CommandLineToArgvW(w_command_line, &argc);
    if (w_argv == NULL) {
        // FIXME: chicken egg problem, can't report errors before sokol_main() is called!
    } else {
        size_t size = wcslen(w_command_line) * 4;
        argv = (char**) _sapp_malloc_clear(((size_t)argc + 1) * sizeof(char*) + size);
        SOKOL_ASSERT(argv);
        args = (char*) &argv[argc + 1];
        int n;
        for (int i = 0; i < argc; ++i) {
            n = WideCharToMultiByte(CP_UTF8, 0, w_argv[i], -1, args, (int)size, NULL, NULL);
            if (n == 0) {
                // FIXME: chicken egg problem, can't report errors before sokol_main() is called!
                break;
            }
            argv[i] = args;
            size -= (size_t)n;
            args += n;
        }
        LocalFree(w_argv);
    }
    *o_argc = argc;
    return argv;
}

#if !defined(SOKOL_NO_ENTRY)
#if defined(SOKOL_WIN32_FORCE_MAIN)
int main(int argc, char* argv[]) {
    sapp_desc desc = sokol_main(argc, argv);
    _sapp_win32_run(&desc);
    return 0;
}
#endif /* SOKOL_WIN32_FORCE_MAIN */
#if defined(SOKOL_WIN32_FORCE_WINMAIN) || !defined(SOKOL_WIN32_FORCE_MAIN)
int WINAPI WinMain(_In_ HINSTANCE hInstance, _In_opt_ HINSTANCE hPrevInstance, _In_ LPSTR lpCmdLine, _In_ int nCmdShow) {
    _SOKOL_UNUSED(hInstance);
    _SOKOL_UNUSED(hPrevInstance);
    _SOKOL_UNUSED(lpCmdLine);
    _SOKOL_UNUSED(nCmdShow);
    int argc_utf8 = 0;
    char** argv_utf8 = _sapp_win32_command_line_to_utf8_argv(GetCommandLineW(), &argc_utf8);
    sapp_desc desc = sokol_main(argc_utf8, argv_utf8);
    _sapp_win32_run(&desc);
    _sapp_free(argv_utf8);
    return 0;
}
#endif /* SOKOL_WIN32_FORCE_WINMAIN */
#endif /* SOKOL_NO_ENTRY */

#ifdef _MSC_VER
    #pragma warning(pop)
#endif

#endif /* _SAPP_WIN32 */

//  █████  ███    ██ ██████  ██████   ██████  ██ ██████
// ██   ██ ████   ██ ██   ██ ██   ██ ██    ██ ██ ██   ██
// ███████ ██ ██  ██ ██   ██ ██████  ██    ██ ██ ██   ██
// ██   ██ ██  ██ ██ ██   ██ ██   ██ ██    ██ ██ ██   ██
// ██   ██ ██   ████ ██████  ██   ██  ██████  ██ ██████
//
// >>android
#if defined(_SAPP_ANDROID)

/* android loop thread */
_SOKOL_PRIVATE bool _sapp_android_init_egl(void) {
    SOKOL_ASSERT(_sapp.android.display == EGL_NO_DISPLAY);
    SOKOL_ASSERT(_sapp.android.context == EGL_NO_CONTEXT);

    EGLDisplay display = eglGetDisplay(EGL_DEFAULT_DISPLAY);
    if (display == EGL_NO_DISPLAY) {
        return false;
    }
    if (eglInitialize(display, NULL, NULL) == EGL_FALSE) {
        return false;
    }
    EGLint alpha_size = _sapp.desc.alpha ? 8 : 0;
    const EGLint cfg_attributes[] = {
        EGL_SURFACE_TYPE, EGL_WINDOW_BIT,
        EGL_RENDERABLE_TYPE, EGL_OPENGL_ES3_BIT,
        EGL_RED_SIZE, 8,
        EGL_GREEN_SIZE, 8,
        EGL_BLUE_SIZE, 8,
        EGL_ALPHA_SIZE, alpha_size,
        EGL_DEPTH_SIZE, 16,
        EGL_STENCIL_SIZE, 0,
        EGL_NONE,
    };
    EGLConfig available_cfgs[32];
    EGLint cfg_count;
    eglChooseConfig(display, cfg_attributes, available_cfgs, 32, &cfg_count);
    SOKOL_ASSERT(cfg_count > 0);
    SOKOL_ASSERT(cfg_count <= 32);

    /* find config with 8-bit rgb buffer if available, ndk sample does not trust egl spec */
    EGLConfig config;
    bool exact_cfg_found = false;
    for (int i = 0; i < cfg_count; ++i) {
        EGLConfig c = available_cfgs[i];
        EGLint r, g, b, a, d;
        if (eglGetConfigAttrib(display, c, EGL_RED_SIZE, &r) == EGL_TRUE &&
            eglGetConfigAttrib(display, c, EGL_GREEN_SIZE, &g) == EGL_TRUE &&
            eglGetConfigAttrib(display, c, EGL_BLUE_SIZE, &b) == EGL_TRUE &&
            eglGetConfigAttrib(display, c, EGL_ALPHA_SIZE, &a) == EGL_TRUE &&
            eglGetConfigAttrib(display, c, EGL_DEPTH_SIZE, &d) == EGL_TRUE &&
            r == 8 && g == 8 && b == 8 && (alpha_size == 0 || a == alpha_size) && d == 16) {
            exact_cfg_found = true;
            config = c;
            break;
        }
    }
    if (!exact_cfg_found) {
        config = available_cfgs[0];
    }

    EGLint ctx_attributes[] = {
        EGL_CONTEXT_MAJOR_VERSION, _sapp.desc.gl_major_version,
        EGL_CONTEXT_MINOR_VERSION, _sapp.desc.gl_minor_version,
        EGL_NONE,
    };
    EGLContext context = eglCreateContext(display, config, EGL_NO_CONTEXT, ctx_attributes);
    if (context == EGL_NO_CONTEXT) {
        return false;
    }

    _sapp.android.config = config;
    _sapp.android.display = display;
    _sapp.android.context = context;
    return true;
}

_SOKOL_PRIVATE void _sapp_android_cleanup_egl(void) {
    if (_sapp.android.display != EGL_NO_DISPLAY) {
        eglMakeCurrent(_sapp.android.display, EGL_NO_SURFACE, EGL_NO_SURFACE, EGL_NO_CONTEXT);
        if (_sapp.android.surface != EGL_NO_SURFACE) {
            eglDestroySurface(_sapp.android.display, _sapp.android.surface);
            _sapp.android.surface = EGL_NO_SURFACE;
        }
        if (_sapp.android.context != EGL_NO_CONTEXT) {
            eglDestroyContext(_sapp.android.display, _sapp.android.context);
            _sapp.android.context = EGL_NO_CONTEXT;
        }
        eglTerminate(_sapp.android.display);
        _sapp.android.display = EGL_NO_DISPLAY;
    }
}

_SOKOL_PRIVATE bool _sapp_android_init_egl_surface(ANativeWindow* window) {
    SOKOL_ASSERT(_sapp.android.display != EGL_NO_DISPLAY);
    SOKOL_ASSERT(_sapp.android.context != EGL_NO_CONTEXT);
    SOKOL_ASSERT(_sapp.android.surface == EGL_NO_SURFACE);
    SOKOL_ASSERT(window);

    /* TODO: set window flags */
    /* ANativeActivity_setWindowFlags(activity, AWINDOW_FLAG_KEEP_SCREEN_ON, 0); */

    /* create egl surface and make it current */
    EGLSurface surface = eglCreateWindowSurface(_sapp.android.display, _sapp.android.config, window, NULL);
    if (surface == EGL_NO_SURFACE) {
        return false;
    }
    if (eglMakeCurrent(_sapp.android.display, surface, surface, _sapp.android.context) == EGL_FALSE) {
        return false;
    }
    _sapp.android.surface = surface;
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&_sapp.gl.framebuffer);
    return true;
}

_SOKOL_PRIVATE void _sapp_android_cleanup_egl_surface(void) {
    if (_sapp.android.display == EGL_NO_DISPLAY) {
        return;
    }
    eglMakeCurrent(_sapp.android.display, EGL_NO_SURFACE, EGL_NO_SURFACE, EGL_NO_CONTEXT);
    if (_sapp.android.surface != EGL_NO_SURFACE) {
        eglDestroySurface(_sapp.android.display, _sapp.android.surface);
        _sapp.android.surface = EGL_NO_SURFACE;
    }
}

_SOKOL_PRIVATE void _sapp_android_app_event(sapp_event_type type) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_android_update_dimensions(ANativeWindow* window, bool force_update) {
    SOKOL_ASSERT(_sapp.android.display != EGL_NO_DISPLAY);
    SOKOL_ASSERT(_sapp.android.context != EGL_NO_CONTEXT);
    SOKOL_ASSERT(_sapp.android.surface != EGL_NO_SURFACE);
    SOKOL_ASSERT(window);

    const int32_t win_w = ANativeWindow_getWidth(window);
    const int32_t win_h = ANativeWindow_getHeight(window);
    SOKOL_ASSERT(win_w >= 0 && win_h >= 0);
    const bool win_changed = (win_w != _sapp.window_width) || (win_h != _sapp.window_height);
    _sapp.window_width = win_w;
    _sapp.window_height = win_h;
    if (win_changed || force_update) {
        if (!_sapp.desc.high_dpi) {
            const int32_t buf_w = win_w / 2;
            const int32_t buf_h = win_h / 2;
            EGLint format;
            EGLBoolean egl_result = eglGetConfigAttrib(_sapp.android.display, _sapp.android.config, EGL_NATIVE_VISUAL_ID, &format);
            SOKOL_ASSERT(egl_result == EGL_TRUE); _SOKOL_UNUSED(egl_result);
            /* NOTE: calling ANativeWindow_setBuffersGeometry() with the same dimensions
                as the ANativeWindow size results in weird display artefacts, that's
                why it's only called when the buffer geometry is different from
                the window size
            */
            int32_t result = ANativeWindow_setBuffersGeometry(window, buf_w, buf_h, format);
            SOKOL_ASSERT(result == 0); _SOKOL_UNUSED(result);
        }
    }

    /* query surface size */
    EGLint fb_w, fb_h;
    EGLBoolean egl_result_w = eglQuerySurface(_sapp.android.display, _sapp.android.surface, EGL_WIDTH, &fb_w);
    EGLBoolean egl_result_h = eglQuerySurface(_sapp.android.display, _sapp.android.surface, EGL_HEIGHT, &fb_h);
    SOKOL_ASSERT(egl_result_w == EGL_TRUE); _SOKOL_UNUSED(egl_result_w);
    SOKOL_ASSERT(egl_result_h == EGL_TRUE); _SOKOL_UNUSED(egl_result_h);
    const bool fb_changed = (fb_w != _sapp.framebuffer_width) || (fb_h != _sapp.framebuffer_height);
    _sapp.framebuffer_width = fb_w;
    _sapp.framebuffer_height = fb_h;
    _sapp.dpi_scale = (float)_sapp.framebuffer_width / (float)_sapp.window_width;
    if (win_changed || fb_changed || force_update) {
        if (!_sapp.first_frame) {
            _sapp_android_app_event(SAPP_EVENTTYPE_RESIZED);
        }
    }
}

_SOKOL_PRIVATE void _sapp_android_cleanup(void) {
    if (_sapp.android.surface != EGL_NO_SURFACE) {
        /* egl context is bound, cleanup gracefully */
        if (_sapp.init_called && !_sapp.cleanup_called) {
            _sapp_call_cleanup();
        }
    }
    /* always try to cleanup by destroying egl context */
    _sapp_android_cleanup_egl();
}

_SOKOL_PRIVATE void _sapp_android_shutdown(void) {
    /* try to cleanup while we still have a surface and can call cleanup_cb() */
    _sapp_android_cleanup();
    /* request exit */
    ANativeActivity_finish(_sapp.android.activity);
}

_SOKOL_PRIVATE void _sapp_android_frame(void) {
    SOKOL_ASSERT(_sapp.android.display != EGL_NO_DISPLAY);
    SOKOL_ASSERT(_sapp.android.context != EGL_NO_CONTEXT);
    SOKOL_ASSERT(_sapp.android.surface != EGL_NO_SURFACE);
    _sapp_timing_measure(&_sapp.timing);
    _sapp_android_update_dimensions(_sapp.android.current.window, false);
    _sapp_frame();
    eglSwapBuffers(_sapp.android.display, _sapp.android.surface);
}

_SOKOL_PRIVATE bool _sapp_android_touch_event(const AInputEvent* e) {
    if (AInputEvent_getType(e) != AINPUT_EVENT_TYPE_MOTION) {
        return false;
    }
    if (!_sapp_events_enabled()) {
        return false;
    }
    int32_t action_idx = AMotionEvent_getAction(e);
    int32_t action = action_idx & AMOTION_EVENT_ACTION_MASK;
    sapp_event_type type = SAPP_EVENTTYPE_INVALID;
    switch (action) {
        case AMOTION_EVENT_ACTION_DOWN:
        case AMOTION_EVENT_ACTION_POINTER_DOWN:
            type = SAPP_EVENTTYPE_TOUCHES_BEGAN;
            break;
        case AMOTION_EVENT_ACTION_MOVE:
            type = SAPP_EVENTTYPE_TOUCHES_MOVED;
            break;
        case AMOTION_EVENT_ACTION_UP:
        case AMOTION_EVENT_ACTION_POINTER_UP:
            type = SAPP_EVENTTYPE_TOUCHES_ENDED;
            break;
        case AMOTION_EVENT_ACTION_CANCEL:
            type = SAPP_EVENTTYPE_TOUCHES_CANCELLED;
            break;
        default:
            break;
    }
    if (type == SAPP_EVENTTYPE_INVALID) {
        return false;
    }
    int32_t idx = action_idx >> AMOTION_EVENT_ACTION_POINTER_INDEX_SHIFT;
    _sapp_init_event(type);
    _sapp.event.num_touches = (int)AMotionEvent_getPointerCount(e);
    if (_sapp.event.num_touches > SAPP_MAX_TOUCHPOINTS) {
        _sapp.event.num_touches = SAPP_MAX_TOUCHPOINTS;
    }
    for (int32_t i = 0; i < _sapp.event.num_touches; i++) {
        sapp_touchpoint* dst = &_sapp.event.touches[i];
        dst->identifier = (uintptr_t)AMotionEvent_getPointerId(e, (size_t)i);
        dst->pos_x = (AMotionEvent_getX(e, (size_t)i) / _sapp.window_width) * _sapp.framebuffer_width;
        dst->pos_y = (AMotionEvent_getY(e, (size_t)i) / _sapp.window_height) * _sapp.framebuffer_height;
        dst->android_tooltype = (sapp_android_tooltype) AMotionEvent_getToolType(e, (size_t)i);
        if (action == AMOTION_EVENT_ACTION_POINTER_DOWN ||
            action == AMOTION_EVENT_ACTION_POINTER_UP) {
            dst->changed = (i == idx);
        } else {
            dst->changed = true;
        }
    }
    _sapp_call_event(&_sapp.event);
    return true;
}

_SOKOL_PRIVATE bool _sapp_android_key_event(const AInputEvent* e) {
    if (AInputEvent_getType(e) != AINPUT_EVENT_TYPE_KEY) {
        return false;
    }
    if (AKeyEvent_getKeyCode(e) == AKEYCODE_BACK) {
        /* FIXME: this should be hooked into a "really quit?" mechanism
           so the app can ask the user for confirmation, this is currently
           generally missing in sokol_app.h
        */
        _sapp_android_shutdown();
        return true;
    }
    return false;
}

_SOKOL_PRIVATE int _sapp_android_input_cb(int fd, int events, void* data) {
    _SOKOL_UNUSED(fd);
    _SOKOL_UNUSED(data);
    if ((events & ALOOPER_EVENT_INPUT) == 0) {
        _SAPP_ERROR(ANDROID_UNSUPPORTED_INPUT_EVENT_INPUT_CB);
        return 1;
    }
    SOKOL_ASSERT(_sapp.android.current.input);
    AInputEvent* event = NULL;
    while (AInputQueue_getEvent(_sapp.android.current.input, &event) >= 0) {
        if (AInputQueue_preDispatchEvent(_sapp.android.current.input, event) != 0) {
            continue;
        }
        int32_t handled = 0;
        if (_sapp_android_touch_event(event) || _sapp_android_key_event(event)) {
            handled = 1;
        }
        AInputQueue_finishEvent(_sapp.android.current.input, event, handled);
    }
    return 1;
}

_SOKOL_PRIVATE int _sapp_android_main_cb(int fd, int events, void* data) {
    _SOKOL_UNUSED(data);
    if ((events & ALOOPER_EVENT_INPUT) == 0) {
        _SAPP_ERROR(ANDROID_UNSUPPORTED_INPUT_EVENT_MAIN_CB);
        return 1;
    }

    _sapp_android_msg_t msg;
    if (read(fd, &msg, sizeof(msg)) != sizeof(msg)) {
        _SAPP_ERROR(ANDROID_READ_MSG_FAILED);
        return 1;
    }

    pthread_mutex_lock(&_sapp.android.pt.mutex);
    switch (msg) {
        case _SOKOL_ANDROID_MSG_CREATE:
            {
                _SAPP_INFO(ANDROID_MSG_CREATE);
                SOKOL_ASSERT(!_sapp.valid);
                bool result = _sapp_android_init_egl();
                SOKOL_ASSERT(result); _SOKOL_UNUSED(result);
                _sapp.valid = true;
                _sapp.android.has_created = true;
            }
            break;
        case _SOKOL_ANDROID_MSG_RESUME:
            _SAPP_INFO(ANDROID_MSG_RESUME);
            _sapp.android.has_resumed = true;
            _sapp_android_app_event(SAPP_EVENTTYPE_RESUMED);
            break;
        case _SOKOL_ANDROID_MSG_PAUSE:
            _SAPP_INFO(ANDROID_MSG_PAUSE);
            _sapp.android.has_resumed = false;
            _sapp_android_app_event(SAPP_EVENTTYPE_SUSPENDED);
            break;
        case _SOKOL_ANDROID_MSG_FOCUS:
            _SAPP_INFO(ANDROID_MSG_FOCUS);
            _sapp.android.has_focus = true;
            break;
        case _SOKOL_ANDROID_MSG_NO_FOCUS:
            _SAPP_INFO(ANDROID_MSG_NO_FOCUS);
            _sapp.android.has_focus = false;
            break;
        case _SOKOL_ANDROID_MSG_SET_NATIVE_WINDOW:
            _SAPP_INFO(ANDROID_MSG_SET_NATIVE_WINDOW);
            if (_sapp.android.current.window != _sapp.android.pending.window) {
                if (_sapp.android.current.window != NULL) {
                    _sapp_android_cleanup_egl_surface();
                }
                if (_sapp.android.pending.window != NULL) {
                    if (_sapp_android_init_egl_surface(_sapp.android.pending.window)) {
                        _sapp_android_update_dimensions(_sapp.android.pending.window, true);
                    } else {
                        _sapp_android_shutdown();
                    }
                }
            }
            _sapp.android.current.window = _sapp.android.pending.window;
            break;
        case _SOKOL_ANDROID_MSG_SET_INPUT_QUEUE:
            _SAPP_INFO(ANDROID_MSG_SET_INPUT_QUEUE);
            if (_sapp.android.current.input != _sapp.android.pending.input) {
                if (_sapp.android.current.input != NULL) {
                    AInputQueue_detachLooper(_sapp.android.current.input);
                }
                if (_sapp.android.pending.input != NULL) {
                    AInputQueue_attachLooper(
                        _sapp.android.pending.input,
                        _sapp.android.looper,
                        ALOOPER_POLL_CALLBACK,
                        _sapp_android_input_cb,
                        NULL); /* data */
                }
            }
            _sapp.android.current.input = _sapp.android.pending.input;
            break;
        case _SOKOL_ANDROID_MSG_DESTROY:
            _SAPP_INFO(ANDROID_MSG_DESTROY);
            _sapp_android_cleanup();
            _sapp.valid = false;
            _sapp.android.is_thread_stopping = true;
            break;
        default:
            _SAPP_WARN(ANDROID_UNKNOWN_MSG);
            break;
    }
    pthread_cond_broadcast(&_sapp.android.pt.cond); /* signal "received" */
    pthread_mutex_unlock(&_sapp.android.pt.mutex);
    return 1;
}

_SOKOL_PRIVATE bool _sapp_android_should_update(void) {
    bool is_in_front = _sapp.android.has_resumed && _sapp.android.has_focus;
    bool has_surface = _sapp.android.surface != EGL_NO_SURFACE;
    return is_in_front && has_surface;
}

_SOKOL_PRIVATE void _sapp_android_show_keyboard(bool shown) {
    SOKOL_ASSERT(_sapp.valid);
    /* This seems to be broken in the NDK, but there is (a very cumbersome) workaround... */
    if (shown) {
        ANativeActivity_showSoftInput(_sapp.android.activity, ANATIVEACTIVITY_SHOW_SOFT_INPUT_FORCED);
    } else {
        ANativeActivity_hideSoftInput(_sapp.android.activity, ANATIVEACTIVITY_HIDE_SOFT_INPUT_NOT_ALWAYS);
    }
}

_SOKOL_PRIVATE void* _sapp_android_loop(void* arg) {
    _SOKOL_UNUSED(arg);
    _SAPP_INFO(ANDROID_LOOP_THREAD_STARTED);

    _sapp.android.looper = ALooper_prepare(0 /* or ALOOPER_PREPARE_ALLOW_NON_CALLBACKS*/);
    ALooper_addFd(_sapp.android.looper,
        _sapp.android.pt.read_from_main_fd,
        ALOOPER_POLL_CALLBACK,
        ALOOPER_EVENT_INPUT,
        _sapp_android_main_cb,
        NULL); /* data */

    /* signal start to main thread */
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    _sapp.android.is_thread_started = true;
    pthread_cond_broadcast(&_sapp.android.pt.cond);
    pthread_mutex_unlock(&_sapp.android.pt.mutex);

    /* main loop */
    while (!_sapp.android.is_thread_stopping) {
        /* sokol frame */
        if (_sapp_android_should_update()) {
            _sapp_android_frame();
        }

        /* process all events (or stop early if app is requested to quit) */
        bool process_events = true;
        while (process_events && !_sapp.android.is_thread_stopping) {
            bool block_until_event = !_sapp.android.is_thread_stopping && !_sapp_android_should_update();
            process_events = ALooper_pollOnce(block_until_event ? -1 : 0, NULL, NULL, NULL) == ALOOPER_POLL_CALLBACK;
        }
    }

    /* cleanup thread */
    if (_sapp.android.current.input != NULL) {
        AInputQueue_detachLooper(_sapp.android.current.input);
    }

    /* the following causes heap corruption on exit, why??
    ALooper_removeFd(_sapp.android.looper, _sapp.android.pt.read_from_main_fd);
    ALooper_release(_sapp.android.looper);*/

    /* signal "destroyed" */
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    _sapp.android.is_thread_stopped = true;
    pthread_cond_broadcast(&_sapp.android.pt.cond);
    pthread_mutex_unlock(&_sapp.android.pt.mutex);

    _SAPP_INFO(ANDROID_LOOP_THREAD_DONE);
    return NULL;
}

/* android main/ui thread */
_SOKOL_PRIVATE void _sapp_android_msg(_sapp_android_msg_t msg) {
    if (write(_sapp.android.pt.write_from_main_fd, &msg, sizeof(msg)) != sizeof(msg)) {
        _SAPP_ERROR(ANDROID_WRITE_MSG_FAILED);
    }
}

_SOKOL_PRIVATE void _sapp_android_on_start(ANativeActivity* activity) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONSTART);
}

_SOKOL_PRIVATE void _sapp_android_on_resume(ANativeActivity* activity) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONRESUME);
    _sapp_android_msg(_SOKOL_ANDROID_MSG_RESUME);
}

_SOKOL_PRIVATE void* _sapp_android_on_save_instance_state(ANativeActivity* activity, size_t* out_size) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONSAVEINSTANCESTATE);
    *out_size = 0;
    return NULL;
}

_SOKOL_PRIVATE void _sapp_android_on_window_focus_changed(ANativeActivity* activity, int has_focus) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONWINDOWFOCUSCHANGED);
    if (has_focus) {
        _sapp_android_msg(_SOKOL_ANDROID_MSG_FOCUS);
    } else {
        _sapp_android_msg(_SOKOL_ANDROID_MSG_NO_FOCUS);
    }
}

_SOKOL_PRIVATE void _sapp_android_on_pause(ANativeActivity* activity) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONPAUSE);
    _sapp_android_msg(_SOKOL_ANDROID_MSG_PAUSE);
}

_SOKOL_PRIVATE void _sapp_android_on_stop(ANativeActivity* activity) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONSTOP);
}

_SOKOL_PRIVATE void _sapp_android_msg_set_native_window(ANativeWindow* window) {
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    _sapp.android.pending.window = window;
    _sapp_android_msg(_SOKOL_ANDROID_MSG_SET_NATIVE_WINDOW);
    while (_sapp.android.current.window != window) {
        pthread_cond_wait(&_sapp.android.pt.cond, &_sapp.android.pt.mutex);
    }
    pthread_mutex_unlock(&_sapp.android.pt.mutex);
}

_SOKOL_PRIVATE void _sapp_android_on_native_window_created(ANativeActivity* activity, ANativeWindow* window) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONNATIVEWINDOWCREATED);
    _sapp_android_msg_set_native_window(window);
}

_SOKOL_PRIVATE void _sapp_android_on_native_window_destroyed(ANativeActivity* activity, ANativeWindow* window) {
    _SOKOL_UNUSED(activity);
    _SOKOL_UNUSED(window);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONNATIVEWINDOWDESTROYED);
    _sapp_android_msg_set_native_window(NULL);
}

_SOKOL_PRIVATE void _sapp_android_msg_set_input_queue(AInputQueue* input) {
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    _sapp.android.pending.input = input;
    _sapp_android_msg(_SOKOL_ANDROID_MSG_SET_INPUT_QUEUE);
    while (_sapp.android.current.input != input) {
        pthread_cond_wait(&_sapp.android.pt.cond, &_sapp.android.pt.mutex);
    }
    pthread_mutex_unlock(&_sapp.android.pt.mutex);
}

_SOKOL_PRIVATE void _sapp_android_on_input_queue_created(ANativeActivity* activity, AInputQueue* queue) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONINPUTQUEUECREATED);
    _sapp_android_msg_set_input_queue(queue);
}

_SOKOL_PRIVATE void _sapp_android_on_input_queue_destroyed(ANativeActivity* activity, AInputQueue* queue) {
    _SOKOL_UNUSED(activity);
    _SOKOL_UNUSED(queue);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONINPUTQUEUEDESTROYED);
    _sapp_android_msg_set_input_queue(NULL);
}

_SOKOL_PRIVATE void _sapp_android_on_config_changed(ANativeActivity* activity) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONCONFIGURATIONCHANGED);
    /* see android:configChanges in manifest */
}

_SOKOL_PRIVATE void _sapp_android_on_low_memory(ANativeActivity* activity) {
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONLOWMEMORY);
}

_SOKOL_PRIVATE void _sapp_android_on_destroy(ANativeActivity* activity) {
    /*
     * For some reason even an empty app using nativeactivity.h will crash (WIN DEATH)
     * on my device (Moto X 2nd gen) when the app is removed from the task view
     * (TaskStackView: onTaskViewDismissed).
     *
     * However, if ANativeActivity_finish() is explicitly called from for example
     * _sapp_android_on_stop(), the crash disappears. Is this a bug in NativeActivity?
     */
    _SOKOL_UNUSED(activity);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONDESTROY);

    /* send destroy msg */
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    _sapp_android_msg(_SOKOL_ANDROID_MSG_DESTROY);
    while (!_sapp.android.is_thread_stopped) {
        pthread_cond_wait(&_sapp.android.pt.cond, &_sapp.android.pt.mutex);
    }
    pthread_mutex_unlock(&_sapp.android.pt.mutex);

    /* clean up main thread */
    pthread_cond_destroy(&_sapp.android.pt.cond);
    pthread_mutex_destroy(&_sapp.android.pt.mutex);

    close(_sapp.android.pt.read_from_main_fd);
    close(_sapp.android.pt.write_from_main_fd);

    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_DONE);

    /* this is a bit naughty, but causes a clean restart of the app (static globals are reset) */
    exit(0);
}

JNIEXPORT
void ANativeActivity_onCreate(ANativeActivity* activity, void* saved_state, size_t saved_state_size) {
    _SOKOL_UNUSED(saved_state);
    _SOKOL_UNUSED(saved_state_size);
    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_ONCREATE);

    // the NativeActity pointer needs to be available inside sokol_main()
    // (see https://github.com/floooh/sokol/issues/708), however _sapp_init_state()
    // will clear the global _sapp_t struct, so we need to initialize the native
    // activity pointer twice, once before sokol_main() and once after _sapp_init_state()
    _sapp_clear(&_sapp, sizeof(_sapp));
    _sapp.android.activity = activity;
    sapp_desc desc = sokol_main(0, NULL);
    _sapp_init_state(&desc);
    _sapp.android.activity = activity;

    int pipe_fd[2];
    if (pipe(pipe_fd) != 0) {
        _SAPP_ERROR(ANDROID_CREATE_THREAD_PIPE_FAILED);
        return;
    }
    _sapp.android.pt.read_from_main_fd = pipe_fd[0];
    _sapp.android.pt.write_from_main_fd = pipe_fd[1];

    pthread_mutex_init(&_sapp.android.pt.mutex, NULL);
    pthread_cond_init(&_sapp.android.pt.cond, NULL);

    pthread_attr_t attr;
    pthread_attr_init(&attr);
    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);
    pthread_create(&_sapp.android.pt.thread, &attr, _sapp_android_loop, 0);
    pthread_attr_destroy(&attr);

    /* wait until main loop has started */
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    while (!_sapp.android.is_thread_started) {
        pthread_cond_wait(&_sapp.android.pt.cond, &_sapp.android.pt.mutex);
    }
    pthread_mutex_unlock(&_sapp.android.pt.mutex);

    /* send create msg */
    pthread_mutex_lock(&_sapp.android.pt.mutex);
    _sapp_android_msg(_SOKOL_ANDROID_MSG_CREATE);
    while (!_sapp.android.has_created) {
        pthread_cond_wait(&_sapp.android.pt.cond, &_sapp.android.pt.mutex);
    }
    pthread_mutex_unlock(&_sapp.android.pt.mutex);

    /* register for callbacks */
    activity->callbacks->onStart = _sapp_android_on_start;
    activity->callbacks->onResume = _sapp_android_on_resume;
    activity->callbacks->onSaveInstanceState = _sapp_android_on_save_instance_state;
    activity->callbacks->onWindowFocusChanged = _sapp_android_on_window_focus_changed;
    activity->callbacks->onPause = _sapp_android_on_pause;
    activity->callbacks->onStop = _sapp_android_on_stop;
    activity->callbacks->onDestroy = _sapp_android_on_destroy;
    activity->callbacks->onNativeWindowCreated = _sapp_android_on_native_window_created;
    /* activity->callbacks->onNativeWindowResized = _sapp_android_on_native_window_resized; */
    /* activity->callbacks->onNativeWindowRedrawNeeded = _sapp_android_on_native_window_redraw_needed; */
    activity->callbacks->onNativeWindowDestroyed = _sapp_android_on_native_window_destroyed;
    activity->callbacks->onInputQueueCreated = _sapp_android_on_input_queue_created;
    activity->callbacks->onInputQueueDestroyed = _sapp_android_on_input_queue_destroyed;
    /* activity->callbacks->onContentRectChanged = _sapp_android_on_content_rect_changed; */
    activity->callbacks->onConfigurationChanged = _sapp_android_on_config_changed;
    activity->callbacks->onLowMemory = _sapp_android_on_low_memory;

    _SAPP_INFO(ANDROID_NATIVE_ACTIVITY_CREATE_SUCCESS);

    /* NOT A BUG: do NOT call sapp_discard_state() */
}

#endif /* _SAPP_ANDROID */

// ██      ██ ███    ██ ██    ██ ██   ██
// ██      ██ ████   ██ ██    ██  ██ ██
// ██      ██ ██ ██  ██ ██    ██   ███
// ██      ██ ██  ██ ██ ██    ██  ██ ██
// ███████ ██ ██   ████  ██████  ██   ██
//
// >>linux
#if defined(_SAPP_LINUX)

/* see GLFW's xkb_unicode.c */
static const struct _sapp_x11_codepair {
  uint16_t keysym;
  uint16_t ucs;
} _sapp_x11_keysymtab[] = {
  { 0x01a1, 0x0104 },
  { 0x01a2, 0x02d8 },
  { 0x01a3, 0x0141 },
  { 0x01a5, 0x013d },
  { 0x01a6, 0x015a },
  { 0x01a9, 0x0160 },
  { 0x01aa, 0x015e },
  { 0x01ab, 0x0164 },
  { 0x01ac, 0x0179 },
  { 0x01ae, 0x017d },
  { 0x01af, 0x017b },
  { 0x01b1, 0x0105 },
  { 0x01b2, 0x02db },
  { 0x01b3, 0x0142 },
  { 0x01b5, 0x013e },
  { 0x01b6, 0x015b },
  { 0x01b7, 0x02c7 },
  { 0x01b9, 0x0161 },
  { 0x01ba, 0x015f },
  { 0x01bb, 0x0165 },
  { 0x01bc, 0x017a },
  { 0x01bd, 0x02dd },
  { 0x01be, 0x017e },
  { 0x01bf, 0x017c },
  { 0x01c0, 0x0154 },
  { 0x01c3, 0x0102 },
  { 0x01c5, 0x0139 },
  { 0x01c6, 0x0106 },
  { 0x01c8, 0x010c },
  { 0x01ca, 0x0118 },
  { 0x01cc, 0x011a },
  { 0x01cf, 0x010e },
  { 0x01d0, 0x0110 },
  { 0x01d1, 0x0143 },
  { 0x01d2, 0x0147 },
  { 0x01d5, 0x0150 },
  { 0x01d8, 0x0158 },
  { 0x01d9, 0x016e },
  { 0x01db, 0x0170 },
  { 0x01de, 0x0162 },
  { 0x01e0, 0x0155 },
  { 0x01e3, 0x0103 },
  { 0x01e5, 0x013a },
  { 0x01e6, 0x0107 },
  { 0x01e8, 0x010d },
  { 0x01ea, 0x0119 },
  { 0x01ec, 0x011b },
  { 0x01ef, 0x010f },
  { 0x01f0, 0x0111 },
  { 0x01f1, 0x0144 },
  { 0x01f2, 0x0148 },
  { 0x01f5, 0x0151 },
  { 0x01f8, 0x0159 },
  { 0x01f9, 0x016f },
  { 0x01fb, 0x0171 },
  { 0x01fe, 0x0163 },
  { 0x01ff, 0x02d9 },
  { 0x02a1, 0x0126 },
  { 0x02a6, 0x0124 },
  { 0x02a9, 0x0130 },
  { 0x02ab, 0x011e },
  { 0x02ac, 0x0134 },
  { 0x02b1, 0x0127 },
  { 0x02b6, 0x0125 },
  { 0x02b9, 0x0131 },
  { 0x02bb, 0x011f },
  { 0x02bc, 0x0135 },
  { 0x02c5, 0x010a },
  { 0x02c6, 0x0108 },
  { 0x02d5, 0x0120 },
  { 0x02d8, 0x011c },
  { 0x02dd, 0x016c },
  { 0x02de, 0x015c },
  { 0x02e5, 0x010b },
  { 0x02e6, 0x0109 },
  { 0x02f5, 0x0121 },
  { 0x02f8, 0x011d },
  { 0x02fd, 0x016d },
  { 0x02fe, 0x015d },
  { 0x03a2, 0x0138 },
  { 0x03a3, 0x0156 },
  { 0x03a5, 0x0128 },
  { 0x03a6, 0x013b },
  { 0x03aa, 0x0112 },
  { 0x03ab, 0x0122 },
  { 0x03ac, 0x0166 },
  { 0x03b3, 0x0157 },
  { 0x03b5, 0x0129 },
  { 0x03b6, 0x013c },
  { 0x03ba, 0x0113 },
  { 0x03bb, 0x0123 },
  { 0x03bc, 0x0167 },
  { 0x03bd, 0x014a },
  { 0x03bf, 0x014b },
  { 0x03c0, 0x0100 },
  { 0x03c7, 0x012e },
  { 0x03cc, 0x0116 },
  { 0x03cf, 0x012a },
  { 0x03d1, 0x0145 },
  { 0x03d2, 0x014c },
  { 0x03d3, 0x0136 },
  { 0x03d9, 0x0172 },
  { 0x03dd, 0x0168 },
  { 0x03de, 0x016a },
  { 0x03e0, 0x0101 },
  { 0x03e7, 0x012f },
  { 0x03ec, 0x0117 },
  { 0x03ef, 0x012b },
  { 0x03f1, 0x0146 },
  { 0x03f2, 0x014d },
  { 0x03f3, 0x0137 },
  { 0x03f9, 0x0173 },
  { 0x03fd, 0x0169 },
  { 0x03fe, 0x016b },
  { 0x047e, 0x203e },
  { 0x04a1, 0x3002 },
  { 0x04a2, 0x300c },
  { 0x04a3, 0x300d },
  { 0x04a4, 0x3001 },
  { 0x04a5, 0x30fb },
  { 0x04a6, 0x30f2 },
  { 0x04a7, 0x30a1 },
  { 0x04a8, 0x30a3 },
  { 0x04a9, 0x30a5 },
  { 0x04aa, 0x30a7 },
  { 0x04ab, 0x30a9 },
  { 0x04ac, 0x30e3 },
  { 0x04ad, 0x30e5 },
  { 0x04ae, 0x30e7 },
  { 0x04af, 0x30c3 },
  { 0x04b0, 0x30fc },
  { 0x04b1, 0x30a2 },
  { 0x04b2, 0x30a4 },
  { 0x04b3, 0x30a6 },
  { 0x04b4, 0x30a8 },
  { 0x04b5, 0x30aa },
  { 0x04b6, 0x30ab },
  { 0x04b7, 0x30ad },
  { 0x04b8, 0x30af },
  { 0x04b9, 0x30b1 },
  { 0x04ba, 0x30b3 },
  { 0x04bb, 0x30b5 },
  { 0x04bc, 0x30b7 },
  { 0x04bd, 0x30b9 },
  { 0x04be, 0x30bb },
  { 0x04bf, 0x30bd },
  { 0x04c0, 0x30bf },
  { 0x04c1, 0x30c1 },
  { 0x04c2, 0x30c4 },
  { 0x04c3, 0x30c6 },
  { 0x04c4, 0x30c8 },
  { 0x04c5, 0x30ca },
  { 0x04c6, 0x30cb },
  { 0x04c7, 0x30cc },
  { 0x04c8, 0x30cd },
  { 0x04c9, 0x30ce },
  { 0x04ca, 0x30cf },
  { 0x04cb, 0x30d2 },
  { 0x04cc, 0x30d5 },
  { 0x04cd, 0x30d8 },
  { 0x04ce, 0x30db },
  { 0x04cf, 0x30de },
  { 0x04d0, 0x30df },
  { 0x04d1, 0x30e0 },
  { 0x04d2, 0x30e1 },
  { 0x04d3, 0x30e2 },
  { 0x04d4, 0x30e4 },
  { 0x04d5, 0x30e6 },
  { 0x04d6, 0x30e8 },
  { 0x04d7, 0x30e9 },
  { 0x04d8, 0x30ea },
  { 0x04d9, 0x30eb },
  { 0x04da, 0x30ec },
  { 0x04db, 0x30ed },
  { 0x04dc, 0x30ef },
  { 0x04dd, 0x30f3 },
  { 0x04de, 0x309b },
  { 0x04df, 0x309c },
  { 0x05ac, 0x060c },
  { 0x05bb, 0x061b },
  { 0x05bf, 0x061f },
  { 0x05c1, 0x0621 },
  { 0x05c2, 0x0622 },
  { 0x05c3, 0x0623 },
  { 0x05c4, 0x0624 },
  { 0x05c5, 0x0625 },
  { 0x05c6, 0x0626 },
  { 0x05c7, 0x0627 },
  { 0x05c8, 0x0628 },
  { 0x05c9, 0x0629 },
  { 0x05ca, 0x062a },
  { 0x05cb, 0x062b },
  { 0x05cc, 0x062c },
  { 0x05cd, 0x062d },
  { 0x05ce, 0x062e },
  { 0x05cf, 0x062f },
  { 0x05d0, 0x0630 },
  { 0x05d1, 0x0631 },
  { 0x05d2, 0x0632 },
  { 0x05d3, 0x0633 },
  { 0x05d4, 0x0634 },
  { 0x05d5, 0x0635 },
  { 0x05d6, 0x0636 },
  { 0x05d7, 0x0637 },
  { 0x05d8, 0x0638 },
  { 0x05d9, 0x0639 },
  { 0x05da, 0x063a },
  { 0x05e0, 0x0640 },
  { 0x05e1, 0x0641 },
  { 0x05e2, 0x0642 },
  { 0x05e3, 0x0643 },
  { 0x05e4, 0x0644 },
  { 0x05e5, 0x0645 },
  { 0x05e6, 0x0646 },
  { 0x05e7, 0x0647 },
  { 0x05e8, 0x0648 },
  { 0x05e9, 0x0649 },
  { 0x05ea, 0x064a },
  { 0x05eb, 0x064b },
  { 0x05ec, 0x064c },
  { 0x05ed, 0x064d },
  { 0x05ee, 0x064e },
  { 0x05ef, 0x064f },
  { 0x05f0, 0x0650 },
  { 0x05f1, 0x0651 },
  { 0x05f2, 0x0652 },
  { 0x06a1, 0x0452 },
  { 0x06a2, 0x0453 },
  { 0x06a3, 0x0451 },
  { 0x06a4, 0x0454 },
  { 0x06a5, 0x0455 },
  { 0x06a6, 0x0456 },
  { 0x06a7, 0x0457 },
  { 0x06a8, 0x0458 },
  { 0x06a9, 0x0459 },
  { 0x06aa, 0x045a },
  { 0x06ab, 0x045b },
  { 0x06ac, 0x045c },
  { 0x06ae, 0x045e },
  { 0x06af, 0x045f },
  { 0x06b0, 0x2116 },
  { 0x06b1, 0x0402 },
  { 0x06b2, 0x0403 },
  { 0x06b3, 0x0401 },
  { 0x06b4, 0x0404 },
  { 0x06b5, 0x0405 },
  { 0x06b6, 0x0406 },
  { 0x06b7, 0x0407 },
  { 0x06b8, 0x0408 },
  { 0x06b9, 0x0409 },
  { 0x06ba, 0x040a },
  { 0x06bb, 0x040b },
  { 0x06bc, 0x040c },
  { 0x06be, 0x040e },
  { 0x06bf, 0x040f },
  { 0x06c0, 0x044e },
  { 0x06c1, 0x0430 },
  { 0x06c2, 0x0431 },
  { 0x06c3, 0x0446 },
  { 0x06c4, 0x0434 },
  { 0x06c5, 0x0435 },
  { 0x06c6, 0x0444 },
  { 0x06c7, 0x0433 },
  { 0x06c8, 0x0445 },
  { 0x06c9, 0x0438 },
  { 0x06ca, 0x0439 },
  { 0x06cb, 0x043a },
  { 0x06cc, 0x043b },
  { 0x06cd, 0x043c },
  { 0x06ce, 0x043d },
  { 0x06cf, 0x043e },
  { 0x06d0, 0x043f },
  { 0x06d1, 0x044f },
  { 0x06d2, 0x0440 },
  { 0x06d3, 0x0441 },
  { 0x06d4, 0x0442 },
  { 0x06d5, 0x0443 },
  { 0x06d6, 0x0436 },
  { 0x06d7, 0x0432 },
  { 0x06d8, 0x044c },
  { 0x06d9, 0x044b },
  { 0x06da, 0x0437 },
  { 0x06db, 0x0448 },
  { 0x06dc, 0x044d },
  { 0x06dd, 0x0449 },
  { 0x06de, 0x0447 },
  { 0x06df, 0x044a },
  { 0x06e0, 0x042e },
  { 0x06e1, 0x0410 },
  { 0x06e2, 0x0411 },
  { 0x06e3, 0x0426 },
  { 0x06e4, 0x0414 },
  { 0x06e5, 0x0415 },
  { 0x06e6, 0x0424 },
  { 0x06e7, 0x0413 },
  { 0x06e8, 0x0425 },
  { 0x06e9, 0x0418 },
  { 0x06ea, 0x0419 },
  { 0x06eb, 0x041a },
  { 0x06ec, 0x041b },
  { 0x06ed, 0x041c },
  { 0x06ee, 0x041d },
  { 0x06ef, 0x041e },
  { 0x06f0, 0x041f },
  { 0x06f1, 0x042f },
  { 0x06f2, 0x0420 },
  { 0x06f3, 0x0421 },
  { 0x06f4, 0x0422 },
  { 0x06f5, 0x0423 },
  { 0x06f6, 0x0416 },
  { 0x06f7, 0x0412 },
  { 0x06f8, 0x042c },
  { 0x06f9, 0x042b },
  { 0x06fa, 0x0417 },
  { 0x06fb, 0x0428 },
  { 0x06fc, 0x042d },
  { 0x06fd, 0x0429 },
  { 0x06fe, 0x0427 },
  { 0x06ff, 0x042a },
  { 0x07a1, 0x0386 },
  { 0x07a2, 0x0388 },
  { 0x07a3, 0x0389 },
  { 0x07a4, 0x038a },
  { 0x07a5, 0x03aa },
  { 0x07a7, 0x038c },
  { 0x07a8, 0x038e },
  { 0x07a9, 0x03ab },
  { 0x07ab, 0x038f },
  { 0x07ae, 0x0385 },
  { 0x07af, 0x2015 },
  { 0x07b1, 0x03ac },
  { 0x07b2, 0x03ad },
  { 0x07b3, 0x03ae },
  { 0x07b4, 0x03af },
  { 0x07b5, 0x03ca },
  { 0x07b6, 0x0390 },
  { 0x07b7, 0x03cc },
  { 0x07b8, 0x03cd },
  { 0x07b9, 0x03cb },
  { 0x07ba, 0x03b0 },
  { 0x07bb, 0x03ce },
  { 0x07c1, 0x0391 },
  { 0x07c2, 0x0392 },
  { 0x07c3, 0x0393 },
  { 0x07c4, 0x0394 },
  { 0x07c5, 0x0395 },
  { 0x07c6, 0x0396 },
  { 0x07c7, 0x0397 },
  { 0x07c8, 0x0398 },
  { 0x07c9, 0x0399 },
  { 0x07ca, 0x039a },
  { 0x07cb, 0x039b },
  { 0x07cc, 0x039c },
  { 0x07cd, 0x039d },
  { 0x07ce, 0x039e },
  { 0x07cf, 0x039f },
  { 0x07d0, 0x03a0 },
  { 0x07d1, 0x03a1 },
  { 0x07d2, 0x03a3 },
  { 0x07d4, 0x03a4 },
  { 0x07d5, 0x03a5 },
  { 0x07d6, 0x03a6 },
  { 0x07d7, 0x03a7 },
  { 0x07d8, 0x03a8 },
  { 0x07d9, 0x03a9 },
  { 0x07e1, 0x03b1 },
  { 0x07e2, 0x03b2 },
  { 0x07e3, 0x03b3 },
  { 0x07e4, 0x03b4 },
  { 0x07e5, 0x03b5 },
  { 0x07e6, 0x03b6 },
  { 0x07e7, 0x03b7 },
  { 0x07e8, 0x03b8 },
  { 0x07e9, 0x03b9 },
  { 0x07ea, 0x03ba },
  { 0x07eb, 0x03bb },
  { 0x07ec, 0x03bc },
  { 0x07ed, 0x03bd },
  { 0x07ee, 0x03be },
  { 0x07ef, 0x03bf },
  { 0x07f0, 0x03c0 },
  { 0x07f1, 0x03c1 },
  { 0x07f2, 0x03c3 },
  { 0x07f3, 0x03c2 },
  { 0x07f4, 0x03c4 },
  { 0x07f5, 0x03c5 },
  { 0x07f6, 0x03c6 },
  { 0x07f7, 0x03c7 },
  { 0x07f8, 0x03c8 },
  { 0x07f9, 0x03c9 },
  { 0x08a1, 0x23b7 },
  { 0x08a2, 0x250c },
  { 0x08a3, 0x2500 },
  { 0x08a4, 0x2320 },
  { 0x08a5, 0x2321 },
  { 0x08a6, 0x2502 },
  { 0x08a7, 0x23a1 },
  { 0x08a8, 0x23a3 },
  { 0x08a9, 0x23a4 },
  { 0x08aa, 0x23a6 },
  { 0x08ab, 0x239b },
  { 0x08ac, 0x239d },
  { 0x08ad, 0x239e },
  { 0x08ae, 0x23a0 },
  { 0x08af, 0x23a8 },
  { 0x08b0, 0x23ac },
  { 0x08bc, 0x2264 },
  { 0x08bd, 0x2260 },
  { 0x08be, 0x2265 },
  { 0x08bf, 0x222b },
  { 0x08c0, 0x2234 },
  { 0x08c1, 0x221d },
  { 0x08c2, 0x221e },
  { 0x08c5, 0x2207 },
  { 0x08c8, 0x223c },
  { 0x08c9, 0x2243 },
  { 0x08cd, 0x21d4 },
  { 0x08ce, 0x21d2 },
  { 0x08cf, 0x2261 },
  { 0x08d6, 0x221a },
  { 0x08da, 0x2282 },
  { 0x08db, 0x2283 },
  { 0x08dc, 0x2229 },
  { 0x08dd, 0x222a },
  { 0x08de, 0x2227 },
  { 0x08df, 0x2228 },
  { 0x08ef, 0x2202 },
  { 0x08f6, 0x0192 },
  { 0x08fb, 0x2190 },
  { 0x08fc, 0x2191 },
  { 0x08fd, 0x2192 },
  { 0x08fe, 0x2193 },
  { 0x09e0, 0x25c6 },
  { 0x09e1, 0x2592 },
  { 0x09e2, 0x2409 },
  { 0x09e3, 0x240c },
  { 0x09e4, 0x240d },
  { 0x09e5, 0x240a },
  { 0x09e8, 0x2424 },
  { 0x09e9, 0x240b },
  { 0x09ea, 0x2518 },
  { 0x09eb, 0x2510 },
  { 0x09ec, 0x250c },
  { 0x09ed, 0x2514 },
  { 0x09ee, 0x253c },
  { 0x09ef, 0x23ba },
  { 0x09f0, 0x23bb },
  { 0x09f1, 0x2500 },
  { 0x09f2, 0x23bc },
  { 0x09f3, 0x23bd },
  { 0x09f4, 0x251c },
  { 0x09f5, 0x2524 },
  { 0x09f6, 0x2534 },
  { 0x09f7, 0x252c },
  { 0x09f8, 0x2502 },
  { 0x0aa1, 0x2003 },
  { 0x0aa2, 0x2002 },
  { 0x0aa3, 0x2004 },
  { 0x0aa4, 0x2005 },
  { 0x0aa5, 0x2007 },
  { 0x0aa6, 0x2008 },
  { 0x0aa7, 0x2009 },
  { 0x0aa8, 0x200a },
  { 0x0aa9, 0x2014 },
  { 0x0aaa, 0x2013 },
  { 0x0aae, 0x2026 },
  { 0x0aaf, 0x2025 },
  { 0x0ab0, 0x2153 },
  { 0x0ab1, 0x2154 },
  { 0x0ab2, 0x2155 },
  { 0x0ab3, 0x2156 },
  { 0x0ab4, 0x2157 },
  { 0x0ab5, 0x2158 },
  { 0x0ab6, 0x2159 },
  { 0x0ab7, 0x215a },
  { 0x0ab8, 0x2105 },
  { 0x0abb, 0x2012 },
  { 0x0abc, 0x2329 },
  { 0x0abe, 0x232a },
  { 0x0ac3, 0x215b },
  { 0x0ac4, 0x215c },
  { 0x0ac5, 0x215d },
  { 0x0ac6, 0x215e },
  { 0x0ac9, 0x2122 },
  { 0x0aca, 0x2613 },
  { 0x0acc, 0x25c1 },
  { 0x0acd, 0x25b7 },
  { 0x0ace, 0x25cb },
  { 0x0acf, 0x25af },
  { 0x0ad0, 0x2018 },
  { 0x0ad1, 0x2019 },
  { 0x0ad2, 0x201c },
  { 0x0ad3, 0x201d },
  { 0x0ad4, 0x211e },
  { 0x0ad6, 0x2032 },
  { 0x0ad7, 0x2033 },
  { 0x0ad9, 0x271d },
  { 0x0adb, 0x25ac },
  { 0x0adc, 0x25c0 },
  { 0x0add, 0x25b6 },
  { 0x0ade, 0x25cf },
  { 0x0adf, 0x25ae },
  { 0x0ae0, 0x25e6 },
  { 0x0ae1, 0x25ab },
  { 0x0ae2, 0x25ad },
  { 0x0ae3, 0x25b3 },
  { 0x0ae4, 0x25bd },
  { 0x0ae5, 0x2606 },
  { 0x0ae6, 0x2022 },
  { 0x0ae7, 0x25aa },
  { 0x0ae8, 0x25b2 },
  { 0x0ae9, 0x25bc },
  { 0x0aea, 0x261c },
  { 0x0aeb, 0x261e },
  { 0x0aec, 0x2663 },
  { 0x0aed, 0x2666 },
  { 0x0aee, 0x2665 },
  { 0x0af0, 0x2720 },
  { 0x0af1, 0x2020 },
  { 0x0af2, 0x2021 },
  { 0x0af3, 0x2713 },
  { 0x0af4, 0x2717 },
  { 0x0af5, 0x266f },
  { 0x0af6, 0x266d },
  { 0x0af7, 0x2642 },
  { 0x0af8, 0x2640 },
  { 0x0af9, 0x260e },
  { 0x0afa, 0x2315 },
  { 0x0afb, 0x2117 },
  { 0x0afc, 0x2038 },
  { 0x0afd, 0x201a },
  { 0x0afe, 0x201e },
  { 0x0ba3, 0x003c },
  { 0x0ba6, 0x003e },
  { 0x0ba8, 0x2228 },
  { 0x0ba9, 0x2227 },
  { 0x0bc0, 0x00af },
  { 0x0bc2, 0x22a5 },
  { 0x0bc3, 0x2229 },
  { 0x0bc4, 0x230a },
  { 0x0bc6, 0x005f },
  { 0x0bca, 0x2218 },
  { 0x0bcc, 0x2395 },
  { 0x0bce, 0x22a4 },
  { 0x0bcf, 0x25cb },
  { 0x0bd3, 0x2308 },
  { 0x0bd6, 0x222a },
  { 0x0bd8, 0x2283 },
  { 0x0bda, 0x2282 },
  { 0x0bdc, 0x22a2 },
  { 0x0bfc, 0x22a3 },
  { 0x0cdf, 0x2017 },
  { 0x0ce0, 0x05d0 },
  { 0x0ce1, 0x05d1 },
  { 0x0ce2, 0x05d2 },
  { 0x0ce3, 0x05d3 },
  { 0x0ce4, 0x05d4 },
  { 0x0ce5, 0x05d5 },
  { 0x0ce6, 0x05d6 },
  { 0x0ce7, 0x05d7 },
  { 0x0ce8, 0x05d8 },
  { 0x0ce9, 0x05d9 },
  { 0x0cea, 0x05da },
  { 0x0ceb, 0x05db },
  { 0x0cec, 0x05dc },
  { 0x0ced, 0x05dd },
  { 0x0cee, 0x05de },
  { 0x0cef, 0x05df },
  { 0x0cf0, 0x05e0 },
  { 0x0cf1, 0x05e1 },
  { 0x0cf2, 0x05e2 },
  { 0x0cf3, 0x05e3 },
  { 0x0cf4, 0x05e4 },
  { 0x0cf5, 0x05e5 },
  { 0x0cf6, 0x05e6 },
  { 0x0cf7, 0x05e7 },
  { 0x0cf8, 0x05e8 },
  { 0x0cf9, 0x05e9 },
  { 0x0cfa, 0x05ea },
  { 0x0da1, 0x0e01 },
  { 0x0da2, 0x0e02 },
  { 0x0da3, 0x0e03 },
  { 0x0da4, 0x0e04 },
  { 0x0da5, 0x0e05 },
  { 0x0da6, 0x0e06 },
  { 0x0da7, 0x0e07 },
  { 0x0da8, 0x0e08 },
  { 0x0da9, 0x0e09 },
  { 0x0daa, 0x0e0a },
  { 0x0dab, 0x0e0b },
  { 0x0dac, 0x0e0c },
  { 0x0dad, 0x0e0d },
  { 0x0dae, 0x0e0e },
  { 0x0daf, 0x0e0f },
  { 0x0db0, 0x0e10 },
  { 0x0db1, 0x0e11 },
  { 0x0db2, 0x0e12 },
  { 0x0db3, 0x0e13 },
  { 0x0db4, 0x0e14 },
  { 0x0db5, 0x0e15 },
  { 0x0db6, 0x0e16 },
  { 0x0db7, 0x0e17 },
  { 0x0db8, 0x0e18 },
  { 0x0db9, 0x0e19 },
  { 0x0dba, 0x0e1a },
  { 0x0dbb, 0x0e1b },
  { 0x0dbc, 0x0e1c },
  { 0x0dbd, 0x0e1d },
  { 0x0dbe, 0x0e1e },
  { 0x0dbf, 0x0e1f },
  { 0x0dc0, 0x0e20 },
  { 0x0dc1, 0x0e21 },
  { 0x0dc2, 0x0e22 },
  { 0x0dc3, 0x0e23 },
  { 0x0dc4, 0x0e24 },
  { 0x0dc5, 0x0e25 },
  { 0x0dc6, 0x0e26 },
  { 0x0dc7, 0x0e27 },
  { 0x0dc8, 0x0e28 },
  { 0x0dc9, 0x0e29 },
  { 0x0dca, 0x0e2a },
  { 0x0dcb, 0x0e2b },
  { 0x0dcc, 0x0e2c },
  { 0x0dcd, 0x0e2d },
  { 0x0dce, 0x0e2e },
  { 0x0dcf, 0x0e2f },
  { 0x0dd0, 0x0e30 },
  { 0x0dd1, 0x0e31 },
  { 0x0dd2, 0x0e32 },
  { 0x0dd3, 0x0e33 },
  { 0x0dd4, 0x0e34 },
  { 0x0dd5, 0x0e35 },
  { 0x0dd6, 0x0e36 },
  { 0x0dd7, 0x0e37 },
  { 0x0dd8, 0x0e38 },
  { 0x0dd9, 0x0e39 },
  { 0x0dda, 0x0e3a },
  { 0x0ddf, 0x0e3f },
  { 0x0de0, 0x0e40 },
  { 0x0de1, 0x0e41 },
  { 0x0de2, 0x0e42 },
  { 0x0de3, 0x0e43 },
  { 0x0de4, 0x0e44 },
  { 0x0de5, 0x0e45 },
  { 0x0de6, 0x0e46 },
  { 0x0de7, 0x0e47 },
  { 0x0de8, 0x0e48 },
  { 0x0de9, 0x0e49 },
  { 0x0dea, 0x0e4a },
  { 0x0deb, 0x0e4b },
  { 0x0dec, 0x0e4c },
  { 0x0ded, 0x0e4d },
  { 0x0df0, 0x0e50 },
  { 0x0df1, 0x0e51 },
  { 0x0df2, 0x0e52 },
  { 0x0df3, 0x0e53 },
  { 0x0df4, 0x0e54 },
  { 0x0df5, 0x0e55 },
  { 0x0df6, 0x0e56 },
  { 0x0df7, 0x0e57 },
  { 0x0df8, 0x0e58 },
  { 0x0df9, 0x0e59 },
  { 0x0ea1, 0x3131 },
  { 0x0ea2, 0x3132 },
  { 0x0ea3, 0x3133 },
  { 0x0ea4, 0x3134 },
  { 0x0ea5, 0x3135 },
  { 0x0ea6, 0x3136 },
  { 0x0ea7, 0x3137 },
  { 0x0ea8, 0x3138 },
  { 0x0ea9, 0x3139 },
  { 0x0eaa, 0x313a },
  { 0x0eab, 0x313b },
  { 0x0eac, 0x313c },
  { 0x0ead, 0x313d },
  { 0x0eae, 0x313e },
  { 0x0eaf, 0x313f },
  { 0x0eb0, 0x3140 },
  { 0x0eb1, 0x3141 },
  { 0x0eb2, 0x3142 },
  { 0x0eb3, 0x3143 },
  { 0x0eb4, 0x3144 },
  { 0x0eb5, 0x3145 },
  { 0x0eb6, 0x3146 },
  { 0x0eb7, 0x3147 },
  { 0x0eb8, 0x3148 },
  { 0x0eb9, 0x3149 },
  { 0x0eba, 0x314a },
  { 0x0ebb, 0x314b },
  { 0x0ebc, 0x314c },
  { 0x0ebd, 0x314d },
  { 0x0ebe, 0x314e },
  { 0x0ebf, 0x314f },
  { 0x0ec0, 0x3150 },
  { 0x0ec1, 0x3151 },
  { 0x0ec2, 0x3152 },
  { 0x0ec3, 0x3153 },
  { 0x0ec4, 0x3154 },
  { 0x0ec5, 0x3155 },
  { 0x0ec6, 0x3156 },
  { 0x0ec7, 0x3157 },
  { 0x0ec8, 0x3158 },
  { 0x0ec9, 0x3159 },
  { 0x0eca, 0x315a },
  { 0x0ecb, 0x315b },
  { 0x0ecc, 0x315c },
  { 0x0ecd, 0x315d },
  { 0x0ece, 0x315e },
  { 0x0ecf, 0x315f },
  { 0x0ed0, 0x3160 },
  { 0x0ed1, 0x3161 },
  { 0x0ed2, 0x3162 },
  { 0x0ed3, 0x3163 },
  { 0x0ed4, 0x11a8 },
  { 0x0ed5, 0x11a9 },
  { 0x0ed6, 0x11aa },
  { 0x0ed7, 0x11ab },
  { 0x0ed8, 0x11ac },
  { 0x0ed9, 0x11ad },
  { 0x0eda, 0x11ae },
  { 0x0edb, 0x11af },
  { 0x0edc, 0x11b0 },
  { 0x0edd, 0x11b1 },
  { 0x0ede, 0x11b2 },
  { 0x0edf, 0x11b3 },
  { 0x0ee0, 0x11b4 },
  { 0x0ee1, 0x11b5 },
  { 0x0ee2, 0x11b6 },
  { 0x0ee3, 0x11b7 },
  { 0x0ee4, 0x11b8 },
  { 0x0ee5, 0x11b9 },
  { 0x0ee6, 0x11ba },
  { 0x0ee7, 0x11bb },
  { 0x0ee8, 0x11bc },
  { 0x0ee9, 0x11bd },
  { 0x0eea, 0x11be },
  { 0x0eeb, 0x11bf },
  { 0x0eec, 0x11c0 },
  { 0x0eed, 0x11c1 },
  { 0x0eee, 0x11c2 },
  { 0x0eef, 0x316d },
  { 0x0ef0, 0x3171 },
  { 0x0ef1, 0x3178 },
  { 0x0ef2, 0x317f },
  { 0x0ef3, 0x3181 },
  { 0x0ef4, 0x3184 },
  { 0x0ef5, 0x3186 },
  { 0x0ef6, 0x318d },
  { 0x0ef7, 0x318e },
  { 0x0ef8, 0x11eb },
  { 0x0ef9, 0x11f0 },
  { 0x0efa, 0x11f9 },
  { 0x0eff, 0x20a9 },
  { 0x13a4, 0x20ac },
  { 0x13bc, 0x0152 },
  { 0x13bd, 0x0153 },
  { 0x13be, 0x0178 },
  { 0x20ac, 0x20ac },
  { 0xfe50,    '`' },
  { 0xfe51, 0x00b4 },
  { 0xfe52,    '^' },
  { 0xfe53,    '~' },
  { 0xfe54, 0x00af },
  { 0xfe55, 0x02d8 },
  { 0xfe56, 0x02d9 },
  { 0xfe57, 0x00a8 },
  { 0xfe58, 0x02da },
  { 0xfe59, 0x02dd },
  { 0xfe5a, 0x02c7 },
  { 0xfe5b, 0x00b8 },
  { 0xfe5c, 0x02db },
  { 0xfe5d, 0x037a },
  { 0xfe5e, 0x309b },
  { 0xfe5f, 0x309c },
  { 0xfe63,    '/' },
  { 0xfe64, 0x02bc },
  { 0xfe65, 0x02bd },
  { 0xfe66, 0x02f5 },
  { 0xfe67, 0x02f3 },
  { 0xfe68, 0x02cd },
  { 0xfe69, 0xa788 },
  { 0xfe6a, 0x02f7 },
  { 0xfe6e,    ',' },
  { 0xfe6f, 0x00a4 },
  { 0xfe80,    'a' }, /* XK_dead_a */
  { 0xfe81,    'A' }, /* XK_dead_A */
  { 0xfe82,    'e' }, /* XK_dead_e */
  { 0xfe83,    'E' }, /* XK_dead_E */
  { 0xfe84,    'i' }, /* XK_dead_i */
  { 0xfe85,    'I' }, /* XK_dead_I */
  { 0xfe86,    'o' }, /* XK_dead_o */
  { 0xfe87,    'O' }, /* XK_dead_O */
  { 0xfe88,    'u' }, /* XK_dead_u */
  { 0xfe89,    'U' }, /* XK_dead_U */
  { 0xfe8a, 0x0259 },
  { 0xfe8b, 0x018f },
  { 0xfe8c, 0x00b5 },
  { 0xfe90,    '_' },
  { 0xfe91, 0x02c8 },
  { 0xfe92, 0x02cc },
  { 0xff80 /*XKB_KEY_KP_Space*/,     ' ' },
  { 0xff95 /*XKB_KEY_KP_7*/, 0x0037 },
  { 0xff96 /*XKB_KEY_KP_4*/, 0x0034 },
  { 0xff97 /*XKB_KEY_KP_8*/, 0x0038 },
  { 0xff98 /*XKB_KEY_KP_6*/, 0x0036 },
  { 0xff99 /*XKB_KEY_KP_2*/, 0x0032 },
  { 0xff9a /*XKB_KEY_KP_9*/, 0x0039 },
  { 0xff9b /*XKB_KEY_KP_3*/, 0x0033 },
  { 0xff9c /*XKB_KEY_KP_1*/, 0x0031 },
  { 0xff9d /*XKB_KEY_KP_5*/, 0x0035 },
  { 0xff9e /*XKB_KEY_KP_0*/, 0x0030 },
  { 0xffaa /*XKB_KEY_KP_Multiply*/,  '*' },
  { 0xffab /*XKB_KEY_KP_Add*/,       '+' },
  { 0xffac /*XKB_KEY_KP_Separator*/, ',' },
  { 0xffad /*XKB_KEY_KP_Subtract*/,  '-' },
  { 0xffae /*XKB_KEY_KP_Decimal*/,   '.' },
  { 0xffaf /*XKB_KEY_KP_Divide*/,    '/' },
  { 0xffb0 /*XKB_KEY_KP_0*/, 0x0030 },
  { 0xffb1 /*XKB_KEY_KP_1*/, 0x0031 },
  { 0xffb2 /*XKB_KEY_KP_2*/, 0x0032 },
  { 0xffb3 /*XKB_KEY_KP_3*/, 0x0033 },
  { 0xffb4 /*XKB_KEY_KP_4*/, 0x0034 },
  { 0xffb5 /*XKB_KEY_KP_5*/, 0x0035 },
  { 0xffb6 /*XKB_KEY_KP_6*/, 0x0036 },
  { 0xffb7 /*XKB_KEY_KP_7*/, 0x0037 },
  { 0xffb8 /*XKB_KEY_KP_8*/, 0x0038 },
  { 0xffb9 /*XKB_KEY_KP_9*/, 0x0039 },
  { 0xffbd /*XKB_KEY_KP_Equal*/,     '=' }
};

_SOKOL_PRIVATE int _sapp_x11_error_handler(Display* display, XErrorEvent* event) {
    _SOKOL_UNUSED(display);
    _sapp.x11.error_code = event->error_code;
    return 0;
}

_SOKOL_PRIVATE void _sapp_x11_grab_error_handler(void) {
    _sapp.x11.error_code = Success;
    XSetErrorHandler(_sapp_x11_error_handler);
}

_SOKOL_PRIVATE void _sapp_x11_release_error_handler(void) {
    XSync(_sapp.x11.display, False);
    XSetErrorHandler(NULL);
}

_SOKOL_PRIVATE void _sapp_x11_init_extensions(void) {
    _sapp.x11.UTF8_STRING             = XInternAtom(_sapp.x11.display, "UTF8_STRING", False);
    _sapp.x11.WM_PROTOCOLS            = XInternAtom(_sapp.x11.display, "WM_PROTOCOLS", False);
    _sapp.x11.WM_DELETE_WINDOW        = XInternAtom(_sapp.x11.display, "WM_DELETE_WINDOW", False);
    _sapp.x11.WM_STATE                = XInternAtom(_sapp.x11.display, "WM_STATE", False);
    _sapp.x11.NET_WM_NAME             = XInternAtom(_sapp.x11.display, "_NET_WM_NAME", False);
    _sapp.x11.NET_WM_ICON_NAME        = XInternAtom(_sapp.x11.display, "_NET_WM_ICON_NAME", False);
    _sapp.x11.NET_WM_ICON             = XInternAtom(_sapp.x11.display, "_NET_WM_ICON", False);
    _sapp.x11.NET_WM_STATE            = XInternAtom(_sapp.x11.display, "_NET_WM_STATE", False);
    _sapp.x11.NET_WM_STATE_FULLSCREEN = XInternAtom(_sapp.x11.display, "_NET_WM_STATE_FULLSCREEN", False);
    _sapp.x11.CLIPBOARD = XInternAtom(_sapp.x11.display, "CLIPBOARD", False);
    _sapp.x11.TARGETS   = XInternAtom(_sapp.x11.display, "TARGETS", False);
    if (_sapp.drop.enabled) {
        _sapp.x11.xdnd.XdndAware        = XInternAtom(_sapp.x11.display, "XdndAware", False);
        _sapp.x11.xdnd.XdndEnter        = XInternAtom(_sapp.x11.display, "XdndEnter", False);
        _sapp.x11.xdnd.XdndPosition     = XInternAtom(_sapp.x11.display, "XdndPosition", False);
        _sapp.x11.xdnd.XdndStatus       = XInternAtom(_sapp.x11.display, "XdndStatus", False);
        _sapp.x11.xdnd.XdndActionCopy   = XInternAtom(_sapp.x11.display, "XdndActionCopy", False);
        _sapp.x11.xdnd.XdndDrop         = XInternAtom(_sapp.x11.display, "XdndDrop", False);
        _sapp.x11.xdnd.XdndFinished     = XInternAtom(_sapp.x11.display, "XdndFinished", False);
        _sapp.x11.xdnd.XdndSelection    = XInternAtom(_sapp.x11.display, "XdndSelection", False);
        _sapp.x11.xdnd.XdndTypeList     = XInternAtom(_sapp.x11.display, "XdndTypeList", False);
        _sapp.x11.xdnd.text_uri_list    = XInternAtom(_sapp.x11.display, "text/uri-list", False);
    }

    /* check Xi extension for raw mouse input */
    if (XQueryExtension(_sapp.x11.display, "XInputExtension", &_sapp.x11.xi.major_opcode, &_sapp.x11.xi.event_base, &_sapp.x11.xi.error_base)) {
        _sapp.x11.xi.major = 2;
        _sapp.x11.xi.minor = 0;
        if (XIQueryVersion(_sapp.x11.display, &_sapp.x11.xi.major, &_sapp.x11.xi.minor) == Success) {
            _sapp.x11.xi.available = true;
        }
    }
}

// translate the X11 KeySyms for a key to sokol-app key code
// NOTE: this is only used as a fallback, in case the XBK method fails
//       it is layout-dependent and will fail partially on most non-US layouts.
//
_SOKOL_PRIVATE sapp_keycode _sapp_x11_translate_keysyms(const KeySym* keysyms, int width) {
    if (width > 1) {
        switch (keysyms[1]) {
            case XK_KP_0:           return SAPP_KEYCODE_KP_0;
            case XK_KP_1:           return SAPP_KEYCODE_KP_1;
            case XK_KP_2:           return SAPP_KEYCODE_KP_2;
            case XK_KP_3:           return SAPP_KEYCODE_KP_3;
            case XK_KP_4:           return SAPP_KEYCODE_KP_4;
            case XK_KP_5:           return SAPP_KEYCODE_KP_5;
            case XK_KP_6:           return SAPP_KEYCODE_KP_6;
            case XK_KP_7:           return SAPP_KEYCODE_KP_7;
            case XK_KP_8:           return SAPP_KEYCODE_KP_8;
            case XK_KP_9:           return SAPP_KEYCODE_KP_9;
            case XK_KP_Separator:
            case XK_KP_Decimal:     return SAPP_KEYCODE_KP_DECIMAL;
            case XK_KP_Equal:       return SAPP_KEYCODE_KP_EQUAL;
            case XK_KP_Enter:       return SAPP_KEYCODE_KP_ENTER;
            default:                break;
        }
    }

    switch (keysyms[0]) {
        case XK_Escape:         return SAPP_KEYCODE_ESCAPE;
        case XK_Tab:            return SAPP_KEYCODE_TAB;
        case XK_Shift_L:        return SAPP_KEYCODE_LEFT_SHIFT;
        case XK_Shift_R:        return SAPP_KEYCODE_RIGHT_SHIFT;
        case XK_Control_L:      return SAPP_KEYCODE_LEFT_CONTROL;
        case XK_Control_R:      return SAPP_KEYCODE_RIGHT_CONTROL;
        case XK_Meta_L:
        case XK_Alt_L:          return SAPP_KEYCODE_LEFT_ALT;
        case XK_Mode_switch: // Mapped to Alt_R on many keyboards
        case XK_ISO_Level3_Shift: // AltGr on at least some machines
        case XK_Meta_R:
        case XK_Alt_R:          return SAPP_KEYCODE_RIGHT_ALT;
        case XK_Super_L:        return SAPP_KEYCODE_LEFT_SUPER;
        case XK_Super_R:        return SAPP_KEYCODE_RIGHT_SUPER;
        case XK_Menu:           return SAPP_KEYCODE_MENU;
        case XK_Num_Lock:       return SAPP_KEYCODE_NUM_LOCK;
        case XK_Caps_Lock:      return SAPP_KEYCODE_CAPS_LOCK;
        case XK_Print:          return SAPP_KEYCODE_PRINT_SCREEN;
        case XK_Scroll_Lock:    return SAPP_KEYCODE_SCROLL_LOCK;
        case XK_Pause:          return SAPP_KEYCODE_PAUSE;
        case XK_Delete:         return SAPP_KEYCODE_DELETE;
        case XK_BackSpace:      return SAPP_KEYCODE_BACKSPACE;
        case XK_Return:         return SAPP_KEYCODE_ENTER;
        case XK_Home:           return SAPP_KEYCODE_HOME;
        case XK_End:            return SAPP_KEYCODE_END;
        case XK_Page_Up:        return SAPP_KEYCODE_PAGE_UP;
        case XK_Page_Down:      return SAPP_KEYCODE_PAGE_DOWN;
        case XK_Insert:         return SAPP_KEYCODE_INSERT;
        case XK_Left:           return SAPP_KEYCODE_LEFT;
        case XK_Right:          return SAPP_KEYCODE_RIGHT;
        case XK_Down:           return SAPP_KEYCODE_DOWN;
        case XK_Up:             return SAPP_KEYCODE_UP;
        case XK_F1:             return SAPP_KEYCODE_F1;
        case XK_F2:             return SAPP_KEYCODE_F2;
        case XK_F3:             return SAPP_KEYCODE_F3;
        case XK_F4:             return SAPP_KEYCODE_F4;
        case XK_F5:             return SAPP_KEYCODE_F5;
        case XK_F6:             return SAPP_KEYCODE_F6;
        case XK_F7:             return SAPP_KEYCODE_F7;
        case XK_F8:             return SAPP_KEYCODE_F8;
        case XK_F9:             return SAPP_KEYCODE_F9;
        case XK_F10:            return SAPP_KEYCODE_F10;
        case XK_F11:            return SAPP_KEYCODE_F11;
        case XK_F12:            return SAPP_KEYCODE_F12;
        case XK_F13:            return SAPP_KEYCODE_F13;
        case XK_F14:            return SAPP_KEYCODE_F14;
        case XK_F15:            return SAPP_KEYCODE_F15;
        case XK_F16:            return SAPP_KEYCODE_F16;
        case XK_F17:            return SAPP_KEYCODE_F17;
        case XK_F18:            return SAPP_KEYCODE_F18;
        case XK_F19:            return SAPP_KEYCODE_F19;
        case XK_F20:            return SAPP_KEYCODE_F20;
        case XK_F21:            return SAPP_KEYCODE_F21;
        case XK_F22:            return SAPP_KEYCODE_F22;
        case XK_F23:            return SAPP_KEYCODE_F23;
        case XK_F24:            return SAPP_KEYCODE_F24;
        case XK_F25:            return SAPP_KEYCODE_F25;

        // numeric keypad
        case XK_KP_Divide:      return SAPP_KEYCODE_KP_DIVIDE;
        case XK_KP_Multiply:    return SAPP_KEYCODE_KP_MULTIPLY;
        case XK_KP_Subtract:    return SAPP_KEYCODE_KP_SUBTRACT;
        case XK_KP_Add:         return SAPP_KEYCODE_KP_ADD;

        // these should have been detected in secondary keysym test above!
        case XK_KP_Insert:      return SAPP_KEYCODE_KP_0;
        case XK_KP_End:         return SAPP_KEYCODE_KP_1;
        case XK_KP_Down:        return SAPP_KEYCODE_KP_2;
        case XK_KP_Page_Down:   return SAPP_KEYCODE_KP_3;
        case XK_KP_Left:        return SAPP_KEYCODE_KP_4;
        case XK_KP_Right:       return SAPP_KEYCODE_KP_6;
        case XK_KP_Home:        return SAPP_KEYCODE_KP_7;
        case XK_KP_Up:          return SAPP_KEYCODE_KP_8;
        case XK_KP_Page_Up:     return SAPP_KEYCODE_KP_9;
        case XK_KP_Delete:      return SAPP_KEYCODE_KP_DECIMAL;
        case XK_KP_Equal:       return SAPP_KEYCODE_KP_EQUAL;
        case XK_KP_Enter:       return SAPP_KEYCODE_KP_ENTER;

        // last resort: Check for printable keys (should not happen if the XKB
        // extension is available). This will give a layout dependent mapping
        // (which is wrong, and we may miss some keys, especially on non-US
        // keyboards), but it's better than nothing...
        case XK_a:              return SAPP_KEYCODE_A;
        case XK_b:              return SAPP_KEYCODE_B;
        case XK_c:              return SAPP_KEYCODE_C;
        case XK_d:              return SAPP_KEYCODE_D;
        case XK_e:              return SAPP_KEYCODE_E;
        case XK_f:              return SAPP_KEYCODE_F;
        case XK_g:              return SAPP_KEYCODE_G;
        case XK_h:              return SAPP_KEYCODE_H;
        case XK_i:              return SAPP_KEYCODE_I;
        case XK_j:              return SAPP_KEYCODE_J;
        case XK_k:              return SAPP_KEYCODE_K;
        case XK_l:              return SAPP_KEYCODE_L;
        case XK_m:              return SAPP_KEYCODE_M;
        case XK_n:              return SAPP_KEYCODE_N;
        case XK_o:              return SAPP_KEYCODE_O;
        case XK_p:              return SAPP_KEYCODE_P;
        case XK_q:              return SAPP_KEYCODE_Q;
        case XK_r:              return SAPP_KEYCODE_R;
        case XK_s:              return SAPP_KEYCODE_S;
        case XK_t:              return SAPP_KEYCODE_T;
        case XK_u:              return SAPP_KEYCODE_U;
        case XK_v:              return SAPP_KEYCODE_V;
        case XK_w:              return SAPP_KEYCODE_W;
        case XK_x:              return SAPP_KEYCODE_X;
        case XK_y:              return SAPP_KEYCODE_Y;
        case XK_z:              return SAPP_KEYCODE_Z;
        case XK_1:              return SAPP_KEYCODE_1;
        case XK_2:              return SAPP_KEYCODE_2;
        case XK_3:              return SAPP_KEYCODE_3;
        case XK_4:              return SAPP_KEYCODE_4;
        case XK_5:              return SAPP_KEYCODE_5;
        case XK_6:              return SAPP_KEYCODE_6;
        case XK_7:              return SAPP_KEYCODE_7;
        case XK_8:              return SAPP_KEYCODE_8;
        case XK_9:              return SAPP_KEYCODE_9;
        case XK_0:              return SAPP_KEYCODE_0;
        case XK_space:          return SAPP_KEYCODE_SPACE;
        case XK_minus:          return SAPP_KEYCODE_MINUS;
        case XK_equal:          return SAPP_KEYCODE_EQUAL;
        case XK_bracketleft:    return SAPP_KEYCODE_LEFT_BRACKET;
        case XK_bracketright:   return SAPP_KEYCODE_RIGHT_BRACKET;
        case XK_backslash:      return SAPP_KEYCODE_BACKSLASH;
        case XK_semicolon:      return SAPP_KEYCODE_SEMICOLON;
        case XK_apostrophe:     return SAPP_KEYCODE_APOSTROPHE;
        case XK_grave:          return SAPP_KEYCODE_GRAVE_ACCENT;
        case XK_comma:          return SAPP_KEYCODE_COMMA;
        case XK_period:         return SAPP_KEYCODE_PERIOD;
        case XK_slash:          return SAPP_KEYCODE_SLASH;
        case XK_less:           return SAPP_KEYCODE_WORLD_1; // At least in some layouts...
        default:                break;
    }

    // no matching translation was found
    return SAPP_KEYCODE_INVALID;
}


// setup dynamic keycode/scancode mapping tables, this is required
// for getting layout-independent keycodes on X11.
//
// see GLFW x11_init.c/createKeyTables()
_SOKOL_PRIVATE void _sapp_x11_init_keytable(void) {
    for (int i = 0; i < SAPP_MAX_KEYCODES; i++) {
        _sapp.keycodes[i] = SAPP_KEYCODE_INVALID;
    }
    // use XKB to determine physical key locations independently of the current keyboard layout
    XkbDescPtr desc = XkbGetMap(_sapp.x11.display, 0, XkbUseCoreKbd);
    SOKOL_ASSERT(desc);
    XkbGetNames(_sapp.x11.display, XkbKeyNamesMask | XkbKeyAliasesMask, desc);

    const int scancode_min = desc->min_key_code;
    const int scancode_max = desc->max_key_code;

    const struct { sapp_keycode key; const char* name; } keymap[] = {
        { SAPP_KEYCODE_GRAVE_ACCENT, "TLDE" },
        { SAPP_KEYCODE_1, "AE01" },
        { SAPP_KEYCODE_2, "AE02" },
        { SAPP_KEYCODE_3, "AE03" },
        { SAPP_KEYCODE_4, "AE04" },
        { SAPP_KEYCODE_5, "AE05" },
        { SAPP_KEYCODE_6, "AE06" },
        { SAPP_KEYCODE_7, "AE07" },
        { SAPP_KEYCODE_8, "AE08" },
        { SAPP_KEYCODE_9, "AE09" },
        { SAPP_KEYCODE_0, "AE10" },
        { SAPP_KEYCODE_MINUS, "AE11" },
        { SAPP_KEYCODE_EQUAL, "AE12" },
        { SAPP_KEYCODE_Q, "AD01" },
        { SAPP_KEYCODE_W, "AD02" },
        { SAPP_KEYCODE_E, "AD03" },
        { SAPP_KEYCODE_R, "AD04" },
        { SAPP_KEYCODE_T, "AD05" },
        { SAPP_KEYCODE_Y, "AD06" },
        { SAPP_KEYCODE_U, "AD07" },
        { SAPP_KEYCODE_I, "AD08" },
        { SAPP_KEYCODE_O, "AD09" },
        { SAPP_KEYCODE_P, "AD10" },
        { SAPP_KEYCODE_LEFT_BRACKET, "AD11" },
        { SAPP_KEYCODE_RIGHT_BRACKET, "AD12" },
        { SAPP_KEYCODE_A, "AC01" },
        { SAPP_KEYCODE_S, "AC02" },
        { SAPP_KEYCODE_D, "AC03" },
        { SAPP_KEYCODE_F, "AC04" },
        { SAPP_KEYCODE_G, "AC05" },
        { SAPP_KEYCODE_H, "AC06" },
        { SAPP_KEYCODE_J, "AC07" },
        { SAPP_KEYCODE_K, "AC08" },
        { SAPP_KEYCODE_L, "AC09" },
        { SAPP_KEYCODE_SEMICOLON, "AC10" },
        { SAPP_KEYCODE_APOSTROPHE, "AC11" },
        { SAPP_KEYCODE_Z, "AB01" },
        { SAPP_KEYCODE_X, "AB02" },
        { SAPP_KEYCODE_C, "AB03" },
        { SAPP_KEYCODE_V, "AB04" },
        { SAPP_KEYCODE_B, "AB05" },
        { SAPP_KEYCODE_N, "AB06" },
        { SAPP_KEYCODE_M, "AB07" },
        { SAPP_KEYCODE_COMMA, "AB08" },
        { SAPP_KEYCODE_PERIOD, "AB09" },
        { SAPP_KEYCODE_SLASH, "AB10" },
        { SAPP_KEYCODE_BACKSLASH, "BKSL" },
        { SAPP_KEYCODE_WORLD_1, "LSGT" },
        { SAPP_KEYCODE_SPACE, "SPCE" },
        { SAPP_KEYCODE_ESCAPE, "ESC" },
        { SAPP_KEYCODE_ENTER, "RTRN" },
        { SAPP_KEYCODE_TAB, "TAB" },
        { SAPP_KEYCODE_BACKSPACE, "BKSP" },
        { SAPP_KEYCODE_INSERT, "INS" },
        { SAPP_KEYCODE_DELETE, "DELE" },
        { SAPP_KEYCODE_RIGHT, "RGHT" },
        { SAPP_KEYCODE_LEFT, "LEFT" },
        { SAPP_KEYCODE_DOWN, "DOWN" },
        { SAPP_KEYCODE_UP, "UP" },
        { SAPP_KEYCODE_PAGE_UP, "PGUP" },
        { SAPP_KEYCODE_PAGE_DOWN, "PGDN" },
        { SAPP_KEYCODE_HOME, "HOME" },
        { SAPP_KEYCODE_END, "END" },
        { SAPP_KEYCODE_CAPS_LOCK, "CAPS" },
        { SAPP_KEYCODE_SCROLL_LOCK, "SCLK" },
        { SAPP_KEYCODE_NUM_LOCK, "NMLK" },
        { SAPP_KEYCODE_PRINT_SCREEN, "PRSC" },
        { SAPP_KEYCODE_PAUSE, "PAUS" },
        { SAPP_KEYCODE_F1, "FK01" },
        { SAPP_KEYCODE_F2, "FK02" },
        { SAPP_KEYCODE_F3, "FK03" },
        { SAPP_KEYCODE_F4, "FK04" },
        { SAPP_KEYCODE_F5, "FK05" },
        { SAPP_KEYCODE_F6, "FK06" },
        { SAPP_KEYCODE_F7, "FK07" },
        { SAPP_KEYCODE_F8, "FK08" },
        { SAPP_KEYCODE_F9, "FK09" },
        { SAPP_KEYCODE_F10, "FK10" },
        { SAPP_KEYCODE_F11, "FK11" },
        { SAPP_KEYCODE_F12, "FK12" },
        { SAPP_KEYCODE_F13, "FK13" },
        { SAPP_KEYCODE_F14, "FK14" },
        { SAPP_KEYCODE_F15, "FK15" },
        { SAPP_KEYCODE_F16, "FK16" },
        { SAPP_KEYCODE_F17, "FK17" },
        { SAPP_KEYCODE_F18, "FK18" },
        { SAPP_KEYCODE_F19, "FK19" },
        { SAPP_KEYCODE_F20, "FK20" },
        { SAPP_KEYCODE_F21, "FK21" },
        { SAPP_KEYCODE_F22, "FK22" },
        { SAPP_KEYCODE_F23, "FK23" },
        { SAPP_KEYCODE_F24, "FK24" },
        { SAPP_KEYCODE_F25, "FK25" },
        { SAPP_KEYCODE_KP_0, "KP0" },
        { SAPP_KEYCODE_KP_1, "KP1" },
        { SAPP_KEYCODE_KP_2, "KP2" },
        { SAPP_KEYCODE_KP_3, "KP3" },
        { SAPP_KEYCODE_KP_4, "KP4" },
        { SAPP_KEYCODE_KP_5, "KP5" },
        { SAPP_KEYCODE_KP_6, "KP6" },
        { SAPP_KEYCODE_KP_7, "KP7" },
        { SAPP_KEYCODE_KP_8, "KP8" },
        { SAPP_KEYCODE_KP_9, "KP9" },
        { SAPP_KEYCODE_KP_DECIMAL, "KPDL" },
        { SAPP_KEYCODE_KP_DIVIDE, "KPDV" },
        { SAPP_KEYCODE_KP_MULTIPLY, "KPMU" },
        { SAPP_KEYCODE_KP_SUBTRACT, "KPSU" },
        { SAPP_KEYCODE_KP_ADD, "KPAD" },
        { SAPP_KEYCODE_KP_ENTER, "KPEN" },
        { SAPP_KEYCODE_KP_EQUAL, "KPEQ" },
        { SAPP_KEYCODE_LEFT_SHIFT, "LFSH" },
        { SAPP_KEYCODE_LEFT_CONTROL, "LCTL" },
        { SAPP_KEYCODE_LEFT_ALT, "LALT" },
        { SAPP_KEYCODE_LEFT_SUPER, "LWIN" },
        { SAPP_KEYCODE_RIGHT_SHIFT, "RTSH" },
        { SAPP_KEYCODE_RIGHT_CONTROL, "RCTL" },
        { SAPP_KEYCODE_RIGHT_ALT, "RALT" },
        { SAPP_KEYCODE_RIGHT_ALT, "LVL3" },
        { SAPP_KEYCODE_RIGHT_ALT, "MDSW" },
        { SAPP_KEYCODE_RIGHT_SUPER, "RWIN" },
        { SAPP_KEYCODE_MENU, "MENU" }
    };
    const int num_keymap_items = (int)(sizeof(keymap) / sizeof(keymap[0]));

    // find X11 keycode to sokol-app key code mapping
    for (int scancode = scancode_min; scancode <= scancode_max; scancode++) {
        sapp_keycode key = SAPP_KEYCODE_INVALID;
        for (int i = 0; i < num_keymap_items; i++) {
            if (strncmp(desc->names->keys[scancode].name, keymap[i].name, XkbKeyNameLength) == 0) {
                key = keymap[i].key;
                break;
            }
        }

        // fall back to key aliases in case the key name did not match
        for (int i = 0; i < desc->names->num_key_aliases; i++) {
            if (key != SAPP_KEYCODE_INVALID) {
                break;
            }
            if (strncmp(desc->names->key_aliases[i].real, desc->names->keys[scancode].name, XkbKeyNameLength) != 0) {
                continue;
            }
            for (int j = 0; j < num_keymap_items; j++) {
                if (strncmp(desc->names->key_aliases[i].alias, keymap[i].name, XkbKeyNameLength) == 0) {
                    key = keymap[i].key;
                    break;
                }
            }
        }
        _sapp.keycodes[scancode] = key;
    }
    XkbFreeNames(desc, XkbKeyNamesMask, True);
    XkbFreeKeyboard(desc, 0, True);

    int width = 0;
    KeySym* keysyms = XGetKeyboardMapping(_sapp.x11.display, scancode_min, scancode_max - scancode_min + 1, &width);
    for (int scancode = scancode_min; scancode <= scancode_max; scancode++) {
        // translate untranslated key codes using the traditional X11 KeySym lookups
        if (_sapp.keycodes[scancode] == SAPP_KEYCODE_INVALID) {
            const size_t base = (size_t)((scancode - scancode_min) * width);
            _sapp.keycodes[scancode] = _sapp_x11_translate_keysyms(&keysyms[base], width);
        }
    }
    XFree(keysyms);
}

_SOKOL_PRIVATE void _sapp_x11_query_system_dpi(void) {
    /* from GLFW:

       NOTE: Default to the display-wide DPI as we don't currently have a policy
             for which monitor a window is considered to be on

        _sapp.x11.dpi = DisplayWidth(_sapp.x11.display, _sapp.x11.screen) *
                        25.4f / DisplayWidthMM(_sapp.x11.display, _sapp.x11.screen);

       NOTE: Basing the scale on Xft.dpi where available should provide the most
             consistent user experience (matches Qt, Gtk, etc), although not
             always the most accurate one
    */
    bool dpi_ok = false;
    char* rms = XResourceManagerString(_sapp.x11.display);
    if (rms) {
        XrmDatabase db = XrmGetStringDatabase(rms);
        if (db) {
            XrmValue value;
            char* type = NULL;
            if (XrmGetResource(db, "Xft.dpi", "Xft.Dpi", &type, &value)) {
                if (type && strcmp(type, "String") == 0) {
                    _sapp.x11.dpi = atof(value.addr);
                    dpi_ok = true;
                }
            }
            XrmDestroyDatabase(db);
        }
    }
    // fallback if querying DPI had failed: assume the standard DPI 96.0f
    if (!dpi_ok) {
        _sapp.x11.dpi = 96.0f;
        _SAPP_WARN(LINUX_X11_QUERY_SYSTEM_DPI_FAILED);
    }
}

#if defined(_SAPP_GLX)

_SOKOL_PRIVATE bool _sapp_glx_has_ext(const char* ext, const char* extensions) {
    SOKOL_ASSERT(ext);
    const char* start = extensions;
    while (true) {
        const char* where = strstr(start, ext);
        if (!where) {
            return false;
        }
        const char* terminator = where + strlen(ext);
        if ((where == start) || (*(where - 1) == ' ')) {
            if (*terminator == ' ' || *terminator == '\0') {
                break;
            }
        }
        start = terminator;
    }
    return true;
}

_SOKOL_PRIVATE bool _sapp_glx_extsupported(const char* ext, const char* extensions) {
    if (extensions) {
        return _sapp_glx_has_ext(ext, extensions);
    }
    else {
        return false;
    }
}

_SOKOL_PRIVATE void* _sapp_glx_getprocaddr(const char* procname)
{
    if (_sapp.glx.GetProcAddress) {
        return (void*) _sapp.glx.GetProcAddress(procname);
    }
    else if (_sapp.glx.GetProcAddressARB) {
        return (void*) _sapp.glx.GetProcAddressARB(procname);
    }
    else {
        return dlsym(_sapp.glx.libgl, procname);
    }
}

_SOKOL_PRIVATE void _sapp_glx_init(void) {
    const char* sonames[] = { "libGL.so.1", "libGL.so", 0 };
    for (int i = 0; sonames[i]; i++) {
        _sapp.glx.libgl = dlopen(sonames[i], RTLD_LAZY|RTLD_GLOBAL);
        if (_sapp.glx.libgl) {
            break;
        }
    }
    if (!_sapp.glx.libgl) {
        _SAPP_PANIC(LINUX_GLX_LOAD_LIBGL_FAILED);
    }
    _sapp.glx.GetFBConfigs          = (PFNGLXGETFBCONFIGSPROC)          dlsym(_sapp.glx.libgl, "glXGetFBConfigs");
    _sapp.glx.GetFBConfigAttrib     = (PFNGLXGETFBCONFIGATTRIBPROC)     dlsym(_sapp.glx.libgl, "glXGetFBConfigAttrib");
    _sapp.glx.GetClientString       = (PFNGLXGETCLIENTSTRINGPROC)       dlsym(_sapp.glx.libgl, "glXGetClientString");
    _sapp.glx.QueryExtension        = (PFNGLXQUERYEXTENSIONPROC)        dlsym(_sapp.glx.libgl, "glXQueryExtension");
    _sapp.glx.QueryVersion          = (PFNGLXQUERYVERSIONPROC)          dlsym(_sapp.glx.libgl, "glXQueryVersion");
    _sapp.glx.DestroyContext        = (PFNGLXDESTROYCONTEXTPROC)        dlsym(_sapp.glx.libgl, "glXDestroyContext");
    _sapp.glx.MakeCurrent           = (PFNGLXMAKECURRENTPROC)           dlsym(_sapp.glx.libgl, "glXMakeCurrent");
    _sapp.glx.SwapBuffers           = (PFNGLXSWAPBUFFERSPROC)           dlsym(_sapp.glx.libgl, "glXSwapBuffers");
    _sapp.glx.QueryExtensionsString = (PFNGLXQUERYEXTENSIONSSTRINGPROC) dlsym(_sapp.glx.libgl, "glXQueryExtensionsString");
    _sapp.glx.CreateWindow          = (PFNGLXCREATEWINDOWPROC)          dlsym(_sapp.glx.libgl, "glXCreateWindow");
    _sapp.glx.DestroyWindow         = (PFNGLXDESTROYWINDOWPROC)         dlsym(_sapp.glx.libgl, "glXDestroyWindow");
    _sapp.glx.GetProcAddress        = (PFNGLXGETPROCADDRESSPROC)        dlsym(_sapp.glx.libgl, "glXGetProcAddress");
    _sapp.glx.GetProcAddressARB     = (PFNGLXGETPROCADDRESSPROC)        dlsym(_sapp.glx.libgl, "glXGetProcAddressARB");
    _sapp.glx.GetVisualFromFBConfig = (PFNGLXGETVISUALFROMFBCONFIGPROC) dlsym(_sapp.glx.libgl, "glXGetVisualFromFBConfig");
    if (!_sapp.glx.GetFBConfigs ||
        !_sapp.glx.GetFBConfigAttrib ||
        !_sapp.glx.GetClientString ||
        !_sapp.glx.QueryExtension ||
        !_sapp.glx.QueryVersion ||
        !_sapp.glx.DestroyContext ||
        !_sapp.glx.MakeCurrent ||
        !_sapp.glx.SwapBuffers ||
        !_sapp.glx.QueryExtensionsString ||
        !_sapp.glx.CreateWindow ||
        !_sapp.glx.DestroyWindow ||
        !_sapp.glx.GetProcAddress ||
        !_sapp.glx.GetProcAddressARB ||
        !_sapp.glx.GetVisualFromFBConfig)
    {
        _SAPP_PANIC(LINUX_GLX_LOAD_ENTRY_POINTS_FAILED);
    }

    if (!_sapp.glx.QueryExtension(_sapp.x11.display, &_sapp.glx.error_base, &_sapp.glx.event_base)) {
        _SAPP_PANIC(LINUX_GLX_EXTENSION_NOT_FOUND);
    }
    if (!_sapp.glx.QueryVersion(_sapp.x11.display, &_sapp.glx.major, &_sapp.glx.minor)) {
        _SAPP_PANIC(LINUX_GLX_QUERY_VERSION_FAILED);
    }
    if (_sapp.glx.major == 1 && _sapp.glx.minor < 3) {
        _SAPP_PANIC(LINUX_GLX_VERSION_TOO_LOW);
    }
    const char* exts = _sapp.glx.QueryExtensionsString(_sapp.x11.display, _sapp.x11.screen);
    if (_sapp_glx_extsupported("GLX_EXT_swap_control", exts)) {
        _sapp.glx.SwapIntervalEXT = (PFNGLXSWAPINTERVALEXTPROC) _sapp_glx_getprocaddr("glXSwapIntervalEXT");
        _sapp.glx.EXT_swap_control = 0 != _sapp.glx.SwapIntervalEXT;
    }
    if (_sapp_glx_extsupported("GLX_MESA_swap_control", exts)) {
        _sapp.glx.SwapIntervalMESA = (PFNGLXSWAPINTERVALMESAPROC) _sapp_glx_getprocaddr("glXSwapIntervalMESA");
        _sapp.glx.MESA_swap_control = 0 != _sapp.glx.SwapIntervalMESA;
    }
    _sapp.glx.ARB_multisample = _sapp_glx_extsupported("GLX_ARB_multisample", exts);
    if (_sapp_glx_extsupported("GLX_ARB_create_context", exts)) {
        _sapp.glx.CreateContextAttribsARB = (PFNGLXCREATECONTEXTATTRIBSARBPROC) _sapp_glx_getprocaddr("glXCreateContextAttribsARB");
        _sapp.glx.ARB_create_context = 0 != _sapp.glx.CreateContextAttribsARB;
    }
    _sapp.glx.ARB_create_context_profile = _sapp_glx_extsupported("GLX_ARB_create_context_profile", exts);
}

_SOKOL_PRIVATE int _sapp_glx_attrib(GLXFBConfig fbconfig, int attrib) {
    int value;
    _sapp.glx.GetFBConfigAttrib(_sapp.x11.display, fbconfig, attrib, &value);
    return value;
}

_SOKOL_PRIVATE GLXFBConfig _sapp_glx_choosefbconfig(void) {
    GLXFBConfig* native_configs;
    _sapp_gl_fbconfig* usable_configs;
    const _sapp_gl_fbconfig* closest;
    int i, native_count, usable_count;
    const char* vendor;
    bool trust_window_bit = true;

    /* HACK: This is a (hopefully temporary) workaround for Chromium
           (VirtualBox GL) not setting the window bit on any GLXFBConfigs
    */
    vendor = _sapp.glx.GetClientString(_sapp.x11.display, GLX_VENDOR);
    if (vendor && strcmp(vendor, "Chromium") == 0) {
        trust_window_bit = false;
    }

    native_configs = _sapp.glx.GetFBConfigs(_sapp.x11.display, _sapp.x11.screen, &native_count);
    if (!native_configs || !native_count) {
        _SAPP_PANIC(LINUX_GLX_NO_GLXFBCONFIGS);
    }

    usable_configs = (_sapp_gl_fbconfig*) _sapp_malloc_clear((size_t)native_count * sizeof(_sapp_gl_fbconfig));
    usable_count = 0;
    for (i = 0;  i < native_count;  i++) {
        const GLXFBConfig n = native_configs[i];
        _sapp_gl_fbconfig* u = usable_configs + usable_count;
        _sapp_gl_init_fbconfig(u);

        /* Only consider RGBA GLXFBConfigs */
        if (0 == (_sapp_glx_attrib(n, GLX_RENDER_TYPE) & GLX_RGBA_BIT)) {
            continue;
        }
        /* Only consider window GLXFBConfigs */
        if (0 == (_sapp_glx_attrib(n, GLX_DRAWABLE_TYPE) & GLX_WINDOW_BIT)) {
            if (trust_window_bit) {
                continue;
            }
        }
        u->red_bits = _sapp_glx_attrib(n, GLX_RED_SIZE);
        u->green_bits = _sapp_glx_attrib(n, GLX_GREEN_SIZE);
        u->blue_bits = _sapp_glx_attrib(n, GLX_BLUE_SIZE);
        u->alpha_bits = _sapp_glx_attrib(n, GLX_ALPHA_SIZE);
        u->depth_bits = _sapp_glx_attrib(n, GLX_DEPTH_SIZE);
        u->stencil_bits = _sapp_glx_attrib(n, GLX_STENCIL_SIZE);
        if (_sapp_glx_attrib(n, GLX_DOUBLEBUFFER)) {
            u->doublebuffer = true;
        }
        if (_sapp.glx.ARB_multisample) {
            u->samples = _sapp_glx_attrib(n, GLX_SAMPLES);
        }
        u->handle = (uintptr_t) n;
        usable_count++;
    }
    _sapp_gl_fbconfig desired;
    _sapp_gl_init_fbconfig(&desired);
    desired.red_bits = 8;
    desired.green_bits = 8;
    desired.blue_bits = 8;
    desired.alpha_bits = 8;
    desired.depth_bits = 24;
    desired.stencil_bits = 8;
    desired.doublebuffer = true;
    desired.samples = _sapp.sample_count > 1 ? _sapp.sample_count : 0;
    closest = _sapp_gl_choose_fbconfig(&desired, usable_configs, usable_count);
    GLXFBConfig result = 0;
    if (closest) {
        result = (GLXFBConfig) closest->handle;
    }
    XFree(native_configs);
    _sapp_free(usable_configs);
    return result;
}

_SOKOL_PRIVATE void _sapp_glx_choose_visual(Visual** visual, int* depth) {
    GLXFBConfig native = _sapp_glx_choosefbconfig();
    if (0 == native) {
        _SAPP_PANIC(LINUX_GLX_NO_SUITABLE_GLXFBCONFIG);
    }
    XVisualInfo* result = _sapp.glx.GetVisualFromFBConfig(_sapp.x11.display, native);
    if (!result) {
        _SAPP_PANIC(LINUX_GLX_GET_VISUAL_FROM_FBCONFIG_FAILED);
    }
    *visual = result->visual;
    *depth = result->depth;
    XFree(result);
}

_SOKOL_PRIVATE void _sapp_glx_make_current(void) {
    _sapp.glx.MakeCurrent(_sapp.x11.display, _sapp.glx.window, _sapp.glx.ctx);
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&_sapp.gl.framebuffer);
}

_SOKOL_PRIVATE void _sapp_glx_create_context(void) {
    GLXFBConfig native = _sapp_glx_choosefbconfig();
    if (0 == native){
        _SAPP_PANIC(LINUX_GLX_NO_SUITABLE_GLXFBCONFIG);
    }
    if (!(_sapp.glx.ARB_create_context && _sapp.glx.ARB_create_context_profile)) {
        _SAPP_PANIC(LINUX_GLX_REQUIRED_EXTENSIONS_MISSING);
    }
    _sapp_x11_grab_error_handler();
    const int attribs[] = {
        GLX_CONTEXT_MAJOR_VERSION_ARB, _sapp.desc.gl_major_version,
        GLX_CONTEXT_MINOR_VERSION_ARB, _sapp.desc.gl_minor_version,
        GLX_CONTEXT_PROFILE_MASK_ARB, GLX_CONTEXT_CORE_PROFILE_BIT_ARB,
        GLX_CONTEXT_FLAGS_ARB, GLX_CONTEXT_FORWARD_COMPATIBLE_BIT_ARB,
        0, 0
    };
    _sapp.glx.ctx = _sapp.glx.CreateContextAttribsARB(_sapp.x11.display, native, NULL, True, attribs);
    if (!_sapp.glx.ctx) {
        _SAPP_PANIC(LINUX_GLX_CREATE_CONTEXT_FAILED);
    }
    _sapp_x11_release_error_handler();
    _sapp.glx.window = _sapp.glx.CreateWindow(_sapp.x11.display, native, _sapp.x11.window, NULL);
    if (!_sapp.glx.window) {
        _SAPP_PANIC(LINUX_GLX_CREATE_WINDOW_FAILED);
    }
    _sapp_glx_make_current();
}

_SOKOL_PRIVATE void _sapp_glx_destroy_context(void) {
    if (_sapp.glx.window) {
        _sapp.glx.DestroyWindow(_sapp.x11.display, _sapp.glx.window);
        _sapp.glx.window = 0;
    }
    if (_sapp.glx.ctx) {
        _sapp.glx.DestroyContext(_sapp.x11.display, _sapp.glx.ctx);
        _sapp.glx.ctx = 0;
    }
}

_SOKOL_PRIVATE void _sapp_glx_swap_buffers(void) {
    _sapp.glx.SwapBuffers(_sapp.x11.display, _sapp.glx.window);
}

_SOKOL_PRIVATE void _sapp_glx_swapinterval(int interval) {
    if (_sapp.glx.EXT_swap_control) {
        _sapp.glx.SwapIntervalEXT(_sapp.x11.display, _sapp.glx.window, interval);
    }
    else if (_sapp.glx.MESA_swap_control) {
        _sapp.glx.SwapIntervalMESA(interval);
    }
}

#endif /* _SAPP_GLX */

_SOKOL_PRIVATE void _sapp_x11_send_event(Atom type, int a, int b, int c, int d, int e) {
    XEvent event;
    _sapp_clear(&event, sizeof(event));

    event.type = ClientMessage;
    event.xclient.window = _sapp.x11.window;
    event.xclient.format = 32;
    event.xclient.message_type = type;
    event.xclient.data.l[0] = a;
    event.xclient.data.l[1] = b;
    event.xclient.data.l[2] = c;
    event.xclient.data.l[3] = d;
    event.xclient.data.l[4] = e;

    XSendEvent(_sapp.x11.display, _sapp.x11.root,
               False,
               SubstructureNotifyMask | SubstructureRedirectMask,
               &event);
}

_SOKOL_PRIVATE void _sapp_x11_query_window_size(void) {
    XWindowAttributes attribs;
    XGetWindowAttributes(_sapp.x11.display, _sapp.x11.window, &attribs);
    _sapp.window_width = attribs.width;
    _sapp.window_height = attribs.height;
    _sapp.framebuffer_width = _sapp.window_width;
    _sapp.framebuffer_height = _sapp.window_height;
}

_SOKOL_PRIVATE void _sapp_x11_set_fullscreen(bool enable) {
    /* NOTE: this function must be called after XMapWindow (which happens in _sapp_x11_show_window()) */
    if (_sapp.x11.NET_WM_STATE && _sapp.x11.NET_WM_STATE_FULLSCREEN) {
        if (enable) {
            const int _NET_WM_STATE_ADD = 1;
            _sapp_x11_send_event(_sapp.x11.NET_WM_STATE,
                                _NET_WM_STATE_ADD,
                                _sapp.x11.NET_WM_STATE_FULLSCREEN,
                                0, 1, 0);
        }
        else {
            const int _NET_WM_STATE_REMOVE = 0;
            _sapp_x11_send_event(_sapp.x11.NET_WM_STATE,
                                _NET_WM_STATE_REMOVE,
                                _sapp.x11.NET_WM_STATE_FULLSCREEN,
                                0, 1, 0);
        }
    }
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE void _sapp_x11_create_hidden_cursor(void) {
    SOKOL_ASSERT(0 == _sapp.x11.hidden_cursor);
    const int w = 16;
    const int h = 16;
    XcursorImage* img = XcursorImageCreate(w, h);
    SOKOL_ASSERT(img && (img->width == 16) && (img->height == 16) && img->pixels);
    img->xhot = 0;
    img->yhot = 0;
    const size_t num_bytes = (size_t)(w * h) * sizeof(XcursorPixel);
    _sapp_clear(img->pixels, num_bytes);
    _sapp.x11.hidden_cursor = XcursorImageLoadCursor(_sapp.x11.display, img);
    XcursorImageDestroy(img);
}

 _SOKOL_PRIVATE void _sapp_x11_create_standard_cursor(sapp_mouse_cursor cursor, const char* name, const char* theme, int size, uint32_t fallback_native) {
    SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
    SOKOL_ASSERT(_sapp.x11.display);
    if (theme) {
        XcursorImage* img = XcursorLibraryLoadImage(name, theme, size);
        if (img) {
            _sapp.x11.cursors[cursor] = XcursorImageLoadCursor(_sapp.x11.display, img);
            XcursorImageDestroy(img);
        }
    }
    if (0 == _sapp.x11.cursors[cursor]) {
        _sapp.x11.cursors[cursor] = XCreateFontCursor(_sapp.x11.display, fallback_native);
    }
}

_SOKOL_PRIVATE void _sapp_x11_create_cursors(void) {
    SOKOL_ASSERT(_sapp.x11.display);
    const char* cursor_theme = XcursorGetTheme(_sapp.x11.display);
    const int size = XcursorGetDefaultSize(_sapp.x11.display);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_ARROW, "default", cursor_theme, size, XC_left_ptr);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_IBEAM, "text", cursor_theme, size, XC_xterm);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_CROSSHAIR, "crosshair", cursor_theme, size, XC_crosshair);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_POINTING_HAND, "pointer", cursor_theme, size, XC_hand2);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_RESIZE_EW, "ew-resize", cursor_theme, size, XC_sb_h_double_arrow);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_RESIZE_NS, "ns-resize", cursor_theme, size, XC_sb_v_double_arrow);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_RESIZE_NWSE, "nwse-resize", cursor_theme, size, 0);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_RESIZE_NESW, "nesw-resize", cursor_theme, size, 0);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_RESIZE_ALL, "all-scroll", cursor_theme, size, XC_fleur);
    _sapp_x11_create_standard_cursor(SAPP_MOUSECURSOR_NOT_ALLOWED, "no-allowed", cursor_theme, size, 0);
    _sapp_x11_create_hidden_cursor();
}

_SOKOL_PRIVATE void _sapp_x11_destroy_cursors(void) {
    SOKOL_ASSERT(_sapp.x11.display);
    if (_sapp.x11.hidden_cursor) {
        XFreeCursor(_sapp.x11.display, _sapp.x11.hidden_cursor);
        _sapp.x11.hidden_cursor = 0;
    }
    for (int i = 0; i < _SAPP_MOUSECURSOR_NUM; i++) {
        if (_sapp.x11.cursors[i]) {
            XFreeCursor(_sapp.x11.display, _sapp.x11.cursors[i]);
            _sapp.x11.cursors[i] = 0;
        }
    }
}

_SOKOL_PRIVATE void _sapp_x11_toggle_fullscreen(void) {
    _sapp.fullscreen = !_sapp.fullscreen;
    _sapp_x11_set_fullscreen(_sapp.fullscreen);
    _sapp_x11_query_window_size();
}

_SOKOL_PRIVATE void _sapp_x11_update_cursor(sapp_mouse_cursor cursor, bool shown) {
    SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
    if (shown) {
        if (_sapp.x11.cursors[cursor]) {
            XDefineCursor(_sapp.x11.display, _sapp.x11.window, _sapp.x11.cursors[cursor]);
        }
        else {
            XUndefineCursor(_sapp.x11.display, _sapp.x11.window);
        }
    }
    else {
        XDefineCursor(_sapp.x11.display, _sapp.x11.window, _sapp.x11.hidden_cursor);
    }
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE void _sapp_x11_lock_mouse(bool lock) {
    if (lock == _sapp.mouse.locked) {
        return;
    }
    _sapp.mouse.dx = 0.0f;
    _sapp.mouse.dy = 0.0f;
    _sapp.mouse.locked = lock;
    if (_sapp.mouse.locked) {
        if (_sapp.x11.xi.available) {
            XIEventMask em;
            unsigned char mask[XIMaskLen(XI_RawMotion)] = { 0 }; // XIMaskLen is a macro
            em.deviceid = XIAllMasterDevices;
            em.mask_len = sizeof(mask);
            em.mask = mask;
            XISetMask(mask, XI_RawMotion);
            XISelectEvents(_sapp.x11.display, _sapp.x11.root, &em, 1);
        }
        XGrabPointer(_sapp.x11.display, // display
            _sapp.x11.window,           // grab_window
            True,                       // owner_events
            ButtonPressMask | ButtonReleaseMask | PointerMotionMask,    // event_mask
            GrabModeAsync,              // pointer_mode
            GrabModeAsync,              // keyboard_mode
            _sapp.x11.window,           // confine_to
            _sapp.x11.hidden_cursor,    // cursor
            CurrentTime);               // time
    }
    else {
        if (_sapp.x11.xi.available) {
            XIEventMask em;
            unsigned char mask[] = { 0 };
            em.deviceid = XIAllMasterDevices;
            em.mask_len = sizeof(mask);
            em.mask = mask;
            XISelectEvents(_sapp.x11.display, _sapp.x11.root, &em, 1);
        }
        XWarpPointer(_sapp.x11.display, None, _sapp.x11.window, 0, 0, 0, 0, (int) _sapp.mouse.x, _sapp.mouse.y);
        XUngrabPointer(_sapp.x11.display, CurrentTime);
    }
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE void _sapp_x11_set_clipboard_string(const char* str) {
    SOKOL_ASSERT(_sapp.clipboard.enabled && _sapp.clipboard.buffer);
    if (strlen(str) >= (size_t)_sapp.clipboard.buf_size) {
        _SAPP_ERROR(CLIPBOARD_STRING_TOO_BIG);
    }
    XSetSelectionOwner(_sapp.x11.display, _sapp.x11.CLIPBOARD, _sapp.x11.window, CurrentTime);
    if (XGetSelectionOwner(_sapp.x11.display, _sapp.x11.CLIPBOARD) != _sapp.x11.window) {
        _SAPP_ERROR(LINUX_X11_FAILED_TO_BECOME_OWNER_OF_CLIPBOARD);
    }
}

_SOKOL_PRIVATE const char* _sapp_x11_get_clipboard_string(void) {
    SOKOL_ASSERT(_sapp.clipboard.enabled && _sapp.clipboard.buffer);
    Atom none = XInternAtom(_sapp.x11.display, "SAPP_SELECTION", False);
    Atom incremental = XInternAtom(_sapp.x11.display, "INCR", False);
    if (XGetSelectionOwner(_sapp.x11.display, _sapp.x11.CLIPBOARD) == _sapp.x11.window) {
        // Instead of doing a large number of X round-trips just to put this
        // string into a window property and then read it back, just return it
        return _sapp.clipboard.buffer;
    }
    XConvertSelection(_sapp.x11.display,
                      _sapp.x11.CLIPBOARD,
                      _sapp.x11.UTF8_STRING,
                      none,
                      _sapp.x11.window,
                      CurrentTime);
    XEvent event;
    while (!XCheckTypedWindowEvent(_sapp.x11.display, _sapp.x11.window, SelectionNotify, &event)) {
        // Wait for event data to arrive on the X11 display socket
        struct pollfd fd = { ConnectionNumber(_sapp.x11.display), POLLIN };
        while (!XPending(_sapp.x11.display)) {
            poll(&fd, 1, -1);
        }
    }
    if (event.xselection.property == None) {
        return NULL;
    }
    char* data = NULL;
    Atom actualType;
    int actualFormat;
    unsigned long itemCount, bytesAfter;
    const bool ret = XGetWindowProperty(_sapp.x11.display,
                        event.xselection.requestor,
                        event.xselection.property,
                        0,
                        LONG_MAX,
                        True,
                        _sapp.x11.UTF8_STRING,
                        &actualType,
                        &actualFormat,
                        &itemCount,
                        &bytesAfter,
                        (unsigned char**) &data);
    if (ret != Success || data == NULL) {
        if (data != NULL) {
            XFree(data);
        }
        return NULL;
    }
    if ((actualType == incremental) || (itemCount >= (size_t)_sapp.clipboard.buf_size)) {
        _SAPP_ERROR(CLIPBOARD_STRING_TOO_BIG);
        XFree(data);
        return NULL;
    }
    _sapp_strcpy(data, _sapp.clipboard.buffer, _sapp.clipboard.buf_size);
    XFree(data);
    return _sapp.clipboard.buffer;
}

_SOKOL_PRIVATE void _sapp_x11_update_window_title(void) {
    Xutf8SetWMProperties(_sapp.x11.display,
        _sapp.x11.window,
        _sapp.window_title, _sapp.window_title,
        NULL, 0, NULL, NULL, NULL);
    XChangeProperty(_sapp.x11.display, _sapp.x11.window,
        _sapp.x11.NET_WM_NAME, _sapp.x11.UTF8_STRING, 8,
        PropModeReplace,
        (unsigned char*)_sapp.window_title,
        strlen(_sapp.window_title));
    XChangeProperty(_sapp.x11.display, _sapp.x11.window,
        _sapp.x11.NET_WM_ICON_NAME, _sapp.x11.UTF8_STRING, 8,
        PropModeReplace,
        (unsigned char*)_sapp.window_title,
        strlen(_sapp.window_title));
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE void _sapp_x11_set_icon(const sapp_icon_desc* icon_desc, int num_images) {
    SOKOL_ASSERT((num_images > 0) && (num_images <= SAPP_MAX_ICONIMAGES));
    int long_count = 0;
    for (int i = 0; i < num_images; i++) {
        const sapp_image_desc* img_desc = &icon_desc->images[i];
        long_count += 2 + (img_desc->width * img_desc->height);
    }
    long* icon_data = (long*) _sapp_malloc_clear((size_t)long_count * sizeof(long));
    SOKOL_ASSERT(icon_data);
    long* dst = icon_data;
    for (int img_index = 0; img_index < num_images; img_index++) {
        const sapp_image_desc* img_desc = &icon_desc->images[img_index];
        const uint8_t* src = (const uint8_t*) img_desc->pixels.ptr;
        *dst++ = img_desc->width;
        *dst++ = img_desc->height;
        const int num_pixels = img_desc->width * img_desc->height;
        for (int pixel_index = 0; pixel_index < num_pixels; pixel_index++) {
            *dst++ = ((long)(src[pixel_index * 4 + 0]) << 16) |
                     ((long)(src[pixel_index * 4 + 1]) << 8) |
                     ((long)(src[pixel_index * 4 + 2]) << 0) |
                     ((long)(src[pixel_index * 4 + 3]) << 24);
        }
    }
    XChangeProperty(_sapp.x11.display, _sapp.x11.window,
        _sapp.x11.NET_WM_ICON,
        XA_CARDINAL, 32,
        PropModeReplace,
        (unsigned char*)icon_data,
        long_count);
    _sapp_free(icon_data);
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE void _sapp_x11_create_window(Visual* visual, int depth) {
    _sapp.x11.colormap = XCreateColormap(_sapp.x11.display, _sapp.x11.root, visual, AllocNone);
    XSetWindowAttributes wa;
    _sapp_clear(&wa, sizeof(wa));
    const uint32_t wamask = CWBorderPixel | CWColormap | CWEventMask;
    wa.colormap = _sapp.x11.colormap;
    wa.border_pixel = 0;
    wa.event_mask = StructureNotifyMask | KeyPressMask | KeyReleaseMask |
                    PointerMotionMask | ButtonPressMask | ButtonReleaseMask |
                    ExposureMask | FocusChangeMask | VisibilityChangeMask |
                    EnterWindowMask | LeaveWindowMask | PropertyChangeMask;

    int display_width = DisplayWidth(_sapp.x11.display, _sapp.x11.screen);
    int display_height = DisplayHeight(_sapp.x11.display, _sapp.x11.screen);
    int window_width = (int)(_sapp.window_width * _sapp.dpi_scale);
    int window_height = (int)(_sapp.window_height * _sapp.dpi_scale);
    if (0 == window_width) {
        window_width = (display_width * 4) / 5;
    }
    if (0 == window_height) {
        window_height = (display_height * 4) / 5;
    }
    _sapp_x11_grab_error_handler();
    _sapp.x11.window = XCreateWindow(_sapp.x11.display,
                                     _sapp.x11.root,
                                     0, 0,
                                     (uint32_t)window_width,
                                     (uint32_t)window_height,
                                     0,     /* border width */
                                     depth, /* color depth */
                                     InputOutput,
                                     visual,
                                     wamask,
                                     &wa);
    _sapp_x11_release_error_handler();
    if (!_sapp.x11.window) {
        _SAPP_PANIC(LINUX_X11_CREATE_WINDOW_FAILED);
    }
    Atom protocols[] = {
        _sapp.x11.WM_DELETE_WINDOW
    };
    XSetWMProtocols(_sapp.x11.display, _sapp.x11.window, protocols, 1);

    // NOTE: PPosition and PSize are obsolete and ignored
    XSizeHints* hints = XAllocSizeHints();
    hints->flags = PWinGravity;
    hints->win_gravity = CenterGravity;
    XSetWMNormalHints(_sapp.x11.display, _sapp.x11.window, hints);
    XFree(hints);

    // announce support for drag'n'drop
    if (_sapp.drop.enabled) {
        const Atom version = _SAPP_X11_XDND_VERSION;
        XChangeProperty(_sapp.x11.display, _sapp.x11.window, _sapp.x11.xdnd.XdndAware, XA_ATOM, 32, PropModeReplace, (unsigned char*) &version, 1);
    }
    _sapp_x11_update_window_title();
    _sapp_x11_query_window_size();
}

_SOKOL_PRIVATE void _sapp_x11_destroy_window(void) {
    if (_sapp.x11.window) {
        XUnmapWindow(_sapp.x11.display, _sapp.x11.window);
        XDestroyWindow(_sapp.x11.display, _sapp.x11.window);
        _sapp.x11.window = 0;
    }
    if (_sapp.x11.colormap) {
        XFreeColormap(_sapp.x11.display, _sapp.x11.colormap);
        _sapp.x11.colormap = 0;
    }
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE bool _sapp_x11_window_visible(void) {
    XWindowAttributes wa;
    XGetWindowAttributes(_sapp.x11.display, _sapp.x11.window, &wa);
    return wa.map_state == IsViewable;
}

_SOKOL_PRIVATE void _sapp_x11_show_window(void) {
    if (!_sapp_x11_window_visible()) {
        XMapWindow(_sapp.x11.display, _sapp.x11.window);
        XRaiseWindow(_sapp.x11.display, _sapp.x11.window);
        XFlush(_sapp.x11.display);
    }
}

_SOKOL_PRIVATE void _sapp_x11_hide_window(void) {
    XUnmapWindow(_sapp.x11.display, _sapp.x11.window);
    XFlush(_sapp.x11.display);
}

_SOKOL_PRIVATE unsigned long _sapp_x11_get_window_property(Window window, Atom property, Atom type, unsigned char** value) {
    Atom actualType;
    int actualFormat;
    unsigned long itemCount, bytesAfter;
    XGetWindowProperty(_sapp.x11.display,
                       window,
                       property,
                       0,
                       LONG_MAX,
                       False,
                       type,
                       &actualType,
                       &actualFormat,
                       &itemCount,
                       &bytesAfter,
                       value);
    return itemCount;
}

_SOKOL_PRIVATE int _sapp_x11_get_window_state(void) {
    int result = WithdrawnState;
    struct {
        CARD32 state;
        Window icon;
    } *state = NULL;

    if (_sapp_x11_get_window_property(_sapp.x11.window, _sapp.x11.WM_STATE, _sapp.x11.WM_STATE, (unsigned char**)&state) >= 2) {
        result = (int)state->state;
    }
    if (state) {
        XFree(state);
    }
    return result;
}

_SOKOL_PRIVATE uint32_t _sapp_x11_key_modifier_bit(sapp_keycode key) {
    switch (key) {
        case SAPP_KEYCODE_LEFT_SHIFT:
        case SAPP_KEYCODE_RIGHT_SHIFT:
            return SAPP_MODIFIER_SHIFT;
        case SAPP_KEYCODE_LEFT_CONTROL:
        case SAPP_KEYCODE_RIGHT_CONTROL:
            return SAPP_MODIFIER_CTRL;
        case SAPP_KEYCODE_LEFT_ALT:
        case SAPP_KEYCODE_RIGHT_ALT:
            return SAPP_MODIFIER_ALT;
        case SAPP_KEYCODE_LEFT_SUPER:
        case SAPP_KEYCODE_RIGHT_SUPER:
            return SAPP_MODIFIER_SUPER;
        default:
            return 0;
    }
}

_SOKOL_PRIVATE uint32_t _sapp_x11_button_modifier_bit(sapp_mousebutton btn) {
    switch (btn) {
        case SAPP_MOUSEBUTTON_LEFT:     return SAPP_MODIFIER_LMB;
        case SAPP_MOUSEBUTTON_RIGHT:    return SAPP_MODIFIER_RMB;
        case SAPP_MOUSEBUTTON_MIDDLE:   return SAPP_MODIFIER_MMB;
        default: return 0;
    }
}

_SOKOL_PRIVATE uint32_t _sapp_x11_mods(uint32_t x11_mods) {
    uint32_t mods = 0;
    if (x11_mods & ShiftMask) {
        mods |= SAPP_MODIFIER_SHIFT;
    }
    if (x11_mods & ControlMask) {
        mods |= SAPP_MODIFIER_CTRL;
    }
    if (x11_mods & Mod1Mask) {
        mods |= SAPP_MODIFIER_ALT;
    }
    if (x11_mods & Mod4Mask) {
        mods |= SAPP_MODIFIER_SUPER;
    }
    if (x11_mods & Button1Mask) {
        mods |= SAPP_MODIFIER_LMB;
    }
    if (x11_mods & Button2Mask) {
        mods |= SAPP_MODIFIER_MMB;
    }
    if (x11_mods & Button3Mask) {
        mods |= SAPP_MODIFIER_RMB;
    }
    return mods;
}

_SOKOL_PRIVATE void _sapp_x11_app_event(sapp_event_type type) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE sapp_mousebutton _sapp_x11_translate_button(const XEvent* event) {
    switch (event->xbutton.button) {
        case Button1: return SAPP_MOUSEBUTTON_LEFT;
        case Button2: return SAPP_MOUSEBUTTON_MIDDLE;
        case Button3: return SAPP_MOUSEBUTTON_RIGHT;
        default:      return SAPP_MOUSEBUTTON_INVALID;
    }
}

_SOKOL_PRIVATE void _sapp_x11_mouse_update(int x, int y, bool clear_dxdy) {
    if (!_sapp.mouse.locked) {
        const float new_x = (float) x;
        const float new_y = (float) y;
        if (clear_dxdy) {
            _sapp.mouse.dx = 0.0f;
            _sapp.mouse.dy = 0.0f;
        } else if (_sapp.mouse.pos_valid) {
            _sapp.mouse.dx = new_x - _sapp.mouse.x;
            _sapp.mouse.dy = new_y - _sapp.mouse.y;
        }
        _sapp.mouse.x = new_x;
        _sapp.mouse.y = new_y;
        _sapp.mouse.pos_valid = true;
    }
}

_SOKOL_PRIVATE void _sapp_x11_mouse_event(sapp_event_type type, sapp_mousebutton btn, uint32_t mods) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp.event.mouse_button = btn;
        _sapp.event.modifiers = mods;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_x11_scroll_event(float x, float y, uint32_t mods) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_MOUSE_SCROLL);
        _sapp.event.modifiers = mods;
        _sapp.event.scroll_x = x;
        _sapp.event.scroll_y = y;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE void _sapp_x11_key_event(sapp_event_type type, sapp_keycode key, bool repeat, uint32_t mods) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(type);
        _sapp.event.key_code = key;
        _sapp.event.key_repeat = repeat;
        _sapp.event.modifiers = mods;
        _sapp_call_event(&_sapp.event);
        /* check if a CLIPBOARD_PASTED event must be sent too */
        if (_sapp.clipboard.enabled &&
            (type == SAPP_EVENTTYPE_KEY_DOWN) &&
            (_sapp.event.modifiers == SAPP_MODIFIER_CTRL) &&
            (_sapp.event.key_code == SAPP_KEYCODE_V))
        {
            _sapp_init_event(SAPP_EVENTTYPE_CLIPBOARD_PASTED);
            _sapp_call_event(&_sapp.event);
        }
    }
}

_SOKOL_PRIVATE void _sapp_x11_char_event(uint32_t chr, bool repeat, uint32_t mods) {
    if (_sapp_events_enabled()) {
        _sapp_init_event(SAPP_EVENTTYPE_CHAR);
        _sapp.event.char_code = chr;
        _sapp.event.key_repeat = repeat;
        _sapp.event.modifiers = mods;
        _sapp_call_event(&_sapp.event);
    }
}

_SOKOL_PRIVATE sapp_keycode _sapp_x11_translate_key(int scancode) {
    if ((scancode >= 0) && (scancode < _SAPP_X11_MAX_X11_KEYCODES)) {
        return _sapp.keycodes[scancode];
    } else {
        return SAPP_KEYCODE_INVALID;
    }
}

_SOKOL_PRIVATE int32_t _sapp_x11_keysym_to_unicode(KeySym keysym) {
    int min = 0;
    int max = sizeof(_sapp_x11_keysymtab) / sizeof(struct _sapp_x11_codepair) - 1;
    int mid;

    /* First check for Latin-1 characters (1:1 mapping) */
    if ((keysym >= 0x0020 && keysym <= 0x007e) ||
        (keysym >= 0x00a0 && keysym <= 0x00ff))
    {
        return keysym;
    }

    /* Also check for directly encoded 24-bit UCS characters */
    if ((keysym & 0xff000000) == 0x01000000) {
        return keysym & 0x00ffffff;
    }

    /* Binary search in table */
    while (max >= min) {
        mid = (min + max) / 2;
        if (_sapp_x11_keysymtab[mid].keysym < keysym) {
            min = mid + 1;
        }
        else if (_sapp_x11_keysymtab[mid].keysym > keysym) {
            max = mid - 1;
        }
        else {
            return _sapp_x11_keysymtab[mid].ucs;
        }
    }

    /* No matching Unicode value found */
    return -1;
}

_SOKOL_PRIVATE bool _sapp_x11_keypress_repeat(int keycode) {
    bool repeat = false;
    if ((keycode >= 0) && (keycode < _SAPP_X11_MAX_X11_KEYCODES)) {
        repeat = _sapp.x11.key_repeat[keycode];
        _sapp.x11.key_repeat[keycode] = true;
    }
    return repeat;
}

_SOKOL_PRIVATE void _sapp_x11_keyrelease_repeat(int keycode) {
    if ((keycode >= 0) && (keycode < _SAPP_X11_MAX_X11_KEYCODES)) {
        _sapp.x11.key_repeat[keycode] = false;
    }
}

_SOKOL_PRIVATE bool _sapp_x11_parse_dropped_files_list(const char* src) {
    SOKOL_ASSERT(src);
    SOKOL_ASSERT(_sapp.drop.buffer);

    _sapp_clear_drop_buffer();
    _sapp.drop.num_files = 0;

    /*
        src is (potentially percent-encoded) string made of one or multiple paths
        separated by \r\n, each path starting with 'file://'
    */
    bool err = false;
    int src_count = 0;
    char src_chr = 0;
    char* dst_ptr = _sapp.drop.buffer;
    const char* dst_end_ptr = dst_ptr + (_sapp.drop.max_path_length - 1); // room for terminating 0
    while (0 != (src_chr = *src++)) {
        src_count++;
        char dst_chr = 0;
        /* check leading 'file://' */
        if (src_count <= 7) {
            if (((src_count == 1) && (src_chr != 'f')) ||
                ((src_count == 2) && (src_chr != 'i')) ||
                ((src_count == 3) && (src_chr != 'l')) ||
                ((src_count == 4) && (src_chr != 'e')) ||
                ((src_count == 5) && (src_chr != ':')) ||
                ((src_count == 6) && (src_chr != '/')) ||
                ((src_count == 7) && (src_chr != '/')))
            {
                _SAPP_ERROR(LINUX_X11_DROPPED_FILE_URI_WRONG_SCHEME);
                err = true;
                break;
            }
        }
        else if (src_chr == '\r') {
            // skip
        }
        else if (src_chr == '\n') {
            src_count = 0;
            _sapp.drop.num_files++;
            // too many files is not an error
            if (_sapp.drop.num_files >= _sapp.drop.max_files) {
                break;
            }
            dst_ptr = _sapp.drop.buffer + _sapp.drop.num_files * _sapp.drop.max_path_length;
            dst_end_ptr = dst_ptr + (_sapp.drop.max_path_length - 1);
        }
        else if ((src_chr == '%') && src[0] && src[1]) {
            // a percent-encoded byte (most likely UTF-8 multibyte sequence)
            const char digits[3] = { src[0], src[1], 0 };
            src += 2;
            dst_chr = (char) strtol(digits, 0, 16);
        }
        else {
            dst_chr = src_chr;
        }
        if (dst_chr) {
            // dst_end_ptr already has adjustment for terminating zero
            if (dst_ptr < dst_end_ptr) {
                *dst_ptr++ = dst_chr;
            }
            else {
                _SAPP_ERROR(DROPPED_FILE_PATH_TOO_LONG);
                err = true;
                break;
            }
        }
    }
    if (err) {
        _sapp_clear_drop_buffer();
        _sapp.drop.num_files = 0;
        return false;
    }
    else {
        return true;
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_genericevent(XEvent* event) {
    if (_sapp.mouse.locked && _sapp.x11.xi.available) {
        if (event->xcookie.extension == _sapp.x11.xi.major_opcode) {
            if (XGetEventData(_sapp.x11.display, &event->xcookie)) {
                if (event->xcookie.evtype == XI_RawMotion) {
                    XIRawEvent* re = (XIRawEvent*) event->xcookie.data;
                    if (re->valuators.mask_len) {
                        const double* values = re->raw_values;
                        if (XIMaskIsSet(re->valuators.mask, 0)) {
                            _sapp.mouse.dx = (float) *values;
                            values++;
                        }
                        if (XIMaskIsSet(re->valuators.mask, 1)) {
                            _sapp.mouse.dy = (float) *values;
                        }
                        _sapp_x11_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID, _sapp_x11_mods(event->xmotion.state));
                    }
                }
                XFreeEventData(_sapp.x11.display, &event->xcookie);
            }
        }
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_focusin(XEvent* event) {
    // NOTE: ignoring NotifyGrab and NotifyUngrab is same behaviour as GLFW
    if ((event->xfocus.mode != NotifyGrab) && (event->xfocus.mode != NotifyUngrab)) {
        _sapp_x11_app_event(SAPP_EVENTTYPE_FOCUSED);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_focusout(XEvent* event) {
    // if focus is lost for any reason, and we're in mouse locked mode, disable mouse lock
    if (_sapp.mouse.locked) {
        _sapp_x11_lock_mouse(false);
    }
    // NOTE: ignoring NotifyGrab and NotifyUngrab is same behaviour as GLFW
    if ((event->xfocus.mode != NotifyGrab) && (event->xfocus.mode != NotifyUngrab)) {
        _sapp_x11_app_event(SAPP_EVENTTYPE_UNFOCUSED);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_keypress(XEvent* event) {
    int keycode = (int)event->xkey.keycode;

    const sapp_keycode key = _sapp_x11_translate_key(keycode);
    const bool repeat = _sapp_x11_keypress_repeat(keycode);
    uint32_t mods = _sapp_x11_mods(event->xkey.state);
    // X11 doesn't set modifier bit on key down, so emulate that
    mods |= _sapp_x11_key_modifier_bit(key);
    if (key != SAPP_KEYCODE_INVALID) {
        _sapp_x11_key_event(SAPP_EVENTTYPE_KEY_DOWN, key, repeat, mods);
    }
    KeySym keysym;
    XLookupString(&event->xkey, NULL, 0, &keysym, NULL);
    int32_t chr = _sapp_x11_keysym_to_unicode(keysym);
    if (chr > 0) {
        _sapp_x11_char_event((uint32_t)chr, repeat, mods);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_keyrelease(XEvent* event) {
    int keycode = (int)event->xkey.keycode;
    const sapp_keycode key = _sapp_x11_translate_key(keycode);
    _sapp_x11_keyrelease_repeat(keycode);
    if (key != SAPP_KEYCODE_INVALID) {
        uint32_t mods = _sapp_x11_mods(event->xkey.state);
        // X11 doesn't clear modifier bit on key up, so emulate that
        mods &= ~_sapp_x11_key_modifier_bit(key);
        _sapp_x11_key_event(SAPP_EVENTTYPE_KEY_UP, key, false, mods);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_buttonpress(XEvent* event) {
    _sapp_x11_mouse_update(event->xbutton.x, event->xbutton.y, false);
    const sapp_mousebutton btn = _sapp_x11_translate_button(event);
    uint32_t mods = _sapp_x11_mods(event->xbutton.state);
    // X11 doesn't set modifier bit on button down, so emulate that
    mods |= _sapp_x11_button_modifier_bit(btn);
    if (btn != SAPP_MOUSEBUTTON_INVALID) {
        _sapp_x11_mouse_event(SAPP_EVENTTYPE_MOUSE_DOWN, btn, mods);
        _sapp.x11.mouse_buttons |= (1 << btn);
    }
    else {
        // might be a scroll event
        switch (event->xbutton.button) {
            case 4: _sapp_x11_scroll_event(0.0f, 1.0f, mods); break;
            case 5: _sapp_x11_scroll_event(0.0f, -1.0f, mods); break;
            case 6: _sapp_x11_scroll_event(1.0f, 0.0f, mods); break;
            case 7: _sapp_x11_scroll_event(-1.0f, 0.0f, mods); break;
        }
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_buttonrelease(XEvent* event) {
    _sapp_x11_mouse_update(event->xbutton.x, event->xbutton.y, false);
    const sapp_mousebutton btn = _sapp_x11_translate_button(event);
    if (btn != SAPP_MOUSEBUTTON_INVALID) {
        uint32_t mods = _sapp_x11_mods(event->xbutton.state);
        // X11 doesn't clear modifier bit on button up, so emulate that
        mods &= ~_sapp_x11_button_modifier_bit(btn);
        _sapp_x11_mouse_event(SAPP_EVENTTYPE_MOUSE_UP, btn, mods);
        _sapp.x11.mouse_buttons &= ~(1 << btn);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_enternotify(XEvent* event) {
    // don't send enter/leave events while mouse button held down
    if (0 == _sapp.x11.mouse_buttons) {
        _sapp_x11_mouse_update(event->xcrossing.x, event->xcrossing.y, true);
        _sapp_x11_mouse_event(SAPP_EVENTTYPE_MOUSE_ENTER, SAPP_MOUSEBUTTON_INVALID, _sapp_x11_mods(event->xcrossing.state));
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_leavenotify(XEvent* event) {
    if (0 == _sapp.x11.mouse_buttons) {
        _sapp_x11_mouse_update(event->xcrossing.x, event->xcrossing.y, true);
        _sapp_x11_mouse_event(SAPP_EVENTTYPE_MOUSE_LEAVE, SAPP_MOUSEBUTTON_INVALID, _sapp_x11_mods(event->xcrossing.state));
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_motionnotify(XEvent* event) {
    if (!_sapp.mouse.locked) {
        _sapp_x11_mouse_update(event->xmotion.x, event->xmotion.y, false);
        _sapp_x11_mouse_event(SAPP_EVENTTYPE_MOUSE_MOVE, SAPP_MOUSEBUTTON_INVALID, _sapp_x11_mods(event->xmotion.state));
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_configurenotify(XEvent* event) {
    if ((event->xconfigure.width != _sapp.window_width) || (event->xconfigure.height != _sapp.window_height)) {
        _sapp.window_width = event->xconfigure.width;
        _sapp.window_height = event->xconfigure.height;
        _sapp.framebuffer_width = _sapp.window_width;
        _sapp.framebuffer_height = _sapp.window_height;
        _sapp_x11_app_event(SAPP_EVENTTYPE_RESIZED);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_propertynotify(XEvent* event) {
    if (event->xproperty.state == PropertyNewValue) {
        if (event->xproperty.atom == _sapp.x11.WM_STATE) {
            const int state = _sapp_x11_get_window_state();
            if (state != _sapp.x11.window_state) {
                _sapp.x11.window_state = state;
                if (state == IconicState) {
                    _sapp_x11_app_event(SAPP_EVENTTYPE_ICONIFIED);
                }
                else if (state == NormalState) {
                    _sapp_x11_app_event(SAPP_EVENTTYPE_RESTORED);
                }
            }
        }
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_selectionnotify(XEvent* event) {
    if (event->xselection.property == _sapp.x11.xdnd.XdndSelection) {
        char* data = 0;
        uint32_t result = _sapp_x11_get_window_property(event->xselection.requestor,
                                                        event->xselection.property,
                                                        event->xselection.target,
                                                        (unsigned char**) &data);
        if (_sapp.drop.enabled && result) {
            if (_sapp_x11_parse_dropped_files_list(data)) {
                _sapp.mouse.dx = 0.0f;
                _sapp.mouse.dy = 0.0f;
                if (_sapp_events_enabled()) {
                    // FIXME: Figure out how to get modifier key state here.
                    // The XSelection event has no 'state' item, and
                    // XQueryKeymap() always returns a zeroed array.
                    _sapp_init_event(SAPP_EVENTTYPE_FILES_DROPPED);
                    _sapp_call_event(&_sapp.event);
                }
            }
        }
        if (_sapp.x11.xdnd.version >= 2) {
            XEvent reply;
            _sapp_clear(&reply, sizeof(reply));
            reply.type = ClientMessage;
            reply.xclient.window = _sapp.x11.xdnd.source;
            reply.xclient.message_type = _sapp.x11.xdnd.XdndFinished;
            reply.xclient.format = 32;
            reply.xclient.data.l[0] = (long)_sapp.x11.window;
            reply.xclient.data.l[1] = result;
            reply.xclient.data.l[2] = (long)_sapp.x11.xdnd.XdndActionCopy;
            XSendEvent(_sapp.x11.display, _sapp.x11.xdnd.source, False, NoEventMask, &reply);
            XFlush(_sapp.x11.display);
        }
        if (data) {
            XFree(data);
        }
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_clientmessage(XEvent* event) {
    if (XFilterEvent(event, None)) {
        return;
    }
    if (event->xclient.message_type == _sapp.x11.WM_PROTOCOLS) {
        const Atom protocol = (Atom)event->xclient.data.l[0];
        if (protocol == _sapp.x11.WM_DELETE_WINDOW) {
            _sapp.quit_requested = true;
        }
    } else if (event->xclient.message_type == _sapp.x11.xdnd.XdndEnter) {
        const bool is_list = 0 != (event->xclient.data.l[1] & 1);
        _sapp.x11.xdnd.source  = (Window)event->xclient.data.l[0];
        _sapp.x11.xdnd.version = event->xclient.data.l[1] >> 24;
        _sapp.x11.xdnd.format  = None;
        if (_sapp.x11.xdnd.version > _SAPP_X11_XDND_VERSION) {
            return;
        }
        uint32_t count = 0;
        Atom* formats = 0;
        if (is_list) {
            count = _sapp_x11_get_window_property(_sapp.x11.xdnd.source, _sapp.x11.xdnd.XdndTypeList, XA_ATOM, (unsigned char**)&formats);
        } else {
            count = 3;
            formats = (Atom*) event->xclient.data.l + 2;
        }
        for (uint32_t i = 0; i < count; i++) {
            if (formats[i] == _sapp.x11.xdnd.text_uri_list) {
                _sapp.x11.xdnd.format = _sapp.x11.xdnd.text_uri_list;
                break;
            }
        }
        if (is_list && formats) {
            XFree(formats);
        }
    } else if (event->xclient.message_type == _sapp.x11.xdnd.XdndDrop) {
        if (_sapp.x11.xdnd.version > _SAPP_X11_XDND_VERSION) {
            return;
        }
        Time time = CurrentTime;
        if (_sapp.x11.xdnd.format) {
            if (_sapp.x11.xdnd.version >= 1) {
                time = (Time)event->xclient.data.l[2];
            }
            XConvertSelection(_sapp.x11.display,
                                _sapp.x11.xdnd.XdndSelection,
                                _sapp.x11.xdnd.format,
                                _sapp.x11.xdnd.XdndSelection,
                                _sapp.x11.window,
                                time);
        } else if (_sapp.x11.xdnd.version >= 2) {
            XEvent reply;
            _sapp_clear(&reply, sizeof(reply));
            reply.type = ClientMessage;
            reply.xclient.window = _sapp.x11.xdnd.source;
            reply.xclient.message_type = _sapp.x11.xdnd.XdndFinished;
            reply.xclient.format = 32;
            reply.xclient.data.l[0] = (long)_sapp.x11.window;
            reply.xclient.data.l[1] = 0;    // drag was rejected
            reply.xclient.data.l[2] = None;
            XSendEvent(_sapp.x11.display, _sapp.x11.xdnd.source, False, NoEventMask, &reply);
            XFlush(_sapp.x11.display);
        }
    } else if (event->xclient.message_type == _sapp.x11.xdnd.XdndPosition) {
        // drag operation has moved over the window
        //  FIXME: we could track the mouse position here, but
        //  this isn't implemented on other platforms either so far
        if (_sapp.x11.xdnd.version > _SAPP_X11_XDND_VERSION) {
            return;
        }
        XEvent reply;
        _sapp_clear(&reply, sizeof(reply));
        reply.type = ClientMessage;
        reply.xclient.window = _sapp.x11.xdnd.source;
        reply.xclient.message_type = _sapp.x11.xdnd.XdndStatus;
        reply.xclient.format = 32;
        reply.xclient.data.l[0] = (long)_sapp.x11.window;
        if (_sapp.x11.xdnd.format) {
            /* reply that we are ready to copy the dragged data */
            reply.xclient.data.l[1] = 1;    // accept with no rectangle
            if (_sapp.x11.xdnd.version >= 2) {
                reply.xclient.data.l[4] = (long)_sapp.x11.xdnd.XdndActionCopy;
            }
        }
        XSendEvent(_sapp.x11.display, _sapp.x11.xdnd.source, False, NoEventMask, &reply);
        XFlush(_sapp.x11.display);
    }
}

_SOKOL_PRIVATE void _sapp_x11_on_selectionrequest(XEvent* event) {
    XSelectionRequestEvent* req = &event->xselectionrequest;
    if (req->selection != _sapp.x11.CLIPBOARD) {
        return;
    }
    if (!_sapp.clipboard.enabled) {
        return;
    }
    SOKOL_ASSERT(_sapp.clipboard.buffer);
    XSelectionEvent reply;
    _sapp_clear(&reply, sizeof(reply));
    reply.type = SelectionNotify;
    reply.display = req->display;
    reply.requestor = req->requestor;
    reply.selection = req->selection;
    reply.target = req->target;
    reply.property = req->property;
    reply.time = req->time;
    if (req->target == _sapp.x11.UTF8_STRING) {
        XChangeProperty(_sapp.x11.display,
                        req->requestor,
                        req->property,
                        _sapp.x11.UTF8_STRING,
                        8,
                        PropModeReplace,
                        (unsigned char*) _sapp.clipboard.buffer,
                        strlen(_sapp.clipboard.buffer));
    } else if (req->target == _sapp.x11.TARGETS) {
        XChangeProperty(_sapp.x11.display,
                        req->requestor,
                        req->property,
                        XA_ATOM,
                        32,
                        PropModeReplace,
                        (unsigned char*) &_sapp.x11.UTF8_STRING,
                        1);
    } else {
        reply.property = None;
    }
    XSendEvent(_sapp.x11.display, req->requestor, False, 0, (XEvent*) &reply);
}

_SOKOL_PRIVATE void _sapp_x11_process_event(XEvent* event) {
    switch (event->type) {
        case GenericEvent:
            _sapp_x11_on_genericevent(event);
            break;
        case FocusIn:
            _sapp_x11_on_focusin(event);
            break;
        case FocusOut:
            _sapp_x11_on_focusout(event);
            break;
        case KeyPress:
            _sapp_x11_on_keypress(event);
            break;
        case KeyRelease:
            _sapp_x11_on_keyrelease(event);
            break;
        case ButtonPress:
            _sapp_x11_on_buttonpress(event);
            break;
        case ButtonRelease:
            _sapp_x11_on_buttonrelease(event);
            break;
        case EnterNotify:
            _sapp_x11_on_enternotify(event);
            break;
        case LeaveNotify:
            _sapp_x11_on_leavenotify(event);
            break;
        case MotionNotify:
            _sapp_x11_on_motionnotify(event);
            break;
        case ConfigureNotify:
            _sapp_x11_on_configurenotify(event);
            break;
        case PropertyNotify:
            _sapp_x11_on_propertynotify(event);
            break;
        case SelectionNotify:
            _sapp_x11_on_selectionnotify(event);
            break;
        case SelectionRequest:
            _sapp_x11_on_selectionrequest(event);
            break;
        case DestroyNotify:
            // not a bug
            break;
        case ClientMessage:
            _sapp_x11_on_clientmessage(event);
            break;
    }
}

#if !defined(_SAPP_GLX)

_SOKOL_PRIVATE void _sapp_egl_init(void) {
#if defined(SOKOL_GLCORE)
    if (!eglBindAPI(EGL_OPENGL_API)) {
        _SAPP_PANIC(LINUX_EGL_BIND_OPENGL_API_FAILED);
    }
#else
    if (!eglBindAPI(EGL_OPENGL_ES_API)) {
        _SAPP_PANIC(LINUX_EGL_BIND_OPENGL_ES_API_FAILED);
    }
#endif

    _sapp.egl.display = eglGetDisplay((EGLNativeDisplayType)_sapp.x11.display);
    if (EGL_NO_DISPLAY == _sapp.egl.display) {
        _SAPP_PANIC(LINUX_EGL_GET_DISPLAY_FAILED);
    }

    EGLint major, minor;
    if (!eglInitialize(_sapp.egl.display, &major, &minor)) {
        _SAPP_PANIC(LINUX_EGL_INITIALIZE_FAILED);
    }

    EGLint sample_count = _sapp.desc.sample_count > 1 ? _sapp.desc.sample_count : 0;
    EGLint alpha_size = _sapp.desc.alpha ? 8 : 0;
    const EGLint config_attrs[] = {
        EGL_SURFACE_TYPE, EGL_WINDOW_BIT,
        #if defined(SOKOL_GLCORE)
            EGL_RENDERABLE_TYPE, EGL_OPENGL_BIT,
        #elif defined(SOKOL_GLES3)
            EGL_RENDERABLE_TYPE, EGL_OPENGL_ES3_BIT,
        #endif
        EGL_RED_SIZE, 8,
        EGL_GREEN_SIZE, 8,
        EGL_BLUE_SIZE, 8,
        EGL_ALPHA_SIZE, alpha_size,
        EGL_DEPTH_SIZE, 24,
        EGL_STENCIL_SIZE, 8,
        EGL_SAMPLE_BUFFERS, _sapp.desc.sample_count > 1 ? 1 : 0,
        EGL_SAMPLES, sample_count,
        EGL_NONE,
    };

    EGLConfig egl_configs[32];
    EGLint config_count;
    if (!eglChooseConfig(_sapp.egl.display, config_attrs, egl_configs, 32, &config_count) || config_count == 0) {
        _SAPP_PANIC(LINUX_EGL_NO_CONFIGS);
    }

    EGLConfig config = egl_configs[0];
    for (int i = 0; i < config_count; ++i) {
        EGLConfig c = egl_configs[i];
        EGLint r, g, b, a, d, s, n;
        if (eglGetConfigAttrib(_sapp.egl.display, c, EGL_RED_SIZE, &r) &&
            eglGetConfigAttrib(_sapp.egl.display, c, EGL_GREEN_SIZE, &g) &&
            eglGetConfigAttrib(_sapp.egl.display, c, EGL_BLUE_SIZE, &b) &&
            eglGetConfigAttrib(_sapp.egl.display, c, EGL_ALPHA_SIZE, &a) &&
            eglGetConfigAttrib(_sapp.egl.display, c, EGL_DEPTH_SIZE, &d) &&
            eglGetConfigAttrib(_sapp.egl.display, c, EGL_STENCIL_SIZE, &s) &&
            eglGetConfigAttrib(_sapp.egl.display, c, EGL_SAMPLES, &n) &&
            (r == 8) && (g == 8) && (b == 8) && (a == alpha_size) && (d == 24) && (s == 8) && (n == sample_count)) {
            config = c;
            break;
        }
    }

    EGLint visual_id;
    if (!eglGetConfigAttrib(_sapp.egl.display, config, EGL_NATIVE_VISUAL_ID, &visual_id)) {
        _SAPP_PANIC(LINUX_EGL_NO_NATIVE_VISUAL);
    }

    XVisualInfo visual_info_template;
    _sapp_clear(&visual_info_template, sizeof(visual_info_template));
    visual_info_template.visualid = (VisualID)visual_id;

    int num_visuals;
    XVisualInfo* visual_info = XGetVisualInfo(_sapp.x11.display, VisualIDMask, &visual_info_template, &num_visuals);
    if (!visual_info) {
        _SAPP_PANIC(LINUX_EGL_GET_VISUAL_INFO_FAILED);
    }

    _sapp_x11_create_window(visual_info->visual, visual_info->depth);
    XFree(visual_info);

    _sapp.egl.surface = eglCreateWindowSurface(_sapp.egl.display, config, (EGLNativeWindowType)_sapp.x11.window, NULL);
    if (EGL_NO_SURFACE == _sapp.egl.surface) {
        _SAPP_PANIC(LINUX_EGL_CREATE_WINDOW_SURFACE_FAILED);
    }

    EGLint ctx_attrs[] = {
        EGL_CONTEXT_MAJOR_VERSION, _sapp.desc.gl_major_version,
        EGL_CONTEXT_MINOR_VERSION, _sapp.desc.gl_minor_version,
        #if defined(SOKOL_GLCORE)
            EGL_CONTEXT_OPENGL_PROFILE_MASK, EGL_CONTEXT_OPENGL_CORE_PROFILE_BIT,
        #endif
        EGL_NONE,
    };

    _sapp.egl.context = eglCreateContext(_sapp.egl.display, config, EGL_NO_CONTEXT, ctx_attrs);
    if (EGL_NO_CONTEXT == _sapp.egl.context) {
        _SAPP_PANIC(LINUX_EGL_CREATE_CONTEXT_FAILED);
    }

    if (!eglMakeCurrent(_sapp.egl.display, _sapp.egl.surface, _sapp.egl.surface, _sapp.egl.context)) {
        _SAPP_PANIC(LINUX_EGL_MAKE_CURRENT_FAILED);
    }
    glGetIntegerv(GL_FRAMEBUFFER_BINDING, (GLint*)&_sapp.gl.framebuffer);

    eglSwapInterval(_sapp.egl.display, _sapp.swap_interval);
}

_SOKOL_PRIVATE void _sapp_egl_destroy(void) {
    if (_sapp.egl.display != EGL_NO_DISPLAY) {
        eglMakeCurrent(_sapp.egl.display, EGL_NO_SURFACE, EGL_NO_SURFACE, EGL_NO_CONTEXT);

        if (_sapp.egl.context != EGL_NO_CONTEXT) {
            eglDestroyContext(_sapp.egl.display, _sapp.egl.context);
            _sapp.egl.context = EGL_NO_CONTEXT;
        }

        if (_sapp.egl.surface != EGL_NO_SURFACE) {
            eglDestroySurface(_sapp.egl.display, _sapp.egl.surface);
            _sapp.egl.surface = EGL_NO_SURFACE;
        }

        eglTerminate(_sapp.egl.display);
        _sapp.egl.display = EGL_NO_DISPLAY;
    }
}

#endif /* _SAPP_GLX */

_SOKOL_PRIVATE void _sapp_linux_run(const sapp_desc* desc) {
    /* The following lines are here to trigger a linker error instead of an
        obscure runtime error if the user has forgotten to add -pthread to
        the compiler or linker options. They have no other purpose.
    */
    pthread_attr_t pthread_attr;
    pthread_attr_init(&pthread_attr);
    pthread_attr_destroy(&pthread_attr);

    _sapp_init_state(desc);
    _sapp.x11.window_state = NormalState;

    XInitThreads();
    XrmInitialize();
    _sapp.x11.display = XOpenDisplay(NULL);
    if (!_sapp.x11.display) {
        _SAPP_PANIC(LINUX_X11_OPEN_DISPLAY_FAILED);
    }
    _sapp.x11.screen = DefaultScreen(_sapp.x11.display);
    _sapp.x11.root = DefaultRootWindow(_sapp.x11.display);
    _sapp_x11_query_system_dpi();
    _sapp.dpi_scale = _sapp.x11.dpi / 96.0f;
    _sapp_x11_init_extensions();
    _sapp_x11_create_cursors();
    XkbSetDetectableAutoRepeat(_sapp.x11.display, true, NULL);
    _sapp_x11_init_keytable();
#if defined(_SAPP_GLX)
    _sapp_glx_init();
    Visual* visual = 0;
    int depth = 0;
    _sapp_glx_choose_visual(&visual, &depth);
    _sapp_x11_create_window(visual, depth);
    _sapp_glx_create_context();
    _sapp_glx_swapinterval(_sapp.swap_interval);
#else
    _sapp_egl_init();
#endif
    sapp_set_icon(&desc->icon);
    _sapp.valid = true;
    _sapp_x11_show_window();
    if (_sapp.fullscreen) {
        _sapp_x11_set_fullscreen(true);
    }

    XFlush(_sapp.x11.display);
    while (!_sapp.quit_ordered) {
        _sapp_timing_measure(&_sapp.timing);
        int count = XPending(_sapp.x11.display);
        while (count--) {
            XEvent event;
            XNextEvent(_sapp.x11.display, &event);
            _sapp_x11_process_event(&event);
        }
        _sapp_frame();
#if defined(_SAPP_GLX)
        _sapp_glx_swap_buffers();
#else
        eglSwapBuffers(_sapp.egl.display, _sapp.egl.surface);
#endif
        XFlush(_sapp.x11.display);
        /* handle quit-requested, either from window or from sapp_request_quit() */
        if (_sapp.quit_requested && !_sapp.quit_ordered) {
            /* give user code a chance to intervene */
            _sapp_x11_app_event(SAPP_EVENTTYPE_QUIT_REQUESTED);
            /* if user code hasn't intervened, quit the app */
            if (_sapp.quit_requested) {
                _sapp.quit_ordered = true;
            }
        }
    }
    _sapp_call_cleanup();
#if defined(_SAPP_GLX)
    _sapp_glx_destroy_context();
#else
    _sapp_egl_destroy();
#endif
    _sapp_x11_destroy_window();
    _sapp_x11_destroy_cursors();
    XCloseDisplay(_sapp.x11.display);
    _sapp_discard_state();
}

#if !defined(SOKOL_NO_ENTRY)
int main(int argc, char* argv[]) {
    sapp_desc desc = sokol_main(argc, argv);
    _sapp_linux_run(&desc);
    return 0;
}
#endif /* SOKOL_NO_ENTRY */
#endif /* _SAPP_LINUX */

// ██████  ██    ██ ██████  ██      ██  ██████
// ██   ██ ██    ██ ██   ██ ██      ██ ██
// ██████  ██    ██ ██████  ██      ██ ██
// ██      ██    ██ ██   ██ ██      ██ ██
// ██       ██████  ██████  ███████ ██  ██████
//
// >>public
#if defined(SOKOL_NO_ENTRY)
SOKOL_API_IMPL void sapp_run(const sapp_desc* desc) {
    SOKOL_ASSERT(desc);
    #if defined(_SAPP_MACOS)
        _sapp_macos_run(desc);
    #elif defined(_SAPP_IOS)
        _sapp_ios_run(desc);
    #elif defined(_SAPP_EMSCRIPTEN)
        _sapp_emsc_run(desc);
    #elif defined(_SAPP_WIN32)
        _sapp_win32_run(desc);
    #elif defined(_SAPP_LINUX)
        _sapp_linux_run(desc);
    #else
    #error "sapp_run() not supported on this platform"
    #endif
}

/* this is just a stub so the linker doesn't complain */
sapp_desc sokol_main(int argc, char* argv[]) {
    _SOKOL_UNUSED(argc);
    _SOKOL_UNUSED(argv);
    sapp_desc desc;
    _sapp_clear(&desc, sizeof(desc));
    return desc;
}
#else
/* likewise, in normal mode, sapp_run() is just an empty stub */
SOKOL_API_IMPL void sapp_run(const sapp_desc* desc) {
    _SOKOL_UNUSED(desc);
}
#endif

SOKOL_API_IMPL bool sapp_isvalid(void) {
    return _sapp.valid;
}

SOKOL_API_IMPL void* sapp_userdata(void) {
    return _sapp.desc.user_data;
}

SOKOL_API_IMPL sapp_desc sapp_query_desc(void) {
    return _sapp.desc;
}

SOKOL_API_IMPL uint64_t sapp_frame_count(void) {
    return _sapp.frame_count;
}

SOKOL_API_IMPL double sapp_frame_duration(void) {
    return _sapp_timing_get_avg(&_sapp.timing);
}

SOKOL_API_IMPL int sapp_width(void) {
    return (_sapp.framebuffer_width > 0) ? _sapp.framebuffer_width : 1;
}

SOKOL_API_IMPL float sapp_widthf(void) {
    return (float)sapp_width();
}

SOKOL_API_IMPL int sapp_height(void) {
    return (_sapp.framebuffer_height > 0) ? _sapp.framebuffer_height : 1;
}

SOKOL_API_IMPL float sapp_heightf(void) {
    return (float)sapp_height();
}

SOKOL_API_IMPL int sapp_color_format(void) {
    #if defined(_SAPP_EMSCRIPTEN) && defined(SOKOL_WGPU)
        switch (_sapp.wgpu.render_format) {
            case WGPUTextureFormat_RGBA8Unorm:
                return _SAPP_PIXELFORMAT_RGBA8;
            case WGPUTextureFormat_BGRA8Unorm:
                return _SAPP_PIXELFORMAT_BGRA8;
            default:
                SOKOL_UNREACHABLE;
                return 0;
        }
    #elif defined(SOKOL_METAL) || defined(SOKOL_D3D11)
        return _SAPP_PIXELFORMAT_BGRA8;
    #else
        return _SAPP_PIXELFORMAT_RGBA8;
    #endif
}

SOKOL_API_IMPL int sapp_depth_format(void) {
    return _SAPP_PIXELFORMAT_DEPTH_STENCIL;
}

SOKOL_API_IMPL int sapp_sample_count(void) {
    return _sapp.sample_count;
}

SOKOL_API_IMPL bool sapp_high_dpi(void) {
    return _sapp.desc.high_dpi && (_sapp.dpi_scale >= 1.5f);
}

SOKOL_API_IMPL float sapp_dpi_scale(void) {
    return _sapp.dpi_scale;
}

SOKOL_API_IMPL const void* sapp_egl_get_display(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_ANDROID)
        return _sapp.android.display;
    #elif defined(_SAPP_LINUX) && !defined(_SAPP_GLX)
        return _sapp.egl.display;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_egl_get_context(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_ANDROID)
        return _sapp.android.context;
    #elif defined(_SAPP_LINUX) && !defined(_SAPP_GLX)
        return _sapp.egl.context;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL void sapp_show_keyboard(bool show) {
    #if defined(_SAPP_IOS)
    _sapp_ios_show_keyboard(show);
    #elif defined(_SAPP_ANDROID)
    _sapp_android_show_keyboard(show);
    #else
    _SOKOL_UNUSED(show);
    #endif
}

SOKOL_API_IMPL bool sapp_keyboard_shown(void) {
    return _sapp.onscreen_keyboard_shown;
}

SOKOL_API_IMPL bool sapp_is_fullscreen(void) {
    return _sapp.fullscreen;
}

SOKOL_API_IMPL void sapp_toggle_fullscreen(void) {
    #if defined(_SAPP_MACOS)
    _sapp_macos_toggle_fullscreen();
    #elif defined(_SAPP_WIN32)
    _sapp_win32_toggle_fullscreen();
    #elif defined(_SAPP_LINUX)
    _sapp_x11_toggle_fullscreen();
    #endif
}

/* NOTE that sapp_show_mouse() does not "stack" like the Win32 or macOS API functions! */
SOKOL_API_IMPL void sapp_show_mouse(bool show) {
    if (_sapp.mouse.shown != show) {
        #if defined(_SAPP_MACOS)
        _sapp_macos_update_cursor(_sapp.mouse.current_cursor, show);
        #elif defined(_SAPP_WIN32)
        _sapp_win32_update_cursor(_sapp.mouse.current_cursor, show, false);
        #elif defined(_SAPP_LINUX)
        _sapp_x11_update_cursor(_sapp.mouse.current_cursor, show);
        #elif defined(_SAPP_EMSCRIPTEN)
        _sapp_emsc_update_cursor(_sapp.mouse.current_cursor, show);
        #endif
        _sapp.mouse.shown = show;
    }
}

SOKOL_API_IMPL bool sapp_mouse_shown(void) {
    return _sapp.mouse.shown;
}

SOKOL_API_IMPL void sapp_lock_mouse(bool lock) {
    #if defined(_SAPP_MACOS)
    _sapp_macos_lock_mouse(lock);
    #elif defined(_SAPP_EMSCRIPTEN)
    _sapp_emsc_lock_mouse(lock);
    #elif defined(_SAPP_WIN32)
    _sapp_win32_lock_mouse(lock);
    #elif defined(_SAPP_LINUX)
    _sapp_x11_lock_mouse(lock);
    #else
    _sapp.mouse.locked = lock;
    #endif
}

SOKOL_API_IMPL bool sapp_mouse_locked(void) {
    return _sapp.mouse.locked;
}

SOKOL_API_IMPL void sapp_set_mouse_cursor(sapp_mouse_cursor cursor) {
    SOKOL_ASSERT((cursor >= 0) && (cursor < _SAPP_MOUSECURSOR_NUM));
    if (_sapp.mouse.current_cursor != cursor) {
        #if defined(_SAPP_MACOS)
        _sapp_macos_update_cursor(cursor, _sapp.mouse.shown);
        #elif defined(_SAPP_WIN32)
        _sapp_win32_update_cursor(cursor, _sapp.mouse.shown, false);
        #elif defined(_SAPP_LINUX)
        _sapp_x11_update_cursor(cursor, _sapp.mouse.shown);
        #elif defined(_SAPP_EMSCRIPTEN)
        _sapp_emsc_update_cursor(cursor, _sapp.mouse.shown);
        #endif
        _sapp.mouse.current_cursor = cursor;
    }
}

SOKOL_API_IMPL sapp_mouse_cursor sapp_get_mouse_cursor(void) {
    return _sapp.mouse.current_cursor;
}

SOKOL_API_IMPL void sapp_request_quit(void) {
    _sapp.quit_requested = true;
}

SOKOL_API_IMPL void sapp_cancel_quit(void) {
    _sapp.quit_requested = false;
}

SOKOL_API_IMPL void sapp_quit(void) {
    _sapp.quit_ordered = true;
}

SOKOL_API_IMPL void sapp_consume_event(void) {
    _sapp.event_consumed = true;
}

/* NOTE: on HTML5, sapp_set_clipboard_string() must be called from within event handler! */
SOKOL_API_IMPL void sapp_set_clipboard_string(const char* str) {
    if (!_sapp.clipboard.enabled) {
        return;
    }
    SOKOL_ASSERT(str);
    #if defined(_SAPP_MACOS)
        _sapp_macos_set_clipboard_string(str);
    #elif defined(_SAPP_EMSCRIPTEN)
        _sapp_emsc_set_clipboard_string(str);
    #elif defined(_SAPP_WIN32)
        _sapp_win32_set_clipboard_string(str);
    #elif defined(_SAPP_LINUX)
        _sapp_x11_set_clipboard_string(str);
    #else
        /* not implemented */
    #endif
    _sapp_strcpy(str, _sapp.clipboard.buffer, _sapp.clipboard.buf_size);
}

SOKOL_API_IMPL const char* sapp_get_clipboard_string(void) {
    if (!_sapp.clipboard.enabled) {
        return "";
    }
    #if defined(_SAPP_MACOS)
        return _sapp_macos_get_clipboard_string();
    #elif defined(_SAPP_EMSCRIPTEN)
        return _sapp.clipboard.buffer;
    #elif defined(_SAPP_WIN32)
        return _sapp_win32_get_clipboard_string();
    #elif defined(_SAPP_LINUX)
        return _sapp_x11_get_clipboard_string();
    #else
        /* not implemented */
        return _sapp.clipboard.buffer;
    #endif
}

SOKOL_API_IMPL void sapp_set_window_title(const char* title) {
    SOKOL_ASSERT(title);
    _sapp_strcpy(title, _sapp.window_title, sizeof(_sapp.window_title));
    #if defined(_SAPP_MACOS)
        _sapp_macos_update_window_title();
    #elif defined(_SAPP_WIN32)
        _sapp_win32_update_window_title();
    #elif defined(_SAPP_LINUX)
        _sapp_x11_update_window_title();
    #endif
}

SOKOL_API_IMPL void sapp_set_icon(const sapp_icon_desc* desc) {
    SOKOL_ASSERT(desc);
    if (desc->sokol_default) {
        if (0 == _sapp.default_icon_pixels) {
            _sapp_setup_default_icon();
        }
        SOKOL_ASSERT(0 != _sapp.default_icon_pixels);
        desc = &_sapp.default_icon_desc;
    }
    const int num_images = _sapp_icon_num_images(desc);
    if (num_images == 0) {
        return;
    }
    SOKOL_ASSERT((num_images > 0) && (num_images <= SAPP_MAX_ICONIMAGES));
    if (!_sapp_validate_icon_desc(desc, num_images)) {
        return;
    }
    #if defined(_SAPP_MACOS)
        _sapp_macos_set_icon(desc, num_images);
    #elif defined(_SAPP_WIN32)
        _sapp_win32_set_icon(desc, num_images);
    #elif defined(_SAPP_LINUX)
        _sapp_x11_set_icon(desc, num_images);
    #elif defined(_SAPP_EMSCRIPTEN)
        _sapp_emsc_set_icon(desc, num_images);
    #endif
}

SOKOL_API_IMPL int sapp_get_num_dropped_files(void) {
    SOKOL_ASSERT(_sapp.drop.enabled);
    return _sapp.drop.num_files;
}

SOKOL_API_IMPL const char* sapp_get_dropped_file_path(int index) {
    SOKOL_ASSERT(_sapp.drop.enabled);
    SOKOL_ASSERT((index >= 0) && (index < _sapp.drop.num_files));
    SOKOL_ASSERT(_sapp.drop.buffer);
    if (!_sapp.drop.enabled) {
        return "";
    }
    if ((index < 0) || (index >= _sapp.drop.max_files)) {
        return "";
    }
    return (const char*) _sapp_dropped_file_path_ptr(index);
}

SOKOL_API_IMPL uint32_t sapp_html5_get_dropped_file_size(int index) {
    SOKOL_ASSERT(_sapp.drop.enabled);
    SOKOL_ASSERT((index >= 0) && (index < _sapp.drop.num_files));
    #if defined(_SAPP_EMSCRIPTEN)
        if (!_sapp.drop.enabled) {
            return 0;
        }
        return sapp_js_dropped_file_size(index);
    #else
        (void)index;
        return 0;
    #endif
}

SOKOL_API_IMPL void sapp_html5_fetch_dropped_file(const sapp_html5_fetch_request* request) {
    SOKOL_ASSERT(_sapp.drop.enabled);
    SOKOL_ASSERT(request);
    SOKOL_ASSERT(request->callback);
    SOKOL_ASSERT(request->buffer.ptr);
    SOKOL_ASSERT(request->buffer.size > 0);
    #if defined(_SAPP_EMSCRIPTEN)
        const int index = request->dropped_file_index;
        sapp_html5_fetch_error error_code = SAPP_HTML5_FETCH_ERROR_NO_ERROR;
        if ((index < 0) || (index >= _sapp.drop.num_files)) {
            error_code = SAPP_HTML5_FETCH_ERROR_OTHER;
        }
        if (sapp_html5_get_dropped_file_size(index) > request->buffer.size) {
            error_code = SAPP_HTML5_FETCH_ERROR_BUFFER_TOO_SMALL;
        }
        if (SAPP_HTML5_FETCH_ERROR_NO_ERROR != error_code) {
            _sapp_emsc_invoke_fetch_cb(index,
                false, // success
                (int)error_code,
                request->callback,
                0, // fetched_size
                (void*)request->buffer.ptr,
                request->buffer.size,
                request->user_data);
        }
        else {
            sapp_js_fetch_dropped_file(index,
                request->callback,
                (void*)request->buffer.ptr,
                request->buffer.size,
                request->user_data);
        }
    #else
        (void)request;
    #endif
}

SOKOL_API_IMPL const void* sapp_metal_get_device(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_METAL)
        #if defined(_SAPP_MACOS)
            const void* obj = (__bridge const void*) _sapp.macos.mtl_device;
        #else
            const void* obj = (__bridge const void*) _sapp.ios.mtl_device;
        #endif
        SOKOL_ASSERT(obj);
        return obj;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_metal_get_current_drawable(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_METAL)
        #if defined(_SAPP_MACOS)
            const void* obj = (__bridge const void*) [_sapp.macos.view currentDrawable];
        #else
            const void* obj = (__bridge const void*) [_sapp.ios.view currentDrawable];
        #endif
        SOKOL_ASSERT(obj);
        return obj;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_metal_get_depth_stencil_texture(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_METAL)
        #if defined(_SAPP_MACOS)
            const void* obj = (__bridge const void*) [_sapp.macos.view depthStencilTexture];
        #else
            const void* obj = (__bridge const void*) [_sapp.ios.view depthStencilTexture];
        #endif
        return obj;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_metal_get_msaa_color_texture(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_METAL)
        #if defined(_SAPP_MACOS)
            const void* obj = (__bridge const void*) [_sapp.macos.view multisampleColorTexture];
        #else
            const void* obj = (__bridge const void*) [_sapp.ios.view multisampleColorTexture];
        #endif
        return obj;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_macos_get_window(void) {
    #if defined(_SAPP_MACOS)
        const void* obj = (__bridge const void*) _sapp.macos.window;
        SOKOL_ASSERT(obj);
        return obj;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_ios_get_window(void) {
    #if defined(_SAPP_IOS)
        const void* obj = (__bridge const void*) _sapp.ios.window;
        SOKOL_ASSERT(obj);
        return obj;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_d3d11_get_device(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_D3D11)
        return _sapp.d3d11.device;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_d3d11_get_device_context(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_D3D11)
        return _sapp.d3d11.device_context;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_d3d11_get_swap_chain(void) {
    SOKOL_ASSERT(_sapp.valid);
#if defined(SOKOL_D3D11)
    return _sapp.d3d11.swap_chain;
#else
    return 0;
#endif
}

SOKOL_API_IMPL const void* sapp_d3d11_get_render_view(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_D3D11)
        if (_sapp.sample_count > 1) {
            SOKOL_ASSERT(_sapp.d3d11.msaa_rtv);
            return _sapp.d3d11.msaa_rtv;
        } else {
            SOKOL_ASSERT(_sapp.d3d11.rtv);
            return _sapp.d3d11.rtv;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_d3d11_get_resolve_view(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_D3D11)
        if (_sapp.sample_count > 1) {
            SOKOL_ASSERT(_sapp.d3d11.rtv);
            return _sapp.d3d11.rtv;
        } else {
            return 0;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_d3d11_get_depth_stencil_view(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(SOKOL_D3D11)
        return _sapp.d3d11.dsv;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_win32_get_hwnd(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_WIN32)
        return _sapp.win32.hwnd;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_wgpu_get_device(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_EMSCRIPTEN) && defined(SOKOL_WGPU)
        return (const void*) _sapp.wgpu.device;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_wgpu_get_render_view(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_EMSCRIPTEN) && defined(SOKOL_WGPU)
        if (_sapp.sample_count > 1) {
            SOKOL_ASSERT(_sapp.wgpu.msaa_view);
            return (const void*) _sapp.wgpu.msaa_view;
        } else {
            SOKOL_ASSERT(_sapp.wgpu.swapchain_view);
            return (const void*) _sapp.wgpu.swapchain_view;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_wgpu_get_resolve_view(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_EMSCRIPTEN) && defined(SOKOL_WGPU)
        if (_sapp.sample_count > 1) {
            SOKOL_ASSERT(_sapp.wgpu.swapchain_view);
            return (const void*) _sapp.wgpu.swapchain_view;
        } else {
            return 0;
        }
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_wgpu_get_depth_stencil_view(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_EMSCRIPTEN) && defined(SOKOL_WGPU)
        return (const void*) _sapp.wgpu.depth_stencil_view;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL uint32_t sapp_gl_get_framebuffer(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_ANY_GL)
        return _sapp.gl.framebuffer;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL int sapp_gl_get_major_version(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_ANY_GL)
        return _sapp.desc.gl_major_version;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL int sapp_gl_get_minor_version(void) {
    SOKOL_ASSERT(_sapp.valid);
    #if defined(_SAPP_ANY_GL)
        return _sapp.desc.gl_minor_version;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL bool sapp_gl_is_gles(void) {
    #if defined(SOKOL_GLES3)
        return true;
    #else
        return false;
    #endif
}

SOKOL_API_IMPL const void* sapp_x11_get_window(void) {
    #if defined(_SAPP_LINUX)
        return (void*)_sapp.x11.window;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_x11_get_display(void) {
    #if defined(_SAPP_LINUX)
        return (void*)_sapp.x11.display;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL const void* sapp_android_get_native_activity(void) {
    // NOTE: _sapp.valid is not asserted here because sapp_android_get_native_activity()
    // needs to be callable from within sokol_main() (see: https://github.com/floooh/sokol/issues/708)
    #if defined(_SAPP_ANDROID)
        return (void*)_sapp.android.activity;
    #else
        return 0;
    #endif
}

SOKOL_API_IMPL void sapp_html5_ask_leave_site(bool ask) {
    _sapp.html5_ask_leave_site = ask;
}

#endif /* SOKOL_APP_IMPL */
//FILE_END
//FILE_START:deps/sokol_glue.h
#if defined(SOKOL_IMPL) && !defined(SOKOL_GLUE_IMPL)
#define SOKOL_GLUE_IMPL
#endif
#ifndef SOKOL_GLUE_INCLUDED
/*
    sokol_glue.h -- glue helper functions for sokol headers

    Project URL: https://github.com/floooh/sokol

    Do this:
        #define SOKOL_IMPL or
        #define SOKOL_GLUE_IMPL
    before you include this file in *one* C or C++ file to create the
    implementation.

    ...optionally provide the following macros to override defaults:

    SOKOL_ASSERT(c)     - your own assert macro (default: assert(c))
    SOKOL_GLUE_API_DECL - public function declaration prefix (default: extern)
    SOKOL_API_DECL      - same as SOKOL_GLUE_API_DECL
    SOKOL_API_IMPL      - public function implementation prefix (default: -)

    If sokol_glue.h is compiled as a DLL, define the following before
    including the declaration or implementation:

    SOKOL_DLL

    On Windows, SOKOL_DLL will define SOKOL_GLUE_API_DECL as __declspec(dllexport)
    or __declspec(dllimport) as needed.

    OVERVIEW
    ========
    sokol_glue.h provides glue helper functions between sokol_gfx.h and sokol_app.h,
    so that sokol_gfx.h doesn't need to depend on sokol_app.h but can be
    used with different window system glue libraries.

    PROVIDED FUNCTIONS
    ==================

    sg_environment sglue_environment(void)

        Returns an sg_environment struct initialized by calling sokol_app.h
        functions. Use this in the sg_setup() call like this:

        sg_setup(&(sg_desc){
            .environment = sglue_environment(),
            ...
        });

    sg_swapchain sglue_swapchain(void)

        Returns an sg_swapchain struct initialized by calling sokol_app.h
        functions. Use this in sg_begin_pass() for a 'swapchain pass' like
        this:

        sg_begin_pass(&(sg_pass){ .swapchain = sglue_swapchain(), ... });

    LICENSE
    =======
    zlib/libpng license

    Copyright (c) 2018 Andre Weissflog

    This software is provided 'as-is', without any express or implied warranty.
    In no event will the authors be held liable for any damages arising from the
    use of this software.

    Permission is granted to anyone to use this software for any purpose,
    including commercial applications, and to alter it and redistribute it
    freely, subject to the following restrictions:

        1. The origin of this software must not be misrepresented; you must not
        claim that you wrote the original software. If you use this software in a
        product, an acknowledgment in the product documentation would be
        appreciated but is not required.

        2. Altered source versions must be plainly marked as such, and must not
        be misrepresented as being the original software.

        3. This notice may not be removed or altered from any source
        distribution.
*/
#define SOKOL_GLUE_INCLUDED

#if defined(SOKOL_API_DECL) && !defined(SOKOL_GLUE_API_DECL)
#define SOKOL_GLUE_API_DECL SOKOL_API_DECL
#endif
#ifndef SOKOL_GLUE_API_DECL
#if defined(_WIN32) && defined(SOKOL_DLL) && defined(SOKOL_GLUE_IMPL)
#define SOKOL_GLUE_API_DECL __declspec(dllexport)
#elif defined(_WIN32) && defined(SOKOL_DLL)
#define SOKOL_GLUE_API_DECL __declspec(dllimport)
#else
#define SOKOL_GLUE_API_DECL extern
#endif
#endif

#ifndef SOKOL_GFX_INCLUDED
#error "Please include sokol_gfx.h before sokol_glue.h"
#endif

#ifdef __cplusplus
extern "C" {
#endif

SOKOL_GLUE_API_DECL sg_environment sglue_environment(void);
SOKOL_GLUE_API_DECL sg_swapchain sglue_swapchain(void);

#ifdef __cplusplus
} /* extern "C" */
#endif
#endif /* SOKOL_GLUE_INCLUDED */

/*-- IMPLEMENTATION ----------------------------------------------------------*/
#ifdef SOKOL_GLUE_IMPL
#define SOKOL_GLUE_IMPL_INCLUDED (1)
#include <string.h> /* memset */

#ifndef SOKOL_APP_INCLUDED
#error "Please include sokol_app.h before the sokol_glue.h implementation"
#endif

#ifndef SOKOL_API_IMPL
#define SOKOL_API_IMPL
#endif


SOKOL_API_IMPL sg_environment sglue_environment(void) {
    sg_environment env;
    memset(&env, 0, sizeof(env));
    env.defaults.color_format = (sg_pixel_format) sapp_color_format();
    env.defaults.depth_format = (sg_pixel_format) sapp_depth_format();
    env.defaults.sample_count = sapp_sample_count();
    env.metal.device = sapp_metal_get_device();
    env.d3d11.device = sapp_d3d11_get_device();
    env.d3d11.device_context = sapp_d3d11_get_device_context();
    env.wgpu.device = sapp_wgpu_get_device();
    return env;
}

SOKOL_API_IMPL sg_swapchain sglue_swapchain(void) {
    sg_swapchain swapchain;
    memset(&swapchain, 0, sizeof(swapchain));
    swapchain.width = sapp_width();
    swapchain.height = sapp_height();
    swapchain.sample_count = sapp_sample_count();
    swapchain.color_format = (sg_pixel_format)sapp_color_format();
    swapchain.depth_format = (sg_pixel_format)sapp_depth_format();
    swapchain.metal.current_drawable = sapp_metal_get_current_drawable();
    swapchain.metal.depth_stencil_texture = sapp_metal_get_depth_stencil_texture();
    swapchain.metal.msaa_color_texture = sapp_metal_get_msaa_color_texture();
    swapchain.d3d11.render_view = sapp_d3d11_get_render_view();
    swapchain.d3d11.resolve_view = sapp_d3d11_get_resolve_view();
    swapchain.d3d11.depth_stencil_view = sapp_d3d11_get_depth_stencil_view();
    swapchain.wgpu.render_view = sapp_wgpu_get_render_view();
    swapchain.wgpu.resolve_view = sapp_wgpu_get_resolve_view();
    swapchain.wgpu.depth_stencil_view = sapp_wgpu_get_depth_stencil_view();
    swapchain.gl.framebuffer = sapp_gl_get_framebuffer();
    return swapchain;
}

#endif /* SOKOL_GLUE_IMPL */
//FILE_END

#endif //PK_NO_SAPP

//FILE_START:deps/hmm.h
/*
  HandmadeMath.h v2.0.0

  This is a single header file with a bunch of useful types and functions for
  games and graphics. Consider it a lightweight alternative to GLM that works
  both C and C++.

  =============================================================================
  CONFIG
  =============================================================================

  By default, all angles in Handmade Math are specified in radians. However, it
  can be configured to use degrees or turns instead. Use one of the following
  defines to specify the default unit for angles:

    #define HANDMADE_MATH_USE_RADIANS
    #define HANDMADE_MATH_USE_DEGREES
    #define HANDMADE_MATH_USE_TURNS

  Regardless of the default angle, you can use the following functions to
  specify an angle in a particular unit:

    HMM_AngleRad(radians)
    HMM_AngleDeg(degrees)
    HMM_AngleTurn(turns)

  The definitions of these functions change depending on the default unit.

  -----------------------------------------------------------------------------

  Handmade Math ships with SSE (SIMD) implementations of several common
  operations. To disable the use of SSE intrinsics, you must define
  HANDMADE_MATH_NO_SSE before including this file:

    #define HANDMADE_MATH_NO_SSE
    #include "HandmadeMath.h"

  -----------------------------------------------------------------------------

  To use Handmade Math without the C runtime library, you must provide your own
  implementations of basic math functions. Otherwise, HandmadeMath.h will use
  the runtime library implementation of these functions.

  Define HANDMADE_MATH_PROVIDE_MATH_FUNCTIONS and provide your own
  implementations of HMM_SINF, HMM_COSF, HMM_TANF, HMM_ACOSF, and HMM_SQRTF
  before including HandmadeMath.h, like so:

    #define HANDMADE_MATH_PROVIDE_MATH_FUNCTIONS
    #define HMM_SINF MySinF
    #define HMM_COSF MyCosF
    #define HMM_TANF MyTanF
    #define HMM_ACOSF MyACosF
    #define HMM_SQRTF MySqrtF
    #include "HandmadeMath.h"
  
  By default, it is assumed that your math functions take radians. To use
  different units, you must define HMM_ANGLE_USER_TO_INTERNAL and
  HMM_ANGLE_INTERNAL_TO_USER. For example, if you want to use degrees in your
  code but your math functions use turns:

    #define HMM_ANGLE_USER_TO_INTERNAL(a) ((a)*HMM_DegToTurn)
    #define HMM_ANGLE_INTERNAL_TO_USER(a) ((a)*HMM_TurnToDeg)

  =============================================================================
  
  LICENSE

  This software is in the public domain. Where that dedication is not
  recognized, you are granted a perpetual, irrevocable license to copy,
  distribute, and modify this file as you see fit.

  =============================================================================

  CREDITS

  Originally written by Zakary Strange.

  Functionality:
   Zakary Strange (strangezak@protonmail.com && @strangezak)
   Matt Mascarenhas (@miblo_)
   Aleph
   FieryDrake (@fierydrake)
   Gingerbill (@TheGingerBill)
   Ben Visness (@bvisness)
   Trinton Bullard (@Peliex_Dev)
   @AntonDan
   Logan Forman (@dev_dwarf)

  Fixes:
   Jeroen van Rijn (@J_vanRijn)
   Kiljacken (@Kiljacken)
   Insofaras (@insofaras)
   Daniel Gibson (@DanielGibson)
*/

#ifndef HANDMADE_MATH_H
#define HANDMADE_MATH_H

// Dummy macros for when test framework is not present.
#ifndef COVERAGE
# define COVERAGE(a, b)
#endif

#ifndef ASSERT_COVERED
# define ASSERT_COVERED(a)
#endif

/* let's figure out if SSE is really available (unless disabled anyway)
   (it isn't on non-x86/x86_64 platforms or even x86 without explicit SSE support)
   => only use "#ifdef HANDMADE_MATH__USE_SSE" to check for SSE support below this block! */
#ifndef HANDMADE_MATH_NO_SSE
# ifdef _MSC_VER /* MSVC supports SSE in amd64 mode or _M_IX86_FP >= 1 (2 means SSE2) */
#  if defined(_M_AMD64) || ( defined(_M_IX86_FP) && _M_IX86_FP >= 1 )
#   define HANDMADE_MATH__USE_SSE 1
#  endif
# else /* not MSVC, probably GCC, clang, icc or something that doesn't support SSE anyway */
#  ifdef __SSE__ /* they #define __SSE__ if it's supported */
#   define HANDMADE_MATH__USE_SSE 1
#  endif /*  __SSE__ */
# endif /* not _MSC_VER */
#endif /* #ifndef HANDMADE_MATH_NO_SSE */

#if (!defined(__cplusplus) && defined(__STDC_VERSION__) && __STDC_VERSION__ >= 201112L)
# define HANDMADE_MATH__USE_C11_GENERICS 1
#endif

#ifdef HANDMADE_MATH__USE_SSE
# include <xmmintrin.h>
#endif

#ifdef _MSC_VER
#pragma warning(disable:4201)
#endif

#if defined(__GNUC__) || defined(__clang__)
# pragma GCC diagnostic push
# pragma GCC diagnostic ignored "-Wfloat-equal"
# if (defined(__GNUC__) && (__GNUC__ == 4 && __GNUC_MINOR__ < 8)) || defined(__clang__)
#  pragma GCC diagnostic ignored "-Wmissing-braces"
# endif
# ifdef __clang__
#  pragma GCC diagnostic ignored "-Wgnu-anonymous-struct"
#  pragma GCC diagnostic ignored "-Wmissing-field-initializers"
# endif
#endif

#if defined(__GNUC__) || defined(__clang__)
# define HMM_DEPRECATED(msg) __attribute__((deprecated(msg)))
#elif defined(_MSC_VER)
# define HMM_DEPRECATED(msg) __declspec(deprecated(msg))
#else
# define HMM_DEPRECATED(msg)
#endif

#ifdef __cplusplus
extern "C"
{
#endif

#if !defined(HANDMADE_MATH_USE_DEGREES) \
    && !defined(HANDMADE_MATH_USE_TURNS) \
    && !defined(HANDMADE_MATH_USE_RADIANS)
# define HANDMADE_MATH_USE_RADIANS
#endif
    
#define HMM_PI 3.14159265358979323846
#define HMM_PI32 3.14159265359f
#define HMM_DEG180 180.0
#define HMM_DEG18032 180.0f
#define HMM_TURNHALF 0.5
#define HMM_TURNHALF32 0.5f
#define HMM_RadToDeg ((float)(HMM_DEG180/HMM_PI))
#define HMM_RadToTurn ((float)(HMM_TURNHALF/HMM_PI))
#define HMM_DegToRad ((float)(HMM_PI/HMM_DEG180))
#define HMM_DegToTurn ((float)(HMM_TURNHALF/HMM_DEG180))
#define HMM_TurnToRad ((float)(HMM_PI/HMM_TURNHALF))
#define HMM_TurnToDeg ((float)(HMM_DEG180/HMM_TURNHALF))

#if defined(HANDMADE_MATH_USE_RADIANS)
# define HMM_AngleRad(a) (a)
# define HMM_AngleDeg(a) ((a)*HMM_DegToRad)
# define HMM_AngleTurn(a) ((a)*HMM_TurnToRad)
#elif defined(HANDMADE_MATH_USE_DEGREES)
# define HMM_AngleRad(a) ((a)*HMM_RadToDeg)
# define HMM_AngleDeg(a) (a)
# define HMM_AngleTurn(a) ((a)*HMM_TurnToDeg)
#elif defined(HANDMADE_MATH_USE_TURNS)
# define HMM_AngleRad(a) ((a)*HMM_RadToTurn)
# define HMM_AngleDeg(a) ((a)*HMM_DegToTurn)
# define HMM_AngleTurn(a) (a)
#endif

#if !defined(HANDMADE_MATH_PROVIDE_MATH_FUNCTIONS)
# include <math.h>
# define HMM_SINF sinf
# define HMM_COSF cosf
# define HMM_TANF tanf
# define HMM_SQRTF sqrtf
# define HMM_ACOSF acosf
#endif

#if !defined(HMM_ANGLE_USER_TO_INTERNAL)
# define HMM_ANGLE_USER_TO_INTERNAL(a) (HMM_ToRad(a))
#endif

#if !defined(HMM_ANGLE_INTERNAL_TO_USER)
# if defined(HANDMADE_MATH_USE_RADIANS)
#  define HMM_ANGLE_INTERNAL_TO_USER(a) (a) 
# elif defined(HANDMADE_MATH_USE_DEGREES)
#  define HMM_ANGLE_INTERNAL_TO_USER(a) ((a)*HMM_RadToDeg)
# elif defined(HANDMADE_MATH_USE_TURNS)
#  define HMM_ANGLE_INTERNAL_TO_USER(a) ((a)*HMM_RadToTurn)
# endif
#endif

#define HMM_MIN(a, b) ((a) > (b) ? (b) : (a))
#define HMM_MAX(a, b) ((a) < (b) ? (b) : (a))
#define HMM_ABS(a) ((a) > 0 ? (a) : -(a))
#define HMM_MOD(a, m) (((a) % (m)) >= 0 ? ((a) % (m)) : (((a) % (m)) + (m)))
#define HMM_SQUARE(x) ((x) * (x))

typedef union HMM_Vec2
{
    struct
    {
        float X, Y;
    };

    struct
    {
        float U, V;
    };

    struct
    {
        float Left, Right;
    };

    struct
    {
        float Width, Height;
    };

    float Elements[2];

#ifdef __cplusplus
    inline float &operator[](const int &Index)
    {
        return Elements[Index];
    }
#endif
} HMM_Vec2;

typedef union HMM_Vec3
{
    struct
    {
        float X, Y, Z;
    };

    struct
    {
        float U, V, W;
    };

    struct
    {
        float R, G, B;
    };

    struct
    {
        HMM_Vec2 XY;
        float _Ignored0;
    };

    struct
    {
        float _Ignored1;
        HMM_Vec2 YZ;
    };

    struct
    {
        HMM_Vec2 UV;
        float _Ignored2;
    };

    struct
    {
        float _Ignored3;
        HMM_Vec2 VW;
    };

    float Elements[3];

#ifdef __cplusplus
    inline float &operator[](const int &Index)
    {
        return Elements[Index];
    }
#endif
} HMM_Vec3;

typedef union HMM_Vec4
{
    struct
    {
        union
        {
            HMM_Vec3 XYZ;
            struct
            {
                float X, Y, Z;
            };
        };

        float W;
    };
    struct
    {
        union
        {
            HMM_Vec3 RGB;
            struct
            {
                float R, G, B;
            };
        };

        float A;
    };

    struct
    {
        HMM_Vec2 XY;
        float _Ignored0;
        float _Ignored1;
    };

    struct
    {
        float _Ignored2;
        HMM_Vec2 YZ;
        float _Ignored3;
    };

    struct
    {
        float _Ignored4;
        float _Ignored5;
        HMM_Vec2 ZW;
    };

    float Elements[4];

#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSE;
#endif

#ifdef __cplusplus
    inline float &operator[](const int &Index)
    {
        return Elements[Index];
    }
#endif
} HMM_Vec4;

typedef union HMM_Mat2
{
    float Elements[2][2];
    HMM_Vec2 Columns[2];

#ifdef __cplusplus
    inline HMM_Vec2 &operator[](const int &Index)
    {
        return Columns[Index];
    }
#endif
} HMM_Mat2;
    
typedef union HMM_Mat3
{
    float Elements[3][3];
    HMM_Vec3 Columns[3];

#ifdef __cplusplus
    inline HMM_Vec3 &operator[](const int &Index)
    {
        return Columns[Index];
    }
#endif
} HMM_Mat3;

typedef union HMM_Mat4
{
    float Elements[4][4];
    HMM_Vec4 Columns[4];

#ifdef __cplusplus
    inline HMM_Vec4 &operator[](const int &Index)
    {
        return Columns[Index];
    }
#endif
} HMM_Mat4;

typedef union HMM_Quat
{
    struct
    {
        union
        {
            HMM_Vec3 XYZ;
            struct
            {
                float X, Y, Z;
            };
        };

        float W;
    };

    float Elements[4];

#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSE;
#endif
} HMM_Quat;

typedef signed int HMM_Bool;

/*
 * Angle unit conversion functions
 */
static inline float HMM_ToRad(float Angle)
{
#if defined(HANDMADE_MATH_USE_RADIANS)
    float Result = Angle;
#elif defined(HANDMADE_MATH_USE_DEGREES) 
    float Result = Angle * HMM_DegToRad;
#elif defined(HANDMADE_MATH_USE_TURNS)
    float Result = Angle * HMM_TurnToRad;
#endif
    
    return Result;
}

static inline float HMM_ToDeg(float Angle)
{
#if defined(HANDMADE_MATH_USE_RADIANS)
    float Result = Angle * HMM_RadToDeg;
#elif defined(HANDMADE_MATH_USE_DEGREES) 
    float Result = Angle;
#elif defined(HANDMADE_MATH_USE_TURNS)
    float Result = Angle * HMM_TurnToDeg;
#endif
    
    return Result;
}

static inline float HMM_ToTurn(float Angle)
{
#if defined(HANDMADE_MATH_USE_RADIANS)
    float Result = Angle * HMM_RadToTurn;
#elif defined(HANDMADE_MATH_USE_DEGREES) 
    float Result = Angle * HMM_DegToTurn;
#elif defined(HANDMADE_MATH_USE_TURNS)
    float Result = Angle;
#endif
    
    return Result;
}

/*
 * Floating-point math functions
 */

COVERAGE(HMM_SinF, 1)
static inline float HMM_SinF(float Angle)
{
    ASSERT_COVERED(HMM_SinF);
    return HMM_SINF(HMM_ANGLE_USER_TO_INTERNAL(Angle));
}

COVERAGE(HMM_CosF, 1)
static inline float HMM_CosF(float Angle)
{
    ASSERT_COVERED(HMM_CosF);
    return HMM_COSF(HMM_ANGLE_USER_TO_INTERNAL(Angle));
}

COVERAGE(HMM_TanF, 1)
static inline float HMM_TanF(float Angle)
{
    ASSERT_COVERED(HMM_TanF);
    return HMM_TANF(HMM_ANGLE_USER_TO_INTERNAL(Angle));
}

COVERAGE(HMM_ACosF, 1)
static inline float HMM_ACosF(float Arg)
{
    ASSERT_COVERED(HMM_ACosF);
    return HMM_ANGLE_INTERNAL_TO_USER(HMM_ACOSF(Arg));
}

COVERAGE(HMM_SqrtF, 1)
static inline float HMM_SqrtF(float Float)
{
    ASSERT_COVERED(HMM_SqrtF);

    float Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 In = _mm_set_ss(Float);
    __m128 Out = _mm_sqrt_ss(In);
    Result = _mm_cvtss_f32(Out);
#else
    Result = HMM_SQRTF(Float);
#endif

    return Result;
}

COVERAGE(HMM_InvSqrtF, 1)
static inline float HMM_InvSqrtF(float Float)
{
    ASSERT_COVERED(HMM_InvSqrtF);

    float Result;

    Result = 1.0f/HMM_SqrtF(Float);

    return Result;
}


/*
 * Utility functions
 */

COVERAGE(HMM_Lerp, 1)
static inline float HMM_Lerp(float A, float Time, float B)
{
    ASSERT_COVERED(HMM_Lerp);
    return (1.0f - Time) * A + Time * B;
}

COVERAGE(HMM_Clamp, 1)
static inline float HMM_Clamp(float Min, float Value, float Max)
{
    ASSERT_COVERED(HMM_Clamp);

    float Result = Value;

    if (Result < Min)
    {
        Result = Min;
    }

    if (Result > Max)
    {
        Result = Max;
    }

    return Result;
}


/*
 * Vector initialization
 */

COVERAGE(HMM_V2, 1)
static inline HMM_Vec2 HMM_V2(float X, float Y)
{
    ASSERT_COVERED(HMM_V2);

    HMM_Vec2 Result;
    Result.X = X;
    Result.Y = Y;

    return Result;
}

COVERAGE(HMM_V3, 1)
static inline HMM_Vec3 HMM_V3(float X, float Y, float Z)
{
    ASSERT_COVERED(HMM_V3);

    HMM_Vec3 Result;
    Result.X = X;
    Result.Y = Y;
    Result.Z = Z;

    return Result;
}

COVERAGE(HMM_V4, 1)
static inline HMM_Vec4 HMM_V4(float X, float Y, float Z, float W)
{
    ASSERT_COVERED(HMM_V4);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_setr_ps(X, Y, Z, W);
#else
    Result.X = X;
    Result.Y = Y;
    Result.Z = Z;
    Result.W = W;
#endif

    return Result;
}

COVERAGE(HMM_V4V, 1)
static inline HMM_Vec4 HMM_V4V(HMM_Vec3 Vector, float W)
{
    ASSERT_COVERED(HMM_V4V);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_setr_ps(Vector.X, Vector.Y, Vector.Z, W);
#else
    Result.XYZ = Vector;
    Result.W = W;
#endif

    return Result;
}


/*
 * Binary vector operations
 */

COVERAGE(HMM_AddV2, 1)
static inline HMM_Vec2 HMM_AddV2(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_AddV2);

    HMM_Vec2 Result;
    Result.X = Left.X + Right.X;
    Result.Y = Left.Y + Right.Y;

    return Result;
}

COVERAGE(HMM_AddV3, 1)
static inline HMM_Vec3 HMM_AddV3(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_AddV3);

    HMM_Vec3 Result;
    Result.X = Left.X + Right.X;
    Result.Y = Left.Y + Right.Y;
    Result.Z = Left.Z + Right.Z;

    return Result;
}

COVERAGE(HMM_AddV4, 1)
static inline HMM_Vec4 HMM_AddV4(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_AddV4);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_add_ps(Left.SSE, Right.SSE);
#else
    Result.X = Left.X + Right.X;
    Result.Y = Left.Y + Right.Y;
    Result.Z = Left.Z + Right.Z;
    Result.W = Left.W + Right.W;
#endif

    return Result;
}

COVERAGE(HMM_SubV2, 1)
static inline HMM_Vec2 HMM_SubV2(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_SubV2);

    HMM_Vec2 Result;
    Result.X = Left.X - Right.X;
    Result.Y = Left.Y - Right.Y;

    return Result;
}

COVERAGE(HMM_SubV3, 1)
static inline HMM_Vec3 HMM_SubV3(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_SubV3);

    HMM_Vec3 Result;
    Result.X = Left.X - Right.X;
    Result.Y = Left.Y - Right.Y;
    Result.Z = Left.Z - Right.Z;

    return Result;
}

COVERAGE(HMM_SubV4, 1)
static inline HMM_Vec4 HMM_SubV4(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_SubV4);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_sub_ps(Left.SSE, Right.SSE);
#else
    Result.X = Left.X - Right.X;
    Result.Y = Left.Y - Right.Y;
    Result.Z = Left.Z - Right.Z;
    Result.W = Left.W - Right.W;
#endif

    return Result;
}

COVERAGE(HMM_MulV2, 1)
static inline HMM_Vec2 HMM_MulV2(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_MulV2);

    HMM_Vec2 Result;
    Result.X = Left.X * Right.X;
    Result.Y = Left.Y * Right.Y;

    return Result;
}

COVERAGE(HMM_MulV2F, 1)
static inline HMM_Vec2 HMM_MulV2F(HMM_Vec2 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV2F);

    HMM_Vec2 Result;
    Result.X = Left.X * Right;
    Result.Y = Left.Y * Right;

    return Result;
}

COVERAGE(HMM_MulV3, 1)
static inline HMM_Vec3 HMM_MulV3(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_MulV3);

    HMM_Vec3 Result;
    Result.X = Left.X * Right.X;
    Result.Y = Left.Y * Right.Y;
    Result.Z = Left.Z * Right.Z;

    return Result;
}

COVERAGE(HMM_MulV3F, 1)
static inline HMM_Vec3 HMM_MulV3F(HMM_Vec3 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV3F);

    HMM_Vec3 Result;
    Result.X = Left.X * Right;
    Result.Y = Left.Y * Right;
    Result.Z = Left.Z * Right;

    return Result;
}

COVERAGE(HMM_MulV4, 1)
static inline HMM_Vec4 HMM_MulV4(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_MulV4);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_mul_ps(Left.SSE, Right.SSE);
#else
    Result.X = Left.X * Right.X;
    Result.Y = Left.Y * Right.Y;
    Result.Z = Left.Z * Right.Z;
    Result.W = Left.W * Right.W;
#endif

    return Result;
}

COVERAGE(HMM_MulV4F, 1)
static inline HMM_Vec4 HMM_MulV4F(HMM_Vec4 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV4F);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 Scalar = _mm_set1_ps(Right);
    Result.SSE = _mm_mul_ps(Left.SSE, Scalar);
#else
    Result.X = Left.X * Right;
    Result.Y = Left.Y * Right;
    Result.Z = Left.Z * Right;
    Result.W = Left.W * Right;
#endif

    return Result;
}

COVERAGE(HMM_DivV2, 1)
static inline HMM_Vec2 HMM_DivV2(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_DivV2);

    HMM_Vec2 Result;
    Result.X = Left.X / Right.X;
    Result.Y = Left.Y / Right.Y;

    return Result;
}

COVERAGE(HMM_DivV2F, 1)
static inline HMM_Vec2 HMM_DivV2F(HMM_Vec2 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV2F);

    HMM_Vec2 Result;
    Result.X = Left.X / Right;
    Result.Y = Left.Y / Right;

    return Result;
}

COVERAGE(HMM_DivV3, 1)
static inline HMM_Vec3 HMM_DivV3(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_DivV3);

    HMM_Vec3 Result;
    Result.X = Left.X / Right.X;
    Result.Y = Left.Y / Right.Y;
    Result.Z = Left.Z / Right.Z;

    return Result;
}

COVERAGE(HMM_DivV3F, 1)
static inline HMM_Vec3 HMM_DivV3F(HMM_Vec3 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV3F);

    HMM_Vec3 Result;
    Result.X = Left.X / Right;
    Result.Y = Left.Y / Right;
    Result.Z = Left.Z / Right;

    return Result;
}

COVERAGE(HMM_DivV4, 1)
static inline HMM_Vec4 HMM_DivV4(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_DivV4);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_div_ps(Left.SSE, Right.SSE);
#else
    Result.X = Left.X / Right.X;
    Result.Y = Left.Y / Right.Y;
    Result.Z = Left.Z / Right.Z;
    Result.W = Left.W / Right.W;
#endif

    return Result;
}

COVERAGE(HMM_DivV4F, 1)
static inline HMM_Vec4 HMM_DivV4F(HMM_Vec4 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV4F);

    HMM_Vec4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 Scalar = _mm_set1_ps(Right);
    Result.SSE = _mm_div_ps(Left.SSE, Scalar);
#else
    Result.X = Left.X / Right;
    Result.Y = Left.Y / Right;
    Result.Z = Left.Z / Right;
    Result.W = Left.W / Right;
#endif

    return Result;
}

COVERAGE(HMM_EqV2, 1)
static inline HMM_Bool HMM_EqV2(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_EqV2);
    return Left.X == Right.X && Left.Y == Right.Y;
}

COVERAGE(HMM_EqV3, 1)
static inline HMM_Bool HMM_EqV3(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_EqV3);
    return Left.X == Right.X && Left.Y == Right.Y && Left.Z == Right.Z;
}

COVERAGE(HMM_EqV4, 1)
static inline HMM_Bool HMM_EqV4(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_EqV4);
    return Left.X == Right.X && Left.Y == Right.Y && Left.Z == Right.Z && Left.W == Right.W;
}

COVERAGE(HMM_DotV2, 1)
static inline float HMM_DotV2(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_DotV2);
    return (Left.X * Right.X) + (Left.Y * Right.Y);
}

COVERAGE(HMM_DotV3, 1)
static inline float HMM_DotV3(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_DotV3);
    return (Left.X * Right.X) + (Left.Y * Right.Y) + (Left.Z * Right.Z);
}

COVERAGE(HMM_DotV4, 1)
static inline float HMM_DotV4(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_DotV4);

    float Result;

    // NOTE(zak): IN the future if we wanna check what version SSE is support
    // we can use _mm_dp_ps (4.3) but for now we will use the old way.
    // Or a r = _mm_mul_ps(v1, v2), r = _mm_hadd_ps(r, r), r = _mm_hadd_ps(r, r) for SSE3
#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSEResultOne = _mm_mul_ps(Left.SSE, Right.SSE);
    __m128 SSEResultTwo = _mm_shuffle_ps(SSEResultOne, SSEResultOne, _MM_SHUFFLE(2, 3, 0, 1));
    SSEResultOne = _mm_add_ps(SSEResultOne, SSEResultTwo);
    SSEResultTwo = _mm_shuffle_ps(SSEResultOne, SSEResultOne, _MM_SHUFFLE(0, 1, 2, 3));
    SSEResultOne = _mm_add_ps(SSEResultOne, SSEResultTwo);
    _mm_store_ss(&Result, SSEResultOne);
#else
    Result = ((Left.X * Right.X) + (Left.Z * Right.Z)) + ((Left.Y * Right.Y) + (Left.W * Right.W));
#endif

    return Result;
}

COVERAGE(HMM_Cross, 1)
static inline HMM_Vec3 HMM_Cross(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_Cross);

    HMM_Vec3 Result;
    Result.X = (Left.Y * Right.Z) - (Left.Z * Right.Y);
    Result.Y = (Left.Z * Right.X) - (Left.X * Right.Z);
    Result.Z = (Left.X * Right.Y) - (Left.Y * Right.X);

    return Result;
}


/*
 * Unary vector operations
 */

COVERAGE(HMM_LenSqrV2, 1)
static inline float HMM_LenSqrV2(HMM_Vec2 A)
{
    ASSERT_COVERED(HMM_LenSqrV2);
    return HMM_DotV2(A, A);
}

COVERAGE(HMM_LenSqrV3, 1)
static inline float HMM_LenSqrV3(HMM_Vec3 A)
{
    ASSERT_COVERED(HMM_LenSqrV3);
    return HMM_DotV3(A, A);
}

COVERAGE(HMM_LenSqrV4, 1)
static inline float HMM_LenSqrV4(HMM_Vec4 A)
{
    ASSERT_COVERED(HMM_LenSqrV4);
    return HMM_DotV4(A, A);
}

COVERAGE(HMM_LenV2, 1)
static inline float HMM_LenV2(HMM_Vec2 A)
{
    ASSERT_COVERED(HMM_LenV2);
    return HMM_SqrtF(HMM_LenSqrV2(A));
}

COVERAGE(HMM_LenV3, 1)
static inline float HMM_LenV3(HMM_Vec3 A)
{
    ASSERT_COVERED(HMM_LenV3);
    return HMM_SqrtF(HMM_LenSqrV3(A));
}

COVERAGE(HMM_LenV4, 1)
static inline float HMM_LenV4(HMM_Vec4 A)
{
    ASSERT_COVERED(HMM_LenV4);
    return HMM_SqrtF(HMM_LenSqrV4(A));
}

COVERAGE(HMM_NormV2, 1)
static inline HMM_Vec2 HMM_NormV2(HMM_Vec2 A)
{
    ASSERT_COVERED(HMM_NormV2);
    return HMM_MulV2F(A, HMM_InvSqrtF(HMM_DotV2(A, A)));
}

COVERAGE(HMM_NormV3, 1)
static inline HMM_Vec3 HMM_NormV3(HMM_Vec3 A)
{
    ASSERT_COVERED(HMM_NormV3);
    return HMM_MulV3F(A, HMM_InvSqrtF(HMM_DotV3(A, A)));
}

COVERAGE(HMM_NormV4, 1)
static inline HMM_Vec4 HMM_NormV4(HMM_Vec4 A)
{
    ASSERT_COVERED(HMM_NormV4);
    return HMM_MulV4F(A, HMM_InvSqrtF(HMM_DotV4(A, A)));
}

/*
 * Utility vector functions
 */

COVERAGE(HMM_LerpV2, 1)
static inline HMM_Vec2 HMM_LerpV2(HMM_Vec2 A, float Time, HMM_Vec2 B) 
{
    ASSERT_COVERED(HMM_LerpV2);
    return HMM_AddV2(HMM_MulV2F(A, 1.0f - Time), HMM_MulV2F(B, Time));
}

COVERAGE(HMM_LerpV3, 1)
static inline HMM_Vec3 HMM_LerpV3(HMM_Vec3 A, float Time, HMM_Vec3 B) 
{
    ASSERT_COVERED(HMM_LerpV3);
    return HMM_AddV3(HMM_MulV3F(A, 1.0f - Time), HMM_MulV3F(B, Time));
}

COVERAGE(HMM_LerpV4, 1)
static inline HMM_Vec4 HMM_LerpV4(HMM_Vec4 A, float Time, HMM_Vec4 B) 
{
    ASSERT_COVERED(HMM_LerpV4);
    return HMM_AddV4(HMM_MulV4F(A, 1.0f - Time), HMM_MulV4F(B, Time));
}

/*
 * SSE stuff
 */

COVERAGE(HMM_LinearCombineV4M4, 1)
static inline HMM_Vec4 HMM_LinearCombineV4M4(HMM_Vec4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_LinearCombineV4M4);

    HMM_Vec4 Result;
#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_mul_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, 0x00), Right.Columns[0].SSE);
    Result.SSE = _mm_add_ps(Result.SSE, _mm_mul_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, 0x55), Right.Columns[1].SSE));
    Result.SSE = _mm_add_ps(Result.SSE, _mm_mul_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, 0xaa), Right.Columns[2].SSE));
    Result.SSE = _mm_add_ps(Result.SSE, _mm_mul_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, 0xff), Right.Columns[3].SSE));
#else
    Result.X = Left.Elements[0] * Right.Columns[0].X;
    Result.Y = Left.Elements[0] * Right.Columns[0].Y;
    Result.Z = Left.Elements[0] * Right.Columns[0].Z;
    Result.W = Left.Elements[0] * Right.Columns[0].W;

    Result.X += Left.Elements[1] * Right.Columns[1].X;
    Result.Y += Left.Elements[1] * Right.Columns[1].Y;
    Result.Z += Left.Elements[1] * Right.Columns[1].Z;
    Result.W += Left.Elements[1] * Right.Columns[1].W;

    Result.X += Left.Elements[2] * Right.Columns[2].X;
    Result.Y += Left.Elements[2] * Right.Columns[2].Y;
    Result.Z += Left.Elements[2] * Right.Columns[2].Z;
    Result.W += Left.Elements[2] * Right.Columns[2].W;

    Result.X += Left.Elements[3] * Right.Columns[3].X;
    Result.Y += Left.Elements[3] * Right.Columns[3].Y;
    Result.Z += Left.Elements[3] * Right.Columns[3].Z;
    Result.W += Left.Elements[3] * Right.Columns[3].W;
#endif

    return Result;
}

/*
 * 2x2 Matrices
 */

COVERAGE(HMM_M2, 1)
static inline HMM_Mat2 HMM_M2(void)
{
    ASSERT_COVERED(HMM_M2);
    HMM_Mat2 Result = {0};
    return Result;
}

COVERAGE(HMM_M2D, 1)
static inline HMM_Mat2 HMM_M2D(float Diagonal)
{
    ASSERT_COVERED(HMM_M2D);
    
    HMM_Mat2 Result = {0};
    Result.Elements[0][0] = Diagonal;
    Result.Elements[1][1] = Diagonal;

    return Result;
}

COVERAGE(HMM_TransposeM2, 1)
static inline HMM_Mat2 HMM_TransposeM2(HMM_Mat2 Matrix)
{
    ASSERT_COVERED(HMM_TransposeM2);
    
    HMM_Mat2 Result = Matrix;

    Result.Elements[0][1] = Matrix.Elements[1][0];
    Result.Elements[1][0] = Matrix.Elements[0][1];
    
    return Result;
}

COVERAGE(HMM_AddM2, 1)
static inline HMM_Mat2 HMM_AddM2(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_AddM2);
    
    HMM_Mat2 Result;

    Result.Elements[0][0] = Left.Elements[0][0] + Right.Elements[0][0];
    Result.Elements[0][1] = Left.Elements[0][1] + Right.Elements[0][1];
    Result.Elements[1][0] = Left.Elements[1][0] + Right.Elements[1][0];
    Result.Elements[1][1] = Left.Elements[1][1] + Right.Elements[1][1];
   
    return Result;    
}

COVERAGE(HMM_SubM2, 1)
static inline HMM_Mat2 HMM_SubM2(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_SubM2);
    
    HMM_Mat2 Result;

    Result.Elements[0][0] = Left.Elements[0][0] - Right.Elements[0][0];
    Result.Elements[0][1] = Left.Elements[0][1] - Right.Elements[0][1];
    Result.Elements[1][0] = Left.Elements[1][0] - Right.Elements[1][0];
    Result.Elements[1][1] = Left.Elements[1][1] - Right.Elements[1][1];
    
    return Result;
}

COVERAGE(HMM_MulM2V2, 1)
static inline HMM_Vec2 HMM_MulM2V2(HMM_Mat2 Matrix, HMM_Vec2 Vector)
{
    ASSERT_COVERED(HMM_MulM2V2);
    
    HMM_Vec2 Result;

    Result.X = Vector.Elements[0] * Matrix.Columns[0].X;
    Result.Y = Vector.Elements[0] * Matrix.Columns[0].Y;

    Result.X += Vector.Elements[1] * Matrix.Columns[1].X;
    Result.Y += Vector.Elements[1] * Matrix.Columns[1].Y;

    return Result;    
}

COVERAGE(HMM_MulM2, 1)
static inline HMM_Mat2 HMM_MulM2(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_MulM2);
    
    HMM_Mat2 Result;
    Result.Columns[0] = HMM_MulM2V2(Left, Right.Columns[0]);
    Result.Columns[1] = HMM_MulM2V2(Left, Right.Columns[1]);

    return Result;    
}

COVERAGE(HMM_MulM2F, 1)
static inline HMM_Mat2 HMM_MulM2F(HMM_Mat2 Matrix, float Scalar)
{
    ASSERT_COVERED(HMM_MulM2F);
    
    HMM_Mat2 Result;

    Result.Elements[0][0] = Matrix.Elements[0][0] * Scalar;
    Result.Elements[0][1] = Matrix.Elements[0][1] * Scalar;
    Result.Elements[1][0] = Matrix.Elements[1][0] * Scalar;
    Result.Elements[1][1] = Matrix.Elements[1][1] * Scalar;
    
    return Result;
}

COVERAGE(HMM_DivM2F, 1)
static inline HMM_Mat2 HMM_DivM2F(HMM_Mat2 Matrix, float Scalar)
{
    ASSERT_COVERED(HMM_DivM2F);
    
    HMM_Mat2 Result;

    Result.Elements[0][0] = Matrix.Elements[0][0] / Scalar;
    Result.Elements[0][1] = Matrix.Elements[0][1] / Scalar;
    Result.Elements[1][0] = Matrix.Elements[1][0] / Scalar;
    Result.Elements[1][1] = Matrix.Elements[1][1] / Scalar;

    return Result;
}

COVERAGE(HMM_DeterminantM2, 1)
static inline float HMM_DeterminantM2(HMM_Mat2 Matrix) 
{
    ASSERT_COVERED(HMM_DeterminantM2);
    return Matrix.Elements[0][0]*Matrix.Elements[1][1] - Matrix.Elements[0][1]*Matrix.Elements[1][0];
}


COVERAGE(HMM_InvGeneralM2, 1)
static inline HMM_Mat2 HMM_InvGeneralM2(HMM_Mat2 Matrix) 
{
    ASSERT_COVERED(HMM_InvGeneralM2);

    HMM_Mat2 Result;
    float InvDeterminant = 1.0f / HMM_DeterminantM2(Matrix);
    Result.Elements[0][0] = InvDeterminant * +Matrix.Elements[1][1];
    Result.Elements[1][1] = InvDeterminant * +Matrix.Elements[0][0];
    Result.Elements[0][1] = InvDeterminant * -Matrix.Elements[0][1];
    Result.Elements[1][0] = InvDeterminant * -Matrix.Elements[1][0];

    return Result;
}

/*
 * 3x3 Matrices
 */

COVERAGE(HMM_M3, 1)
static inline HMM_Mat3 HMM_M3(void)
{
    ASSERT_COVERED(HMM_M3);
    HMM_Mat3 Result = {0};
    return Result;
}

COVERAGE(HMM_M3D, 1)
static inline HMM_Mat3 HMM_M3D(float Diagonal)
{
    ASSERT_COVERED(HMM_M3D);
    
    HMM_Mat3 Result = {0};
    Result.Elements[0][0] = Diagonal;
    Result.Elements[1][1] = Diagonal;
    Result.Elements[2][2] = Diagonal;

    return Result;
}

COVERAGE(HMM_TransposeM3, 1)
static inline HMM_Mat3 HMM_TransposeM3(HMM_Mat3 Matrix)
{
    ASSERT_COVERED(HMM_TransposeM3);

    HMM_Mat3 Result = Matrix;

    Result.Elements[0][1] = Matrix.Elements[1][0];
    Result.Elements[0][2] = Matrix.Elements[2][0];
    Result.Elements[1][0] = Matrix.Elements[0][1];
    Result.Elements[1][2] = Matrix.Elements[2][1];
    Result.Elements[2][1] = Matrix.Elements[1][2];
    Result.Elements[2][0] = Matrix.Elements[0][2];
    
    return Result;
}

COVERAGE(HMM_AddM3, 1)
static inline HMM_Mat3 HMM_AddM3(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_AddM3);
    
    HMM_Mat3 Result;
    
    Result.Elements[0][0] = Left.Elements[0][0] + Right.Elements[0][0];
    Result.Elements[0][1] = Left.Elements[0][1] + Right.Elements[0][1];
    Result.Elements[0][2] = Left.Elements[0][2] + Right.Elements[0][2];
    Result.Elements[1][0] = Left.Elements[1][0] + Right.Elements[1][0];
    Result.Elements[1][1] = Left.Elements[1][1] + Right.Elements[1][1];
    Result.Elements[1][2] = Left.Elements[1][2] + Right.Elements[1][2];
    Result.Elements[2][0] = Left.Elements[2][0] + Right.Elements[2][0];
    Result.Elements[2][1] = Left.Elements[2][1] + Right.Elements[2][1];
    Result.Elements[2][2] = Left.Elements[2][2] + Right.Elements[2][2];

    return Result;    
}

COVERAGE(HMM_SubM3, 1)
static inline HMM_Mat3 HMM_SubM3(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_SubM3);

    HMM_Mat3 Result;

    Result.Elements[0][0] = Left.Elements[0][0] - Right.Elements[0][0];
    Result.Elements[0][1] = Left.Elements[0][1] - Right.Elements[0][1];
    Result.Elements[0][2] = Left.Elements[0][2] - Right.Elements[0][2];
    Result.Elements[1][0] = Left.Elements[1][0] - Right.Elements[1][0];
    Result.Elements[1][1] = Left.Elements[1][1] - Right.Elements[1][1];
    Result.Elements[1][2] = Left.Elements[1][2] - Right.Elements[1][2];
    Result.Elements[2][0] = Left.Elements[2][0] - Right.Elements[2][0];
    Result.Elements[2][1] = Left.Elements[2][1] - Right.Elements[2][1];
    Result.Elements[2][2] = Left.Elements[2][2] - Right.Elements[2][2];

    return Result;
}

COVERAGE(HMM_MulM3V3, 1)
static inline HMM_Vec3 HMM_MulM3V3(HMM_Mat3 Matrix, HMM_Vec3 Vector)
{
    ASSERT_COVERED(HMM_MulM3V3);
    
    HMM_Vec3 Result;

    Result.X = Vector.Elements[0] * Matrix.Columns[0].X;
    Result.Y = Vector.Elements[0] * Matrix.Columns[0].Y;
    Result.Z = Vector.Elements[0] * Matrix.Columns[0].Z;

    Result.X += Vector.Elements[1] * Matrix.Columns[1].X;
    Result.Y += Vector.Elements[1] * Matrix.Columns[1].Y;
    Result.Z += Vector.Elements[1] * Matrix.Columns[1].Z;

    Result.X += Vector.Elements[2] * Matrix.Columns[2].X;
    Result.Y += Vector.Elements[2] * Matrix.Columns[2].Y;
    Result.Z += Vector.Elements[2] * Matrix.Columns[2].Z;
    
    return Result;    
}

COVERAGE(HMM_MulM3, 1)
static inline HMM_Mat3 HMM_MulM3(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_MulM3);

    HMM_Mat3 Result;
    Result.Columns[0] = HMM_MulM3V3(Left, Right.Columns[0]);
    Result.Columns[1] = HMM_MulM3V3(Left, Right.Columns[1]);
    Result.Columns[2] = HMM_MulM3V3(Left, Right.Columns[2]);

    return Result;    
}

COVERAGE(HMM_MulM3F, 1)
static inline HMM_Mat3 HMM_MulM3F(HMM_Mat3 Matrix, float Scalar)
{
    ASSERT_COVERED(HMM_MulM3F);

    HMM_Mat3 Result;

    Result.Elements[0][0] = Matrix.Elements[0][0] * Scalar;
    Result.Elements[0][1] = Matrix.Elements[0][1] * Scalar;
    Result.Elements[0][2] = Matrix.Elements[0][2] * Scalar;
    Result.Elements[1][0] = Matrix.Elements[1][0] * Scalar;
    Result.Elements[1][1] = Matrix.Elements[1][1] * Scalar;
    Result.Elements[1][2] = Matrix.Elements[1][2] * Scalar;
    Result.Elements[2][0] = Matrix.Elements[2][0] * Scalar;
    Result.Elements[2][1] = Matrix.Elements[2][1] * Scalar;
    Result.Elements[2][2] = Matrix.Elements[2][2] * Scalar;

    return Result;            
}

COVERAGE(HMM_DivM3, 1)
static inline HMM_Mat3 HMM_DivM3F(HMM_Mat3 Matrix, float Scalar)
{
    ASSERT_COVERED(HMM_DivM3);

    HMM_Mat3 Result;
    
    Result.Elements[0][0] = Matrix.Elements[0][0] / Scalar;
    Result.Elements[0][1] = Matrix.Elements[0][1] / Scalar;
    Result.Elements[0][2] = Matrix.Elements[0][2] / Scalar;
    Result.Elements[1][0] = Matrix.Elements[1][0] / Scalar;
    Result.Elements[1][1] = Matrix.Elements[1][1] / Scalar;
    Result.Elements[1][2] = Matrix.Elements[1][2] / Scalar;
    Result.Elements[2][0] = Matrix.Elements[2][0] / Scalar;
    Result.Elements[2][1] = Matrix.Elements[2][1] / Scalar;
    Result.Elements[2][2] = Matrix.Elements[2][2] / Scalar;

    return Result;                    
}

COVERAGE(HMM_DeterminantM3, 1)
static inline float HMM_DeterminantM3(HMM_Mat3 Matrix) 
{
    ASSERT_COVERED(HMM_DeterminantM3);

    HMM_Mat3 Cross;
    Cross.Columns[0] = HMM_Cross(Matrix.Columns[1], Matrix.Columns[2]);
    Cross.Columns[1] = HMM_Cross(Matrix.Columns[2], Matrix.Columns[0]);
    Cross.Columns[2] = HMM_Cross(Matrix.Columns[0], Matrix.Columns[1]);

    return HMM_DotV3(Cross.Columns[2], Matrix.Columns[2]);
}

COVERAGE(HMM_InvGeneralM3, 1)
static inline HMM_Mat3 HMM_InvGeneralM3(HMM_Mat3 Matrix) 
{
    ASSERT_COVERED(HMM_InvGeneralM3);

    HMM_Mat3 Cross;
    Cross.Columns[0] = HMM_Cross(Matrix.Columns[1], Matrix.Columns[2]);
    Cross.Columns[1] = HMM_Cross(Matrix.Columns[2], Matrix.Columns[0]);
    Cross.Columns[2] = HMM_Cross(Matrix.Columns[0], Matrix.Columns[1]);

    float InvDeterminant = 1.0f / HMM_DotV3(Cross.Columns[2], Matrix.Columns[2]);

    HMM_Mat3 Result;
    Result.Columns[0] = HMM_MulV3F(Cross.Columns[0], InvDeterminant);
    Result.Columns[1] = HMM_MulV3F(Cross.Columns[1], InvDeterminant);
    Result.Columns[2] = HMM_MulV3F(Cross.Columns[2], InvDeterminant);

    return HMM_TransposeM3(Result);
}

/*
 * 4x4 Matrices
 */

COVERAGE(HMM_M4, 1)
static inline HMM_Mat4 HMM_M4(void)
{
    ASSERT_COVERED(HMM_M4);
    HMM_Mat4 Result = {0};
    return Result;
}

COVERAGE(HMM_M4D, 1)
static inline HMM_Mat4 HMM_M4D(float Diagonal)
{
    ASSERT_COVERED(HMM_M4D);

    HMM_Mat4 Result = {0};
    Result.Elements[0][0] = Diagonal;
    Result.Elements[1][1] = Diagonal;
    Result.Elements[2][2] = Diagonal;
    Result.Elements[3][3] = Diagonal;

    return Result;
}

COVERAGE(HMM_TransposeM4, 1)
static inline HMM_Mat4 HMM_TransposeM4(HMM_Mat4 Matrix)
{
    ASSERT_COVERED(HMM_TransposeM4);

    HMM_Mat4 Result = Matrix;
#ifdef HANDMADE_MATH__USE_SSE
    _MM_TRANSPOSE4_PS(Result.Columns[0].SSE, Result.Columns[1].SSE, Result.Columns[2].SSE, Result.Columns[3].SSE);
#else
    Result.Elements[0][1] = Matrix.Elements[1][0];
    Result.Elements[0][2] = Matrix.Elements[2][0];
    Result.Elements[0][3] = Matrix.Elements[3][0];
    Result.Elements[1][0] = Matrix.Elements[0][1];
    Result.Elements[1][2] = Matrix.Elements[2][1];
    Result.Elements[1][3] = Matrix.Elements[3][1];
    Result.Elements[2][1] = Matrix.Elements[1][2];
    Result.Elements[2][0] = Matrix.Elements[0][2];
    Result.Elements[2][3] = Matrix.Elements[3][2];
    Result.Elements[3][1] = Matrix.Elements[1][3];
    Result.Elements[3][2] = Matrix.Elements[2][3];
    Result.Elements[3][0] = Matrix.Elements[0][3];
#endif

    return Result;
}

COVERAGE(HMM_AddM4, 1)
static inline HMM_Mat4 HMM_AddM4(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_AddM4);

    HMM_Mat4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.Columns[0].SSE = _mm_add_ps(Left.Columns[0].SSE, Right.Columns[0].SSE);
    Result.Columns[1].SSE = _mm_add_ps(Left.Columns[1].SSE, Right.Columns[1].SSE);
    Result.Columns[2].SSE = _mm_add_ps(Left.Columns[2].SSE, Right.Columns[2].SSE);
    Result.Columns[3].SSE = _mm_add_ps(Left.Columns[3].SSE, Right.Columns[3].SSE);
#else
    Result.Elements[0][0] = Left.Elements[0][0] + Right.Elements[0][0];
    Result.Elements[0][1] = Left.Elements[0][1] + Right.Elements[0][1];
    Result.Elements[0][2] = Left.Elements[0][2] + Right.Elements[0][2];
    Result.Elements[0][3] = Left.Elements[0][3] + Right.Elements[0][3];
    Result.Elements[1][0] = Left.Elements[1][0] + Right.Elements[1][0];
    Result.Elements[1][1] = Left.Elements[1][1] + Right.Elements[1][1];
    Result.Elements[1][2] = Left.Elements[1][2] + Right.Elements[1][2];
    Result.Elements[1][3] = Left.Elements[1][3] + Right.Elements[1][3];
    Result.Elements[2][0] = Left.Elements[2][0] + Right.Elements[2][0];
    Result.Elements[2][1] = Left.Elements[2][1] + Right.Elements[2][1];
    Result.Elements[2][2] = Left.Elements[2][2] + Right.Elements[2][2];
    Result.Elements[2][3] = Left.Elements[2][3] + Right.Elements[2][3];
    Result.Elements[3][0] = Left.Elements[3][0] + Right.Elements[3][0];
    Result.Elements[3][1] = Left.Elements[3][1] + Right.Elements[3][1];
    Result.Elements[3][2] = Left.Elements[3][2] + Right.Elements[3][2];
    Result.Elements[3][3] = Left.Elements[3][3] + Right.Elements[3][3];
#endif

    return Result;
}

COVERAGE(HMM_SubM4, 1)
static inline HMM_Mat4 HMM_SubM4(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_SubM4);

    HMM_Mat4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.Columns[0].SSE = _mm_sub_ps(Left.Columns[0].SSE, Right.Columns[0].SSE);
    Result.Columns[1].SSE = _mm_sub_ps(Left.Columns[1].SSE, Right.Columns[1].SSE);
    Result.Columns[2].SSE = _mm_sub_ps(Left.Columns[2].SSE, Right.Columns[2].SSE);
    Result.Columns[3].SSE = _mm_sub_ps(Left.Columns[3].SSE, Right.Columns[3].SSE);
#else
    Result.Elements[0][0] = Left.Elements[0][0] - Right.Elements[0][0];
    Result.Elements[0][1] = Left.Elements[0][1] - Right.Elements[0][1];
    Result.Elements[0][2] = Left.Elements[0][2] - Right.Elements[0][2];
    Result.Elements[0][3] = Left.Elements[0][3] - Right.Elements[0][3];
    Result.Elements[1][0] = Left.Elements[1][0] - Right.Elements[1][0];
    Result.Elements[1][1] = Left.Elements[1][1] - Right.Elements[1][1];
    Result.Elements[1][2] = Left.Elements[1][2] - Right.Elements[1][2];
    Result.Elements[1][3] = Left.Elements[1][3] - Right.Elements[1][3];
    Result.Elements[2][0] = Left.Elements[2][0] - Right.Elements[2][0];
    Result.Elements[2][1] = Left.Elements[2][1] - Right.Elements[2][1];
    Result.Elements[2][2] = Left.Elements[2][2] - Right.Elements[2][2];
    Result.Elements[2][3] = Left.Elements[2][3] - Right.Elements[2][3];
    Result.Elements[3][0] = Left.Elements[3][0] - Right.Elements[3][0];
    Result.Elements[3][1] = Left.Elements[3][1] - Right.Elements[3][1];
    Result.Elements[3][2] = Left.Elements[3][2] - Right.Elements[3][2];
    Result.Elements[3][3] = Left.Elements[3][3] - Right.Elements[3][3];
#endif
 
    return Result;
}

COVERAGE(HMM_MulM4, 1)
static inline HMM_Mat4 HMM_MulM4(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_MulM4);

    HMM_Mat4 Result;
    Result.Columns[0] = HMM_LinearCombineV4M4(Right.Columns[0], Left);
    Result.Columns[1] = HMM_LinearCombineV4M4(Right.Columns[1], Left);
    Result.Columns[2] = HMM_LinearCombineV4M4(Right.Columns[2], Left);
    Result.Columns[3] = HMM_LinearCombineV4M4(Right.Columns[3], Left);

    return Result;
}

COVERAGE(HMM_MulM4F, 1)
static inline HMM_Mat4 HMM_MulM4F(HMM_Mat4 Matrix, float Scalar)
{
    ASSERT_COVERED(HMM_MulM4F);

    HMM_Mat4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSEScalar = _mm_set1_ps(Scalar);
    Result.Columns[0].SSE = _mm_mul_ps(Matrix.Columns[0].SSE, SSEScalar);
    Result.Columns[1].SSE = _mm_mul_ps(Matrix.Columns[1].SSE, SSEScalar);
    Result.Columns[2].SSE = _mm_mul_ps(Matrix.Columns[2].SSE, SSEScalar);
    Result.Columns[3].SSE = _mm_mul_ps(Matrix.Columns[3].SSE, SSEScalar);
#else
    Result.Elements[0][0] = Matrix.Elements[0][0] * Scalar;
    Result.Elements[0][1] = Matrix.Elements[0][1] * Scalar;
    Result.Elements[0][2] = Matrix.Elements[0][2] * Scalar;
    Result.Elements[0][3] = Matrix.Elements[0][3] * Scalar;
    Result.Elements[1][0] = Matrix.Elements[1][0] * Scalar;
    Result.Elements[1][1] = Matrix.Elements[1][1] * Scalar;
    Result.Elements[1][2] = Matrix.Elements[1][2] * Scalar;
    Result.Elements[1][3] = Matrix.Elements[1][3] * Scalar;
    Result.Elements[2][0] = Matrix.Elements[2][0] * Scalar;
    Result.Elements[2][1] = Matrix.Elements[2][1] * Scalar;
    Result.Elements[2][2] = Matrix.Elements[2][2] * Scalar;
    Result.Elements[2][3] = Matrix.Elements[2][3] * Scalar;
    Result.Elements[3][0] = Matrix.Elements[3][0] * Scalar;
    Result.Elements[3][1] = Matrix.Elements[3][1] * Scalar;
    Result.Elements[3][2] = Matrix.Elements[3][2] * Scalar;
    Result.Elements[3][3] = Matrix.Elements[3][3] * Scalar;
#endif

    return Result;
}

COVERAGE(HMM_MulM4V4, 1)
static inline HMM_Vec4 HMM_MulM4V4(HMM_Mat4 Matrix, HMM_Vec4 Vector)
{
    ASSERT_COVERED(HMM_MulM4V4);
    return HMM_LinearCombineV4M4(Vector, Matrix);
}

COVERAGE(HMM_DivM4F, 1)
static inline HMM_Mat4 HMM_DivM4F(HMM_Mat4 Matrix, float Scalar)
{
    ASSERT_COVERED(HMM_DivM4F);

    HMM_Mat4 Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSEScalar = _mm_set1_ps(Scalar);
    Result.Columns[0].SSE = _mm_div_ps(Matrix.Columns[0].SSE, SSEScalar);
    Result.Columns[1].SSE = _mm_div_ps(Matrix.Columns[1].SSE, SSEScalar);
    Result.Columns[2].SSE = _mm_div_ps(Matrix.Columns[2].SSE, SSEScalar);
    Result.Columns[3].SSE = _mm_div_ps(Matrix.Columns[3].SSE, SSEScalar);
#else
    Result.Elements[0][0] = Matrix.Elements[0][0] / Scalar;
    Result.Elements[0][1] = Matrix.Elements[0][1] / Scalar;
    Result.Elements[0][2] = Matrix.Elements[0][2] / Scalar;
    Result.Elements[0][3] = Matrix.Elements[0][3] / Scalar;
    Result.Elements[1][0] = Matrix.Elements[1][0] / Scalar;
    Result.Elements[1][1] = Matrix.Elements[1][1] / Scalar;
    Result.Elements[1][2] = Matrix.Elements[1][2] / Scalar;
    Result.Elements[1][3] = Matrix.Elements[1][3] / Scalar;
    Result.Elements[2][0] = Matrix.Elements[2][0] / Scalar;
    Result.Elements[2][1] = Matrix.Elements[2][1] / Scalar;
    Result.Elements[2][2] = Matrix.Elements[2][2] / Scalar;
    Result.Elements[2][3] = Matrix.Elements[2][3] / Scalar;
    Result.Elements[3][0] = Matrix.Elements[3][0] / Scalar;
    Result.Elements[3][1] = Matrix.Elements[3][1] / Scalar;
    Result.Elements[3][2] = Matrix.Elements[3][2] / Scalar;
    Result.Elements[3][3] = Matrix.Elements[3][3] / Scalar;
#endif

    return Result;
}

COVERAGE(HMM_DeterminantM4, 1)
static inline float HMM_DeterminantM4(HMM_Mat4 Matrix) 
{
    ASSERT_COVERED(HMM_DeterminantM4);

    HMM_Vec3 C01 = HMM_Cross(Matrix.Columns[0].XYZ, Matrix.Columns[1].XYZ);
    HMM_Vec3 C23 = HMM_Cross(Matrix.Columns[2].XYZ, Matrix.Columns[3].XYZ);
    HMM_Vec3 B10 = HMM_SubV3(HMM_MulV3F(Matrix.Columns[0].XYZ, Matrix.Columns[1].W), HMM_MulV3F(Matrix.Columns[1].XYZ, Matrix.Columns[0].W));
    HMM_Vec3 B32 = HMM_SubV3(HMM_MulV3F(Matrix.Columns[2].XYZ, Matrix.Columns[3].W), HMM_MulV3F(Matrix.Columns[3].XYZ, Matrix.Columns[2].W));
    
    return HMM_DotV3(C01, B32) + HMM_DotV3(C23, B10);
}

COVERAGE(HMM_InvGeneralM4, 1)
// Returns a general-purpose inverse of an HMM_Mat4. Note that special-purpose inverses of many transformations
// are available and will be more efficient.
static inline HMM_Mat4 HMM_InvGeneralM4(HMM_Mat4 Matrix) 
{
    ASSERT_COVERED(HMM_InvGeneralM4);

    HMM_Vec3 C01 = HMM_Cross(Matrix.Columns[0].XYZ, Matrix.Columns[1].XYZ);
    HMM_Vec3 C23 = HMM_Cross(Matrix.Columns[2].XYZ, Matrix.Columns[3].XYZ);
    HMM_Vec3 B10 = HMM_SubV3(HMM_MulV3F(Matrix.Columns[0].XYZ, Matrix.Columns[1].W), HMM_MulV3F(Matrix.Columns[1].XYZ, Matrix.Columns[0].W));
    HMM_Vec3 B32 = HMM_SubV3(HMM_MulV3F(Matrix.Columns[2].XYZ, Matrix.Columns[3].W), HMM_MulV3F(Matrix.Columns[3].XYZ, Matrix.Columns[2].W));
    
    float InvDeterminant = 1.0f / (HMM_DotV3(C01, B32) + HMM_DotV3(C23, B10));
    C01 = HMM_MulV3F(C01, InvDeterminant);
    C23 = HMM_MulV3F(C23, InvDeterminant);
    B10 = HMM_MulV3F(B10, InvDeterminant);
    B32 = HMM_MulV3F(B32, InvDeterminant);

    HMM_Mat4 Result;
    Result.Columns[0] = HMM_V4V(HMM_AddV3(HMM_Cross(Matrix.Columns[1].XYZ, B32), HMM_MulV3F(C23, Matrix.Columns[1].W)), -HMM_DotV3(Matrix.Columns[1].XYZ, C23));
    Result.Columns[1] = HMM_V4V(HMM_SubV3(HMM_Cross(B32, Matrix.Columns[0].XYZ), HMM_MulV3F(C23, Matrix.Columns[0].W)), +HMM_DotV3(Matrix.Columns[0].XYZ, C23));
    Result.Columns[2] = HMM_V4V(HMM_AddV3(HMM_Cross(Matrix.Columns[3].XYZ, B10), HMM_MulV3F(C01, Matrix.Columns[3].W)), -HMM_DotV3(Matrix.Columns[3].XYZ, C01));
    Result.Columns[3] = HMM_V4V(HMM_SubV3(HMM_Cross(B10, Matrix.Columns[2].XYZ), HMM_MulV3F(C01, Matrix.Columns[2].W)), +HMM_DotV3(Matrix.Columns[2].XYZ, C01));
        
    return HMM_TransposeM4(Result);
}

/*
 * Common graphics transformations
 */

COVERAGE(HMM_Orthographic_RH_NO, 1)
// Produces a right-handed orthographic projection matrix with Z ranging from -1 to 1 (the GL convention).
// Left, Right, Bottom, and Top specify the coordinates of their respective clipping planes.
// Near and Far specify the distances to the near and far clipping planes.
static inline HMM_Mat4 HMM_Orthographic_RH_NO(float Left, float Right, float Bottom, float Top, float Near, float Far)
{
    ASSERT_COVERED(HMM_Orthographic_RH_NO);

    HMM_Mat4 Result = {0};

    Result.Elements[0][0] = 2.0f / (Right - Left);
    Result.Elements[1][1] = 2.0f / (Top - Bottom);
    Result.Elements[2][2] = 2.0f / (Near - Far);
    Result.Elements[3][3] = 1.0f;

    Result.Elements[3][0] = (Left + Right) / (Left - Right);
    Result.Elements[3][1] = (Bottom + Top) / (Bottom - Top);
    Result.Elements[3][2] = (Near + Far) / (Near - Far);

    return Result;
}

COVERAGE(HMM_Orthographic_RH_ZO, 1)
// Produces a right-handed orthographic projection matrix with Z ranging from 0 to 1 (the DirectX convention).
// Left, Right, Bottom, and Top specify the coordinates of their respective clipping planes.
// Near and Far specify the distances to the near and far clipping planes.
static inline HMM_Mat4 HMM_Orthographic_RH_ZO(float Left, float Right, float Bottom, float Top, float Near, float Far)
{
    ASSERT_COVERED(HMM_Orthographic_RH_ZO);

    HMM_Mat4 Result = {0};

    Result.Elements[0][0] = 2.0f / (Right - Left);
    Result.Elements[1][1] = 2.0f / (Top - Bottom);
    Result.Elements[2][2] = 1.0f / (Near - Far);
    Result.Elements[3][3] = 1.0f;

    Result.Elements[3][0] = (Left + Right) / (Left - Right);
    Result.Elements[3][1] = (Bottom + Top) / (Bottom - Top);
    Result.Elements[3][2] = (Near) / (Near - Far);

    return Result;
}

COVERAGE(HMM_Orthographic_LH_NO, 1)
// Produces a left-handed orthographic projection matrix with Z ranging from -1 to 1 (the GL convention).
// Left, Right, Bottom, and Top specify the coordinates of their respective clipping planes.
// Near and Far specify the distances to the near and far clipping planes.
static inline HMM_Mat4 HMM_Orthographic_LH_NO(float Left, float Right, float Bottom, float Top, float Near, float Far)
{
    ASSERT_COVERED(HMM_Orthographic_LH_NO);

    HMM_Mat4 Result = HMM_Orthographic_RH_NO(Left, Right, Bottom, Top, Near, Far);
    Result.Elements[2][2] = -Result.Elements[2][2];
    
    return Result;
}

COVERAGE(HMM_Orthographic_LH_ZO, 1)
// Produces a left-handed orthographic projection matrix with Z ranging from 0 to 1 (the DirectX convention).
// Left, Right, Bottom, and Top specify the coordinates of their respective clipping planes.
// Near and Far specify the distances to the near and far clipping planes.
static inline HMM_Mat4 HMM_Orthographic_LH_ZO(float Left, float Right, float Bottom, float Top, float Near, float Far)
{
    ASSERT_COVERED(HMM_Orthographic_LH_ZO);

    HMM_Mat4 Result = HMM_Orthographic_RH_ZO(Left, Right, Bottom, Top, Near, Far);
    Result.Elements[2][2] = -Result.Elements[2][2];
    
    return Result;
}

COVERAGE(HMM_InvOrthographic, 1)
// Returns an inverse for the given orthographic projection matrix. Works for all orthographic
// projection matrices, regardless of handedness or NDC convention.
static inline HMM_Mat4 HMM_InvOrthographic(HMM_Mat4 OrthoMatrix)
{
    ASSERT_COVERED(HMM_InvOrthographic);

    HMM_Mat4 Result = {0};
    Result.Elements[0][0] = 1.0f / OrthoMatrix.Elements[0][0];
    Result.Elements[1][1] = 1.0f / OrthoMatrix.Elements[1][1];
    Result.Elements[2][2] = 1.0f / OrthoMatrix.Elements[2][2];
    Result.Elements[3][3] = 1.0f;
    
    Result.Elements[3][0] = -OrthoMatrix.Elements[3][0] * Result.Elements[0][0];
    Result.Elements[3][1] = -OrthoMatrix.Elements[3][1] * Result.Elements[1][1];
    Result.Elements[3][2] = -OrthoMatrix.Elements[3][2] * Result.Elements[2][2];

    return Result;
}

COVERAGE(HMM_Perspective_RH_NO, 1)
static inline HMM_Mat4 HMM_Perspective_RH_NO(float FOV, float AspectRatio, float Near, float Far)
{
    ASSERT_COVERED(HMM_Perspective_RH_NO);

    HMM_Mat4 Result = {0};

    // See https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/gluPerspective.xml

    float Cotangent = 1.0f / HMM_TanF(FOV / 2.0f);
    Result.Elements[0][0] = Cotangent / AspectRatio;
    Result.Elements[1][1] = Cotangent;
    Result.Elements[2][3] = -1.0f;

    Result.Elements[2][2] = (Near + Far) / (Near - Far);
    Result.Elements[3][2] = (2.0f * Near * Far) / (Near - Far);
    
    return Result;
}

COVERAGE(HMM_Perspective_RH_ZO, 1)
static inline HMM_Mat4 HMM_Perspective_RH_ZO(float FOV, float AspectRatio, float Near, float Far)
{
    ASSERT_COVERED(HMM_Perspective_RH_ZO);

    HMM_Mat4 Result = {0};

    // See https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/gluPerspective.xml

    float Cotangent = 1.0f / HMM_TanF(FOV / 2.0f);
    Result.Elements[0][0] = Cotangent / AspectRatio;
    Result.Elements[1][1] = Cotangent;
    Result.Elements[2][3] = -1.0f;

    Result.Elements[2][2] = (Far) / (Near - Far);
    Result.Elements[3][2] = (Near * Far) / (Near - Far);

    return Result;
}

COVERAGE(HMM_Perspective_LH_NO, 1)
static inline HMM_Mat4 HMM_Perspective_LH_NO(float FOV, float AspectRatio, float Near, float Far)
{ 
    ASSERT_COVERED(HMM_Perspective_LH_NO);

    HMM_Mat4 Result = HMM_Perspective_RH_NO(FOV, AspectRatio, Near, Far);
    Result.Elements[2][2] = -Result.Elements[2][2];
    Result.Elements[2][3] = -Result.Elements[2][3];
    
    return Result;
}

COVERAGE(HMM_Perspective_LH_ZO, 1)
static inline HMM_Mat4 HMM_Perspective_LH_ZO(float FOV, float AspectRatio, float Near, float Far)
{ 
    ASSERT_COVERED(HMM_Perspective_LH_ZO);

    HMM_Mat4 Result = HMM_Perspective_RH_ZO(FOV, AspectRatio, Near, Far);
    Result.Elements[2][2] = -Result.Elements[2][2];
    Result.Elements[2][3] = -Result.Elements[2][3];
    
    return Result;
}

COVERAGE(HMM_InvPerspective_RH, 1)
static inline HMM_Mat4 HMM_InvPerspective_RH(HMM_Mat4 PerspectiveMatrix)
{
    ASSERT_COVERED(HMM_InvPerspective_RH);

    HMM_Mat4 Result = {0};
    Result.Elements[0][0] = 1.0f / PerspectiveMatrix.Elements[0][0];
    Result.Elements[1][1] = 1.0f / PerspectiveMatrix.Elements[1][1];
    Result.Elements[2][2] = 0.0f;

    Result.Elements[2][3] = 1.0f / PerspectiveMatrix.Elements[3][2];
    Result.Elements[3][3] = PerspectiveMatrix.Elements[2][2] * Result.Elements[2][3];
    Result.Elements[3][2] = PerspectiveMatrix.Elements[2][3];

    return Result;
}

COVERAGE(HMM_InvPerspective_LH, 1)
static inline HMM_Mat4 HMM_InvPerspective_LH(HMM_Mat4 PerspectiveMatrix)
{
    ASSERT_COVERED(HMM_InvPerspective_LH);

    HMM_Mat4 Result = {0};
    Result.Elements[0][0] = 1.0f / PerspectiveMatrix.Elements[0][0];
    Result.Elements[1][1] = 1.0f / PerspectiveMatrix.Elements[1][1];
    Result.Elements[2][2] = 0.0f;

    Result.Elements[2][3] = 1.0f / PerspectiveMatrix.Elements[3][2];
    Result.Elements[3][3] = PerspectiveMatrix.Elements[2][2] * -Result.Elements[2][3];
    Result.Elements[3][2] = PerspectiveMatrix.Elements[2][3];

    return Result;
}

COVERAGE(HMM_Translate, 1)
static inline HMM_Mat4 HMM_Translate(HMM_Vec3 Translation)
{
    ASSERT_COVERED(HMM_Translate);

    HMM_Mat4 Result = HMM_M4D(1.0f);
    Result.Elements[3][0] = Translation.X;
    Result.Elements[3][1] = Translation.Y;
    Result.Elements[3][2] = Translation.Z;

    return Result;
}

COVERAGE(HMM_InvTranslate, 1)
static inline HMM_Mat4 HMM_InvTranslate(HMM_Mat4 TranslationMatrix)
{
    ASSERT_COVERED(HMM_InvTranslate);

    HMM_Mat4 Result = TranslationMatrix;
    Result.Elements[3][0] = -Result.Elements[3][0];
    Result.Elements[3][1] = -Result.Elements[3][1];
    Result.Elements[3][2] = -Result.Elements[3][2];

    return Result;
}

COVERAGE(HMM_Rotate_RH, 1)
static inline HMM_Mat4 HMM_Rotate_RH(float Angle, HMM_Vec3 Axis)
{
    ASSERT_COVERED(HMM_Rotate_RH);

    HMM_Mat4 Result = HMM_M4D(1.0f);

    Axis = HMM_NormV3(Axis);

    float SinTheta = HMM_SinF(Angle);
    float CosTheta = HMM_CosF(Angle);
    float CosValue = 1.0f - CosTheta;

    Result.Elements[0][0] = (Axis.X * Axis.X * CosValue) + CosTheta;
    Result.Elements[0][1] = (Axis.X * Axis.Y * CosValue) + (Axis.Z * SinTheta);
    Result.Elements[0][2] = (Axis.X * Axis.Z * CosValue) - (Axis.Y * SinTheta);

    Result.Elements[1][0] = (Axis.Y * Axis.X * CosValue) - (Axis.Z * SinTheta);
    Result.Elements[1][1] = (Axis.Y * Axis.Y * CosValue) + CosTheta;
    Result.Elements[1][2] = (Axis.Y * Axis.Z * CosValue) + (Axis.X * SinTheta);

    Result.Elements[2][0] = (Axis.Z * Axis.X * CosValue) + (Axis.Y * SinTheta);
    Result.Elements[2][1] = (Axis.Z * Axis.Y * CosValue) - (Axis.X * SinTheta);
    Result.Elements[2][2] = (Axis.Z * Axis.Z * CosValue) + CosTheta;

    return Result;
}

COVERAGE(HMM_Rotate_LH, 1)
static inline HMM_Mat4 HMM_Rotate_LH(float Angle, HMM_Vec3 Axis)
{
    ASSERT_COVERED(HMM_Rotate_LH);
    /* NOTE(lcf): Matrix will be inverse/transpose of RH. */
    return HMM_Rotate_RH(-Angle, Axis);
}

COVERAGE(HMM_InvRotate, 1)
static inline HMM_Mat4 HMM_InvRotate(HMM_Mat4 RotationMatrix)
{
    ASSERT_COVERED(HMM_InvRotate);
    return HMM_TransposeM4(RotationMatrix);
}

COVERAGE(HMM_Scale, 1)
static inline HMM_Mat4 HMM_Scale(HMM_Vec3 Scale)
{
    ASSERT_COVERED(HMM_Scale);

    HMM_Mat4 Result = HMM_M4D(1.0f);
    Result.Elements[0][0] = Scale.X;
    Result.Elements[1][1] = Scale.Y;
    Result.Elements[2][2] = Scale.Z;

    return Result;
}

COVERAGE(HMM_InvScale, 1)
static inline HMM_Mat4 HMM_InvScale(HMM_Mat4 ScaleMatrix) 
{
    ASSERT_COVERED(HMM_InvScale);

    HMM_Mat4 Result = ScaleMatrix;
    Result.Elements[0][0] = 1.0f / Result.Elements[0][0];
    Result.Elements[1][1] = 1.0f / Result.Elements[1][1];
    Result.Elements[2][2] = 1.0f / Result.Elements[2][2];

    return Result;
}

static inline HMM_Mat4 _HMM_LookAt(HMM_Vec3 F,  HMM_Vec3 S, HMM_Vec3 U,  HMM_Vec3 Eye)
{
    HMM_Mat4 Result;

    Result.Elements[0][0] = S.X;
    Result.Elements[0][1] = U.X;
    Result.Elements[0][2] = -F.X;
    Result.Elements[0][3] = 0.0f;

    Result.Elements[1][0] = S.Y;
    Result.Elements[1][1] = U.Y;
    Result.Elements[1][2] = -F.Y;
    Result.Elements[1][3] = 0.0f;

    Result.Elements[2][0] = S.Z;
    Result.Elements[2][1] = U.Z;
    Result.Elements[2][2] = -F.Z;
    Result.Elements[2][3] = 0.0f;

    Result.Elements[3][0] = -HMM_DotV3(S, Eye);
    Result.Elements[3][1] = -HMM_DotV3(U, Eye);
    Result.Elements[3][2] = HMM_DotV3(F, Eye);
    Result.Elements[3][3] = 1.0f;

    return Result;
}

COVERAGE(HMM_LookAt_RH, 1)
static inline HMM_Mat4 HMM_LookAt_RH(HMM_Vec3 Eye, HMM_Vec3 Center, HMM_Vec3 Up)
{
    ASSERT_COVERED(HMM_LookAt_RH);

    HMM_Vec3 F = HMM_NormV3(HMM_SubV3(Center, Eye));
    HMM_Vec3 S = HMM_NormV3(HMM_Cross(F, Up));
    HMM_Vec3 U = HMM_Cross(S, F);

    return _HMM_LookAt(F, S, U, Eye);
}

COVERAGE(HMM_LookAt_LH, 1)
static inline HMM_Mat4 HMM_LookAt_LH(HMM_Vec3 Eye, HMM_Vec3 Center, HMM_Vec3 Up)
{
    ASSERT_COVERED(HMM_LookAt_LH);

    HMM_Vec3 F = HMM_NormV3(HMM_SubV3(Eye, Center));
    HMM_Vec3 S = HMM_NormV3(HMM_Cross(F, Up));
    HMM_Vec3 U = HMM_Cross(S, F);

    return _HMM_LookAt(F, S, U, Eye);
}

COVERAGE(HMM_InvLookAt, 1)
static inline HMM_Mat4 HMM_InvLookAt(HMM_Mat4 Matrix)
{
    ASSERT_COVERED(HMM_InvLookAt);
    HMM_Mat4 Result;

    HMM_Mat3 Rotation = {0};
    Rotation.Columns[0] = Matrix.Columns[0].XYZ;
    Rotation.Columns[1] = Matrix.Columns[1].XYZ;
    Rotation.Columns[2] = Matrix.Columns[2].XYZ;
    Rotation = HMM_TransposeM3(Rotation);

    Result.Columns[0] = HMM_V4V(Rotation.Columns[0], 0.0f);
    Result.Columns[1] = HMM_V4V(Rotation.Columns[1], 0.0f);
    Result.Columns[2] = HMM_V4V(Rotation.Columns[2], 0.0f);
    Result.Columns[3] = HMM_MulV4F(Matrix.Columns[3], -1.0f);
    Result.Elements[3][0] = -1.0f * Matrix.Elements[3][0] /
        (Rotation.Elements[0][0] + Rotation.Elements[0][1] + Rotation.Elements[0][2]);
    Result.Elements[3][1] = -1.0f * Matrix.Elements[3][1] /
        (Rotation.Elements[1][0] + Rotation.Elements[1][1] + Rotation.Elements[1][2]);
    Result.Elements[3][2] = -1.0f * Matrix.Elements[3][2] /
        (Rotation.Elements[2][0] + Rotation.Elements[2][1] + Rotation.Elements[2][2]);
    Result.Elements[3][3] = 1.0f;

    return Result;
}

/*
 * Quaternion operations
 */

COVERAGE(HMM_Q, 1)
static inline HMM_Quat HMM_Q(float X, float Y, float Z, float W)
{
    ASSERT_COVERED(HMM_Q);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_setr_ps(X, Y, Z, W);
#else
    Result.X = X;
    Result.Y = Y;
    Result.Z = Z;
    Result.W = W;
#endif

    return Result;
}

COVERAGE(HMM_QV4, 1)
static inline HMM_Quat HMM_QV4(HMM_Vec4 Vector)
{
    ASSERT_COVERED(HMM_QV4);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = Vector.SSE;
#else
    Result.X = Vector.X;
    Result.Y = Vector.Y;
    Result.Z = Vector.Z;
    Result.W = Vector.W;
#endif

    return Result;
}

COVERAGE(HMM_AddQ, 1)
static inline HMM_Quat HMM_AddQ(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_AddQ);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_add_ps(Left.SSE, Right.SSE);
#else

    Result.X = Left.X + Right.X;
    Result.Y = Left.Y + Right.Y;
    Result.Z = Left.Z + Right.Z;
    Result.W = Left.W + Right.W;
#endif

    return Result;
}

COVERAGE(HMM_SubQ, 1)
static inline HMM_Quat HMM_SubQ(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_SubQ);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_sub_ps(Left.SSE, Right.SSE);
#else
    Result.X = Left.X - Right.X;
    Result.Y = Left.Y - Right.Y;
    Result.Z = Left.Z - Right.Z;
    Result.W = Left.W - Right.W;
#endif

    return Result;
}

COVERAGE(HMM_MulQ, 1)
static inline HMM_Quat HMM_MulQ(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_MulQ);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSEResultOne = _mm_xor_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, _MM_SHUFFLE(0, 0, 0, 0)), _mm_setr_ps(0.f, -0.f, 0.f, -0.f));
    __m128 SSEResultTwo = _mm_shuffle_ps(Right.SSE, Right.SSE, _MM_SHUFFLE(0, 1, 2, 3));
    __m128 SSEResultThree = _mm_mul_ps(SSEResultTwo, SSEResultOne);

    SSEResultOne = _mm_xor_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, _MM_SHUFFLE(1, 1, 1, 1)) , _mm_setr_ps(0.f, 0.f, -0.f, -0.f));
    SSEResultTwo = _mm_shuffle_ps(Right.SSE, Right.SSE, _MM_SHUFFLE(1, 0, 3, 2));
    SSEResultThree = _mm_add_ps(SSEResultThree, _mm_mul_ps(SSEResultTwo, SSEResultOne));

    SSEResultOne = _mm_xor_ps(_mm_shuffle_ps(Left.SSE, Left.SSE, _MM_SHUFFLE(2, 2, 2, 2)), _mm_setr_ps(-0.f, 0.f, 0.f, -0.f));
    SSEResultTwo = _mm_shuffle_ps(Right.SSE, Right.SSE, _MM_SHUFFLE(2, 3, 0, 1));
    SSEResultThree = _mm_add_ps(SSEResultThree, _mm_mul_ps(SSEResultTwo, SSEResultOne));

    SSEResultOne = _mm_shuffle_ps(Left.SSE, Left.SSE, _MM_SHUFFLE(3, 3, 3, 3));
    SSEResultTwo = _mm_shuffle_ps(Right.SSE, Right.SSE, _MM_SHUFFLE(3, 2, 1, 0));
    Result.SSE = _mm_add_ps(SSEResultThree, _mm_mul_ps(SSEResultTwo, SSEResultOne));
#else
    Result.X =  Right.Elements[3] * +Left.Elements[0];
    Result.Y =  Right.Elements[2] * -Left.Elements[0];
    Result.Z =  Right.Elements[1] * +Left.Elements[0];
    Result.W =  Right.Elements[0] * -Left.Elements[0];

    Result.X += Right.Elements[2] * +Left.Elements[1];
    Result.Y += Right.Elements[3] * +Left.Elements[1];
    Result.Z += Right.Elements[0] * -Left.Elements[1];
    Result.W += Right.Elements[1] * -Left.Elements[1];
    
    Result.X += Right.Elements[1] * -Left.Elements[2];
    Result.Y += Right.Elements[0] * +Left.Elements[2];
    Result.Z += Right.Elements[3] * +Left.Elements[2];
    Result.W += Right.Elements[2] * -Left.Elements[2];

    Result.X += Right.Elements[0] * +Left.Elements[3];
    Result.Y += Right.Elements[1] * +Left.Elements[3];
    Result.Z += Right.Elements[2] * +Left.Elements[3];
    Result.W += Right.Elements[3] * +Left.Elements[3];
#endif

    return Result;
}

COVERAGE(HMM_MulQF, 1)
static inline HMM_Quat HMM_MulQF(HMM_Quat Left, float Multiplicative)
{
    ASSERT_COVERED(HMM_MulQF);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 Scalar = _mm_set1_ps(Multiplicative);
    Result.SSE = _mm_mul_ps(Left.SSE, Scalar);
#else
    Result.X = Left.X * Multiplicative;
    Result.Y = Left.Y * Multiplicative;
    Result.Z = Left.Z * Multiplicative;
    Result.W = Left.W * Multiplicative;
#endif

    return Result;
}

COVERAGE(HMM_DivQF, 1)
static inline HMM_Quat HMM_DivQF(HMM_Quat Left, float Divnd)
{
    ASSERT_COVERED(HMM_DivQF);

    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 Scalar = _mm_set1_ps(Divnd);
    Result.SSE = _mm_div_ps(Left.SSE, Scalar);
#else
    Result.X = Left.X / Divnd;
    Result.Y = Left.Y / Divnd;
    Result.Z = Left.Z / Divnd;
    Result.W = Left.W / Divnd;
#endif

    return Result;
}

COVERAGE(HMM_DotQ, 1)
static inline float HMM_DotQ(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_DotQ);

    float Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 SSEResultOne = _mm_mul_ps(Left.SSE, Right.SSE);
    __m128 SSEResultTwo = _mm_shuffle_ps(SSEResultOne, SSEResultOne, _MM_SHUFFLE(2, 3, 0, 1));
    SSEResultOne = _mm_add_ps(SSEResultOne, SSEResultTwo);
    SSEResultTwo = _mm_shuffle_ps(SSEResultOne, SSEResultOne, _MM_SHUFFLE(0, 1, 2, 3));
    SSEResultOne = _mm_add_ps(SSEResultOne, SSEResultTwo);
    _mm_store_ss(&Result, SSEResultOne);
#else
    Result = ((Left.X * Right.X) + (Left.Z * Right.Z)) + ((Left.Y * Right.Y) + (Left.W * Right.W));
#endif

    return Result;
}

COVERAGE(HMM_InvQ, 1)
static inline HMM_Quat HMM_InvQ(HMM_Quat Left)
{
    ASSERT_COVERED(HMM_InvQ);
    
    HMM_Quat Result;
    Result.X = -Left.X;
    Result.Y = -Left.Y;
    Result.Z = -Left.Z;
    Result.W = Left.W;

    return HMM_DivQF(Result, (HMM_DotQ(Left, Left)));
}

COVERAGE(HMM_NormQ, 1)
static inline HMM_Quat HMM_NormQ(HMM_Quat Quat)
{
    ASSERT_COVERED(HMM_NormQ);

    /* NOTE(lcf): Take advantage of SSE implementation in HMM_NormV4 */
    HMM_Vec4 Vec = {Quat.X, Quat.Y, Quat.Z, Quat.W};
    Vec = HMM_NormV4(Vec);
    HMM_Quat Result = {Vec.X, Vec.Y, Vec.Z, Vec.W};

    return Result;
}

static inline HMM_Quat _HMM_MixQ(HMM_Quat Left, float MixLeft, HMM_Quat Right, float MixRight) {
    HMM_Quat Result;

#ifdef HANDMADE_MATH__USE_SSE
    __m128 ScalarLeft = _mm_set1_ps(MixLeft);
    __m128 ScalarRight = _mm_set1_ps(MixRight);
    __m128 SSEResultOne = _mm_mul_ps(Left.SSE, ScalarLeft);
    __m128 SSEResultTwo = _mm_mul_ps(Right.SSE, ScalarRight);
    Result.SSE = _mm_add_ps(SSEResultOne, SSEResultTwo);
#else
    Result.X = Left.X*MixLeft + Right.X*MixRight;
    Result.Y = Left.Y*MixLeft + Right.Y*MixRight;
    Result.Z = Left.Z*MixLeft + Right.Z*MixRight;
    Result.W = Left.W*MixLeft + Right.W*MixRight;
#endif

    return Result;
}

COVERAGE(HMM_NLerp, 1)
static inline HMM_Quat HMM_NLerp(HMM_Quat Left, float Time, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_NLerp);

    HMM_Quat Result = _HMM_MixQ(Left, 1.0f-Time, Right, Time);
    Result = HMM_NormQ(Result);

    return Result;
}

COVERAGE(HMM_SLerp, 1)
static inline HMM_Quat HMM_SLerp(HMM_Quat Left, float Time, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_SLerp);

    HMM_Quat Result;

    float Cos_Theta = HMM_DotQ(Left, Right);

    if (Cos_Theta < 0.0f) { /* NOTE(lcf): Take shortest path on Hyper-sphere */
        Cos_Theta = -Cos_Theta;
        Right = HMM_Q(-Right.X, -Right.Y, -Right.Z, -Right.W);
    }
    
    /* NOTE(lcf): Use Normalized Linear interpolation when vectors are roughly not L.I. */
    if (Cos_Theta > 0.9995f) {
        Result = HMM_NLerp(Left, Time, Right);
    } else {
        float Angle = HMM_ACosF(Cos_Theta);
        float MixLeft = HMM_SinF((1.0f - Time) * Angle);
        float MixRight = HMM_SinF(Time * Angle);

        Result = _HMM_MixQ(Left, MixLeft, Right, MixRight);
        Result = HMM_NormQ(Result);
    }
    
    return Result;
}

COVERAGE(HMM_QToM4, 1)
static inline HMM_Mat4 HMM_QToM4(HMM_Quat Left)
{
    ASSERT_COVERED(HMM_QToM4);

    HMM_Mat4 Result;

    HMM_Quat NormalizedQ = HMM_NormQ(Left);

    float XX, YY, ZZ,
          XY, XZ, YZ,
          WX, WY, WZ;

    XX = NormalizedQ.X * NormalizedQ.X;
    YY = NormalizedQ.Y * NormalizedQ.Y;
    ZZ = NormalizedQ.Z * NormalizedQ.Z;
    XY = NormalizedQ.X * NormalizedQ.Y;
    XZ = NormalizedQ.X * NormalizedQ.Z;
    YZ = NormalizedQ.Y * NormalizedQ.Z;
    WX = NormalizedQ.W * NormalizedQ.X;
    WY = NormalizedQ.W * NormalizedQ.Y;
    WZ = NormalizedQ.W * NormalizedQ.Z;

    Result.Elements[0][0] = 1.0f - 2.0f * (YY + ZZ);
    Result.Elements[0][1] = 2.0f * (XY + WZ);
    Result.Elements[0][2] = 2.0f * (XZ - WY);
    Result.Elements[0][3] = 0.0f;

    Result.Elements[1][0] = 2.0f * (XY - WZ);
    Result.Elements[1][1] = 1.0f - 2.0f * (XX + ZZ);
    Result.Elements[1][2] = 2.0f * (YZ + WX);
    Result.Elements[1][3] = 0.0f;

    Result.Elements[2][0] = 2.0f * (XZ + WY);
    Result.Elements[2][1] = 2.0f * (YZ - WX);
    Result.Elements[2][2] = 1.0f - 2.0f * (XX + YY);
    Result.Elements[2][3] = 0.0f;

    Result.Elements[3][0] = 0.0f;
    Result.Elements[3][1] = 0.0f;
    Result.Elements[3][2] = 0.0f;
    Result.Elements[3][3] = 1.0f;

    return Result;
}

// This method taken from Mike Day at Insomniac Games.
// https://d3cw3dd2w32x2b.cloudfront.net/wp-content/uploads/2015/01/matrix-to-quat.pdf
//
// Note that as mentioned at the top of the paper, the paper assumes the matrix
// would be *post*-multiplied to a vector to rotate it, meaning the matrix is
// the transpose of what we're dealing with. But, because our matrices are
// stored in column-major order, the indices *appear* to match the paper.
//
// For example, m12 in the paper is row 1, column 2. We need to transpose it to
// row 2, column 1. But, because the column comes first when referencing
// elements, it looks like M.Elements[1][2].
//
// Don't be confused! Or if you must be confused, at least trust this
// comment. :)
COVERAGE(HMM_M4ToQ_RH, 4)
static inline HMM_Quat HMM_M4ToQ_RH(HMM_Mat4 M)
{
    float T;
    HMM_Quat Q;

    if (M.Elements[2][2] < 0.0f) {
        if (M.Elements[0][0] > M.Elements[1][1]) {
            ASSERT_COVERED(HMM_M4ToQ_RH);

            T = 1 + M.Elements[0][0] - M.Elements[1][1] - M.Elements[2][2];
            Q = HMM_Q(
                T,
                M.Elements[0][1] + M.Elements[1][0],
                M.Elements[2][0] + M.Elements[0][2],
                M.Elements[1][2] - M.Elements[2][1]
            );
        } else {
            ASSERT_COVERED(HMM_M4ToQ_RH);

            T = 1 - M.Elements[0][0] + M.Elements[1][1] - M.Elements[2][2];
            Q = HMM_Q(
                M.Elements[0][1] + M.Elements[1][0],
                T,
                M.Elements[1][2] + M.Elements[2][1],
                M.Elements[2][0] - M.Elements[0][2]
            );
        }
    } else {
        if (M.Elements[0][0] < -M.Elements[1][1]) {
            ASSERT_COVERED(HMM_M4ToQ_RH);

            T = 1 - M.Elements[0][0] - M.Elements[1][1] + M.Elements[2][2];
            Q = HMM_Q(
                M.Elements[2][0] + M.Elements[0][2],
                M.Elements[1][2] + M.Elements[2][1],
                T,
                M.Elements[0][1] - M.Elements[1][0]
            );
        } else {
            ASSERT_COVERED(HMM_M4ToQ_RH);

            T = 1 + M.Elements[0][0] + M.Elements[1][1] + M.Elements[2][2];
            Q = HMM_Q(
                M.Elements[1][2] - M.Elements[2][1],
                M.Elements[2][0] - M.Elements[0][2],
                M.Elements[0][1] - M.Elements[1][0],
                T
            );
        }
    }

    Q = HMM_MulQF(Q, 0.5f / HMM_SqrtF(T));

    return Q;
}

COVERAGE(HMM_M4ToQ_LH, 4)
static inline HMM_Quat HMM_M4ToQ_LH(HMM_Mat4 M)
{
    float T;
    HMM_Quat Q;

    if (M.Elements[2][2] < 0.0f) {
        if (M.Elements[0][0] > M.Elements[1][1]) {
            ASSERT_COVERED(HMM_M4ToQ_LH);

            T = 1 + M.Elements[0][0] - M.Elements[1][1] - M.Elements[2][2];
            Q = HMM_Q(
                T,
                M.Elements[0][1] + M.Elements[1][0],
                M.Elements[2][0] + M.Elements[0][2],
                M.Elements[2][1] - M.Elements[1][2]
            );
        } else {
            ASSERT_COVERED(HMM_M4ToQ_LH);

            T = 1 - M.Elements[0][0] + M.Elements[1][1] - M.Elements[2][2];
            Q = HMM_Q(
                M.Elements[0][1] + M.Elements[1][0],
                T,
                M.Elements[1][2] + M.Elements[2][1],
                M.Elements[0][2] - M.Elements[2][0]
            );
        }
    } else {
        if (M.Elements[0][0] < -M.Elements[1][1]) {
            ASSERT_COVERED(HMM_M4ToQ_LH);

            T = 1 - M.Elements[0][0] - M.Elements[1][1] + M.Elements[2][2];
            Q = HMM_Q(
                M.Elements[2][0] + M.Elements[0][2],
                M.Elements[1][2] + M.Elements[2][1],
                T,
                M.Elements[1][0] - M.Elements[0][1]
            );
        } else {
            ASSERT_COVERED(HMM_M4ToQ_LH);

            T = 1 + M.Elements[0][0] + M.Elements[1][1] + M.Elements[2][2];
            Q = HMM_Q(
                M.Elements[2][1] - M.Elements[1][2],
                M.Elements[0][2] - M.Elements[2][0],
                M.Elements[1][0] - M.Elements[0][2],
                T
            );
        }
    }

    Q = HMM_MulQF(Q, 0.5f / HMM_SqrtF(T));

    return Q;
}


COVERAGE(HMM_QFromAxisAngle_RH, 1)
static inline HMM_Quat HMM_QFromAxisAngle_RH(HMM_Vec3 Axis, float AngleOfRotation)
{
    ASSERT_COVERED(HMM_QFromAxisAngle_RH);

    HMM_Quat Result;

    HMM_Vec3 AxisNormalized = HMM_NormV3(Axis);
    float SineOfRotation = HMM_SinF(AngleOfRotation / 2.0f);

    Result.XYZ = HMM_MulV3F(AxisNormalized, SineOfRotation);
    Result.W = HMM_CosF(AngleOfRotation / 2.0f);

    return Result;
}

COVERAGE(HMM_QFromAxisAngle_LH, 1)
static inline HMM_Quat HMM_QFromAxisAngle_LH(HMM_Vec3 Axis, float AngleOfRotation)
{
    ASSERT_COVERED(HMM_QFromAxisAngle_LH);

    return HMM_QFromAxisAngle_RH(Axis, -AngleOfRotation);
}


#ifdef __cplusplus
}
#endif

#ifdef __cplusplus

COVERAGE(HMM_LenV2CPP, 1)
static inline float HMM_Len(HMM_Vec2 A)
{
    ASSERT_COVERED(HMM_LenV2CPP);
    return HMM_LenV2(A);
}

COVERAGE(HMM_LenV3CPP, 1)
static inline float HMM_Len(HMM_Vec3 A)
{
    ASSERT_COVERED(HMM_LenV3CPP);
    return HMM_LenV3(A);
}

COVERAGE(HMM_LenV4CPP, 1)
static inline float HMM_Len(HMM_Vec4 A)
{
    ASSERT_COVERED(HMM_LenV4CPP);
    return HMM_LenV4(A);
}

COVERAGE(HMM_LenSqrV2CPP, 1)
static inline float HMM_LenSqr(HMM_Vec2 A)
{
    ASSERT_COVERED(HMM_LenSqrV2CPP);
    return HMM_LenSqrV2(A);
}

COVERAGE(HMM_LenSqrV3CPP, 1)
static inline float HMM_LenSqr(HMM_Vec3 A)
{
    ASSERT_COVERED(HMM_LenSqrV3CPP);
    return HMM_LenSqrV3(A);
}

COVERAGE(HMM_LenSqrV4CPP, 1)
static inline float HMM_LenSqr(HMM_Vec4 A)
{
    ASSERT_COVERED(HMM_LenSqrV4CPP);
    return HMM_LenSqrV4(A);
}

COVERAGE(HMM_NormV2CPP, 1)
static inline HMM_Vec2 HMM_Norm(HMM_Vec2 A)
{
    ASSERT_COVERED(HMM_NormV2CPP);
    return HMM_NormV2(A);
}

COVERAGE(HMM_NormV3CPP, 1)
static inline HMM_Vec3 HMM_Norm(HMM_Vec3 A)
{
    ASSERT_COVERED(HMM_NormV3CPP);
    return HMM_NormV3(A);
}

COVERAGE(HMM_NormV4CPP, 1)
static inline HMM_Vec4 HMM_Norm(HMM_Vec4 A)
{
    ASSERT_COVERED(HMM_NormV4CPP);
    return HMM_NormV4(A);
}

COVERAGE(HMM_NormQCPP, 1)
static inline HMM_Quat HMM_Norm(HMM_Quat A)
{
    ASSERT_COVERED(HMM_NormQCPP);
    return HMM_NormQ(A);
}

COVERAGE(HMM_DotV2CPP, 1)
static inline float HMM_Dot(HMM_Vec2 Left, HMM_Vec2 VecTwo)
{
    ASSERT_COVERED(HMM_DotV2CPP);
    return HMM_DotV2(Left, VecTwo);
}

COVERAGE(HMM_DotV3CPP, 1)
static inline float HMM_Dot(HMM_Vec3 Left, HMM_Vec3 VecTwo)
{
    ASSERT_COVERED(HMM_DotV3CPP);
    return HMM_DotV3(Left, VecTwo);
}

COVERAGE(HMM_DotV4CPP, 1)
static inline float HMM_Dot(HMM_Vec4 Left, HMM_Vec4 VecTwo)
{
    ASSERT_COVERED(HMM_DotV4CPP);
    return HMM_DotV4(Left, VecTwo);
}
 
COVERAGE(HMM_LerpV2CPP, 1)
static inline HMM_Vec2 HMM_Lerp(HMM_Vec2 Left, float Time, HMM_Vec2 Right) 
{
    ASSERT_COVERED(HMM_LerpV2CPP);
    return HMM_LerpV2(Left, Time, Right);
}

COVERAGE(HMM_LerpV3CPP, 1)
static inline HMM_Vec3 HMM_Lerp(HMM_Vec3 Left, float Time, HMM_Vec3 Right) 
{
    ASSERT_COVERED(HMM_LerpV3CPP);
    return HMM_LerpV3(Left, Time, Right);
}

COVERAGE(HMM_LerpV4CPP, 1)
static inline HMM_Vec4 HMM_Lerp(HMM_Vec4 Left, float Time, HMM_Vec4 Right) 
{
    ASSERT_COVERED(HMM_LerpV4CPP);
    return HMM_LerpV4(Left, Time, Right);
}

COVERAGE(HMM_TransposeM2CPP, 1)
static inline HMM_Mat2 HMM_Transpose(HMM_Mat2 Matrix)
{
    ASSERT_COVERED(HMM_TransposeM2CPP);
    return HMM_TransposeM2(Matrix);
}

COVERAGE(HMM_TransposeM3CPP, 1)
static inline HMM_Mat3 HMM_Transpose(HMM_Mat3 Matrix)
{
    ASSERT_COVERED(HMM_TransposeM3CPP);
    return HMM_TransposeM3(Matrix);
}

COVERAGE(HMM_TransposeM4CPP, 1)
static inline HMM_Mat4 HMM_Transpose(HMM_Mat4 Matrix)
{
    ASSERT_COVERED(HMM_TransposeM4CPP);
    return HMM_TransposeM4(Matrix);
}

COVERAGE(HMM_DeterminantM2CPP, 1)
static inline float HMM_Determinant(HMM_Mat2 Matrix)
{
    ASSERT_COVERED(HMM_DeterminantM2CPP);
    return HMM_DeterminantM2(Matrix);
}

COVERAGE(HMM_DeterminantM3CPP, 1)
static inline float HMM_Determinant(HMM_Mat3 Matrix)
{
    ASSERT_COVERED(HMM_DeterminantM3CPP);
    return HMM_DeterminantM3(Matrix);
}

COVERAGE(HMM_DeterminantM4CPP, 1)
static inline float HMM_Determinant(HMM_Mat4 Matrix)
{
    ASSERT_COVERED(HMM_DeterminantM4CPP);
    return HMM_DeterminantM4(Matrix);
}

COVERAGE(HMM_InvGeneralM2CPP, 1)
static inline HMM_Mat2 HMM_InvGeneral(HMM_Mat2 Matrix)
{
    ASSERT_COVERED(HMM_InvGeneralM2CPP);
    return HMM_InvGeneralM2(Matrix);
}

COVERAGE(HMM_InvGeneralM3CPP, 1)
static inline HMM_Mat3 HMM_InvGeneral(HMM_Mat3 Matrix)
{
    ASSERT_COVERED(HMM_InvGeneralM3CPP);
    return HMM_InvGeneralM3(Matrix);
}

COVERAGE(HMM_InvGeneralM4CPP, 1)
static inline HMM_Mat4 HMM_InvGeneral(HMM_Mat4 Matrix)
{
    ASSERT_COVERED(HMM_InvGeneralM4CPP);
    return HMM_InvGeneralM4(Matrix);
}

COVERAGE(HMM_DotQCPP, 1)
static inline float HMM_Dot(HMM_Quat QuatOne, HMM_Quat QuatTwo)
{
    ASSERT_COVERED(HMM_DotQCPP);
    return HMM_DotQ(QuatOne, QuatTwo);
}

COVERAGE(HMM_AddV2CPP, 1)
static inline HMM_Vec2 HMM_Add(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_AddV2CPP);
    return HMM_AddV2(Left, Right);
}

COVERAGE(HMM_AddV3CPP, 1)
static inline HMM_Vec3 HMM_Add(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_AddV3CPP);
    return HMM_AddV3(Left, Right);
}

COVERAGE(HMM_AddV4CPP, 1)
static inline HMM_Vec4 HMM_Add(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_AddV4CPP);
    return HMM_AddV4(Left, Right);
}

COVERAGE(HMM_AddM2CPP, 1)
static inline HMM_Mat2 HMM_Add(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_AddM2CPP);
    return HMM_AddM2(Left, Right);
}

COVERAGE(HMM_AddM3CPP, 1)
static inline HMM_Mat3 HMM_Add(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_AddM3CPP);
    return HMM_AddM3(Left, Right);
}

COVERAGE(HMM_AddM4CPP, 1)
static inline HMM_Mat4 HMM_Add(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_AddM4CPP);
    return HMM_AddM4(Left, Right);
}

COVERAGE(HMM_AddQCPP, 1)
static inline HMM_Quat HMM_Add(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_AddQCPP);
    return HMM_AddQ(Left, Right);
}

COVERAGE(HMM_SubV2CPP, 1)
static inline HMM_Vec2 HMM_Sub(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_SubV2CPP);
    return HMM_SubV2(Left, Right);
}

COVERAGE(HMM_SubV3CPP, 1)
static inline HMM_Vec3 HMM_Sub(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_SubV3CPP);
    return HMM_SubV3(Left, Right);
}

COVERAGE(HMM_SubV4CPP, 1)
static inline HMM_Vec4 HMM_Sub(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_SubV4CPP);
    return HMM_SubV4(Left, Right);
}

COVERAGE(HMM_SubM2CPP, 1)
static inline HMM_Mat2 HMM_Sub(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_SubM2CPP);
    return HMM_SubM2(Left, Right);
}

COVERAGE(HMM_SubM3CPP, 1)
static inline HMM_Mat3 HMM_Sub(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_SubM3CPP);
    return HMM_SubM3(Left, Right);
}

COVERAGE(HMM_SubM4CPP, 1)
static inline HMM_Mat4 HMM_Sub(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_SubM4CPP);
    return HMM_SubM4(Left, Right);
}

COVERAGE(HMM_SubQCPP, 1)
static inline HMM_Quat HMM_Sub(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_SubQCPP);
    return HMM_SubQ(Left, Right);
}

COVERAGE(HMM_MulV2CPP, 1)
static inline HMM_Vec2 HMM_Mul(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_MulV2CPP);
    return HMM_MulV2(Left, Right);
}

COVERAGE(HMM_MulV2FCPP, 1)
static inline HMM_Vec2 HMM_Mul(HMM_Vec2 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV2FCPP);
    return HMM_MulV2F(Left, Right);
}

COVERAGE(HMM_MulV3CPP, 1)
static inline HMM_Vec3 HMM_Mul(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_MulV3CPP);
    return HMM_MulV3(Left, Right);
}

COVERAGE(HMM_MulV3FCPP, 1)
static inline HMM_Vec3 HMM_Mul(HMM_Vec3 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV3FCPP);
    return HMM_MulV3F(Left, Right);
}

COVERAGE(HMM_MulV4CPP, 1)
static inline HMM_Vec4 HMM_Mul(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_MulV4CPP);
    return HMM_MulV4(Left, Right);
}

COVERAGE(HMM_MulV4FCPP, 1)
static inline HMM_Vec4 HMM_Mul(HMM_Vec4 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV4FCPP);
    return HMM_MulV4F(Left, Right);
}

COVERAGE(HMM_MulM2CPP, 1)
static inline HMM_Mat2 HMM_Mul(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_MulM2CPP);
    return HMM_MulM2(Left, Right);
}

COVERAGE(HMM_MulM3CPP, 1)
static inline HMM_Mat3 HMM_Mul(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_MulM3CPP);
    return HMM_MulM3(Left, Right);
}

COVERAGE(HMM_MulM4CPP, 1)
static inline HMM_Mat4 HMM_Mul(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_MulM4CPP);
    return HMM_MulM4(Left, Right);
}

COVERAGE(HMM_MulM2FCPP, 1)
static inline HMM_Mat2 HMM_Mul(HMM_Mat2 Left, float Right)
{
    ASSERT_COVERED(HMM_MulM2FCPP);
    return HMM_MulM2F(Left, Right);
}

COVERAGE(HMM_MulM3FCPP, 1)
static inline HMM_Mat3 HMM_Mul(HMM_Mat3 Left, float Right)
{
    ASSERT_COVERED(HMM_MulM3FCPP);
    return HMM_MulM3F(Left, Right);
}

COVERAGE(HMM_MulM4FCPP, 1)
static inline HMM_Mat4 HMM_Mul(HMM_Mat4 Left, float Right)
{
    ASSERT_COVERED(HMM_MulM4FCPP);
    return HMM_MulM4F(Left, Right);
}

COVERAGE(HMM_MulM2V2CPP, 1)
static inline HMM_Vec2 HMM_Mul(HMM_Mat2 Matrix, HMM_Vec2 Vector)
{
    ASSERT_COVERED(HMM_MulM2V2CPP);
    return HMM_MulM2V2(Matrix, Vector);
}

COVERAGE(HMM_MulM3V3CPP, 1)
static inline HMM_Vec3 HMM_Mul(HMM_Mat3 Matrix, HMM_Vec3 Vector)
{
    ASSERT_COVERED(HMM_MulM3V3CPP);
    return HMM_MulM3V3(Matrix, Vector);
}

COVERAGE(HMM_MulM4V4CPP, 1)
static inline HMM_Vec4 HMM_Mul(HMM_Mat4 Matrix, HMM_Vec4 Vector)
{
    ASSERT_COVERED(HMM_MulM4V4CPP);
    return HMM_MulM4V4(Matrix, Vector);
}

COVERAGE(HMM_MulQCPP, 1)
static inline HMM_Quat HMM_Mul(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_MulQCPP);
    return HMM_MulQ(Left, Right);
}

COVERAGE(HMM_MulQFCPP, 1)
static inline HMM_Quat HMM_Mul(HMM_Quat Left, float Right)
{
    ASSERT_COVERED(HMM_MulQFCPP);
    return HMM_MulQF(Left, Right);
}

COVERAGE(HMM_DivV2CPP, 1)
static inline HMM_Vec2 HMM_Div(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_DivV2CPP);
    return HMM_DivV2(Left, Right);
}

COVERAGE(HMM_DivV2FCPP, 1)
static inline HMM_Vec2 HMM_Div(HMM_Vec2 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV2FCPP);
    return HMM_DivV2F(Left, Right);
}

COVERAGE(HMM_DivV3CPP, 1)
static inline HMM_Vec3 HMM_Div(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_DivV3CPP);
    return HMM_DivV3(Left, Right);
}

COVERAGE(HMM_DivV3FCPP, 1)
static inline HMM_Vec3 HMM_Div(HMM_Vec3 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV3FCPP);
    return HMM_DivV3F(Left, Right);
}

COVERAGE(HMM_DivV4CPP, 1)
static inline HMM_Vec4 HMM_Div(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_DivV4CPP);
    return HMM_DivV4(Left, Right);
}

COVERAGE(HMM_DivV4FCPP, 1)
static inline HMM_Vec4 HMM_Div(HMM_Vec4 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV4FCPP);
    return HMM_DivV4F(Left, Right);
}

COVERAGE(HMM_DivM2FCPP, 1)
static inline HMM_Mat2 HMM_Div(HMM_Mat2 Left, float Right)
{
    ASSERT_COVERED(HMM_DivM2FCPP);
    return HMM_DivM2F(Left, Right);
}

COVERAGE(HMM_DivM3FCPP, 1)
static inline HMM_Mat3 HMM_Div(HMM_Mat3 Left, float Right)
{
    ASSERT_COVERED(HMM_DivM3FCPP);
    return HMM_DivM3F(Left, Right);
}

COVERAGE(HMM_DivM4FCPP, 1)
static inline HMM_Mat4 HMM_Div(HMM_Mat4 Left, float Right)
{
    ASSERT_COVERED(HMM_DivM4FCPP);
    return HMM_DivM4F(Left, Right);
}

COVERAGE(HMM_DivQFCPP, 1)
static inline HMM_Quat HMM_Div(HMM_Quat Left, float Right)
{
    ASSERT_COVERED(HMM_DivQFCPP);
    return HMM_DivQF(Left, Right);
}

COVERAGE(HMM_EqV2CPP, 1)
static inline HMM_Bool HMM_Eq(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_EqV2CPP);
    return HMM_EqV2(Left, Right);
}

COVERAGE(HMM_EqV3CPP, 1)
static inline HMM_Bool HMM_Eq(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_EqV3CPP);
    return HMM_EqV3(Left, Right);
}

COVERAGE(HMM_EqV4CPP, 1)
static inline HMM_Bool HMM_Eq(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_EqV4CPP);
    return HMM_EqV4(Left, Right);
}

COVERAGE(HMM_AddV2Op, 1)
static inline HMM_Vec2 operator+(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_AddV2Op);
    return HMM_AddV2(Left, Right);
}

COVERAGE(HMM_AddV3Op, 1)
static inline HMM_Vec3 operator+(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_AddV3Op);
    return HMM_AddV3(Left, Right);
}

COVERAGE(HMM_AddV4Op, 1)
static inline HMM_Vec4 operator+(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_AddV4Op);
    return HMM_AddV4(Left, Right);
}

COVERAGE(HMM_AddM2Op, 1)
static inline HMM_Mat2 operator+(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_AddM2Op);
    return HMM_AddM2(Left, Right);
}

COVERAGE(HMM_AddM3Op, 1)
static inline HMM_Mat3 operator+(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_AddM3Op);
    return HMM_AddM3(Left, Right);
}

COVERAGE(HMM_AddM4Op, 1)
static inline HMM_Mat4 operator+(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_AddM4Op);
    return HMM_AddM4(Left, Right);
}

COVERAGE(HMM_AddQOp, 1)
static inline HMM_Quat operator+(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_AddQOp);
    return HMM_AddQ(Left, Right);
}

COVERAGE(HMM_SubV2Op, 1)
static inline HMM_Vec2 operator-(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_SubV2Op);
    return HMM_SubV2(Left, Right);
}

COVERAGE(HMM_SubV3Op, 1)
static inline HMM_Vec3 operator-(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_SubV3Op);
    return HMM_SubV3(Left, Right);
}

COVERAGE(HMM_SubV4Op, 1)
static inline HMM_Vec4 operator-(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_SubV4Op);
    return HMM_SubV4(Left, Right);
}

COVERAGE(HMM_SubM2Op, 1)
static inline HMM_Mat2 operator-(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_SubM2Op);
    return HMM_SubM2(Left, Right);
}

COVERAGE(HMM_SubM3Op, 1)
static inline HMM_Mat3 operator-(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_SubM3Op);
    return HMM_SubM3(Left, Right);
}

COVERAGE(HMM_SubM4Op, 1)
static inline HMM_Mat4 operator-(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_SubM4Op);
    return HMM_SubM4(Left, Right);
}

COVERAGE(HMM_SubQOp, 1)
static inline HMM_Quat operator-(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_SubQOp);
    return HMM_SubQ(Left, Right);
}

COVERAGE(HMM_MulV2Op, 1)
static inline HMM_Vec2 operator*(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_MulV2Op);
    return HMM_MulV2(Left, Right);
}

COVERAGE(HMM_MulV3Op, 1)
static inline HMM_Vec3 operator*(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_MulV3Op);
    return HMM_MulV3(Left, Right);
}

COVERAGE(HMM_MulV4Op, 1)
static inline HMM_Vec4 operator*(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_MulV4Op);
    return HMM_MulV4(Left, Right);
}

COVERAGE(HMM_MulM2Op, 1)
static inline HMM_Mat2 operator*(HMM_Mat2 Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_MulM2Op);
    return HMM_MulM2(Left, Right);
}

COVERAGE(HMM_MulM3Op, 1)
static inline HMM_Mat3 operator*(HMM_Mat3 Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_MulM3Op);
    return HMM_MulM3(Left, Right);
}

COVERAGE(HMM_MulM4Op, 1)
static inline HMM_Mat4 operator*(HMM_Mat4 Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_MulM4Op);
    return HMM_MulM4(Left, Right);
}

COVERAGE(HMM_MulQOp, 1)
static inline HMM_Quat operator*(HMM_Quat Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_MulQOp);
    return HMM_MulQ(Left, Right);
}

COVERAGE(HMM_MulV2FOp, 1)
static inline HMM_Vec2 operator*(HMM_Vec2 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV2FOp);
    return HMM_MulV2F(Left, Right);
}

COVERAGE(HMM_MulV3FOp, 1)
static inline HMM_Vec3 operator*(HMM_Vec3 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV3FOp);
    return HMM_MulV3F(Left, Right);
}

COVERAGE(HMM_MulV4FOp, 1)
static inline HMM_Vec4 operator*(HMM_Vec4 Left, float Right)
{
    ASSERT_COVERED(HMM_MulV4FOp);
    return HMM_MulV4F(Left, Right);
}

COVERAGE(HMM_MulM2FOp, 1)
static inline HMM_Mat2 operator*(HMM_Mat2 Left, float Right)
{
    ASSERT_COVERED(HMM_MulM2FOp);
    return HMM_MulM2F(Left, Right);
}

COVERAGE(HMM_MulM3FOp, 1)
static inline HMM_Mat3 operator*(HMM_Mat3 Left, float Right)
{
    ASSERT_COVERED(HMM_MulM3FOp);
    return HMM_MulM3F(Left, Right);
}

COVERAGE(HMM_MulM4FOp, 1)
static inline HMM_Mat4 operator*(HMM_Mat4 Left, float Right)
{
    ASSERT_COVERED(HMM_MulM4FOp);
    return HMM_MulM4F(Left, Right);
}

COVERAGE(HMM_MulQFOp, 1)
static inline HMM_Quat operator*(HMM_Quat Left, float Right)
{
    ASSERT_COVERED(HMM_MulQFOp);
    return HMM_MulQF(Left, Right);
}

COVERAGE(HMM_MulV2FOpLeft, 1)
static inline HMM_Vec2 operator*(float Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_MulV2FOpLeft);
    return HMM_MulV2F(Right, Left);
}

COVERAGE(HMM_MulV3FOpLeft, 1)
static inline HMM_Vec3 operator*(float Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_MulV3FOpLeft);
    return HMM_MulV3F(Right, Left);
}

COVERAGE(HMM_MulV4FOpLeft, 1)
static inline HMM_Vec4 operator*(float Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_MulV4FOpLeft);
    return HMM_MulV4F(Right, Left);
}

COVERAGE(HMM_MulM2FOpLeft, 1)
static inline HMM_Mat2 operator*(float Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_MulM2FOpLeft);
    return HMM_MulM2F(Right, Left);
}

COVERAGE(HMM_MulM3FOpLeft, 1)
static inline HMM_Mat3 operator*(float Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_MulM3FOpLeft);
    return HMM_MulM3F(Right, Left);
}

COVERAGE(HMM_MulM4FOpLeft, 1)
static inline HMM_Mat4 operator*(float Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_MulM4FOpLeft);
    return HMM_MulM4F(Right, Left);
}

COVERAGE(HMM_MulQFOpLeft, 1)
static inline HMM_Quat operator*(float Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_MulQFOpLeft);
    return HMM_MulQF(Right, Left);
}

COVERAGE(HMM_MulM2V2Op, 1)
static inline HMM_Vec2 operator*(HMM_Mat2 Matrix, HMM_Vec2 Vector)
{
    ASSERT_COVERED(HMM_MulM2V2Op);
    return HMM_MulM2V2(Matrix, Vector);
}

COVERAGE(HMM_MulM3V3Op, 1)
static inline HMM_Vec3 operator*(HMM_Mat3 Matrix, HMM_Vec3 Vector)
{
    ASSERT_COVERED(HMM_MulM3V3Op);
    return HMM_MulM3V3(Matrix, Vector);
}

COVERAGE(HMM_MulM4V4Op, 1)
static inline HMM_Vec4 operator*(HMM_Mat4 Matrix, HMM_Vec4 Vector)
{
    ASSERT_COVERED(HMM_MulM4V4Op);
    return HMM_MulM4V4(Matrix, Vector);
}

COVERAGE(HMM_DivV2Op, 1)
static inline HMM_Vec2 operator/(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_DivV2Op);
    return HMM_DivV2(Left, Right);
}

COVERAGE(HMM_DivV3Op, 1)
static inline HMM_Vec3 operator/(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_DivV3Op);
    return HMM_DivV3(Left, Right);
}

COVERAGE(HMM_DivV4Op, 1)
static inline HMM_Vec4 operator/(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_DivV4Op);
    return HMM_DivV4(Left, Right);
}

COVERAGE(HMM_DivV2FOp, 1)
static inline HMM_Vec2 operator/(HMM_Vec2 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV2FOp);
    return HMM_DivV2F(Left, Right);
}

COVERAGE(HMM_DivV3FOp, 1)
static inline HMM_Vec3 operator/(HMM_Vec3 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV3FOp);
    return HMM_DivV3F(Left, Right);
}

COVERAGE(HMM_DivV4FOp, 1)
static inline HMM_Vec4 operator/(HMM_Vec4 Left, float Right)
{
    ASSERT_COVERED(HMM_DivV4FOp);
    return HMM_DivV4F(Left, Right);
}

COVERAGE(HMM_DivM4FOp, 1)
static inline HMM_Mat4 operator/(HMM_Mat4 Left, float Right)
{
    ASSERT_COVERED(HMM_DivM4FOp);
    return HMM_DivM4F(Left, Right);
}

COVERAGE(HMM_DivM3FOp, 1)
static inline HMM_Mat3 operator/(HMM_Mat3 Left, float Right)
{
    ASSERT_COVERED(HMM_DivM3FOp);
    return HMM_DivM3F(Left, Right);
}

COVERAGE(HMM_DivM2FOp, 1)
static inline HMM_Mat2 operator/(HMM_Mat2 Left, float Right)
{
    ASSERT_COVERED(HMM_DivM2FOp);
    return HMM_DivM2F(Left, Right);
}

COVERAGE(HMM_DivQFOp, 1)
static inline HMM_Quat operator/(HMM_Quat Left, float Right)
{
    ASSERT_COVERED(HMM_DivQFOp);
    return HMM_DivQF(Left, Right);
}

COVERAGE(HMM_AddV2Assign, 1)
static inline HMM_Vec2 &operator+=(HMM_Vec2 &Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_AddV2Assign);
    return Left = Left + Right;
}

COVERAGE(HMM_AddV3Assign, 1)
static inline HMM_Vec3 &operator+=(HMM_Vec3 &Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_AddV3Assign);
    return Left = Left + Right;
}

COVERAGE(HMM_AddV4Assign, 1)
static inline HMM_Vec4 &operator+=(HMM_Vec4 &Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_AddV4Assign);
    return Left = Left + Right;
}

COVERAGE(HMM_AddM2Assign, 1)
static inline HMM_Mat2 &operator+=(HMM_Mat2 &Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_AddM2Assign);
    return Left = Left + Right;
}

COVERAGE(HMM_AddM3Assign, 1)
static inline HMM_Mat3 &operator+=(HMM_Mat3 &Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_AddM3Assign);
    return Left = Left + Right;
}

COVERAGE(HMM_AddM4Assign, 1)
static inline HMM_Mat4 &operator+=(HMM_Mat4 &Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_AddM4Assign);
    return Left = Left + Right;
}

COVERAGE(HMM_AddQAssign, 1)
static inline HMM_Quat &operator+=(HMM_Quat &Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_AddQAssign);
    return Left = Left + Right;
}

COVERAGE(HMM_SubV2Assign, 1)
static inline HMM_Vec2 &operator-=(HMM_Vec2 &Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_SubV2Assign);
    return Left = Left - Right;
}

COVERAGE(HMM_SubV3Assign, 1)
static inline HMM_Vec3 &operator-=(HMM_Vec3 &Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_SubV3Assign);
    return Left = Left - Right;
}

COVERAGE(HMM_SubV4Assign, 1)
static inline HMM_Vec4 &operator-=(HMM_Vec4 &Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_SubV4Assign);
    return Left = Left - Right;
}

COVERAGE(HMM_SubM2Assign, 1)
static inline HMM_Mat2 &operator-=(HMM_Mat2 &Left, HMM_Mat2 Right)
{
    ASSERT_COVERED(HMM_SubM2Assign);
    return Left = Left - Right;
}

COVERAGE(HMM_SubM3Assign, 1)
static inline HMM_Mat3 &operator-=(HMM_Mat3 &Left, HMM_Mat3 Right)
{
    ASSERT_COVERED(HMM_SubM3Assign);
    return Left = Left - Right;
}

COVERAGE(HMM_SubM4Assign, 1)
static inline HMM_Mat4 &operator-=(HMM_Mat4 &Left, HMM_Mat4 Right)
{
    ASSERT_COVERED(HMM_SubM4Assign);
    return Left = Left - Right;
}

COVERAGE(HMM_SubQAssign, 1)
static inline HMM_Quat &operator-=(HMM_Quat &Left, HMM_Quat Right)
{
    ASSERT_COVERED(HMM_SubQAssign);
    return Left = Left - Right;
}

COVERAGE(HMM_MulV2Assign, 1)
static inline HMM_Vec2 &operator*=(HMM_Vec2 &Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_MulV2Assign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulV3Assign, 1)
static inline HMM_Vec3 &operator*=(HMM_Vec3 &Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_MulV3Assign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulV4Assign, 1)
static inline HMM_Vec4 &operator*=(HMM_Vec4 &Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_MulV4Assign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulV2FAssign, 1)
static inline HMM_Vec2 &operator*=(HMM_Vec2 &Left, float Right)
{
    ASSERT_COVERED(HMM_MulV2FAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulV3FAssign, 1)
static inline HMM_Vec3 &operator*=(HMM_Vec3 &Left, float Right)
{
    ASSERT_COVERED(HMM_MulV3FAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulV4FAssign, 1)
static inline HMM_Vec4 &operator*=(HMM_Vec4 &Left, float Right)
{
    ASSERT_COVERED(HMM_MulV4FAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulM2FAssign, 1)
static inline HMM_Mat2 &operator*=(HMM_Mat2 &Left, float Right)
{
    ASSERT_COVERED(HMM_MulM2FAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulM3FAssign, 1)
static inline HMM_Mat3 &operator*=(HMM_Mat3 &Left, float Right)
{
    ASSERT_COVERED(HMM_MulM3FAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulM4FAssign, 1)
static inline HMM_Mat4 &operator*=(HMM_Mat4 &Left, float Right)
{
    ASSERT_COVERED(HMM_MulM4FAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_MulQFAssign, 1)
static inline HMM_Quat &operator*=(HMM_Quat &Left, float Right)
{
    ASSERT_COVERED(HMM_MulQFAssign);
    return Left = Left * Right;
}

COVERAGE(HMM_DivV2Assign, 1)
static inline HMM_Vec2 &operator/=(HMM_Vec2 &Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_DivV2Assign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivV3Assign, 1)
static inline HMM_Vec3 &operator/=(HMM_Vec3 &Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_DivV3Assign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivV4Assign, 1)
static inline HMM_Vec4 &operator/=(HMM_Vec4 &Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_DivV4Assign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivV2FAssign, 1)
static inline HMM_Vec2 &operator/=(HMM_Vec2 &Left, float Right)
{
    ASSERT_COVERED(HMM_DivV2FAssign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivV3FAssign, 1)
static inline HMM_Vec3 &operator/=(HMM_Vec3 &Left, float Right)
{
    ASSERT_COVERED(HMM_DivV3FAssign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivV4FAssign, 1)
static inline HMM_Vec4 &operator/=(HMM_Vec4 &Left, float Right)
{
    ASSERT_COVERED(HMM_DivV4FAssign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivM4FAssign, 1)
static inline HMM_Mat4 &operator/=(HMM_Mat4 &Left, float Right)
{
    ASSERT_COVERED(HMM_DivM4FAssign);
    return Left = Left / Right;
}

COVERAGE(HMM_DivQFAssign, 1)
static inline HMM_Quat &operator/=(HMM_Quat &Left, float Right)
{
    ASSERT_COVERED(HMM_DivQFAssign);
    return Left = Left / Right;
}

COVERAGE(HMM_EqV2Op, 1)
static inline HMM_Bool operator==(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_EqV2Op);
    return HMM_EqV2(Left, Right);
}

COVERAGE(HMM_EqV3Op, 1)
static inline HMM_Bool operator==(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_EqV3Op);
    return HMM_EqV3(Left, Right);
}

COVERAGE(HMM_EqV4Op, 1)
static inline HMM_Bool operator==(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_EqV4Op);
    return HMM_EqV4(Left, Right);
}

COVERAGE(HMM_EqV2OpNot, 1)
static inline HMM_Bool operator!=(HMM_Vec2 Left, HMM_Vec2 Right)
{
    ASSERT_COVERED(HMM_EqV2OpNot);
    return !HMM_EqV2(Left, Right);
}

COVERAGE(HMM_EqV3OpNot, 1)
static inline HMM_Bool operator!=(HMM_Vec3 Left, HMM_Vec3 Right)
{
    ASSERT_COVERED(HMM_EqV3OpNot);
    return !HMM_EqV3(Left, Right);
}

COVERAGE(HMM_EqV4OpNot, 1)
static inline HMM_Bool operator!=(HMM_Vec4 Left, HMM_Vec4 Right)
{
    ASSERT_COVERED(HMM_EqV4OpNot);
    return !HMM_EqV4(Left, Right);
}

COVERAGE(HMM_UnaryMinusV2, 1)
static inline HMM_Vec2 operator-(HMM_Vec2 In)
{
    ASSERT_COVERED(HMM_UnaryMinusV2);

    HMM_Vec2 Result;
    Result.X = -In.X;
    Result.Y = -In.Y;

    return Result;
}

COVERAGE(HMM_UnaryMinusV3, 1)
static inline HMM_Vec3 operator-(HMM_Vec3 In)
{
    ASSERT_COVERED(HMM_UnaryMinusV3);

    HMM_Vec3 Result;
    Result.X = -In.X;
    Result.Y = -In.Y;
    Result.Z = -In.Z;

    return Result;
}

COVERAGE(HMM_UnaryMinusV4, 1)
static inline HMM_Vec4 operator-(HMM_Vec4 In)
{
    ASSERT_COVERED(HMM_UnaryMinusV4);

    HMM_Vec4 Result;
#if HANDMADE_MATH__USE_SSE
    Result.SSE = _mm_xor_ps(In.SSE, _mm_set1_ps(-0.0f));
#else
    Result.X = -In.X;
    Result.Y = -In.Y;
    Result.Z = -In.Z;
    Result.W = -In.W;
#endif

    return Result;
}

#endif /* __cplusplus*/

#ifdef HANDMADE_MATH__USE_C11_GENERICS
#define HMM_Add(A, B) _Generic((A), \
        HMM_Vec2: HMM_AddV2, \
        HMM_Vec3: HMM_AddV3, \
        HMM_Vec4: HMM_AddV4, \
        HMM_Mat2: HMM_AddM2, \
        HMM_Mat3: HMM_AddM3, \
        HMM_Mat4: HMM_AddM4, \
        HMM_Quat: HMM_AddQ \
)(A, B)

#define HMM_Sub(A, B) _Generic((A), \
        HMM_Vec2: HMM_SubV2, \
        HMM_Vec3: HMM_SubV3, \
        HMM_Vec4: HMM_SubV4, \
        HMM_Mat2: HMM_SubM2, \
        HMM_Mat3: HMM_SubM3, \
        HMM_Mat4: HMM_SubM4, \
        HMM_Quat: HMM_SubQ \
)(A, B)

#define HMM_Mul(A, B) _Generic((B), \
     float: _Generic((A), \
        HMM_Vec2: HMM_MulV2F, \
        HMM_Vec3: HMM_MulV3F, \
        HMM_Vec4: HMM_MulV4F, \
        HMM_Mat2: HMM_MulM2F, \
        HMM_Mat3: HMM_MulM3F, \
        HMM_Mat4: HMM_MulM4F, \
        HMM_Quat: HMM_MulQF \
     ), \
     HMM_Mat2: HMM_MulM2, \
     HMM_Mat3: HMM_MulM3, \
     HMM_Mat4: HMM_MulM4, \
     HMM_Quat: HMM_MulQ, \
     default: _Generic((A), \
        HMM_Vec2: HMM_MulV2, \
        HMM_Vec3: HMM_MulV3, \
        HMM_Vec4: HMM_MulV4, \
        HMM_Mat2: HMM_MulM2V2, \
        HMM_Mat3: HMM_MulM3V3, \
        HMM_Mat4: HMM_MulM4V4 \
    ) \
)(A, B)

#define HMM_Div(A, B) _Generic((B), \
     float: _Generic((A), \
        HMM_Mat2: HMM_DivM2F, \
        HMM_Mat3: HMM_DivM3F, \
        HMM_Mat4: HMM_DivM4F, \
        HMM_Vec2: HMM_DivV2F, \
        HMM_Vec3: HMM_DivV3F, \
        HMM_Vec4: HMM_DivV4F, \
        HMM_Quat: HMM_DivQF  \
     ), \
     HMM_Mat2: HMM_DivM2, \
     HMM_Mat3: HMM_DivM3, \
     HMM_Mat4: HMM_DivM4, \
     HMM_Quat: HMM_DivQ, \
     default: _Generic((A), \
        HMM_Vec2: HMM_DivV2, \
        HMM_Vec3: HMM_DivV3, \
        HMM_Vec4: HMM_DivV4  \
    ) \
)(A, B)

#define HMM_Len(A) _Generic((A), \
        HMM_Vec2: HMM_LenV2, \
        HMM_Vec3: HMM_LenV3, \
        HMM_Vec4: HMM_LenV4  \
)(A)

#define HMM_LenSqr(A) _Generic((A), \
        HMM_Vec2: HMM_LenSqrV2, \
        HMM_Vec3: HMM_LenSqrV3, \
        HMM_Vec4: HMM_LenSqrV4  \
)(A)

#define HMM_Norm(A) _Generic((A), \
        HMM_Vec2: HMM_NormV2, \
        HMM_Vec3: HMM_NormV3, \
        HMM_Vec4: HMM_NormV4  \
)(A)

#define HMM_Dot(A, B) _Generic((A), \
        HMM_Vec2: HMM_DotV2, \
        HMM_Vec3: HMM_DotV3, \
        HMM_Vec4: HMM_DotV4  \
)(A, B)

#define HMM_Lerp(A, T, B) _Generic((A), \
        float: HMM_Lerp, \
        HMM_Vec2: HMM_LerpV2, \
        HMM_Vec3: HMM_LerpV3, \
        HMM_Vec4: HMM_LerpV4 \
)(A, T, B)

#define HMM_Eq(A, B) _Generic((A), \
        HMM_Vec2: HMM_EqV2, \
        HMM_Vec3: HMM_EqV3, \
        HMM_Vec4: HMM_EqV4  \
)(A, B)

#define HMM_Transpose(M) _Generic((M), \
        HMM_Mat2: HMM_TransposeM2, \
        HMM_Mat3: HMM_TransposeM3, \
        HMM_Mat4: HMM_TransposeM4  \
)(M)

#define HMM_Determinant(M) _Generic((M), \
        HMM_Mat2: HMM_DeterminantM2, \
        HMM_Mat3: HMM_DeterminantM3, \
        HMM_Mat4: HMM_DeterminantM4  \
)(M)

#define HMM_InvGeneral(M) _Generic((M), \
        HMM_Mat2: HMM_InvGeneralM2, \
        HMM_Mat3: HMM_InvGeneralM3, \
        HMM_Mat4: HMM_InvGeneralM4  \
)(M)

#endif

#if defined(__GNUC__) || defined(__clang__)
#pragma GCC diagnostic pop
#endif

#endif /* HANDMADE_MATH_H */



//FILE_END

//FILE_START:shaders/shaders.glsl.h
#pragma once
/*
    #version:1# (machine generated, don't edit!)

    Generated by sokol-shdc (https://github.com/floooh/sokol-tools)

    Cmdline:
        sokol-shdc -i shaders.glsl -o shaders.glsl.h -f sokol_impl --slang hlsl5:glsl430:glsl300es

    Overview:
    =========
    Shader program: 'phong_color':
        Get shader desc: pk_phong_color_shader_desc(sg_query_backend());
        Vertex Shader: phong_color_vs
        Fragment Shader: phong_color_fs
        Attributes:
            ATTR_pk_phong_color_position => 0
            ATTR_pk_phong_color_normal => 1
            ATTR_pk_phong_color_uv => 2
    Shader program: 'phong_tex':
        Get shader desc: pk_phong_tex_shader_desc(sg_query_backend());
        Vertex Shader: phong_tex_vs
        Fragment Shader: phong_tex_fs
        Attributes:
            ATTR_pk_phong_tex_position => 0
            ATTR_pk_phong_tex_normal => 1
            ATTR_pk_phong_tex_uv => 2
    Shader program: 'skinned_phong_tex':
        Get shader desc: pk_skinned_phong_tex_shader_desc(sg_query_backend());
        Vertex Shader: skinned_vs
        Fragment Shader: phong_tex_fs
        Attributes:
            ATTR_pk_skinned_phong_tex_pos => 0
            ATTR_pk_skinned_phong_tex_nrm => 1
            ATTR_pk_skinned_phong_tex_uv => 2
            ATTR_pk_skinned_phong_tex_bone_indices => 3
            ATTR_pk_skinned_phong_tex_weights => 4
    Shader program: 'unlit_color':
        Get shader desc: pk_unlit_color_shader_desc(sg_query_backend());
        Vertex Shader: unlit_col_vs
        Fragment Shader: unlit_col_fs
        Attributes:
            ATTR_pk_unlit_color_position => 0
    Shader program: 'unlit_tex':
        Get shader desc: pk_unlit_tex_shader_desc(sg_query_backend());
        Vertex Shader: unlit_tex_vs
        Fragment Shader: unlit_tex_fs
        Attributes:
            ATTR_pk_unlit_tex_position => 0
            ATTR_pk_unlit_tex_normal => 1
            ATTR_pk_unlit_tex_uv => 2
    Bindings:
        Uniform block 'vs_params':
            C struct: pk_vs_params_t
            Bind slot: UB_pk_vs_params => 0
        Uniform block 'dir_light':
            C struct: pk_dir_light_t
            Bind slot: UB_pk_dir_light => 3
        Uniform block 'col_material':
            C struct: pk_col_material_t
            Bind slot: UB_pk_col_material => 2
        Uniform block 'tex_material':
            C struct: pk_tex_material_t
            Bind slot: UB_pk_tex_material => 2
        Uniform block 'bone_matrices':
            C struct: pk_bone_matrices_t
            Bind slot: UB_pk_bone_matrices => 1
        Uniform block 'color':
            C struct: pk_color_t
            Bind slot: UB_pk_color => 1
        Image 'col_tex':
            Image type: SG_IMAGETYPE_2D
            Sample type: SG_IMAGESAMPLETYPE_FLOAT
            Multisampled: false
            Bind slot: IMG_pk_col_tex => 0
        Image 'tex':
            Image type: SG_IMAGETYPE_2D
            Sample type: SG_IMAGESAMPLETYPE_FLOAT
            Multisampled: false
            Bind slot: IMG_pk_tex => 0
        Sampler 'col_smp':
            Type: SG_SAMPLERTYPE_FILTERING
            Bind slot: SMP_pk_col_smp => 0
        Sampler 'smp':
            Type: SG_SAMPLERTYPE_FILTERING
            Bind slot: SMP_pk_smp => 0
*/
#if !defined(SOKOL_GFX_INCLUDED)
#error "Please include sokol_gfx.h before shaders.glsl.h"
#endif
#if !defined(SOKOL_SHDC_ALIGN)
#if defined(_MSC_VER)
#define SOKOL_SHDC_ALIGN(a) __declspec(align(a))
#else
#define SOKOL_SHDC_ALIGN(a) __attribute__((aligned(a)))
#endif
#endif
const sg_shader_desc* pk_phong_color_shader_desc(sg_backend backend);
const sg_shader_desc* pk_phong_tex_shader_desc(sg_backend backend);
const sg_shader_desc* pk_skinned_phong_tex_shader_desc(sg_backend backend);
const sg_shader_desc* pk_unlit_color_shader_desc(sg_backend backend);
const sg_shader_desc* pk_unlit_tex_shader_desc(sg_backend backend);
#define ATTR_pk_phong_color_position (0)
#define ATTR_pk_phong_color_normal (1)
#define ATTR_pk_phong_color_uv (2)
#define ATTR_pk_phong_tex_position (0)
#define ATTR_pk_phong_tex_normal (1)
#define ATTR_pk_phong_tex_uv (2)
#define ATTR_pk_skinned_phong_tex_pos (0)
#define ATTR_pk_skinned_phong_tex_nrm (1)
#define ATTR_pk_skinned_phong_tex_uv (2)
#define ATTR_pk_skinned_phong_tex_bone_indices (3)
#define ATTR_pk_skinned_phong_tex_weights (4)
#define ATTR_pk_unlit_color_position (0)
#define ATTR_pk_unlit_tex_position (0)
#define ATTR_pk_unlit_tex_normal (1)
#define ATTR_pk_unlit_tex_uv (2)
#define UB_pk_vs_params (0)
#define UB_pk_dir_light (3)
#define UB_pk_col_material (2)
#define UB_pk_tex_material (2)
#define UB_pk_bone_matrices (1)
#define UB_pk_color (1)
#define IMG_pk_col_tex (0)
#define IMG_pk_tex (0)
#define SMP_pk_col_smp (0)
#define SMP_pk_smp (0)
#pragma pack(push,1)
SOKOL_SHDC_ALIGN(16) typedef struct pk_vs_params_t {
    HMM_Mat4 view;
    HMM_Mat4 proj;
    HMM_Mat4 model;
    HMM_Vec3 viewpos;
    uint8_t _pad_204[4];
} pk_vs_params_t;
#pragma pack(pop)
#pragma pack(push,1)
SOKOL_SHDC_ALIGN(16) typedef struct pk_dir_light_t {
    HMM_Vec3 direction;
    uint8_t _pad_12[4];
    sg_color ambient;
    sg_color diffuse;
    sg_color specular;
} pk_dir_light_t;
#pragma pack(pop)
#pragma pack(push,1)
SOKOL_SHDC_ALIGN(16) typedef struct pk_col_material_t {
    sg_color ambient;
    sg_color diffuse;
    sg_color specular;
    float shininess;
    uint8_t _pad_52[12];
} pk_col_material_t;
#pragma pack(pop)
#pragma pack(push,1)
SOKOL_SHDC_ALIGN(16) typedef struct pk_tex_material_t {
    float shininess;
    uint8_t _pad_4[12];
} pk_tex_material_t;
#pragma pack(pop)
#pragma pack(push,1)
SOKOL_SHDC_ALIGN(16) typedef struct pk_bone_matrices_t {
    HMM_Mat4 bones[32];
} pk_bone_matrices_t;
#pragma pack(pop)
#pragma pack(push,1)
SOKOL_SHDC_ALIGN(16) typedef struct pk_color_t {
    sg_color col;
} pk_color_t;
#pragma pack(pop)
#if defined(SOKOL_SHDC_IMPL)
/*
    #version 430

    uniform vec4 bone_matrices[128];
    uniform vec4 vs_params[13];
    layout(location = 3) in uvec4 bone_indices;
    layout(location = 4) in vec4 weights;
    layout(location = 0) in vec3 pos;
    layout(location = 1) in vec3 nrm;
    layout(location = 0) out vec3 v_pos;
    layout(location = 1) out vec3 v_normal;
    layout(location = 2) out vec2 v_uv;
    layout(location = 2) in vec2 uv;
    layout(location = 3) out vec3 v_viewpos;

    void main()
    {
        mat4 _37 = mat4(bone_matrices[bone_indices.x * 4 + 0], bone_matrices[bone_indices.x * 4 + 1], bone_matrices[bone_indices.x * 4 + 2], bone_matrices[bone_indices.x * 4 + 3]) * weights.x;
        mat4 _45 = mat4(bone_matrices[bone_indices.y * 4 + 0], bone_matrices[bone_indices.y * 4 + 1], bone_matrices[bone_indices.y * 4 + 2], bone_matrices[bone_indices.y * 4 + 3]) * weights.y;
        mat4 _66 = mat4(bone_matrices[bone_indices.z * 4 + 0], bone_matrices[bone_indices.z * 4 + 1], bone_matrices[bone_indices.z * 4 + 2], bone_matrices[bone_indices.z * 4 + 3]) * weights.z;
        mat4 _87 = mat4(bone_matrices[bone_indices.w * 4 + 0], bone_matrices[bone_indices.w * 4 + 1], bone_matrices[bone_indices.w * 4 + 2], bone_matrices[bone_indices.w * 4 + 3]) * weights.w;
        vec4 _90 = ((_37[0] + _45[0]) + _66[0]) + _87[0];
        vec4 _93 = ((_37[1] + _45[1]) + _66[1]) + _87[1];
        vec4 _96 = ((_37[2] + _45[2]) + _66[2]) + _87[2];
        vec4 _113 = mat4(_90, _93, _96, ((_37[3] + _45[3]) + _66[3]) + _87[3]) * vec4(pos, 1.0);
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11])) * _113;
        v_pos = _113.xyz;
        v_normal = normalize(mat3(_90.xyz, _93.xyz, _96.xyz) * nrm);
        v_uv = uv;
        v_viewpos = vs_params[12].xyz;
    }

*/
static const uint8_t pk_skinned_vs_source_glsl430[1798] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x62,0x6f,0x6e,0x65,0x5f,
    0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x31,0x32,0x38,0x5d,0x3b,0x0a,0x75,
    0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,
    0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x33,0x29,0x20,
    0x69,0x6e,0x20,0x75,0x76,0x65,0x63,0x34,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,
    0x64,0x69,0x63,0x65,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,
    0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x34,0x29,0x20,0x69,0x6e,0x20,0x76,
    0x65,0x63,0x34,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x3b,0x0a,0x6c,0x61,0x79,
    0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,
    0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x3b,0x0a,0x6c,
    0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,
    0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x6e,0x72,0x6d,0x3b,
    0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,
    0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,
    0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,
    0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,
    0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6c,0x61,
    0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x32,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x32,0x20,0x76,0x5f,0x75,0x76,
    0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,
    0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,0x75,
    0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x33,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,
    0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x0a,0x76,0x6f,0x69,
    0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x6d,
    0x61,0x74,0x34,0x20,0x5f,0x33,0x37,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x62,
    0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,
    0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x78,0x20,0x2a,0x20,0x34,0x20,
    0x2b,0x20,0x30,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,
    0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,
    0x2e,0x78,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,
    0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,
    0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x78,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,
    0x32,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,
    0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x78,
    0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x33,0x5d,0x29,0x20,0x2a,0x20,0x77,0x65,0x69,
    0x67,0x68,0x74,0x73,0x2e,0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,
    0x20,0x5f,0x34,0x35,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,0x6e,0x65,
    0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,
    0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x30,
    0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,
    0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x79,0x20,
    0x2a,0x20,0x34,0x20,0x2b,0x20,0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,
    0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,
    0x69,0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,0x5d,0x2c,
    0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,
    0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,0x20,
    0x34,0x20,0x2b,0x20,0x33,0x5d,0x29,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,
    0x73,0x2e,0x79,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x36,
    0x36,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,
    0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,
    0x63,0x65,0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x30,0x5d,0x2c,0x20,
    0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,
    0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,
    0x20,0x2b,0x20,0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,
    0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,
    0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,0x5d,0x2c,0x20,0x62,0x6f,
    0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,
    0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,0x2b,
    0x20,0x33,0x5d,0x29,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x2e,0x7a,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x38,0x37,0x20,0x3d,
    0x20,0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,
    0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,
    0x2e,0x77,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x30,0x5d,0x2c,0x20,0x62,0x6f,0x6e,
    0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,
    0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x77,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,
    0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,
    0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x77,
    0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,
    0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,
    0x64,0x69,0x63,0x65,0x73,0x2e,0x77,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x33,0x5d,
    0x29,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x2e,0x77,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x39,0x30,0x20,0x3d,0x20,0x28,0x28,
    0x5f,0x33,0x37,0x5b,0x30,0x5d,0x20,0x2b,0x20,0x5f,0x34,0x35,0x5b,0x30,0x5d,0x29,
    0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x30,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,
    0x5b,0x30,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x39,
    0x33,0x20,0x3d,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x31,0x5d,0x20,0x2b,0x20,0x5f,
    0x34,0x35,0x5b,0x31,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x31,0x5d,0x29,
    0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x31,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x65,0x63,0x34,0x20,0x5f,0x39,0x36,0x20,0x3d,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,
    0x32,0x5d,0x20,0x2b,0x20,0x5f,0x34,0x35,0x5b,0x32,0x5d,0x29,0x20,0x2b,0x20,0x5f,
    0x36,0x36,0x5b,0x32,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x32,0x5d,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x31,0x31,0x33,0x20,0x3d,
    0x20,0x6d,0x61,0x74,0x34,0x28,0x5f,0x39,0x30,0x2c,0x20,0x5f,0x39,0x33,0x2c,0x20,
    0x5f,0x39,0x36,0x2c,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x33,0x5d,0x20,0x2b,0x20,
    0x5f,0x34,0x35,0x5b,0x33,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x33,0x5d,
    0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x33,0x5d,0x29,0x20,0x2a,0x20,0x76,0x65,
    0x63,0x34,0x28,0x70,0x6f,0x73,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x35,
    0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x36,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x37,0x5d,0x29,0x20,0x2a,
    0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x29,0x20,0x2a,
    0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x38,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x29,
    0x20,0x2a,0x20,0x5f,0x31,0x31,0x33,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x70,
    0x6f,0x73,0x20,0x3d,0x20,0x5f,0x31,0x31,0x33,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x6d,0x61,0x74,0x33,0x28,0x5f,0x39,0x30,
    0x2e,0x78,0x79,0x7a,0x2c,0x20,0x5f,0x39,0x33,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x5f,
    0x39,0x36,0x2e,0x78,0x79,0x7a,0x29,0x20,0x2a,0x20,0x6e,0x72,0x6d,0x29,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x75,0x76,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x32,0x5d,0x2e,0x78,0x79,0x7a,
    0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;

    void main()
    {
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11])) * vec4(position, 1.0);
    }

*/
static const uint8_t pk_unlit_col_vs_source_glsl430[334] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,
    0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,
    0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,
    0x3d,0x20,0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,
    0x6d,0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x36,
    0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x37,0x5d,0x29,
    0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x29,
    0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x38,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x39,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,
    0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,
    0x29,0x29,0x20,0x2a,0x20,0x76,0x65,0x63,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    uniform vec4 color[1];
    layout(location = 0) out vec4 frag_color;

    void main()
    {
        frag_color = color[0];
    }

*/
static const uint8_t pk_unlit_col_fs_source_glsl430[125] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,0x6f,0x72,
    0x5b,0x31,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,
    0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,
    0x63,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,
    0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,
    0x20,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x63,
    0x6f,0x6c,0x6f,0x72,0x5b,0x30,0x5d,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;
    layout(location = 0) out vec2 v_uv;
    layout(location = 2) in vec2 uv;
    layout(location = 1) in vec3 normal;

    void main()
    {
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11])) * vec4(position, 1.0);
        v_uv = uv;
    }

*/
static const uint8_t pk_unlit_tex_vs_source_glsl430[455] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,
    0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,
    0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,
    0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x32,0x20,0x76,
    0x5f,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,
    0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,
    0x32,0x20,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,
    0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,
    0x63,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,
    0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,
    0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x28,0x28,0x6d,0x61,
    0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x35,0x5d,0x2c,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x36,0x5d,0x2c,0x20,0x76,0x73,0x5f,
    0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x37,0x5d,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,
    0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,
    0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,
    0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x29,0x20,0x2a,0x20,0x76,
    0x65,0x63,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,
    0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x75,
    0x76,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    layout(binding = 16) uniform sampler2D tex_smp;

    layout(location = 0) in vec2 v_uv;
    layout(location = 0) out vec4 frag_color;

    void main()
    {
        frag_color = texture(tex_smp, v_uv);
    }

*/
static const uint8_t pk_unlit_tex_fs_source_glsl430[200] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x6c,0x61,
    0x79,0x6f,0x75,0x74,0x28,0x62,0x69,0x6e,0x64,0x69,0x6e,0x67,0x20,0x3d,0x20,0x31,
    0x36,0x29,0x20,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x73,0x61,0x6d,0x70,0x6c,
    0x65,0x72,0x32,0x44,0x20,0x74,0x65,0x78,0x5f,0x73,0x6d,0x70,0x3b,0x0a,0x0a,0x6c,
    0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,
    0x20,0x30,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,0x76,0x5f,0x75,0x76,
    0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,
    0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x34,0x20,
    0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x76,0x6f,0x69,
    0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x74,0x65,0x78,0x74,
    0x75,0x72,0x65,0x28,0x74,0x65,0x78,0x5f,0x73,0x6d,0x70,0x2c,0x20,0x76,0x5f,0x75,
    0x76,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;
    layout(location = 0) out vec3 v_pos;
    layout(location = 1) out vec3 v_normal;
    layout(location = 1) in vec3 normal;
    layout(location = 2) out vec3 v_viewpos;
    layout(location = 2) in vec2 uv;

    void main()
    {
        mat4 _30 = mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11]);
        vec4 _39 = vec4(position, 1.0);
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * _30) * _39;
        v_pos = vec3((_30 * _39).xyz);
        v_normal = mat3(_30[0].xyz, _30[1].xyz, _30[2].xyz) * normal;
        v_viewpos = vs_params[12].xyz;
    }

*/
static const uint8_t pk_phong_color_vs_source_glsl430[698] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,
    0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,
    0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,
    0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,
    0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,
    0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,
    0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6c,0x61,
    0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,
    0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,
    0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,
    0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,0x75,0x76,0x3b,0x0a,0x0a,0x76,0x6f,
    0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x6d,0x61,0x74,0x34,0x20,0x5f,0x33,0x30,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,0x2c,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x65,0x63,0x34,0x20,0x5f,0x33,0x39,0x20,0x3d,0x20,0x76,0x65,0x63,0x34,0x28,0x70,
    0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,
    0x20,0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x36,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x37,0x5d,0x29,0x20,
    0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,
    0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x29,0x20,
    0x2a,0x20,0x5f,0x33,0x30,0x29,0x20,0x2a,0x20,0x5f,0x33,0x39,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x65,0x63,0x33,0x28,0x28,
    0x5f,0x33,0x30,0x20,0x2a,0x20,0x5f,0x33,0x39,0x29,0x2e,0x78,0x79,0x7a,0x29,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,
    0x6d,0x61,0x74,0x33,0x28,0x5f,0x33,0x30,0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x2c,
    0x20,0x5f,0x33,0x30,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x5f,0x33,0x30,
    0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x29,0x20,0x2a,0x20,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x3d,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x32,0x5d,
    0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    uniform vec4 dir_light[4];
    uniform vec4 col_material[4];
    layout(location = 0) in vec3 v_pos;
    layout(location = 1) in vec3 v_normal;
    layout(location = 2) in vec3 v_viewpos;
    layout(location = 0) out vec4 FragColor;

    vec3 phong_light(vec3 v_pos_1, vec3 v_normal_1, vec3 viewpos, vec3 material_ambient, vec3 material_diffuse, vec3 material_specular, float shininess, vec4 tex_color)
    {
        vec3 _25 = normalize(v_normal_1);
        vec3 _41 = normalize(-dir_light[0].xyz);
        return fma(dir_light[3].xyz * pow(max(dot(normalize(viewpos - v_pos_1), reflect(-_41, _25)), 0.0), shininess), material_specular, fma(dir_light[1].xyz, material_ambient, (dir_light[2].xyz * max(dot(_25, _41), 0.0)) * material_diffuse));
    }

    void main()
    {
        vec3 param = v_pos;
        vec3 param_1 = v_normal;
        vec3 param_2 = v_viewpos;
        vec3 param_3 = col_material[0].xyz;
        vec3 param_4 = col_material[1].xyz;
        vec3 param_5 = col_material[2].xyz;
        float param_6 = col_material[3].x;
        vec4 param_7 = vec4(1.0);
        FragColor = vec4(phong_light(param, param_1, param_2, param_3, param_4, param_5, param_6, param_7), 1.0);
    }

*/
static const uint8_t pk_phong_color_fs_source_glsl430[1122] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x64,0x69,0x72,0x5f,0x6c,
    0x69,0x67,0x68,0x74,0x5b,0x34,0x5d,0x3b,0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,
    0x20,0x76,0x65,0x63,0x34,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5b,0x34,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,
    0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,0x6e,0x20,0x76,
    0x65,0x63,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,
    0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,
    0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,
    0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x76,
    0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,
    0x75,0x74,0x20,0x76,0x65,0x63,0x34,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,
    0x72,0x3b,0x0a,0x0a,0x76,0x65,0x63,0x33,0x20,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,
    0x69,0x67,0x68,0x74,0x28,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,
    0x31,0x2c,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x5f,0x31,0x2c,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x2c,0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,
    0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,
    0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2c,0x20,
    0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,
    0x65,0x63,0x75,0x6c,0x61,0x72,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x20,0x73,0x68,
    0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x2c,0x20,0x76,0x65,0x63,0x34,0x20,0x74,0x65,
    0x78,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x65,0x63,0x33,0x20,0x5f,0x32,0x35,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x69,0x7a,0x65,0x28,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x29,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x5f,0x34,0x31,0x20,0x3d,0x20,
    0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x2d,0x64,0x69,0x72,0x5f,0x6c,
    0x69,0x67,0x68,0x74,0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x66,0x6d,0x61,0x28,0x64,0x69,0x72,
    0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x33,0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,
    0x70,0x6f,0x77,0x28,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x69,0x7a,0x65,0x28,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x2d,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x5f,0x31,0x29,0x2c,0x20,0x72,0x65,0x66,0x6c,0x65,0x63,
    0x74,0x28,0x2d,0x5f,0x34,0x31,0x2c,0x20,0x5f,0x32,0x35,0x29,0x29,0x2c,0x20,0x30,
    0x2e,0x30,0x29,0x2c,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x29,0x2c,
    0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,
    0x61,0x72,0x2c,0x20,0x66,0x6d,0x61,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,
    0x74,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x28,0x64,0x69,0x72,
    0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,
    0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x5f,0x32,0x35,0x2c,0x20,0x5f,0x34,0x31,
    0x29,0x2c,0x20,0x30,0x2e,0x30,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,
    0x69,0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x29,0x29,0x3b,0x0a,0x7d,
    0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x20,0x3d,
    0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,
    0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,0x72,
    0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,
    0x72,0x61,0x6d,0x5f,0x32,0x20,0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,
    0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x33,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x20,0x3d,0x20,0x63,0x6f,
    0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,0x31,0x5d,0x2e,0x78,0x79,
    0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x35,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x20,0x3d,0x20,0x63,
    0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,0x33,0x5d,0x2e,0x78,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x70,0x61,0x72,0x61,0x6d,
    0x5f,0x37,0x20,0x3d,0x20,0x76,0x65,0x63,0x34,0x28,0x31,0x2e,0x30,0x29,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,
    0x76,0x65,0x63,0x34,0x28,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,
    0x28,0x70,0x61,0x72,0x61,0x6d,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x2c,
    0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,
    0x33,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x2c,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x35,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x2c,0x20,0x70,0x61,
    0x72,0x61,0x6d,0x5f,0x37,0x29,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x7d,0x0a,
    0x0a,0x00,
};
/*
    #version 430

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;
    layout(location = 0) out vec3 v_pos;
    layout(location = 1) out vec3 v_normal;
    layout(location = 1) in vec3 normal;
    layout(location = 2) out vec2 v_uv;
    layout(location = 2) in vec2 uv;
    layout(location = 3) out vec3 v_viewpos;

    void main()
    {
        mat4 _30 = mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11]);
        vec4 _39 = vec4(position, 1.0);
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * _30) * _39;
        v_pos = vec3((_30 * _39).xyz);
        v_normal = mat3(_30[0].xyz, _30[1].xyz, _30[2].xyz) * normal;
        v_uv = uv;
        v_viewpos = vs_params[12].xyz;
    }

*/
static const uint8_t pk_phong_tex_vs_source_glsl430[749] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,
    0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,
    0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,
    0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,
    0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,
    0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,
    0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6c,0x61,
    0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x32,
    0x20,0x76,0x5f,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,
    0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,
    0x65,0x63,0x32,0x20,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,
    0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x33,0x29,0x20,0x6f,0x75,0x74,
    0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,
    0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x33,0x30,0x20,0x3d,0x20,0x6d,
    0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x33,0x39,0x20,0x3d,0x20,0x76,0x65,
    0x63,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,
    0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,
    0x61,0x6d,0x73,0x5b,0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x36,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x37,0x5d,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,
    0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,
    0x5d,0x29,0x29,0x20,0x2a,0x20,0x5f,0x33,0x30,0x29,0x20,0x2a,0x20,0x5f,0x33,0x39,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x65,
    0x63,0x33,0x28,0x28,0x5f,0x33,0x30,0x20,0x2a,0x20,0x5f,0x33,0x39,0x29,0x2e,0x78,
    0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x20,0x3d,0x20,0x6d,0x61,0x74,0x33,0x28,0x5f,0x33,0x30,0x5b,0x30,0x5d,0x2e,
    0x78,0x79,0x7a,0x2c,0x20,0x5f,0x33,0x30,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x2c,
    0x20,0x5f,0x33,0x30,0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x29,0x20,0x2a,0x20,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,
    0x3d,0x20,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,
    0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x31,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 430

    uniform vec4 dir_light[4];
    uniform vec4 tex_material[1];
    layout(binding = 16) uniform sampler2D col_tex_col_smp;

    layout(location = 2) in vec2 v_uv;
    layout(location = 0) in vec3 v_pos;
    layout(location = 1) in vec3 v_normal;
    layout(location = 3) in vec3 v_viewpos;
    layout(location = 0) out vec4 FragColor;

    vec3 phong_light(vec3 v_pos_1, vec3 v_normal_1, vec3 viewpos, vec3 material_ambient, vec3 material_diffuse, vec3 material_specular, float shininess, vec4 tex_color)
    {
        vec3 _25 = normalize(v_normal_1);
        vec3 _41 = normalize(-dir_light[0].xyz);
        return fma(dir_light[3].xyz * pow(max(dot(normalize(viewpos - v_pos_1), reflect(-_41, _25)), 0.0), shininess), material_specular, fma(dir_light[1].xyz, material_ambient, (dir_light[2].xyz * max(dot(_25, _41), 0.0)) * material_diffuse));
    }

    void main()
    {
        vec4 _108 = texture(col_tex_col_smp, v_uv);
        vec3 param = v_pos;
        vec3 param_1 = v_normal;
        vec3 param_2 = v_viewpos;
        vec3 _130 = _108.xyz;
        vec3 param_3 = _130;
        vec3 param_4 = _130;
        vec3 param_5 = vec3(_108.w);
        float param_6 = tex_material[0].x;
        vec4 param_7 = _108;
        FragColor = vec4(phong_light(param, param_1, param_2, param_3, param_4, param_5, param_6, param_7), 1.0);
    }

*/
static const uint8_t pk_phong_tex_fs_source_glsl430[1246] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x34,0x33,0x30,0x0a,0x0a,0x75,0x6e,
    0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x64,0x69,0x72,0x5f,0x6c,
    0x69,0x67,0x68,0x74,0x5b,0x34,0x5d,0x3b,0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,
    0x20,0x76,0x65,0x63,0x34,0x20,0x74,0x65,0x78,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5b,0x31,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x62,0x69,
    0x6e,0x64,0x69,0x6e,0x67,0x20,0x3d,0x20,0x31,0x36,0x29,0x20,0x75,0x6e,0x69,0x66,
    0x6f,0x72,0x6d,0x20,0x73,0x61,0x6d,0x70,0x6c,0x65,0x72,0x32,0x44,0x20,0x63,0x6f,
    0x6c,0x5f,0x74,0x65,0x78,0x5f,0x63,0x6f,0x6c,0x5f,0x73,0x6d,0x70,0x3b,0x0a,0x0a,
    0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,
    0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,0x76,0x5f,0x75,
    0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,
    0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,
    0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6c,0x61,
    0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x33,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,
    0x77,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,
    0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x76,
    0x65,0x63,0x34,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,
    0x76,0x65,0x63,0x33,0x20,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,
    0x28,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,0x31,0x2c,0x20,0x76,
    0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x2c,0x20,
    0x76,0x65,0x63,0x33,0x20,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x2c,0x20,0x76,0x65,
    0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,
    0x65,0x6e,0x74,0x2c,0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2c,0x20,0x76,0x65,0x63,0x33,
    0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,
    0x61,0x72,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,
    0x65,0x73,0x73,0x2c,0x20,0x76,0x65,0x63,0x34,0x20,0x74,0x65,0x78,0x5f,0x63,0x6f,
    0x6c,0x6f,0x72,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,
    0x5f,0x32,0x35,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,
    0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x29,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x76,0x65,0x63,0x33,0x20,0x5f,0x34,0x31,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x69,0x7a,0x65,0x28,0x2d,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,
    0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,
    0x74,0x75,0x72,0x6e,0x20,0x66,0x6d,0x61,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,
    0x68,0x74,0x5b,0x33,0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,0x70,0x6f,0x77,0x28,
    0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,
    0x65,0x28,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x2d,0x20,0x76,0x5f,0x70,0x6f,
    0x73,0x5f,0x31,0x29,0x2c,0x20,0x72,0x65,0x66,0x6c,0x65,0x63,0x74,0x28,0x2d,0x5f,
    0x34,0x31,0x2c,0x20,0x5f,0x32,0x35,0x29,0x29,0x2c,0x20,0x30,0x2e,0x30,0x29,0x2c,
    0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x29,0x2c,0x20,0x6d,0x61,0x74,
    0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x2c,0x20,
    0x66,0x6d,0x61,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x31,0x5d,
    0x2e,0x78,0x79,0x7a,0x2c,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x61,
    0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,
    0x68,0x74,0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,0x6d,0x61,0x78,0x28,
    0x64,0x6f,0x74,0x28,0x5f,0x32,0x35,0x2c,0x20,0x5f,0x34,0x31,0x29,0x2c,0x20,0x30,
    0x2e,0x30,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,
    0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x29,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x76,0x6f,
    0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x76,0x65,0x63,0x34,0x20,0x5f,0x31,0x30,0x38,0x20,0x3d,0x20,0x74,0x65,0x78,0x74,
    0x75,0x72,0x65,0x28,0x63,0x6f,0x6c,0x5f,0x74,0x65,0x78,0x5f,0x63,0x6f,0x6c,0x5f,
    0x73,0x6d,0x70,0x2c,0x20,0x76,0x5f,0x75,0x76,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x20,0x3d,0x20,0x76,0x5f,0x70,
    0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,
    0x61,0x6d,0x5f,0x31,0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,
    0x32,0x20,0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x5f,0x31,0x33,0x30,0x20,0x3d,0x20,0x5f,
    0x31,0x30,0x38,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,
    0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x33,0x20,0x3d,0x20,0x5f,0x31,0x33,0x30,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,
    0x5f,0x34,0x20,0x3d,0x20,0x5f,0x31,0x33,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,0x20,0x3d,0x20,0x76,0x65,
    0x63,0x33,0x28,0x5f,0x31,0x30,0x38,0x2e,0x77,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x20,0x3d,0x20,
    0x74,0x65,0x78,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,0x30,0x5d,0x2e,
    0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x37,0x20,0x3d,0x20,0x5f,0x31,0x30,0x38,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x76,0x65,0x63,0x34,
    0x28,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,0x28,0x70,0x61,0x72,
    0x61,0x6d,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x2c,0x20,0x70,0x61,0x72,
    0x61,0x6d,0x5f,0x32,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x33,0x2c,0x20,0x70,
    0x61,0x72,0x61,0x6d,0x5f,0x34,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,0x2c,
    0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,
    0x37,0x29,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es

    uniform vec4 bone_matrices[128];
    uniform vec4 vs_params[13];
    layout(location = 3) in uvec4 bone_indices;
    layout(location = 4) in vec4 weights;
    layout(location = 0) in vec3 pos;
    layout(location = 1) in vec3 nrm;
    out vec3 v_pos;
    out vec3 v_normal;
    out vec2 v_uv;
    layout(location = 2) in vec2 uv;
    out vec3 v_viewpos;

    void main()
    {
        mat4 _37 = mat4(bone_matrices[bone_indices.x * 4 + 0], bone_matrices[bone_indices.x * 4 + 1], bone_matrices[bone_indices.x * 4 + 2], bone_matrices[bone_indices.x * 4 + 3]) * weights.x;
        mat4 _45 = mat4(bone_matrices[bone_indices.y * 4 + 0], bone_matrices[bone_indices.y * 4 + 1], bone_matrices[bone_indices.y * 4 + 2], bone_matrices[bone_indices.y * 4 + 3]) * weights.y;
        mat4 _66 = mat4(bone_matrices[bone_indices.z * 4 + 0], bone_matrices[bone_indices.z * 4 + 1], bone_matrices[bone_indices.z * 4 + 2], bone_matrices[bone_indices.z * 4 + 3]) * weights.z;
        mat4 _87 = mat4(bone_matrices[bone_indices.w * 4 + 0], bone_matrices[bone_indices.w * 4 + 1], bone_matrices[bone_indices.w * 4 + 2], bone_matrices[bone_indices.w * 4 + 3]) * weights.w;
        vec4 _90 = ((_37[0] + _45[0]) + _66[0]) + _87[0];
        vec4 _93 = ((_37[1] + _45[1]) + _66[1]) + _87[1];
        vec4 _96 = ((_37[2] + _45[2]) + _66[2]) + _87[2];
        vec4 _113 = mat4(_90, _93, _96, ((_37[3] + _45[3]) + _66[3]) + _87[3]) * vec4(pos, 1.0);
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11])) * _113;
        v_pos = _113.xyz;
        v_normal = normalize(mat3(_90.xyz, _93.xyz, _96.xyz) * nrm);
        v_uv = uv;
        v_viewpos = vs_params[12].xyz;
    }

*/
static const uint8_t pk_skinned_vs_source_glsl300es[1717] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x62,0x6f,
    0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x31,0x32,0x38,0x5d,
    0x3b,0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,
    0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x33,0x29,0x20,0x69,0x6e,0x20,0x75,0x76,0x65,0x63,0x34,0x20,0x62,0x6f,0x6e,0x65,
    0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x34,0x29,0x20,0x69,
    0x6e,0x20,0x76,0x65,0x63,0x34,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x3b,0x0a,
    0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,
    0x3d,0x20,0x30,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,
    0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,
    0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x6e,
    0x72,0x6d,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,
    0x6f,0x73,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x32,0x20,
    0x76,0x5f,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,
    0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,
    0x63,0x32,0x20,0x75,0x76,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,
    0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,
    0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,
    0x74,0x34,0x20,0x5f,0x33,0x37,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,
    0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,
    0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x78,0x20,0x2a,0x20,0x34,0x20,0x2b,
    0x20,0x30,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,
    0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,
    0x78,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,
    0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,
    0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x78,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,
    0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,
    0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x78,0x20,
    0x2a,0x20,0x34,0x20,0x2b,0x20,0x33,0x5d,0x29,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,
    0x68,0x74,0x73,0x2e,0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,
    0x5f,0x34,0x35,0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,0x6e,0x65,0x5f,
    0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,
    0x64,0x69,0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x30,0x5d,
    0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,
    0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,
    0x20,0x34,0x20,0x2b,0x20,0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,
    0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,
    0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,0x5d,0x2c,0x20,
    0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,
    0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x79,0x20,0x2a,0x20,0x34,
    0x20,0x2b,0x20,0x33,0x5d,0x29,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,
    0x2e,0x79,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x36,0x36,
    0x20,0x3d,0x20,0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,
    0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,
    0x65,0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x30,0x5d,0x2c,0x20,0x62,
    0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,
    0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,
    0x2b,0x20,0x31,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,
    0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,
    0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,0x5d,0x2c,0x20,0x62,0x6f,0x6e,
    0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,
    0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x7a,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,
    0x33,0x5d,0x29,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x2e,0x7a,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x38,0x37,0x20,0x3d,0x20,
    0x6d,0x61,0x74,0x34,0x28,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,
    0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,
    0x77,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x30,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,
    0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,
    0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x77,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x31,
    0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,0x72,0x69,0x63,0x65,0x73,
    0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x77,0x20,
    0x2a,0x20,0x34,0x20,0x2b,0x20,0x32,0x5d,0x2c,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,
    0x61,0x74,0x72,0x69,0x63,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,
    0x69,0x63,0x65,0x73,0x2e,0x77,0x20,0x2a,0x20,0x34,0x20,0x2b,0x20,0x33,0x5d,0x29,
    0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x2e,0x77,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x39,0x30,0x20,0x3d,0x20,0x28,0x28,0x5f,
    0x33,0x37,0x5b,0x30,0x5d,0x20,0x2b,0x20,0x5f,0x34,0x35,0x5b,0x30,0x5d,0x29,0x20,
    0x2b,0x20,0x5f,0x36,0x36,0x5b,0x30,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,
    0x30,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x39,0x33,
    0x20,0x3d,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x31,0x5d,0x20,0x2b,0x20,0x5f,0x34,
    0x35,0x5b,0x31,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x31,0x5d,0x29,0x20,
    0x2b,0x20,0x5f,0x38,0x37,0x5b,0x31,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,
    0x63,0x34,0x20,0x5f,0x39,0x36,0x20,0x3d,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x32,
    0x5d,0x20,0x2b,0x20,0x5f,0x34,0x35,0x5b,0x32,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,
    0x36,0x5b,0x32,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x32,0x5d,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x31,0x31,0x33,0x20,0x3d,0x20,
    0x6d,0x61,0x74,0x34,0x28,0x5f,0x39,0x30,0x2c,0x20,0x5f,0x39,0x33,0x2c,0x20,0x5f,
    0x39,0x36,0x2c,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x33,0x5d,0x20,0x2b,0x20,0x5f,
    0x34,0x35,0x5b,0x33,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x33,0x5d,0x29,
    0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x33,0x5d,0x29,0x20,0x2a,0x20,0x76,0x65,0x63,
    0x34,0x28,0x70,0x6f,0x73,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x28,
    0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x35,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x36,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x37,0x5d,0x29,0x20,0x2a,0x20,
    0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x30,
    0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x29,0x20,0x2a,0x20,
    0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,
    0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x29,0x20,
    0x2a,0x20,0x5f,0x31,0x31,0x33,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,
    0x73,0x20,0x3d,0x20,0x5f,0x31,0x31,0x33,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x6e,0x6f,0x72,
    0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x6d,0x61,0x74,0x33,0x28,0x5f,0x39,0x30,0x2e,
    0x78,0x79,0x7a,0x2c,0x20,0x5f,0x39,0x33,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x5f,0x39,
    0x36,0x2e,0x78,0x79,0x7a,0x29,0x20,0x2a,0x20,0x6e,0x72,0x6d,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x75,0x76,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x3b,
    0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;

    void main()
    {
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11])) * vec4(position, 1.0);
    }

*/
static const uint8_t pk_unlit_col_vs_source_glsl300es[337] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,
    0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,
    0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,
    0x61,0x6d,0x73,0x5b,0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x36,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x37,0x5d,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,
    0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,
    0x5d,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,
    0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x31,0x31,0x5d,0x29,0x29,0x20,0x2a,0x20,0x76,0x65,0x63,0x34,0x28,0x70,0x6f,0x73,
    0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,
    0x00,
};
/*
    #version 300 es
    precision mediump float;
    precision highp int;

    uniform highp vec4 color[1];
    layout(location = 0) out highp vec4 frag_color;

    void main()
    {
        frag_color = color[0];
    }

*/
static const uint8_t pk_unlit_col_fs_source_glsl300es[186] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x70,0x72,0x65,0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,0x6d,0x65,0x64,0x69,0x75,0x6d,
    0x70,0x20,0x66,0x6c,0x6f,0x61,0x74,0x3b,0x0a,0x70,0x72,0x65,0x63,0x69,0x73,0x69,
    0x6f,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x69,0x6e,0x74,0x3b,0x0a,0x0a,0x75,
    0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,
    0x34,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x5b,0x31,0x5d,0x3b,0x0a,0x6c,0x61,0x79,0x6f,
    0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,
    0x20,0x6f,0x75,0x74,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,
    0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x76,0x6f,0x69,
    0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x6f,
    0x72,0x5b,0x30,0x5d,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;
    out vec2 v_uv;
    layout(location = 2) in vec2 uv;
    layout(location = 1) in vec3 normal;

    void main()
    {
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11])) * vec4(position, 1.0);
        v_uv = uv;
    }

*/
static const uint8_t pk_unlit_tex_vs_source_glsl300es[437] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,
    0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,
    0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x32,0x20,0x76,0x5f,0x75,
    0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,
    0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,
    0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,
    0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,
    0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,
    0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x28,0x28,0x6d,0x61,0x74,0x34,
    0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,
    0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x36,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x37,0x5d,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,
    0x61,0x6d,0x73,0x5b,0x33,0x5d,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,0x2c,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x29,0x20,0x2a,0x20,0x76,0x65,0x63,
    0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,0x29,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x75,0x76,0x3b,
    0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es
    precision mediump float;
    precision highp int;

    uniform highp sampler2D tex_smp;

    in highp vec2 v_uv;
    layout(location = 0) out highp vec4 frag_color;

    void main()
    {
        frag_color = texture(tex_smp, v_uv);
    }

*/
static const uint8_t pk_unlit_tex_fs_source_glsl300es[225] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x70,0x72,0x65,0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,0x6d,0x65,0x64,0x69,0x75,0x6d,
    0x70,0x20,0x66,0x6c,0x6f,0x61,0x74,0x3b,0x0a,0x70,0x72,0x65,0x63,0x69,0x73,0x69,
    0x6f,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x69,0x6e,0x74,0x3b,0x0a,0x0a,0x75,
    0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x73,0x61,0x6d,
    0x70,0x6c,0x65,0x72,0x32,0x44,0x20,0x74,0x65,0x78,0x5f,0x73,0x6d,0x70,0x3b,0x0a,
    0x0a,0x69,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x32,0x20,0x76,
    0x5f,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,
    0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,0x20,0x68,0x69,
    0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,
    0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,
    0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,
    0x6f,0x72,0x20,0x3d,0x20,0x74,0x65,0x78,0x74,0x75,0x72,0x65,0x28,0x74,0x65,0x78,
    0x5f,0x73,0x6d,0x70,0x2c,0x20,0x76,0x5f,0x75,0x76,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,
    0x00,
};
/*
    #version 300 es

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;
    out vec3 v_pos;
    out vec3 v_normal;
    layout(location = 1) in vec3 normal;
    out vec3 v_viewpos;
    layout(location = 2) in vec2 uv;

    void main()
    {
        mat4 _30 = mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11]);
        vec4 _39 = vec4(position, 1.0);
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * _30) * _39;
        v_pos = vec3((_30 * _39).xyz);
        v_normal = mat3(_30[0].xyz, _30[1].xyz, _30[2].xyz) * normal;
        v_viewpos = vs_params[12].xyz;
    }

*/
static const uint8_t pk_phong_color_vs_source_glsl300es[638] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,
    0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,
    0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,
    0x6f,0x73,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,
    0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,
    0x65,0x63,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6f,0x75,0x74,0x20,
    0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,
    0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,
    0x3d,0x20,0x32,0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,0x75,0x76,0x3b,
    0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x33,0x30,0x20,0x3d,0x20,0x6d,
    0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,
    0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,
    0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x33,0x39,0x20,0x3d,0x20,0x76,0x65,
    0x63,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,
    0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x20,0x3d,0x20,0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,
    0x61,0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,
    0x61,0x6d,0x73,0x5b,0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x36,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x37,0x5d,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,
    0x6d,0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,
    0x5d,0x29,0x29,0x20,0x2a,0x20,0x5f,0x33,0x30,0x29,0x20,0x2a,0x20,0x5f,0x33,0x39,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x65,
    0x63,0x33,0x28,0x28,0x5f,0x33,0x30,0x20,0x2a,0x20,0x5f,0x33,0x39,0x29,0x2e,0x78,
    0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x20,0x3d,0x20,0x6d,0x61,0x74,0x33,0x28,0x5f,0x33,0x30,0x5b,0x30,0x5d,0x2e,
    0x78,0x79,0x7a,0x2c,0x20,0x5f,0x33,0x30,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x2c,
    0x20,0x5f,0x33,0x30,0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x29,0x20,0x2a,0x20,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,
    0x77,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x31,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es
    precision mediump float;
    precision highp int;

    uniform highp vec4 dir_light[4];
    uniform highp vec4 col_material[4];
    in highp vec3 v_pos;
    in highp vec3 v_normal;
    in highp vec3 v_viewpos;
    layout(location = 0) out highp vec4 FragColor;

    highp vec3 phong_light(highp vec3 v_pos_1, highp vec3 v_normal_1, highp vec3 viewpos, highp vec3 material_ambient, highp vec3 material_diffuse, highp vec3 material_specular, highp float shininess, highp vec4 tex_color)
    {
        highp vec3 _25 = normalize(v_normal_1);
        highp vec3 _41 = normalize(-dir_light[0].xyz);
        return (dir_light[3].xyz * pow(max(dot(normalize(viewpos - v_pos_1), reflect(-_41, _25)), 0.0), shininess)) * material_specular + (dir_light[1].xyz * material_ambient + ((dir_light[2].xyz * max(dot(_25, _41), 0.0)) * material_diffuse));
    }

    void main()
    {
        highp vec3 param = v_pos;
        highp vec3 param_1 = v_normal;
        highp vec3 param_2 = v_viewpos;
        highp vec3 param_3 = col_material[0].xyz;
        highp vec3 param_4 = col_material[1].xyz;
        highp vec3 param_5 = col_material[2].xyz;
        highp float param_6 = col_material[3].x;
        highp vec4 param_7 = vec4(1.0);
        FragColor = vec4(phong_light(param, param_1, param_2, param_3, param_4, param_5, param_6, param_7), 1.0);
    }

*/
static const uint8_t pk_phong_color_fs_source_glsl300es[1258] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x70,0x72,0x65,0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,0x6d,0x65,0x64,0x69,0x75,0x6d,
    0x70,0x20,0x66,0x6c,0x6f,0x61,0x74,0x3b,0x0a,0x70,0x72,0x65,0x63,0x69,0x73,0x69,
    0x6f,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x69,0x6e,0x74,0x3b,0x0a,0x0a,0x75,
    0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,
    0x34,0x20,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x34,0x5d,0x3b,0x0a,
    0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,
    0x63,0x34,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,
    0x34,0x5d,0x3b,0x0a,0x69,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,
    0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x69,0x6e,0x20,0x68,0x69,0x67,0x68,
    0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,
    0x0a,0x69,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,
    0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,
    0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,
    0x75,0x74,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x46,0x72,
    0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x68,0x69,0x67,0x68,0x70,0x20,
    0x76,0x65,0x63,0x33,0x20,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,
    0x28,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,0x6f,
    0x73,0x5f,0x31,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,
    0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x2c,0x20,0x68,0x69,0x67,0x68,
    0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x2c,0x20,
    0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,
    0x69,0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x68,0x69,0x67,
    0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,
    0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,
    0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,
    0x65,0x63,0x75,0x6c,0x61,0x72,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x2c,0x20,0x68,
    0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x74,0x65,0x78,0x5f,0x63,0x6f,
    0x6c,0x6f,0x72,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,
    0x20,0x76,0x65,0x63,0x33,0x20,0x5f,0x32,0x35,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x69,0x7a,0x65,0x28,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,
    0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,
    0x33,0x20,0x5f,0x34,0x31,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,
    0x65,0x28,0x2d,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x30,0x5d,0x2e,
    0x78,0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,
    0x20,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x33,0x5d,0x2e,0x78,
    0x79,0x7a,0x20,0x2a,0x20,0x70,0x6f,0x77,0x28,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,
    0x28,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x76,0x69,0x65,0x77,0x70,
    0x6f,0x73,0x20,0x2d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,0x31,0x29,0x2c,0x20,0x72,
    0x65,0x66,0x6c,0x65,0x63,0x74,0x28,0x2d,0x5f,0x34,0x31,0x2c,0x20,0x5f,0x32,0x35,
    0x29,0x29,0x2c,0x20,0x30,0x2e,0x30,0x29,0x2c,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,
    0x65,0x73,0x73,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,
    0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x20,0x2b,0x20,0x28,0x64,0x69,0x72,
    0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,
    0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,
    0x20,0x2b,0x20,0x28,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x32,
    0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,
    0x5f,0x32,0x35,0x2c,0x20,0x5f,0x34,0x31,0x29,0x2c,0x20,0x30,0x2e,0x30,0x29,0x29,
    0x20,0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,
    0x75,0x73,0x65,0x29,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,
    0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,
    0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x20,0x3d,0x20,0x76,
    0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,
    0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x20,0x3d,0x20,0x76,
    0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,
    0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,0x20,
    0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x33,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,
    0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,
    0x34,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,
    0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,
    0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,0x20,
    0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,0x32,
    0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x20,0x3d,
    0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,0x33,0x5d,
    0x2e,0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,
    0x63,0x34,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x37,0x20,0x3d,0x20,0x76,0x65,0x63,
    0x34,0x28,0x31,0x2e,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x46,0x72,0x61,0x67,
    0x43,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x76,0x65,0x63,0x34,0x28,0x70,0x68,0x6f,
    0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,0x28,0x70,0x61,0x72,0x61,0x6d,0x2c,0x20,
    0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,
    0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x33,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,
    0x5f,0x34,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,0x2c,0x20,0x70,0x61,0x72,
    0x61,0x6d,0x5f,0x36,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x37,0x29,0x2c,0x20,
    0x31,0x2e,0x30,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es

    uniform vec4 vs_params[13];
    layout(location = 0) in vec3 position;
    out vec3 v_pos;
    out vec3 v_normal;
    layout(location = 1) in vec3 normal;
    out vec2 v_uv;
    layout(location = 2) in vec2 uv;
    out vec3 v_viewpos;

    void main()
    {
        mat4 _30 = mat4(vs_params[8], vs_params[9], vs_params[10], vs_params[11]);
        vec4 _39 = vec4(position, 1.0);
        gl_Position = ((mat4(vs_params[4], vs_params[5], vs_params[6], vs_params[7]) * mat4(vs_params[0], vs_params[1], vs_params[2], vs_params[3])) * _30) * _39;
        v_pos = vec3((_30 * _39).xyz);
        v_normal = mat3(_30[0].xyz, _30[1].xyz, _30[2].xyz) * normal;
        v_uv = uv;
        v_viewpos = vs_params[12].xyz;
    }

*/
static const uint8_t pk_phong_tex_vs_source_glsl300es[668] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x76,0x65,0x63,0x34,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x33,0x5d,0x3b,0x0a,0x6c,0x61,0x79,
    0x6f,0x75,0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,
    0x29,0x20,0x69,0x6e,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,
    0x6f,0x73,0x3b,0x0a,0x6f,0x75,0x74,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,0x6f,
    0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x31,0x29,0x20,0x69,0x6e,0x20,0x76,
    0x65,0x63,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x6f,0x75,0x74,0x20,
    0x76,0x65,0x63,0x32,0x20,0x76,0x5f,0x75,0x76,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,
    0x74,0x28,0x6c,0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x32,0x29,0x20,
    0x69,0x6e,0x20,0x76,0x65,0x63,0x32,0x20,0x75,0x76,0x3b,0x0a,0x6f,0x75,0x74,0x20,
    0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,
    0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x6d,0x61,0x74,0x34,0x20,0x5f,0x33,0x30,0x20,0x3d,0x20,0x6d,0x61,
    0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x38,0x5d,0x2c,
    0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x39,0x5d,0x2c,0x20,0x76,
    0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x30,0x5d,0x2c,0x20,0x76,0x73,
    0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,0x31,0x5d,0x29,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x65,0x63,0x34,0x20,0x5f,0x33,0x39,0x20,0x3d,0x20,0x76,0x65,0x63,
    0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,0x29,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,
    0x6e,0x20,0x3d,0x20,0x28,0x28,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,
    0x72,0x61,0x6d,0x73,0x5b,0x34,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,
    0x6d,0x73,0x5b,0x35,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,
    0x5b,0x36,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x37,
    0x5d,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x34,0x28,0x76,0x73,0x5f,0x70,0x61,0x72,
    0x61,0x6d,0x73,0x5b,0x30,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x5b,0x31,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,
    0x32,0x5d,0x2c,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x33,0x5d,
    0x29,0x29,0x20,0x2a,0x20,0x5f,0x33,0x30,0x29,0x20,0x2a,0x20,0x5f,0x33,0x39,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x65,0x63,
    0x33,0x28,0x28,0x5f,0x33,0x30,0x20,0x2a,0x20,0x5f,0x33,0x39,0x29,0x2e,0x78,0x79,
    0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x20,0x3d,0x20,0x6d,0x61,0x74,0x33,0x28,0x5f,0x33,0x30,0x5b,0x30,0x5d,0x2e,0x78,
    0x79,0x7a,0x2c,0x20,0x5f,0x33,0x30,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x2c,0x20,
    0x5f,0x33,0x30,0x5b,0x32,0x5d,0x2e,0x78,0x79,0x7a,0x29,0x20,0x2a,0x20,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,
    0x20,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,
    0x6f,0x73,0x20,0x3d,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,0x73,0x5b,0x31,
    0x32,0x5d,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x7d,0x0a,0x0a,0x00,
};
/*
    #version 300 es
    precision mediump float;
    precision highp int;

    uniform highp vec4 dir_light[4];
    uniform highp vec4 tex_material[1];
    uniform highp sampler2D col_tex_col_smp;

    in highp vec2 v_uv;
    in highp vec3 v_pos;
    in highp vec3 v_normal;
    in highp vec3 v_viewpos;
    layout(location = 0) out highp vec4 FragColor;

    highp vec3 phong_light(highp vec3 v_pos_1, highp vec3 v_normal_1, highp vec3 viewpos, highp vec3 material_ambient, highp vec3 material_diffuse, highp vec3 material_specular, highp float shininess, highp vec4 tex_color)
    {
        highp vec3 _25 = normalize(v_normal_1);
        highp vec3 _41 = normalize(-dir_light[0].xyz);
        return (dir_light[3].xyz * pow(max(dot(normalize(viewpos - v_pos_1), reflect(-_41, _25)), 0.0), shininess)) * material_specular + (dir_light[1].xyz * material_ambient + ((dir_light[2].xyz * max(dot(_25, _41), 0.0)) * material_diffuse));
    }

    void main()
    {
        highp vec4 _108 = texture(col_tex_col_smp, v_uv);
        highp vec3 param = v_pos;
        highp vec3 param_1 = v_normal;
        highp vec3 param_2 = v_viewpos;
        highp vec3 _130 = _108.xyz;
        highp vec3 param_3 = _130;
        highp vec3 param_4 = _130;
        highp vec3 param_5 = vec3(_108.w);
        highp float param_6 = tex_material[0].x;
        highp vec4 param_7 = _108;
        FragColor = vec4(phong_light(param, param_1, param_2, param_3, param_4, param_5, param_6, param_7), 1.0);
    }

*/
static const uint8_t pk_phong_tex_fs_source_glsl300es[1364] = {
    0x23,0x76,0x65,0x72,0x73,0x69,0x6f,0x6e,0x20,0x33,0x30,0x30,0x20,0x65,0x73,0x0a,
    0x70,0x72,0x65,0x63,0x69,0x73,0x69,0x6f,0x6e,0x20,0x6d,0x65,0x64,0x69,0x75,0x6d,
    0x70,0x20,0x66,0x6c,0x6f,0x61,0x74,0x3b,0x0a,0x70,0x72,0x65,0x63,0x69,0x73,0x69,
    0x6f,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x69,0x6e,0x74,0x3b,0x0a,0x0a,0x75,
    0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,
    0x34,0x20,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x34,0x5d,0x3b,0x0a,
    0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,
    0x63,0x34,0x20,0x74,0x65,0x78,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,
    0x31,0x5d,0x3b,0x0a,0x75,0x6e,0x69,0x66,0x6f,0x72,0x6d,0x20,0x68,0x69,0x67,0x68,
    0x70,0x20,0x73,0x61,0x6d,0x70,0x6c,0x65,0x72,0x32,0x44,0x20,0x63,0x6f,0x6c,0x5f,
    0x74,0x65,0x78,0x5f,0x63,0x6f,0x6c,0x5f,0x73,0x6d,0x70,0x3b,0x0a,0x0a,0x69,0x6e,
    0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x32,0x20,0x76,0x5f,0x75,0x76,
    0x3b,0x0a,0x69,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x69,0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,
    0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x69,
    0x6e,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x6c,0x61,0x79,0x6f,0x75,0x74,0x28,0x6c,
    0x6f,0x63,0x61,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x30,0x29,0x20,0x6f,0x75,0x74,
    0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x46,0x72,0x61,0x67,
    0x43,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,
    0x63,0x33,0x20,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,0x28,0x68,
    0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,
    0x31,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x76,0x5f,
    0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,
    0x76,0x65,0x63,0x33,0x20,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x2c,0x20,0x68,0x69,
    0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,
    0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,
    0x20,0x76,0x65,0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x64,
    0x69,0x66,0x66,0x75,0x73,0x65,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,
    0x63,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,0x65,0x63,
    0x75,0x6c,0x61,0x72,0x2c,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x2c,0x20,0x68,0x69,0x67,
    0x68,0x70,0x20,0x76,0x65,0x63,0x34,0x20,0x74,0x65,0x78,0x5f,0x63,0x6f,0x6c,0x6f,
    0x72,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,
    0x65,0x63,0x33,0x20,0x5f,0x32,0x35,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x69,0x7a,0x65,0x28,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x29,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,
    0x5f,0x34,0x31,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,
    0x2d,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x30,0x5d,0x2e,0x78,0x79,
    0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x28,
    0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x33,0x5d,0x2e,0x78,0x79,0x7a,
    0x20,0x2a,0x20,0x70,0x6f,0x77,0x28,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x2d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,0x31,0x29,0x2c,0x20,0x72,0x65,0x66,
    0x6c,0x65,0x63,0x74,0x28,0x2d,0x5f,0x34,0x31,0x2c,0x20,0x5f,0x32,0x35,0x29,0x29,
    0x2c,0x20,0x30,0x2e,0x30,0x29,0x2c,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,
    0x73,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,
    0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x20,0x2b,0x20,0x28,0x64,0x69,0x72,0x5f,0x6c,
    0x69,0x67,0x68,0x74,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,0x6d,0x61,
    0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x20,0x2b,
    0x20,0x28,0x28,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,0x74,0x5b,0x32,0x5d,0x2e,
    0x78,0x79,0x7a,0x20,0x2a,0x20,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x5f,0x32,
    0x35,0x2c,0x20,0x5f,0x34,0x31,0x29,0x2c,0x20,0x30,0x2e,0x30,0x29,0x29,0x20,0x2a,
    0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,
    0x65,0x29,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x6d,0x61,0x69,
    0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,
    0x76,0x65,0x63,0x34,0x20,0x5f,0x31,0x30,0x38,0x20,0x3d,0x20,0x74,0x65,0x78,0x74,
    0x75,0x72,0x65,0x28,0x63,0x6f,0x6c,0x5f,0x74,0x65,0x78,0x5f,0x63,0x6f,0x6c,0x5f,
    0x73,0x6d,0x70,0x2c,0x20,0x76,0x5f,0x75,0x76,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,
    0x20,0x3d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,
    0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,
    0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x32,0x20,0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,
    0x5f,0x31,0x33,0x30,0x20,0x3d,0x20,0x5f,0x31,0x30,0x38,0x2e,0x78,0x79,0x7a,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,
    0x70,0x61,0x72,0x61,0x6d,0x5f,0x33,0x20,0x3d,0x20,0x5f,0x31,0x33,0x30,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,
    0x61,0x72,0x61,0x6d,0x5f,0x34,0x20,0x3d,0x20,0x5f,0x31,0x33,0x30,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,0x33,0x20,0x70,0x61,
    0x72,0x61,0x6d,0x5f,0x35,0x20,0x3d,0x20,0x76,0x65,0x63,0x33,0x28,0x5f,0x31,0x30,
    0x38,0x2e,0x77,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x20,0x3d,0x20,
    0x74,0x65,0x78,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5b,0x30,0x5d,0x2e,
    0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x68,0x69,0x67,0x68,0x70,0x20,0x76,0x65,0x63,
    0x34,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x37,0x20,0x3d,0x20,0x5f,0x31,0x30,0x38,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,
    0x3d,0x20,0x76,0x65,0x63,0x34,0x28,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,
    0x68,0x74,0x28,0x70,0x61,0x72,0x61,0x6d,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,
    0x31,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,0x2c,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x33,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x2c,0x20,0x70,0x61,
    0x72,0x61,0x6d,0x5f,0x35,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x2c,0x20,
    0x70,0x61,0x72,0x61,0x6d,0x5f,0x37,0x29,0x2c,0x20,0x31,0x2e,0x30,0x29,0x3b,0x0a,
    0x7d,0x0a,0x0a,0x00,
};
/*
    cbuffer bone_matrices : register(b0)
    {
        row_major float4x4 _28_bones[32] : packoffset(c0);
    };

    cbuffer vs_params : register(b1)
    {
        row_major float4x4 _134_view : packoffset(c0);
        row_major float4x4 _134_proj : packoffset(c4);
        row_major float4x4 _134_model : packoffset(c8);
        float3 _134_viewpos : packoffset(c12);
    };


    static float4 gl_Position;
    static uint4 bone_indices;
    static float4 weights;
    static float3 pos;
    static float3 nrm;
    static float3 v_pos;
    static float3 v_normal;
    static float2 v_uv;
    static float2 uv;
    static float3 v_viewpos;

    struct SPIRV_Cross_Input
    {
        float3 pos : TEXCOORD0;
        float3 nrm : TEXCOORD1;
        float2 uv : TEXCOORD2;
        uint4 bone_indices : TEXCOORD3;
        float4 weights : TEXCOORD4;
    };

    struct SPIRV_Cross_Output
    {
        float3 v_pos : TEXCOORD0;
        float3 v_normal : TEXCOORD1;
        float2 v_uv : TEXCOORD2;
        float3 v_viewpos : TEXCOORD3;
        float4 gl_Position : SV_Position;
    };

    void vert_main()
    {
        float4x4 _37 = _28_bones[bone_indices.x] * weights.x;
        float4x4 _45 = _28_bones[bone_indices.y] * weights.y;
        float4x4 _66 = _28_bones[bone_indices.z] * weights.z;
        float4x4 _87 = _28_bones[bone_indices.w] * weights.w;
        float4 _90 = ((_37[0] + _45[0]) + _66[0]) + _87[0];
        float4 _93 = ((_37[1] + _45[1]) + _66[1]) + _87[1];
        float4 _96 = ((_37[2] + _45[2]) + _66[2]) + _87[2];
        float4 _113 = mul(float4(pos, 1.0f), float4x4(_90, _93, _96, ((_37[3] + _45[3]) + _66[3]) + _87[3]));
        gl_Position = mul(_113, mul(_134_model, mul(_134_view, _134_proj)));
        v_pos = _113.xyz;
        v_normal = normalize(mul(nrm, float3x3(_90.xyz, _93.xyz, _96.xyz)));
        v_uv = uv;
        v_viewpos = _134_viewpos;
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        bone_indices = stage_input.bone_indices;
        weights = stage_input.weights;
        pos = stage_input.pos;
        nrm = stage_input.nrm;
        uv = stage_input.uv;
        vert_main();
        SPIRV_Cross_Output stage_output;
        stage_output.gl_Position = gl_Position;
        stage_output.v_pos = v_pos;
        stage_output.v_normal = v_normal;
        stage_output.v_uv = v_uv;
        stage_output.v_viewpos = v_viewpos;
        return stage_output;
    }
*/
static const uint8_t pk_skinned_vs_source_hlsl5[2160] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x6d,0x61,0x74,
    0x72,0x69,0x63,0x65,0x73,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,
    0x28,0x62,0x30,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,
    0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,
    0x38,0x5f,0x62,0x6f,0x6e,0x65,0x73,0x5b,0x33,0x32,0x5d,0x20,0x3a,0x20,0x70,0x61,
    0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x30,0x29,0x3b,0x0a,0x7d,0x3b,
    0x0a,0x0a,0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,
    0x61,0x6d,0x73,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,
    0x31,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,
    0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x31,0x33,0x34,
    0x5f,0x76,0x69,0x65,0x77,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,
    0x65,0x74,0x28,0x63,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,
    0x6d,0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,
    0x31,0x33,0x34,0x5f,0x70,0x72,0x6f,0x6a,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,
    0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x34,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,
    0x6f,0x77,0x5f,0x6d,0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,
    0x34,0x20,0x5f,0x31,0x33,0x34,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x20,0x3a,0x20,0x70,
    0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x38,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x5f,0x31,0x33,0x34,0x5f,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,
    0x73,0x65,0x74,0x28,0x63,0x31,0x32,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,
    0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,
    0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,
    0x20,0x75,0x69,0x6e,0x74,0x34,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,
    0x63,0x65,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x34,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,
    0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x6f,0x73,0x3b,0x0a,0x73,
    0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6e,0x72,0x6d,
    0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x73,
    0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,
    0x76,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,
    0x20,0x75,0x76,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x0a,0x73,
    0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,
    0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x70,0x6f,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,
    0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x20,0x6e,0x72,0x6d,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x31,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x75,0x76,0x20,
    0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x75,0x69,0x6e,0x74,0x34,0x20,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,
    0x63,0x65,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x33,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x77,0x65,0x69,0x67,
    0x68,0x74,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x34,0x3b,
    0x0a,0x7d,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,
    0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,
    0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x31,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,0x76,0x20,
    0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,
    0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x33,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,
    0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,0x53,0x56,0x5f,0x50,0x6f,0x73,0x69,0x74,
    0x69,0x6f,0x6e,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x76,0x65,
    0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x33,0x37,0x20,0x3d,0x20,0x5f,
    0x32,0x38,0x5f,0x62,0x6f,0x6e,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,
    0x64,0x69,0x63,0x65,0x73,0x2e,0x78,0x5d,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,
    0x74,0x73,0x2e,0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,
    0x78,0x34,0x20,0x5f,0x34,0x35,0x20,0x3d,0x20,0x5f,0x32,0x38,0x5f,0x62,0x6f,0x6e,
    0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,
    0x79,0x5d,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x2e,0x79,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x36,0x36,
    0x20,0x3d,0x20,0x5f,0x32,0x38,0x5f,0x62,0x6f,0x6e,0x65,0x73,0x5b,0x62,0x6f,0x6e,
    0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x2e,0x7a,0x5d,0x20,0x2a,0x20,0x77,
    0x65,0x69,0x67,0x68,0x74,0x73,0x2e,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x38,0x37,0x20,0x3d,0x20,0x5f,0x32,0x38,
    0x5f,0x62,0x6f,0x6e,0x65,0x73,0x5b,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,
    0x63,0x65,0x73,0x2e,0x77,0x5d,0x20,0x2a,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,
    0x2e,0x77,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,
    0x39,0x30,0x20,0x3d,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x30,0x5d,0x20,0x2b,0x20,
    0x5f,0x34,0x35,0x5b,0x30,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x30,0x5d,
    0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x30,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,0x39,0x33,0x20,0x3d,0x20,0x28,0x28,0x5f,
    0x33,0x37,0x5b,0x31,0x5d,0x20,0x2b,0x20,0x5f,0x34,0x35,0x5b,0x31,0x5d,0x29,0x20,
    0x2b,0x20,0x5f,0x36,0x36,0x5b,0x31,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,
    0x31,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,
    0x39,0x36,0x20,0x3d,0x20,0x28,0x28,0x5f,0x33,0x37,0x5b,0x32,0x5d,0x20,0x2b,0x20,
    0x5f,0x34,0x35,0x5b,0x32,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x36,0x36,0x5b,0x32,0x5d,
    0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,0x32,0x5d,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,0x31,0x31,0x33,0x20,0x3d,0x20,0x6d,0x75,
    0x6c,0x28,0x66,0x6c,0x6f,0x61,0x74,0x34,0x28,0x70,0x6f,0x73,0x2c,0x20,0x31,0x2e,
    0x30,0x66,0x29,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x28,0x5f,0x39,
    0x30,0x2c,0x20,0x5f,0x39,0x33,0x2c,0x20,0x5f,0x39,0x36,0x2c,0x20,0x28,0x28,0x5f,
    0x33,0x37,0x5b,0x33,0x5d,0x20,0x2b,0x20,0x5f,0x34,0x35,0x5b,0x33,0x5d,0x29,0x20,
    0x2b,0x20,0x5f,0x36,0x36,0x5b,0x33,0x5d,0x29,0x20,0x2b,0x20,0x5f,0x38,0x37,0x5b,
    0x33,0x5d,0x29,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,
    0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x31,0x31,0x33,
    0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x31,0x33,0x34,0x5f,0x6d,0x6f,0x64,0x65,0x6c,
    0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x31,0x33,0x34,0x5f,0x76,0x69,0x65,0x77,0x2c,
    0x20,0x5f,0x31,0x33,0x34,0x5f,0x70,0x72,0x6f,0x6a,0x29,0x29,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x5f,0x31,0x31,0x33,0x2e,
    0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x6d,0x75,
    0x6c,0x28,0x6e,0x72,0x6d,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x78,0x33,0x28,
    0x5f,0x39,0x30,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x5f,0x39,0x33,0x2e,0x78,0x79,0x7a,
    0x2c,0x20,0x5f,0x39,0x36,0x2e,0x78,0x79,0x7a,0x29,0x29,0x29,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3d,0x20,0x5f,0x31,0x33,
    0x34,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x7d,0x0a,0x0a,0x53,0x50,
    0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,
    0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,
    0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,
    0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x62,0x6f,0x6e,0x65,0x5f,
    0x69,0x6e,0x64,0x69,0x63,0x65,0x73,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,
    0x69,0x6e,0x70,0x75,0x74,0x2e,0x62,0x6f,0x6e,0x65,0x5f,0x69,0x6e,0x64,0x69,0x63,
    0x65,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x77,0x65,0x69,0x67,0x68,0x74,0x73,0x20,
    0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x77,0x65,
    0x69,0x67,0x68,0x74,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x70,0x6f,0x73,0x20,0x3d,
    0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x70,0x6f,0x73,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x6e,0x72,0x6d,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,
    0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x6e,0x72,0x6d,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x75,0x76,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,
    0x74,0x2e,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,
    0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x53,0x50,0x49,0x52,0x56,
    0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x67,0x6c,0x5f,
    0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x67,0x6c,0x5f,0x50,0x6f,
    0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,
    0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,
    0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,
    0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,
    0x6c,0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,
    0x5f,0x75,0x76,0x20,0x3d,0x20,0x76,0x5f,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,
    0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x73,
    0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,

};
/*
    cbuffer vs_params : register(b0)
    {
        row_major float4x4 _20_view : packoffset(c0);
        row_major float4x4 _20_proj : packoffset(c4);
        row_major float4x4 _20_model : packoffset(c8);
        float3 _20_viewpos : packoffset(c12);
    };


    static float4 gl_Position;
    static float3 position;

    struct SPIRV_Cross_Input
    {
        float3 position : TEXCOORD0;
    };

    struct SPIRV_Cross_Output
    {
        float4 gl_Position : SV_Position;
    };

    void vert_main()
    {
        gl_Position = mul(float4(position, 1.0f), mul(_20_model, mul(_20_view, _20_proj)));
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        position = stage_input.position;
        vert_main();
        SPIRV_Cross_Output stage_output;
        stage_output.gl_Position = gl_Position;
        return stage_output;
    }
*/
static const uint8_t pk_unlit_col_vs_source_hlsl5[749] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,0x6f,0x72,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,
    0x65,0x77,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,
    0x63,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,
    0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,
    0x70,0x72,0x6f,0x6a,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,
    0x74,0x28,0x63,0x34,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,
    0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,
    0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,
    0x66,0x73,0x65,0x74,0x28,0x63,0x38,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x31,
    0x32,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x0a,0x73,0x74,0x72,
    0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,
    0x49,0x6e,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,0x54,0x45,
    0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x73,0x74,0x72,
    0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,
    0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,
    0x3a,0x20,0x53,0x56,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x7d,
    0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,
    0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,
    0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x66,0x6c,0x6f,0x61,
    0x74,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,0x31,0x2e,0x30,
    0x66,0x29,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,
    0x6c,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x2c,
    0x20,0x5f,0x32,0x30,0x5f,0x70,0x72,0x6f,0x6a,0x29,0x29,0x29,0x3b,0x0a,0x7d,0x0a,
    0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,
    0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,
    0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,
    0x5f,0x69,0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x70,0x6f,
    0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,
    0x6e,0x70,0x75,0x74,0x2e,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,
    0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,
    0x70,0x75,0x74,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,
    0x75,0x74,0x70,0x75,0x74,0x2e,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,
    0x6e,0x20,0x3d,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,
    0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,
};
/*
    cbuffer color : register(b0)
    {
        float4 _12_col : packoffset(c0);
    };


    static float4 frag_color;

    struct SPIRV_Cross_Output
    {
        float4 frag_color : SV_Target0;
    };

    void frag_main()
    {
        frag_color = _12_col;
    }

    SPIRV_Cross_Output main()
    {
        frag_main();
        SPIRV_Cross_Output stage_output;
        stage_output.frag_color = frag_color;
        return stage_output;
    }
*/
static const uint8_t pk_unlit_col_fs_source_hlsl5[368] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3a,0x20,
    0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,0x31,0x32,0x5f,0x63,0x6f,
    0x6c,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,
    0x30,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,
    0x72,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,
    0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,
    0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3a,0x20,0x53,0x56,0x5f,0x54,0x61,0x72,0x67,0x65,
    0x74,0x30,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x66,0x72,0x61,
    0x67,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x5f,0x31,0x32,0x5f,
    0x63,0x6f,0x6c,0x3b,0x0a,0x7d,0x0a,0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,
    0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,
    0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x72,0x61,0x67,0x5f,0x6d,0x61,0x69,
    0x6e,0x28,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,
    0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,
    0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x66,0x72,0x61,0x67,0x5f,
    0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,
    0x6f,0x72,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x73,
    0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,

};
/*
    cbuffer vs_params : register(b0)
    {
        row_major float4x4 _20_view : packoffset(c0);
        row_major float4x4 _20_proj : packoffset(c4);
        row_major float4x4 _20_model : packoffset(c8);
        float3 _20_viewpos : packoffset(c12);
    };


    static float4 gl_Position;
    static float3 position;
    static float2 v_uv;
    static float2 uv;
    static float3 normal;

    struct SPIRV_Cross_Input
    {
        float3 position : TEXCOORD0;
        float3 normal : TEXCOORD1;
        float2 uv : TEXCOORD2;
    };

    struct SPIRV_Cross_Output
    {
        float2 v_uv : TEXCOORD0;
        float4 gl_Position : SV_Position;
    };

    void vert_main()
    {
        gl_Position = mul(float4(position, 1.0f), mul(_20_model, mul(_20_view, _20_proj)));
        v_uv = uv;
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        position = stage_input.position;
        uv = stage_input.uv;
        normal = stage_input.normal;
        vert_main();
        SPIRV_Cross_Output stage_output;
        stage_output.gl_Position = gl_Position;
        stage_output.v_uv = v_uv;
        return stage_output;
    }
*/
static const uint8_t pk_unlit_tex_vs_source_hlsl5[999] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,0x6f,0x72,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,
    0x65,0x77,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,
    0x63,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,
    0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,
    0x70,0x72,0x6f,0x6a,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,
    0x74,0x28,0x63,0x34,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,
    0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,
    0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,
    0x66,0x73,0x65,0x74,0x28,0x63,0x38,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x31,
    0x32,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,
    0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,0x76,0x3b,0x0a,
    0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x75,0x76,
    0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,
    0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,
    0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,
    0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,
    0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,
    0x52,0x44,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,
    0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,
    0x44,0x31,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x75,
    0x76,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,0x3b,0x0a,0x7d,
    0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,
    0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,0x76,0x20,0x3a,
    0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x20,0x3a,0x20,0x53,0x56,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,
    0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x76,0x65,0x72,0x74,0x5f,
    0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,
    0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x66,
    0x6c,0x6f,0x61,0x74,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,0x20,
    0x31,0x2e,0x30,0x66,0x29,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x6d,
    0x6f,0x64,0x65,0x6c,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x76,0x69,
    0x65,0x77,0x2c,0x20,0x5f,0x32,0x30,0x5f,0x70,0x72,0x6f,0x6a,0x29,0x29,0x29,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x75,0x76,0x3b,0x0a,
    0x7d,0x0a,0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,
    0x75,0x74,0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,0x49,0x52,0x56,
    0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,0x73,0x74,0x61,
    0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,
    0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x75,0x76,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,
    0x69,0x6e,0x70,0x75,0x74,0x2e,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,
    0x75,0x74,0x2e,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,
    0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,
    0x74,0x2e,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,
    0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,
    0x75,0x76,0x20,0x3d,0x20,0x76,0x5f,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,
    0x65,0x74,0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,
    0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,
};
/*
    Texture2D<float4> tex : register(t0);
    SamplerState smp : register(s0);

    static float2 v_uv;
    static float4 frag_color;

    struct SPIRV_Cross_Input
    {
        float2 v_uv : TEXCOORD0;
    };

    struct SPIRV_Cross_Output
    {
        float4 frag_color : SV_Target0;
    };

    void frag_main()
    {
        frag_color = tex.Sample(smp, v_uv);
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        v_uv = stage_input.v_uv;
        frag_main();
        SPIRV_Cross_Output stage_output;
        stage_output.frag_color = frag_color;
        return stage_output;
    }
*/
static const uint8_t pk_unlit_tex_fs_source_hlsl5[519] = {
    0x54,0x65,0x78,0x74,0x75,0x72,0x65,0x32,0x44,0x3c,0x66,0x6c,0x6f,0x61,0x74,0x34,
    0x3e,0x20,0x74,0x65,0x78,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,
    0x28,0x74,0x30,0x29,0x3b,0x0a,0x53,0x61,0x6d,0x70,0x6c,0x65,0x72,0x53,0x74,0x61,
    0x74,0x65,0x20,0x73,0x6d,0x70,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,
    0x72,0x28,0x73,0x30,0x29,0x3b,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,0x76,0x3b,0x0a,0x73,0x74,0x61,0x74,
    0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,
    0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,
    0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x0a,
    0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,
    0x76,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x7d,
    0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,
    0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x66,0x72,0x61,0x67,0x5f,0x63,
    0x6f,0x6c,0x6f,0x72,0x20,0x3a,0x20,0x53,0x56,0x5f,0x54,0x61,0x72,0x67,0x65,0x74,
    0x30,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x66,0x72,0x61,0x67,
    0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x72,
    0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x74,0x65,0x78,0x2e,0x53,
    0x61,0x6d,0x70,0x6c,0x65,0x28,0x73,0x6d,0x70,0x2c,0x20,0x76,0x5f,0x75,0x76,0x29,
    0x3b,0x0a,0x7d,0x0a,0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,
    0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,0x49,
    0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,0x73,
    0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,
    0x6e,0x70,0x75,0x74,0x2e,0x76,0x5f,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x72,0x61,0x67,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,
    0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,
    0x74,0x2e,0x66,0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x66,
    0x72,0x61,0x67,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,
    0x65,0x74,0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,
    0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,
};
/*
    cbuffer vs_params : register(b0)
    {
        row_major float4x4 _20_view : packoffset(c0);
        row_major float4x4 _20_proj : packoffset(c4);
        row_major float4x4 _20_model : packoffset(c8);
        float3 _20_viewpos : packoffset(c12);
    };


    static float4 gl_Position;
    static float3 position;
    static float3 v_pos;
    static float3 v_normal;
    static float3 normal;
    static float3 v_viewpos;
    static float2 uv;

    struct SPIRV_Cross_Input
    {
        float3 position : TEXCOORD0;
        float3 normal : TEXCOORD1;
        float2 uv : TEXCOORD2;
    };

    struct SPIRV_Cross_Output
    {
        float3 v_pos : TEXCOORD0;
        float3 v_normal : TEXCOORD1;
        float3 v_viewpos : TEXCOORD2;
        float4 gl_Position : SV_Position;
    };

    void vert_main()
    {
        float4 _39 = float4(position, 1.0f);
        gl_Position = mul(_39, mul(_20_model, mul(_20_view, _20_proj)));
        v_pos = float3(mul(_39, _20_model).xyz);
        v_normal = mul(normal, float3x3(_20_model[0].xyz, _20_model[1].xyz, _20_model[2].xyz));
        v_viewpos = _20_viewpos;
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        position = stage_input.position;
        normal = stage_input.normal;
        uv = stage_input.uv;
        vert_main();
        SPIRV_Cross_Output stage_output;
        stage_output.gl_Position = gl_Position;
        stage_output.v_pos = v_pos;
        stage_output.v_normal = v_normal;
        stage_output.v_viewpos = v_viewpos;
        return stage_output;
    }
*/
static const uint8_t pk_phong_color_vs_source_hlsl5[1370] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,0x6f,0x72,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,
    0x65,0x77,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,
    0x63,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,
    0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,
    0x70,0x72,0x6f,0x6a,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,
    0x74,0x28,0x63,0x34,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,
    0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,
    0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,
    0x66,0x73,0x65,0x74,0x28,0x63,0x38,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x31,
    0x32,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,
    0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,
    0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,
    0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x73,
    0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x32,0x20,0x75,0x76,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,
    0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,
    0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,
    0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,
    0x4f,0x52,0x44,0x31,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,
    0x20,0x75,0x76,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,0x3b,
    0x0a,0x7d,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,
    0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,
    0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x31,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,
    0x77,0x70,0x6f,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,
    0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,0x53,0x56,0x5f,0x50,0x6f,
    0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x76,0x6f,0x69,0x64,
    0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,0x33,0x39,0x20,0x3d,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x2c,
    0x20,0x31,0x2e,0x30,0x66,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,0x50,
    0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x33,
    0x39,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,
    0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x2c,0x20,
    0x5f,0x32,0x30,0x5f,0x70,0x72,0x6f,0x6a,0x29,0x29,0x29,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x28,
    0x6d,0x75,0x6c,0x28,0x5f,0x33,0x39,0x2c,0x20,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,
    0x65,0x6c,0x29,0x2e,0x78,0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,
    0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x6e,0x6f,0x72,
    0x6d,0x61,0x6c,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x78,0x33,0x28,0x5f,0x32,
    0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x2c,0x20,
    0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x5b,0x31,0x5d,0x2e,0x78,0x79,0x7a,
    0x2c,0x20,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x5b,0x32,0x5d,0x2e,0x78,
    0x79,0x7a,0x29,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,
    0x70,0x6f,0x73,0x20,0x3d,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,
    0x73,0x3b,0x0a,0x7d,0x0a,0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,
    0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,
    0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,
    0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,
    0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x6e,0x6f,0x72,
    0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x75,0x76,0x20,0x3d,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x75,0x76,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,
    0x75,0x74,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,
    0x75,0x74,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,
    0x74,0x70,0x75,0x74,0x2e,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,
    0x20,0x3d,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,
    0x2e,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,
    0x2e,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,
    0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,
    0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,
};
/*
    cbuffer dir_light : register(b0)
    {
        float3 light_direction : packoffset(c0);
        float4 light_ambient : packoffset(c1);
        float4 light_diffuse : packoffset(c2);
        float4 light_specular : packoffset(c3);
    };

    cbuffer col_material : register(b1)
    {
        float4 col_mat_ambient : packoffset(c0);
        float4 col_mat_diffuse : packoffset(c1);
        float4 col_mat_specular : packoffset(c2);
        float col_mat_shininess : packoffset(c3);
    };


    static float3 v_pos;
    static float3 v_normal;
    static float3 v_viewpos;
    static float4 FragColor;

    struct SPIRV_Cross_Input
    {
        float3 v_pos : TEXCOORD0;
        float3 v_normal : TEXCOORD1;
        float3 v_viewpos : TEXCOORD2;
    };

    struct SPIRV_Cross_Output
    {
        float4 FragColor : SV_Target0;
    };

    float3 phong_light(float3 v_pos_1, float3 v_normal_1, float3 viewpos, float3 material_ambient, float3 material_diffuse, float3 material_specular, float shininess, float4 tex_color)
    {
        float3 _25 = normalize(v_normal_1);
        float3 _41 = normalize(-light_direction);
        return mad(light_specular.xyz * pow(max(dot(normalize(viewpos - v_pos_1), reflect(-_41, _25)), 0.0f), shininess), material_specular, mad(light_ambient.xyz, material_ambient, (light_diffuse.xyz * max(dot(_25, _41), 0.0f)) * material_diffuse));
    }

    void frag_main()
    {
        float3 param = v_pos;
        float3 param_1 = v_normal;
        float3 param_2 = v_viewpos;
        float3 param_3 = col_mat_ambient.xyz;
        float3 param_4 = col_mat_diffuse.xyz;
        float3 param_5 = col_mat_specular.xyz;
        float param_6 = col_mat_shininess;
        float4 param_7 = 1.0f.xxxx;
        FragColor = float4(phong_light(param, param_1, param_2, param_3, param_4, param_5, param_6, param_7), 1.0f);
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        v_pos = stage_input.v_pos;
        v_normal = stage_input.v_normal;
        v_viewpos = stage_input.v_viewpos;
        frag_main();
        SPIRV_Cross_Output stage_output;
        stage_output.FragColor = FragColor;
        return stage_output;
    }
*/
static const uint8_t pk_phong_color_fs_source_hlsl5[1957] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,
    0x74,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6c,0x69,
    0x67,0x68,0x74,0x5f,0x64,0x69,0x72,0x65,0x63,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,
    0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x30,0x29,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x6c,0x69,0x67,0x68,0x74,
    0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,
    0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x31,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x34,0x20,0x6c,0x69,0x67,0x68,0x74,0x5f,0x64,0x69,0x66,0x66,
    0x75,0x73,0x65,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,
    0x28,0x63,0x32,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,
    0x20,0x6c,0x69,0x67,0x68,0x74,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x20,
    0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x33,0x29,
    0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x63,0x6f,
    0x6c,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x20,0x3a,0x20,0x72,0x65,0x67,
    0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x31,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x61,
    0x6d,0x62,0x69,0x65,0x6e,0x74,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,
    0x73,0x65,0x74,0x28,0x63,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x34,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x64,0x69,0x66,0x66,
    0x75,0x73,0x65,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,
    0x28,0x63,0x31,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,
    0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,
    0x72,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,
    0x32,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x20,0x63,0x6f,
    0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x20,
    0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x33,0x29,
    0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,
    0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x73,0x74,0x61,
    0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x46,0x72,0x61,0x67,0x43,
    0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,
    0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x0a,
    0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,
    0x6f,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,
    0x6d,0x61,0x6c,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x31,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x76,0x69,
    0x65,0x77,0x70,0x6f,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,
    0x32,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,
    0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x46,0x72,
    0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,0x3a,0x20,0x53,0x56,0x5f,0x54,0x61,0x72,
    0x67,0x65,0x74,0x30,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x20,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,0x28,0x66,0x6c,0x6f,
    0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,0x31,0x2c,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x2c,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x2c,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,
    0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,
    0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,
    0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,
    0x6c,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x2c,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x2c,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x34,0x20,0x74,0x65,0x78,0x5f,0x63,0x6f,0x6c,0x6f,0x72,0x29,0x0a,0x7b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x5f,0x32,0x35,0x20,
    0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x76,0x5f,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x5f,0x31,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x33,0x20,0x5f,0x34,0x31,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x69,0x7a,0x65,0x28,0x2d,0x6c,0x69,0x67,0x68,0x74,0x5f,0x64,0x69,0x72,0x65,0x63,
    0x74,0x69,0x6f,0x6e,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,
    0x6e,0x20,0x6d,0x61,0x64,0x28,0x6c,0x69,0x67,0x68,0x74,0x5f,0x73,0x70,0x65,0x63,
    0x75,0x6c,0x61,0x72,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,0x70,0x6f,0x77,0x28,0x6d,
    0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,
    0x28,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x2d,0x20,0x76,0x5f,0x70,0x6f,0x73,
    0x5f,0x31,0x29,0x2c,0x20,0x72,0x65,0x66,0x6c,0x65,0x63,0x74,0x28,0x2d,0x5f,0x34,
    0x31,0x2c,0x20,0x5f,0x32,0x35,0x29,0x29,0x2c,0x20,0x30,0x2e,0x30,0x66,0x29,0x2c,
    0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x29,0x2c,0x20,0x6d,0x61,0x74,
    0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x2c,0x20,
    0x6d,0x61,0x64,0x28,0x6c,0x69,0x67,0x68,0x74,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,
    0x74,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,
    0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,0x20,0x28,0x6c,0x69,0x67,0x68,0x74,0x5f,
    0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2e,0x78,0x79,0x7a,0x20,0x2a,0x20,0x6d,0x61,
    0x78,0x28,0x64,0x6f,0x74,0x28,0x5f,0x32,0x35,0x2c,0x20,0x5f,0x34,0x31,0x29,0x2c,
    0x20,0x30,0x2e,0x30,0x66,0x29,0x29,0x20,0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,
    0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x29,0x29,0x3b,0x0a,0x7d,0x0a,
    0x0a,0x76,0x6f,0x69,0x64,0x20,0x66,0x72,0x61,0x67,0x5f,0x6d,0x61,0x69,0x6e,0x28,
    0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,
    0x61,0x72,0x61,0x6d,0x20,0x3d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,
    0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,0x20,
    0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x33,0x20,
    0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,
    0x74,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x5f,
    0x6d,0x61,0x74,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2e,0x78,0x79,0x7a,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,0x61,
    0x6d,0x5f,0x35,0x20,0x3d,0x20,0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x73,0x70,
    0x65,0x63,0x75,0x6c,0x61,0x72,0x2e,0x78,0x79,0x7a,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x20,0x3d,0x20,
    0x63,0x6f,0x6c,0x5f,0x6d,0x61,0x74,0x5f,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,
    0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x70,0x61,
    0x72,0x61,0x6d,0x5f,0x37,0x20,0x3d,0x20,0x31,0x2e,0x30,0x66,0x2e,0x78,0x78,0x78,
    0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,
    0x20,0x3d,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x28,0x70,0x68,0x6f,0x6e,0x67,0x5f,
    0x6c,0x69,0x67,0x68,0x74,0x28,0x70,0x61,0x72,0x61,0x6d,0x2c,0x20,0x70,0x61,0x72,
    0x61,0x6d,0x5f,0x31,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,0x2c,0x20,0x70,
    0x61,0x72,0x61,0x6d,0x5f,0x33,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x2c,
    0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,
    0x36,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x37,0x29,0x2c,0x20,0x31,0x2e,0x30,
    0x66,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,
    0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,
    0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,
    0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,
    0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x76,0x5f,0x6e,0x6f,0x72,0x6d,
    0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,
    0x73,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,
    0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x72,0x61,0x67,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,
    0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,
    0x74,0x2e,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x46,0x72,
    0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x65,0x74,
    0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,
    0x3b,0x0a,0x7d,0x0a,0x00,
};
/*
    cbuffer vs_params : register(b0)
    {
        row_major float4x4 _20_view : packoffset(c0);
        row_major float4x4 _20_proj : packoffset(c4);
        row_major float4x4 _20_model : packoffset(c8);
        float3 _20_viewpos : packoffset(c12);
    };


    static float4 gl_Position;
    static float3 position;
    static float3 v_pos;
    static float3 v_normal;
    static float3 normal;
    static float2 v_uv;
    static float2 uv;
    static float3 v_viewpos;

    struct SPIRV_Cross_Input
    {
        float3 position : TEXCOORD0;
        float3 normal : TEXCOORD1;
        float2 uv : TEXCOORD2;
    };

    struct SPIRV_Cross_Output
    {
        float3 v_pos : TEXCOORD0;
        float3 v_normal : TEXCOORD1;
        float2 v_uv : TEXCOORD2;
        float3 v_viewpos : TEXCOORD3;
        float4 gl_Position : SV_Position;
    };

    void vert_main()
    {
        float4 _39 = float4(position, 1.0f);
        gl_Position = mul(_39, mul(_20_model, mul(_20_view, _20_proj)));
        v_pos = float3(mul(_39, _20_model).xyz);
        v_normal = mul(normal, float3x3(_20_model[0].xyz, _20_model[1].xyz, _20_model[2].xyz));
        v_uv = uv;
        v_viewpos = _20_viewpos;
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        position = stage_input.position;
        normal = stage_input.normal;
        uv = stage_input.uv;
        vert_main();
        SPIRV_Cross_Output stage_output;
        stage_output.gl_Position = gl_Position;
        stage_output.v_pos = v_pos;
        stage_output.v_normal = v_normal;
        stage_output.v_uv = v_uv;
        stage_output.v_viewpos = v_viewpos;
        return stage_output;
    }
*/
static const uint8_t pk_phong_tex_vs_source_hlsl5[1464] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x76,0x73,0x5f,0x70,0x61,0x72,0x61,0x6d,
    0x73,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,0x6f,0x72,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,
    0x65,0x77,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,
    0x63,0x30,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,0x61,0x6a,
    0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,0x30,0x5f,
    0x70,0x72,0x6f,0x6a,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,
    0x74,0x28,0x63,0x34,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x72,0x6f,0x77,0x5f,0x6d,
    0x61,0x6a,0x6f,0x72,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x78,0x34,0x20,0x5f,0x32,
    0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,
    0x66,0x73,0x65,0x74,0x28,0x63,0x38,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x31,
    0x32,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x73,0x74,0x61,0x74,
    0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,
    0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,
    0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x73,
    0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,
    0x76,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,
    0x20,0x75,0x76,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x0a,0x73,
    0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,
    0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,
    0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x33,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3a,0x20,0x54,
    0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x31,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x32,0x20,0x75,0x76,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,
    0x52,0x44,0x32,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,
    0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,
    0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,
    0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,
    0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,
    0x44,0x31,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,
    0x5f,0x75,0x76,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x76,0x69,
    0x65,0x77,0x70,0x6f,0x73,0x20,0x3a,0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,
    0x33,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x67,0x6c,
    0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,0x53,0x56,0x5f,0x50,
    0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x76,0x6f,0x69,
    0x64,0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,0x33,0x39,0x20,0x3d,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x28,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,
    0x2c,0x20,0x31,0x2e,0x30,0x66,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x67,0x6c,0x5f,
    0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x5f,
    0x33,0x39,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,
    0x6c,0x2c,0x20,0x6d,0x75,0x6c,0x28,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x2c,
    0x20,0x5f,0x32,0x30,0x5f,0x70,0x72,0x6f,0x6a,0x29,0x29,0x29,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x28,0x6d,0x75,0x6c,0x28,0x5f,0x33,0x39,0x2c,0x20,0x5f,0x32,0x30,0x5f,0x6d,0x6f,
    0x64,0x65,0x6c,0x29,0x2e,0x78,0x79,0x7a,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,
    0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x6d,0x75,0x6c,0x28,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x78,0x33,0x28,0x5f,
    0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x5b,0x30,0x5d,0x2e,0x78,0x79,0x7a,0x2c,
    0x20,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x5b,0x31,0x5d,0x2e,0x78,0x79,
    0x7a,0x2c,0x20,0x5f,0x32,0x30,0x5f,0x6d,0x6f,0x64,0x65,0x6c,0x5b,0x32,0x5d,0x2e,
    0x78,0x79,0x7a,0x29,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,0x20,
    0x3d,0x20,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,
    0x70,0x6f,0x73,0x20,0x3d,0x20,0x5f,0x32,0x30,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,
    0x73,0x3b,0x0a,0x7d,0x0a,0x0a,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,
    0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,
    0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,
    0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,
    0x20,0x20,0x20,0x70,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x20,0x3d,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x70,0x6f,0x73,0x69,0x74,0x69,
    0x6f,0x6e,0x3b,0x0a,0x20,0x20,0x20,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,
    0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x6e,0x6f,0x72,
    0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x75,0x76,0x20,0x3d,0x20,0x73,0x74,
    0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x75,0x76,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x76,0x65,0x72,0x74,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,
    0x75,0x74,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,
    0x75,0x74,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,
    0x74,0x70,0x75,0x74,0x2e,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,
    0x20,0x3d,0x20,0x67,0x6c,0x5f,0x50,0x6f,0x73,0x69,0x74,0x69,0x6f,0x6e,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,
    0x2e,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,0x70,0x75,0x74,
    0x2e,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,
    0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,0x75,0x76,0x20,0x3d,0x20,0x76,0x5f,
    0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,
    0x74,0x70,0x75,0x74,0x2e,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3d,
    0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,0x74,
    0x70,0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,
};
/*
    cbuffer dir_light : register(b0)
    {
        float3 light_direction : packoffset(c0);
        float4 light_ambient : packoffset(c1);
        float4 light_diffuse : packoffset(c2);
        float4 light_specular : packoffset(c3);
    };

    cbuffer tex_material : register(b1)
    {
        float tex_mat_shininess : packoffset(c0);
    };

    Texture2D<float4> col_tex : register(t0);
    SamplerState col_smp : register(s0);

    static float2 v_uv;
    static float3 v_pos;
    static float3 v_normal;
    static float3 v_viewpos;
    static float4 FragColor;

    struct SPIRV_Cross_Input
    {
        float3 v_pos : TEXCOORD0;
        float3 v_normal : TEXCOORD1;
        float2 v_uv : TEXCOORD2;
        float3 v_viewpos : TEXCOORD3;
    };

    struct SPIRV_Cross_Output
    {
        float4 FragColor : SV_Target0;
    };

    float3 phong_light(float3 v_pos_1, float3 v_normal_1, float3 viewpos, float3 material_ambient, float3 material_diffuse, float3 material_specular, float shininess, float4 tex_color)
    {
        float3 _25 = normalize(v_normal_1);
        float3 _41 = normalize(-light_direction);
        return mad(light_specular.xyz * pow(max(dot(normalize(viewpos - v_pos_1), reflect(-_41, _25)), 0.0f), shininess), material_specular, mad(light_ambient.xyz, material_ambient, (light_diffuse.xyz * max(dot(_25, _41), 0.0f)) * material_diffuse));
    }

    void frag_main()
    {
        float4 _108 = col_tex.Sample(col_smp, v_uv);
        float3 param = v_pos;
        float3 param_1 = v_normal;
        float3 param_2 = v_viewpos;
        float3 _130 = _108.xyz;
        float3 param_3 = _130;
        float3 param_4 = _130;
        float3 param_5 = _108.w.xxx;
        float param_6 = tex_mat_shininess;
        float4 param_7 = _108;
        FragColor = float4(phong_light(param, param_1, param_2, param_3, param_4, param_5, param_6, param_7), 1.0f);
    }

    SPIRV_Cross_Output main(SPIRV_Cross_Input stage_input)
    {
        v_uv = stage_input.v_uv;
        v_pos = stage_input.v_pos;
        v_normal = stage_input.v_normal;
        v_viewpos = stage_input.v_viewpos;
        frag_main();
        SPIRV_Cross_Output stage_output;
        stage_output.FragColor = FragColor;
        return stage_output;
    }
*/
static const uint8_t pk_phong_tex_fs_source_hlsl5[2010] = {
    0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x64,0x69,0x72,0x5f,0x6c,0x69,0x67,0x68,
    0x74,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x30,0x29,
    0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6c,0x69,
    0x67,0x68,0x74,0x5f,0x64,0x69,0x72,0x65,0x63,0x74,0x69,0x6f,0x6e,0x20,0x3a,0x20,
    0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x30,0x29,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x6c,0x69,0x67,0x68,0x74,
    0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,
    0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x31,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x34,0x20,0x6c,0x69,0x67,0x68,0x74,0x5f,0x64,0x69,0x66,0x66,
    0x75,0x73,0x65,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,
    0x28,0x63,0x32,0x29,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,
    0x20,0x6c,0x69,0x67,0x68,0x74,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x20,
    0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,0x66,0x73,0x65,0x74,0x28,0x63,0x33,0x29,
    0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x63,0x62,0x75,0x66,0x66,0x65,0x72,0x20,0x74,0x65,
    0x78,0x5f,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x20,0x3a,0x20,0x72,0x65,0x67,
    0x69,0x73,0x74,0x65,0x72,0x28,0x62,0x31,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x20,0x74,0x65,0x78,0x5f,0x6d,0x61,0x74,0x5f,0x73,0x68,
    0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x20,0x3a,0x20,0x70,0x61,0x63,0x6b,0x6f,0x66,
    0x66,0x73,0x65,0x74,0x28,0x63,0x30,0x29,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x54,0x65,
    0x78,0x74,0x75,0x72,0x65,0x32,0x44,0x3c,0x66,0x6c,0x6f,0x61,0x74,0x34,0x3e,0x20,
    0x63,0x6f,0x6c,0x5f,0x74,0x65,0x78,0x20,0x3a,0x20,0x72,0x65,0x67,0x69,0x73,0x74,
    0x65,0x72,0x28,0x74,0x30,0x29,0x3b,0x0a,0x53,0x61,0x6d,0x70,0x6c,0x65,0x72,0x53,
    0x74,0x61,0x74,0x65,0x20,0x63,0x6f,0x6c,0x5f,0x73,0x6d,0x70,0x20,0x3a,0x20,0x72,
    0x65,0x67,0x69,0x73,0x74,0x65,0x72,0x28,0x73,0x30,0x29,0x3b,0x0a,0x0a,0x73,0x74,
    0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,0x76,
    0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,
    0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x73,
    0x74,0x61,0x74,0x69,0x63,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,0x73,0x74,0x61,0x74,0x69,0x63,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x34,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x3b,
    0x0a,0x0a,0x73,0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,
    0x72,0x6f,0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3a,0x20,
    0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x20,0x3a,
    0x20,0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x31,0x3b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x32,0x20,0x76,0x5f,0x75,0x76,0x20,0x3a,0x20,0x54,0x45,
    0x58,0x43,0x4f,0x4f,0x52,0x44,0x32,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x33,0x20,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3a,0x20,
    0x54,0x45,0x58,0x43,0x4f,0x4f,0x52,0x44,0x33,0x3b,0x0a,0x7d,0x3b,0x0a,0x0a,0x73,
    0x74,0x72,0x75,0x63,0x74,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,
    0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,
    0x6c,0x6f,0x61,0x74,0x34,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,
    0x3a,0x20,0x53,0x56,0x5f,0x54,0x61,0x72,0x67,0x65,0x74,0x30,0x3b,0x0a,0x7d,0x3b,
    0x0a,0x0a,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,
    0x69,0x67,0x68,0x74,0x28,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x70,0x6f,
    0x73,0x5f,0x31,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,0x5f,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x5f,0x31,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6d,
    0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,
    0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,
    0x61,0x72,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,
    0x65,0x73,0x73,0x2c,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x74,0x65,0x78,0x5f,
    0x63,0x6f,0x6c,0x6f,0x72,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x33,0x20,0x5f,0x32,0x35,0x20,0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x69,0x7a,0x65,0x28,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x5f,0x31,0x29,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x5f,0x34,0x31,0x20,
    0x3d,0x20,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x2d,0x6c,0x69,0x67,
    0x68,0x74,0x5f,0x64,0x69,0x72,0x65,0x63,0x74,0x69,0x6f,0x6e,0x29,0x3b,0x0a,0x20,
    0x20,0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x6d,0x61,0x64,0x28,0x6c,0x69,
    0x67,0x68,0x74,0x5f,0x73,0x70,0x65,0x63,0x75,0x6c,0x61,0x72,0x2e,0x78,0x79,0x7a,
    0x20,0x2a,0x20,0x70,0x6f,0x77,0x28,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x6e,
    0x6f,0x72,0x6d,0x61,0x6c,0x69,0x7a,0x65,0x28,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,
    0x20,0x2d,0x20,0x76,0x5f,0x70,0x6f,0x73,0x5f,0x31,0x29,0x2c,0x20,0x72,0x65,0x66,
    0x6c,0x65,0x63,0x74,0x28,0x2d,0x5f,0x34,0x31,0x2c,0x20,0x5f,0x32,0x35,0x29,0x29,
    0x2c,0x20,0x30,0x2e,0x30,0x66,0x29,0x2c,0x20,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,
    0x73,0x73,0x29,0x2c,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x73,0x70,
    0x65,0x63,0x75,0x6c,0x61,0x72,0x2c,0x20,0x6d,0x61,0x64,0x28,0x6c,0x69,0x67,0x68,
    0x74,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2e,0x78,0x79,0x7a,0x2c,0x20,0x6d,
    0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x61,0x6d,0x62,0x69,0x65,0x6e,0x74,0x2c,
    0x20,0x28,0x6c,0x69,0x67,0x68,0x74,0x5f,0x64,0x69,0x66,0x66,0x75,0x73,0x65,0x2e,
    0x78,0x79,0x7a,0x20,0x2a,0x20,0x6d,0x61,0x78,0x28,0x64,0x6f,0x74,0x28,0x5f,0x32,
    0x35,0x2c,0x20,0x5f,0x34,0x31,0x29,0x2c,0x20,0x30,0x2e,0x30,0x66,0x29,0x29,0x20,
    0x2a,0x20,0x6d,0x61,0x74,0x65,0x72,0x69,0x61,0x6c,0x5f,0x64,0x69,0x66,0x66,0x75,
    0x73,0x65,0x29,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x76,0x6f,0x69,0x64,0x20,0x66,0x72,
    0x61,0x67,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,
    0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x5f,0x31,0x30,0x38,0x20,0x3d,0x20,0x63,0x6f,
    0x6c,0x5f,0x74,0x65,0x78,0x2e,0x53,0x61,0x6d,0x70,0x6c,0x65,0x28,0x63,0x6f,0x6c,
    0x5f,0x73,0x6d,0x70,0x2c,0x20,0x76,0x5f,0x75,0x76,0x29,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x20,0x3d,0x20,
    0x76,0x5f,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x20,0x3d,0x20,0x76,0x5f,0x6e,0x6f,
    0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x32,0x20,0x3d,0x20,0x76,0x5f,0x76,0x69,0x65,
    0x77,0x70,0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,
    0x20,0x5f,0x31,0x33,0x30,0x20,0x3d,0x20,0x5f,0x31,0x30,0x38,0x2e,0x78,0x79,0x7a,
    0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,
    0x61,0x6d,0x5f,0x33,0x20,0x3d,0x20,0x5f,0x31,0x33,0x30,0x3b,0x0a,0x20,0x20,0x20,
    0x20,0x66,0x6c,0x6f,0x61,0x74,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x20,
    0x3d,0x20,0x5f,0x31,0x33,0x30,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,
    0x74,0x33,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,0x20,0x3d,0x20,0x5f,0x31,0x30,
    0x38,0x2e,0x77,0x2e,0x78,0x78,0x78,0x3b,0x0a,0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,
    0x61,0x74,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x20,0x3d,0x20,0x74,0x65,0x78,
    0x5f,0x6d,0x61,0x74,0x5f,0x73,0x68,0x69,0x6e,0x69,0x6e,0x65,0x73,0x73,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x6c,0x6f,0x61,0x74,0x34,0x20,0x70,0x61,0x72,0x61,0x6d,
    0x5f,0x37,0x20,0x3d,0x20,0x5f,0x31,0x30,0x38,0x3b,0x0a,0x20,0x20,0x20,0x20,0x46,
    0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x20,0x3d,0x20,0x66,0x6c,0x6f,0x61,0x74,
    0x34,0x28,0x70,0x68,0x6f,0x6e,0x67,0x5f,0x6c,0x69,0x67,0x68,0x74,0x28,0x70,0x61,
    0x72,0x61,0x6d,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x31,0x2c,0x20,0x70,0x61,
    0x72,0x61,0x6d,0x5f,0x32,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x33,0x2c,0x20,
    0x70,0x61,0x72,0x61,0x6d,0x5f,0x34,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x35,
    0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,0x5f,0x36,0x2c,0x20,0x70,0x61,0x72,0x61,0x6d,
    0x5f,0x37,0x29,0x2c,0x20,0x31,0x2e,0x30,0x66,0x29,0x3b,0x0a,0x7d,0x0a,0x0a,0x53,
    0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,0x5f,0x4f,0x75,0x74,0x70,0x75,
    0x74,0x20,0x6d,0x61,0x69,0x6e,0x28,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,
    0x73,0x73,0x5f,0x49,0x6e,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,
    0x6e,0x70,0x75,0x74,0x29,0x0a,0x7b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x75,0x76,
    0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x76,
    0x5f,0x75,0x76,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x70,0x6f,0x73,0x20,0x3d,
    0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x76,0x5f,0x70,
    0x6f,0x73,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,
    0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,0x6e,0x70,0x75,0x74,0x2e,0x76,
    0x5f,0x6e,0x6f,0x72,0x6d,0x61,0x6c,0x3b,0x0a,0x20,0x20,0x20,0x20,0x76,0x5f,0x76,
    0x69,0x65,0x77,0x70,0x6f,0x73,0x20,0x3d,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x69,
    0x6e,0x70,0x75,0x74,0x2e,0x76,0x5f,0x76,0x69,0x65,0x77,0x70,0x6f,0x73,0x3b,0x0a,
    0x20,0x20,0x20,0x20,0x66,0x72,0x61,0x67,0x5f,0x6d,0x61,0x69,0x6e,0x28,0x29,0x3b,
    0x0a,0x20,0x20,0x20,0x20,0x53,0x50,0x49,0x52,0x56,0x5f,0x43,0x72,0x6f,0x73,0x73,
    0x5f,0x4f,0x75,0x74,0x70,0x75,0x74,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,0x75,
    0x74,0x70,0x75,0x74,0x3b,0x0a,0x20,0x20,0x20,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,
    0x6f,0x75,0x74,0x70,0x75,0x74,0x2e,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,
    0x20,0x3d,0x20,0x46,0x72,0x61,0x67,0x43,0x6f,0x6c,0x6f,0x72,0x3b,0x0a,0x20,0x20,
    0x20,0x20,0x72,0x65,0x74,0x75,0x72,0x6e,0x20,0x73,0x74,0x61,0x67,0x65,0x5f,0x6f,
    0x75,0x74,0x70,0x75,0x74,0x3b,0x0a,0x7d,0x0a,0x00,
};
const sg_shader_desc* pk_phong_color_shader_desc(sg_backend backend) {
    if (backend == SG_BACKEND_GLCORE) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_phong_color_vs_source_glsl430;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_color_fs_source_glsl430;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.attrs[1].glsl_name = "normal";
            desc.attrs[2].glsl_name = "uv";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 64;
            desc.uniform_blocks[2].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[2].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[2].glsl_uniforms[0].glsl_name = "col_material";
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[3].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[3].glsl_uniforms[0].glsl_name = "dir_light";
            desc.label = "pk_phong_color_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_GLES3) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_phong_color_vs_source_glsl300es;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_color_fs_source_glsl300es;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.attrs[1].glsl_name = "normal";
            desc.attrs[2].glsl_name = "uv";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 64;
            desc.uniform_blocks[2].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[2].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[2].glsl_uniforms[0].glsl_name = "col_material";
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[3].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[3].glsl_uniforms[0].glsl_name = "dir_light";
            desc.label = "pk_phong_color_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_D3D11) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_phong_color_vs_source_hlsl5;
            desc.vertex_func.d3d11_target = "vs_5_0";
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_color_fs_source_hlsl5;
            desc.fragment_func.d3d11_target = "ps_5_0";
            desc.fragment_func.entry = "main";
            desc.attrs[0].hlsl_sem_name = "TEXCOORD";
            desc.attrs[0].hlsl_sem_index = 0;
            desc.attrs[1].hlsl_sem_name = "TEXCOORD";
            desc.attrs[1].hlsl_sem_index = 1;
            desc.attrs[2].hlsl_sem_name = "TEXCOORD";
            desc.attrs[2].hlsl_sem_index = 2;
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].hlsl_register_b_n = 0;
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 64;
            desc.uniform_blocks[2].hlsl_register_b_n = 1;
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].hlsl_register_b_n = 0;
            desc.label = "pk_phong_color_shader";
        }
        return &desc;
    }
    return 0;
}
const sg_shader_desc* pk_phong_tex_shader_desc(sg_backend backend) {
    if (backend == SG_BACKEND_GLCORE) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_phong_tex_vs_source_glsl430;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_tex_fs_source_glsl430;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.attrs[1].glsl_name = "normal";
            desc.attrs[2].glsl_name = "uv";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 16;
            desc.uniform_blocks[2].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[2].glsl_uniforms[0].array_count = 1;
            desc.uniform_blocks[2].glsl_uniforms[0].glsl_name = "tex_material";
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[3].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[3].glsl_uniforms[0].glsl_name = "dir_light";
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.image_sampler_pairs[0].glsl_name = "col_tex_col_smp";
            desc.label = "pk_phong_tex_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_GLES3) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_phong_tex_vs_source_glsl300es;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_tex_fs_source_glsl300es;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.attrs[1].glsl_name = "normal";
            desc.attrs[2].glsl_name = "uv";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 16;
            desc.uniform_blocks[2].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[2].glsl_uniforms[0].array_count = 1;
            desc.uniform_blocks[2].glsl_uniforms[0].glsl_name = "tex_material";
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[3].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[3].glsl_uniforms[0].glsl_name = "dir_light";
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.image_sampler_pairs[0].glsl_name = "col_tex_col_smp";
            desc.label = "pk_phong_tex_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_D3D11) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_phong_tex_vs_source_hlsl5;
            desc.vertex_func.d3d11_target = "vs_5_0";
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_tex_fs_source_hlsl5;
            desc.fragment_func.d3d11_target = "ps_5_0";
            desc.fragment_func.entry = "main";
            desc.attrs[0].hlsl_sem_name = "TEXCOORD";
            desc.attrs[0].hlsl_sem_index = 0;
            desc.attrs[1].hlsl_sem_name = "TEXCOORD";
            desc.attrs[1].hlsl_sem_index = 1;
            desc.attrs[2].hlsl_sem_name = "TEXCOORD";
            desc.attrs[2].hlsl_sem_index = 2;
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].hlsl_register_b_n = 0;
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 16;
            desc.uniform_blocks[2].hlsl_register_b_n = 1;
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].hlsl_register_b_n = 0;
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.images[0].hlsl_register_t_n = 0;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.samplers[0].hlsl_register_s_n = 0;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.label = "pk_phong_tex_shader";
        }
        return &desc;
    }
    return 0;
}
const sg_shader_desc* pk_skinned_phong_tex_shader_desc(sg_backend backend) {
    if (backend == SG_BACKEND_GLCORE) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_skinned_vs_source_glsl430;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_tex_fs_source_glsl430;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "pos";
            desc.attrs[1].glsl_name = "nrm";
            desc.attrs[2].glsl_name = "uv";
            desc.attrs[3].glsl_name = "bone_indices";
            desc.attrs[4].glsl_name = "weights";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[1].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[1].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[1].size = 2048;
            desc.uniform_blocks[1].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[1].glsl_uniforms[0].array_count = 128;
            desc.uniform_blocks[1].glsl_uniforms[0].glsl_name = "bone_matrices";
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 16;
            desc.uniform_blocks[2].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[2].glsl_uniforms[0].array_count = 1;
            desc.uniform_blocks[2].glsl_uniforms[0].glsl_name = "tex_material";
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[3].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[3].glsl_uniforms[0].glsl_name = "dir_light";
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.image_sampler_pairs[0].glsl_name = "col_tex_col_smp";
            desc.label = "pk_skinned_phong_tex_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_GLES3) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_skinned_vs_source_glsl300es;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_tex_fs_source_glsl300es;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "pos";
            desc.attrs[1].glsl_name = "nrm";
            desc.attrs[2].glsl_name = "uv";
            desc.attrs[3].glsl_name = "bone_indices";
            desc.attrs[4].glsl_name = "weights";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[1].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[1].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[1].size = 2048;
            desc.uniform_blocks[1].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[1].glsl_uniforms[0].array_count = 128;
            desc.uniform_blocks[1].glsl_uniforms[0].glsl_name = "bone_matrices";
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 16;
            desc.uniform_blocks[2].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[2].glsl_uniforms[0].array_count = 1;
            desc.uniform_blocks[2].glsl_uniforms[0].glsl_name = "tex_material";
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[3].glsl_uniforms[0].array_count = 4;
            desc.uniform_blocks[3].glsl_uniforms[0].glsl_name = "dir_light";
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.image_sampler_pairs[0].glsl_name = "col_tex_col_smp";
            desc.label = "pk_skinned_phong_tex_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_D3D11) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_skinned_vs_source_hlsl5;
            desc.vertex_func.d3d11_target = "vs_5_0";
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_phong_tex_fs_source_hlsl5;
            desc.fragment_func.d3d11_target = "ps_5_0";
            desc.fragment_func.entry = "main";
            desc.attrs[0].hlsl_sem_name = "TEXCOORD";
            desc.attrs[0].hlsl_sem_index = 0;
            desc.attrs[1].hlsl_sem_name = "TEXCOORD";
            desc.attrs[1].hlsl_sem_index = 1;
            desc.attrs[2].hlsl_sem_name = "TEXCOORD";
            desc.attrs[2].hlsl_sem_index = 2;
            desc.attrs[3].hlsl_sem_name = "TEXCOORD";
            desc.attrs[3].hlsl_sem_index = 3;
            desc.attrs[4].hlsl_sem_name = "TEXCOORD";
            desc.attrs[4].hlsl_sem_index = 4;
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].hlsl_register_b_n = 1;
            desc.uniform_blocks[1].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[1].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[1].size = 2048;
            desc.uniform_blocks[1].hlsl_register_b_n = 0;
            desc.uniform_blocks[2].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[2].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[2].size = 16;
            desc.uniform_blocks[2].hlsl_register_b_n = 1;
            desc.uniform_blocks[3].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[3].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[3].size = 64;
            desc.uniform_blocks[3].hlsl_register_b_n = 0;
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.images[0].hlsl_register_t_n = 0;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.samplers[0].hlsl_register_s_n = 0;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.label = "pk_skinned_phong_tex_shader";
        }
        return &desc;
    }
    return 0;
}
const sg_shader_desc* pk_unlit_color_shader_desc(sg_backend backend) {
    if (backend == SG_BACKEND_GLCORE) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_unlit_col_vs_source_glsl430;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_unlit_col_fs_source_glsl430;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[1].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[1].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[1].size = 16;
            desc.uniform_blocks[1].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[1].glsl_uniforms[0].array_count = 1;
            desc.uniform_blocks[1].glsl_uniforms[0].glsl_name = "color";
            desc.label = "pk_unlit_color_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_GLES3) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_unlit_col_vs_source_glsl300es;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_unlit_col_fs_source_glsl300es;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.uniform_blocks[1].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[1].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[1].size = 16;
            desc.uniform_blocks[1].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[1].glsl_uniforms[0].array_count = 1;
            desc.uniform_blocks[1].glsl_uniforms[0].glsl_name = "color";
            desc.label = "pk_unlit_color_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_D3D11) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_unlit_col_vs_source_hlsl5;
            desc.vertex_func.d3d11_target = "vs_5_0";
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_unlit_col_fs_source_hlsl5;
            desc.fragment_func.d3d11_target = "ps_5_0";
            desc.fragment_func.entry = "main";
            desc.attrs[0].hlsl_sem_name = "TEXCOORD";
            desc.attrs[0].hlsl_sem_index = 0;
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].hlsl_register_b_n = 0;
            desc.uniform_blocks[1].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.uniform_blocks[1].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[1].size = 16;
            desc.uniform_blocks[1].hlsl_register_b_n = 0;
            desc.label = "pk_unlit_color_shader";
        }
        return &desc;
    }
    return 0;
}
const sg_shader_desc* pk_unlit_tex_shader_desc(sg_backend backend) {
    if (backend == SG_BACKEND_GLCORE) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_unlit_tex_vs_source_glsl430;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_unlit_tex_fs_source_glsl430;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.attrs[1].glsl_name = "normal";
            desc.attrs[2].glsl_name = "uv";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.image_sampler_pairs[0].glsl_name = "tex_smp";
            desc.label = "pk_unlit_tex_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_GLES3) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_unlit_tex_vs_source_glsl300es;
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_unlit_tex_fs_source_glsl300es;
            desc.fragment_func.entry = "main";
            desc.attrs[0].glsl_name = "position";
            desc.attrs[1].glsl_name = "normal";
            desc.attrs[2].glsl_name = "uv";
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].glsl_uniforms[0].type = SG_UNIFORMTYPE_FLOAT4;
            desc.uniform_blocks[0].glsl_uniforms[0].array_count = 13;
            desc.uniform_blocks[0].glsl_uniforms[0].glsl_name = "vs_params";
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.image_sampler_pairs[0].glsl_name = "tex_smp";
            desc.label = "pk_unlit_tex_shader";
        }
        return &desc;
    }
    if (backend == SG_BACKEND_D3D11) {
        static sg_shader_desc desc;
        static bool valid;
        if (!valid) {
            valid = true;
            desc.vertex_func.source = (const char*)pk_unlit_tex_vs_source_hlsl5;
            desc.vertex_func.d3d11_target = "vs_5_0";
            desc.vertex_func.entry = "main";
            desc.fragment_func.source = (const char*)pk_unlit_tex_fs_source_hlsl5;
            desc.fragment_func.d3d11_target = "ps_5_0";
            desc.fragment_func.entry = "main";
            desc.attrs[0].hlsl_sem_name = "TEXCOORD";
            desc.attrs[0].hlsl_sem_index = 0;
            desc.attrs[1].hlsl_sem_name = "TEXCOORD";
            desc.attrs[1].hlsl_sem_index = 1;
            desc.attrs[2].hlsl_sem_name = "TEXCOORD";
            desc.attrs[2].hlsl_sem_index = 2;
            desc.uniform_blocks[0].stage = SG_SHADERSTAGE_VERTEX;
            desc.uniform_blocks[0].layout = SG_UNIFORMLAYOUT_STD140;
            desc.uniform_blocks[0].size = 208;
            desc.uniform_blocks[0].hlsl_register_b_n = 0;
            desc.images[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.images[0].image_type = SG_IMAGETYPE_2D;
            desc.images[0].sample_type = SG_IMAGESAMPLETYPE_FLOAT;
            desc.images[0].multisampled = false;
            desc.images[0].hlsl_register_t_n = 0;
            desc.samplers[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.samplers[0].sampler_type = SG_SAMPLERTYPE_FILTERING;
            desc.samplers[0].hlsl_register_s_n = 0;
            desc.image_sampler_pairs[0].stage = SG_SHADERSTAGE_FRAGMENT;
            desc.image_sampler_pairs[0].image_slot = 0;
            desc.image_sampler_pairs[0].sampler_slot = 0;
            desc.label = "pk_unlit_tex_shader";
        }
        return &desc;
    }
    return 0;
}
#endif // SOKOL_SHDC_IMPL//FILE_END

//FILE_START:deps/cute_png.h
/*
	------------------------------------------------------------------------------
		Licensing information can be found at the end of the file.
	------------------------------------------------------------------------------

	cute_png.h - v1.05

	To create implementation (the function definitions)
		#define CUTE_PNG_IMPLEMENTATION
	in *one* C/CPP file (translation unit) that includes this file


	SUMMARY:

		This header wraps some very nice functions by Richard Mitton from his
		tigr (Tiny Graphics) library, with some additional features and small
		bug-fixes.


	Revision history:
		1.00 (12/23/2016) initial release
		1.01 (03/08/2017) tRNS chunk support for paletted images
		1.02 (10/23/2017) support for explicitly loading paletted png images
		1.03 (11/12/2017) construct atlas in memory
		1.04 (08/23/2018) various bug fixes for filter and word decoder
		                  added `cp_load_blank`
		1.05 (11/10/2022) added `cp_save_png_to_memory`


	EXAMPLES:

		Loading a PNG from disk, then freeing it
			cp_image_t img = cp_load_png("images/pic.png");
			...
			free(img.pix);
			CUTE_PNG_MEMSET(&img, 0, sizeof(img));

		Loading a PNG from memory, then freeing it
			cp_image_t img = cp_load_png_mem(memory, sizeof(memory));
			...
			free(img.pix);
			CUTE_PNG_MEMSET(&img, 0, sizeof(img));

		Saving a PNG to disk
			cp_save_png("images/example.png", &img);
			// img is just a raw RGBA buffer, and can come from anywhere,
			// not only from cp_load*** functions

		Creating a texture atlas in memory
			int w = 1024;
			int h = 1024;
			cp_atlas_image_t* imgs_out = (cp_atlas_image_t*)malloc(sizeof(cp_atlas_image_t) * my_png_count);
			cp_image_t atlas_img = cp_make_atlas(w, int h, my_png_array, my_png_count, imgs_out);
			// just pass an array of pointers to images along with the image count. Make sure to also
			// provide an array of `cp_atlas_image_t` for `cp_make_atlas` to output important UV info for the
			// images that fit into the atlas.

		Using the default atlas saver
			int errors = cp_default_save_atlas("atlas.png", "atlas.txt", atlas_img, atlas_imgs, img_count, names_of_all_images ? names_of_all_images : 0);
			if (errors) { ... }
			// Atlas info (like uv coordinates) are in "atlas.txt", and the image was writen to "atlas.png".
			// atlas_imgs was an array of `cp_atlas_image_t` from the `cp_make_atlas` function.

		Inflating a DEFLATE block (decompressing memory stored in DEFLATE format)
			cp_inflate(in, in_bytes, out, out_bytes);
			// this function requires knowledge of the un-compressed size
			// does *not* do any internal realloc! Will return errors if an
			// attempt to overwrite the out buffer is made

	CUSTOMIZATION

		There are various macros in this header you can customize by defining them before
		including cute_png.h. Simply define one to override the default behavior.

			CUTE_PNG_ALLOCA
			CUTE_PNG_ALLOC
			CUTE_PNG_FREE
			CUTE_PNG_CALLOC
			CUTE_PNG_REALLOC
			CUTE_PNG_MEMCPY
			CUTE_PNG_MEMCMP
			CUTE_PNG_MEMSET
			CUTE_PNG_ASSERT
			CUTE_PNG_FPRINTF
			CUTE_PNG_SEEK_SET
			CUTE_PNG_SEEK_END
			CUTE_PNG_FILE
			CUTE_PNG_FOPEN
			CUTE_PNG_FSEEK
			CUTE_PNG_FREAD
			CUTE_PNG_FTELL
			CUTE_PNG_FWRITE
			CUTE_PNG_FCLOSE
			CUTE_PNG_FERROR
			CUTE_PNG_ATLAS_MUST_FIT
			CUTE_PNG_ATLAS_FLIP_Y_AXIS_FOR_UV
			CUTE_PNG_ATLAS_EMPTY_COLOR
*/

/*
	Contributors:
		Zachary Carter    1.01 - bug catch for tRNS chunk in paletted images
		Dennis Korpel     1.03 - fix some pointer/memory related bugs
		Dennis Korpel     1.04 - fix for filter on first row of pixels
*/

#if !defined(CUTE_PNG_H)

#ifdef _WIN32
	#if !defined(_CRT_SECURE_NO_WARNINGS)
		#define _CRT_SECURE_NO_WARNINGS
	#endif
#endif

#ifndef CUTE_PNG_ATLAS_MUST_FIT
	#define CUTE_PNG_ATLAS_MUST_FIT            1 // returns error from cp_make_atlas if *any* input image does not fit
#endif // CUTE_PNG_ATLAS_MUST_FIT

#ifndef CUTE_PNG_ATLAS_FLIP_Y_AXIS_FOR_UV
	#define CUTE_PNG_ATLAS_FLIP_Y_AXIS_FOR_UV  1 // flips output uv coordinate's y. Can be useful to "flip image on load"
#endif // CUTE_PNG_ATLAS_FLIP_Y_AXIS_FOR_UV

#ifndef CUTE_PNG_ATLAS_EMPTY_COLOR
	#define CUTE_PNG_ATLAS_EMPTY_COLOR         0x000000FF // the fill color for empty areas in a texture atlas (RGBA)
#endif // CUTE_PNG_ATLAS_EMPTY_COLOR

#include <stdint.h>
#include <limits.h>

typedef struct cp_pixel_t cp_pixel_t;
typedef struct cp_image_t cp_image_t;
typedef struct cp_indexed_image_t cp_indexed_image_t;
typedef struct cp_atlas_image_t cp_atlas_image_t;

// Read this in the event of errors from any function
extern const char* cp_error_reason;

// return 1 for success, 0 for failures
int cp_inflate(void* in, int in_bytes, void* out, int out_bytes);
int cp_save_png(const char* file_name, const cp_image_t* img);

typedef struct cp_saved_png_t
{
	int size;   // Size of the `data` buffer.
	void* data; // Pointer to the saved png in memory.
	            // NULL if something went wrong.
	            // Call CUTE_PNG_FREE on `data` when done.
} cp_saved_png_t;

// Saves a png file to memory.
// Call CUTE_PNG_FREE on .data when done.
cp_saved_png_t cp_save_png_to_memory(const cp_image_t* img);

// Constructs an atlas image in-memory. The atlas pixels are stored in the returned image. free the pixels
// when done with them. The user must provide an array of cp_atlas_image_t for the `imgs` param. `imgs` holds
// information about uv coordinates for an associated image in the `pngs` array. Output image has NULL
// pixels buffer in the event of errors.
cp_image_t cp_make_atlas(int atlasWidth, int atlasHeight, const cp_image_t* pngs, int png_count, cp_atlas_image_t* imgs_out);

// A decent "default" function, ready to use out-of-the-box. Saves out an easy to parse text formatted info file
// along with an atlas image. `names` param can be optionally NULL.
int cp_default_save_atlas(const char* out_path_image, const char* out_path_atlas_txt, const cp_image_t* atlas, const cp_atlas_image_t* imgs, int img_count, const char** names);

// these two functions return cp_image_t::pix as 0 in event of errors
// call free on cp_image_t::pix when done, or call cp_free_png
cp_image_t cp_load_png(const char *file_name);
cp_image_t cp_load_png_mem(const void *png_data, int png_length);
cp_image_t cp_load_blank(int w, int h); // Alloc's pixels, but `pix` memory is uninitialized.
void cp_free_png(cp_image_t* img);
void cp_flip_image_horizontal(cp_image_t* img);

// Reads the w/h of the png without doing any other decompression or parsing.
void cp_load_png_wh(const void* png_data, int png_length, int* w, int* h);

// loads indexed (paletted) pngs, but does not depalette the image into RGBA pixels
// these two functions return cp_indexed_image_t::pix as 0 in event of errors
// call free on cp_indexed_image_t::pix when done, or call cp_free_indexed_png
cp_indexed_image_t cp_load_indexed_png(const char* file_name);
cp_indexed_image_t cp_load_indexed_png_mem(const void *png_data, int png_length);
void cp_free_indexed_png(cp_indexed_image_t* img);

// converts paletted image into a standard RGBA image
// call free on cp_image_t::pix when done
cp_image_t cp_depallete_indexed_image(cp_indexed_image_t* img);

// Pre-process the pixels to transform the image data to a premultiplied alpha format.
// Resource: http://www.essentialmath.com/GDC2015/VanVerth_Jim_DoingMathwRGB.pdf
void cp_premultiply(cp_image_t* img);

struct cp_pixel_t
{
	uint8_t r;
	uint8_t g;
	uint8_t b;
	uint8_t a;
};

struct cp_image_t
{
	int w;
	int h;
	cp_pixel_t* pix;
};

struct cp_indexed_image_t
{
	int w;
	int h;
	uint8_t* pix;
	uint8_t palette_len;
	cp_pixel_t palette[256];
};

struct cp_atlas_image_t
{
	int img_index;    // index into the `imgs` array
	int w, h;         // pixel w/h of original image
	float minx, miny; // u coordinate
	float maxx, maxy; // v coordinate
	int fit;          // non-zero if image fit and was placed into the atlas
};

#define CUTE_PNG_H
#endif

#ifdef CUTE_PNG_IMPLEMENTATION
#ifndef CUTE_PNG_IMPLEMENTATION_ONCE
#define CUTE_PNG_IMPLEMENTATION_ONCE

#if !defined(CUTE_PNG_ALLOCA)
	#define CUTE_PNG_ALLOCA alloca

	#ifdef _WIN32
		#include <malloc.h>
	#elif defined(__linux__)
		#include <alloca.h>
	#endif
#endif

#if !defined(CUTE_PNG_ALLOC)
	#include <stdlib.h>
	#define CUTE_PNG_ALLOC malloc
#endif

#if !defined(CUTE_PNG_FREE)
	#include <stdlib.h>
	#define CUTE_PNG_FREE free
#endif

#if !defined(CUTE_PNG_CALLOC)
	#include <stdlib.h>
	#define CUTE_PNG_CALLOC calloc
#endif

#if !defined(CUTE_PNG_REALLOC)
	#include <stdlib.h>
	#define CUTE_PNG_REALLOC realloc
#endif

#if !defined(CUTE_PNG_MEMCPY)
	#include <string.h>
	#define CUTE_PNG_MEMCPY memcpy
#endif

#if !defined(CUTE_PNG_MEMCMP)
	#include <string.h>
	#define CUTE_PNG_MEMCMP memcmp
#endif

#if !defined(CUTE_PNG_MEMSET)
	#include <string.h>
	#define CUTE_PNG_MEMSET memset
#endif

#if !defined(CUTE_PNG_ASSERT)
	#include <assert.h>
	#define CUTE_PNG_ASSERT assert
#endif

#if !defined(CUTE_PNG_FPRINTF)
	#include <stdio.h>
	#define CUTE_PNG_FPRINTF fprintf
#endif

#if !defined(CUTE_PNG_SEEK_SET)
	#include <stdio.h>
	#define CUTE_PNG_SEEK_SET SEEK_SET
#endif

#if !defined(CUTE_PNG_SEEK_END)
	#include <stdio.h>
	#define CUTE_PNG_SEEK_END SEEK_END
#endif

#if !defined(CUTE_PNG_FILE)
	#include <stdio.h>
	#define CUTE_PNG_FILE FILE
#endif

#if !defined(CUTE_PNG_FOPEN)
	#include <stdio.h>
	#define CUTE_PNG_FOPEN fopen
#endif

#if !defined(CUTE_PNG_FSEEK)
	#include <stdio.h>
	#define CUTE_PNG_FSEEK fseek
#endif

#if !defined(CUTE_PNG_FREAD)
	#include <stdio.h>
	#define CUTE_PNG_FREAD fread
#endif

#if !defined(CUTE_PNG_FTELL)
	#include <stdio.h>
	#define CUTE_PNG_FTELL ftell
#endif

#if !defined(CUTE_PNG_FWRITE)
	#include <stdio.h>
	#define CUTE_PNG_FWRITE fwrite
#endif

#if !defined(CUTE_PNG_FCLOSE)
	#include <stdio.h>
	#define CUTE_PNG_FCLOSE fclose
#endif

#if !defined(CUTE_PNG_FERROR)
	#include <stdio.h>
	#define CUTE_PNG_FERROR ferror
#endif

static cp_pixel_t cp_make_pixel_a(uint8_t r, uint8_t g, uint8_t b, uint8_t a)
{
	cp_pixel_t p;
	p.r = r; p.g = g; p.b = b; p.a = a;
	return p;
}

static cp_pixel_t cp_make_pixel(uint8_t r, uint8_t g, uint8_t b)
{
	cp_pixel_t p;
	p.r = r; p.g = g; p.b = b; p.a = 0xFF;
	return p;
}

const char* cp_error_reason;
#define CUTE_PNG_FAIL() do { goto cp_err; } while (0)
#define CUTE_PNG_CHECK(X, Y) do { if (!(X)) { cp_error_reason = Y; CUTE_PNG_FAIL(); } } while (0)
#define CUTE_PNG_CALL(X) do { if (!(X)) goto cp_err; } while (0)
#define CUTE_PNG_LOOKUP_BITS 9
#define CUTE_PNG_LOOKUP_COUNT (1 << CUTE_PNG_LOOKUP_BITS)
#define CUTE_PNG_LOOKUP_MASK (CUTE_PNG_LOOKUP_COUNT - 1)
#define CUTE_PNG_DEFLATE_MAX_BITLEN 15

// DEFLATE tables from RFC 1951
uint8_t cp_fixed_table[288 + 32] = {
	8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,
	8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,
	8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,
	9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,
	7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,
}; // 3.2.6
uint8_t cp_permutation_order[19] = { 16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15 }; // 3.2.7
uint8_t cp_len_extra_bits[29 + 2] = { 0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,  0,0 }; // 3.2.5
uint32_t cp_len_base[29 + 2] = { 3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,  0,0 }; // 3.2.5
uint8_t cp_dist_extra_bits[30 + 2] = { 0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,  0,0 }; // 3.2.5
uint32_t cp_dist_base[30 + 2] = { 1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577, 0,0 }; // 3.2.5

typedef struct cp_state_t
{
	uint64_t bits;
	int count;
	uint32_t* words;
	int word_count;
	int word_index;
	int bits_left;

	int final_word_available;
	uint32_t final_word;

	char* out;
	char* out_end;
	char* begin;

	uint16_t lookup[CUTE_PNG_LOOKUP_COUNT];
	uint32_t lit[288];
	uint32_t dst[32];
	uint32_t len[19];
	uint32_t nlit;
	uint32_t ndst;
	uint32_t nlen;
} cp_state_t;

static int cp_would_overflow(cp_state_t* s, int num_bits)
{
	return (s->bits_left + s->count) - num_bits < 0;
}

static char* cp_ptr(cp_state_t* s)
{
	CUTE_PNG_ASSERT(!(s->bits_left & 7));
	return (char*)(s->words + s->word_index) - (s->count / 8);
}

static uint64_t cp_peak_bits(cp_state_t* s, int num_bits_to_read)
{
	if (s->count < num_bits_to_read)
	{
		if (s->word_index < s->word_count)
		{
			uint32_t word = s->words[s->word_index++];
			s->bits |= (uint64_t)word << s->count;
			s->count += 32;
			CUTE_PNG_ASSERT(s->word_index <= s->word_count);
		}

		else if (s->final_word_available)
		{
			uint32_t word = s->final_word;
			s->bits |= (uint64_t)word << s->count;
			s->count += s->bits_left;
			s->final_word_available = 0;
		}
	}

	return s->bits;
}

static uint32_t cp_consume_bits(cp_state_t* s, int num_bits_to_read)
{
	CUTE_PNG_ASSERT(s->count >= num_bits_to_read);
	uint32_t bits = s->bits & (((uint64_t)1 << num_bits_to_read) - 1);
	s->bits >>= num_bits_to_read;
	s->count -= num_bits_to_read;
	s->bits_left -= num_bits_to_read;
	return bits;
}

static uint32_t cp_read_bits(cp_state_t* s, int num_bits_to_read)
{
	CUTE_PNG_ASSERT(num_bits_to_read <= 32);
	CUTE_PNG_ASSERT(num_bits_to_read >= 0);
	CUTE_PNG_ASSERT(s->bits_left > 0);
	CUTE_PNG_ASSERT(s->count <= 64);
	CUTE_PNG_ASSERT(!cp_would_overflow(s, num_bits_to_read));
	cp_peak_bits(s, num_bits_to_read);
	uint32_t bits = cp_consume_bits(s, num_bits_to_read);
	return bits;
}

static char* cp_read_file_to_memory(const char* path, int* size)
{
	char* data = 0;
	CUTE_PNG_FILE* fp = CUTE_PNG_FOPEN(path, "rb");
	int sizeNum = 0;

	if (fp)
	{
		CUTE_PNG_FSEEK(fp, 0, CUTE_PNG_SEEK_END);
		sizeNum = CUTE_PNG_FTELL(fp);
		CUTE_PNG_FSEEK(fp, 0, CUTE_PNG_SEEK_SET);
		data = (char*)CUTE_PNG_ALLOC(sizeNum + 1);
		CUTE_PNG_FREAD(data, sizeNum, 1, fp);
		data[sizeNum] = 0;
		CUTE_PNG_FCLOSE(fp);
	}

	if (size) *size = sizeNum;
	return data;
}

static uint32_t cp_rev16(uint32_t a)
{
	a = ((a & 0xAAAA) >>  1) | ((a & 0x5555) << 1);
	a = ((a & 0xCCCC) >>  2) | ((a & 0x3333) << 2);
	a = ((a & 0xF0F0) >>  4) | ((a & 0x0F0F) << 4);
	a = ((a & 0xFF00) >>  8) | ((a & 0x00FF) << 8);
	return a;
}

// RFC 1951 section 3.2.2
static int cp_build(cp_state_t* s, uint32_t* tree, uint8_t* lens, int sym_count)
{
	int n, codes[16], first[16], counts[16] = { 0 };

	// Frequency count
	for (n = 0; n < sym_count; n++) counts[lens[n]]++;

	// Distribute codes
	counts[0] = codes[0] = first[0] = 0;
	for (n = 1; n <= 15; ++n)
	{
		codes[n] = (codes[n - 1] + counts[n - 1]) << 1;
		first[n] = first[n - 1] + counts[n - 1];
	}

	if (s) CUTE_PNG_MEMSET(s->lookup, 0, sizeof(s->lookup));
	for (int i = 0; i < sym_count; ++i)
	{
		int len = lens[i];

		if (len != 0)
		{
			CUTE_PNG_ASSERT(len < 16);
			uint32_t code = codes[len]++;
			uint32_t slot = first[len]++;
			tree[slot] = (code << (32 - len)) | (i << 4) | len;

			if (s && len <= CUTE_PNG_LOOKUP_BITS)
			{
				int j = cp_rev16(code) >> (16 - len);
				while (j < (1 << CUTE_PNG_LOOKUP_BITS))
				{
					s->lookup[j] = (uint16_t)((len << CUTE_PNG_LOOKUP_BITS) | i);
					j += (1 << len);
				}
			}
		}
	}

	int max_index = first[15];
	return max_index;
}

static int cp_stored(cp_state_t* s)
{
	char* p;

	// 3.2.3
	// skip any remaining bits in current partially processed byte
	cp_read_bits(s, s->count & 7);

	// 3.2.4
	// read LEN and NLEN, should complement each other
	uint16_t LEN = (uint16_t)cp_read_bits(s, 16);
	uint16_t NLEN = (uint16_t)cp_read_bits(s, 16);
	CUTE_PNG_CHECK(LEN == (uint16_t)(~NLEN), "Failed to find LEN and NLEN as complements within stored (uncompressed) stream.");
	CUTE_PNG_CHECK(s->bits_left / 8 <= (int)LEN, "Stored block extends beyond end of input stream.");
	p = cp_ptr(s);
	CUTE_PNG_MEMCPY(s->out, p, LEN);
	s->out += LEN;
	return 1;

cp_err:
	return 0;
}

// 3.2.6
static int cp_fixed(cp_state_t* s)
{
	s->nlit = cp_build(s, s->lit, cp_fixed_table, 288);
	s->ndst = cp_build(0, s->dst, cp_fixed_table + 288, 32);
	return 1;
}

static int cp_decode(cp_state_t* s, uint32_t* tree, int hi)
{
	uint64_t bits = cp_peak_bits(s, 16);
	uint32_t search = (cp_rev16((uint32_t)bits) << 16) | 0xFFFF;
	int lo = 0;
	while (lo < hi)
	{
		int guess = (lo + hi) >> 1;
		if (search < tree[guess]) hi = guess;
		else lo = guess + 1;
	}

	uint32_t key = tree[lo - 1];
	uint32_t len = (32 - (key & 0xF));
	CUTE_PNG_ASSERT((search >> len) == (key >> len));

	int code = cp_consume_bits(s, key & 0xF);
	(void)code;
	return (key >> 4) & 0xFFF;
}

// 3.2.7
static int cp_dynamic(cp_state_t* s)
{
	uint8_t lenlens[19] = { 0 };

	int nlit = 257 + cp_read_bits(s, 5);
	int ndst = 1 + cp_read_bits(s, 5);
	int nlen = 4 + cp_read_bits(s, 4);

	for (int i = 0 ; i < nlen; ++i)
		lenlens[cp_permutation_order[i]] = (uint8_t)cp_read_bits(s, 3);

	// Build the tree for decoding code lengths
	s->nlen = cp_build(0, s->len, lenlens, 19);
	uint8_t lens[288 + 32];

	for (int n = 0; n < nlit + ndst;)
	{
		int sym = cp_decode(s, s->len, s->nlen);
		switch (sym)
		{
		case 16: for (int i =  3 + cp_read_bits(s, 2); i; --i, ++n) lens[n] = lens[n - 1]; break;
		case 17: for (int i =  3 + cp_read_bits(s, 3); i; --i, ++n) lens[n] = 0; break;
		case 18: for (int i = 11 + cp_read_bits(s, 7); i; --i, ++n) lens[n] = 0; break;
		default: lens[n++] = (uint8_t)sym; break;
		}
	}

	s->nlit = cp_build(s, s->lit, lens, nlit);
	s->ndst = cp_build(0, s->dst, lens + nlit, ndst);
	return 1;
}

// 3.2.3
static int cp_block(cp_state_t* s)
{
	while (1)
	{
		int symbol = cp_decode(s, s->lit, s->nlit);

		if (symbol < 256)
		{
			CUTE_PNG_CHECK(s->out + 1 <= s->out_end, "Attempted to overwrite out buffer while outputting a symbol.");
			*s->out = (char)symbol;
			s->out += 1;
		}

		else if (symbol > 256)
		{
			symbol -= 257;
			int length = cp_read_bits(s, cp_len_extra_bits[symbol]) + cp_len_base[symbol];
			int distance_symbol = cp_decode(s, s->dst, s->ndst);
			int backwards_distance = cp_read_bits(s, cp_dist_extra_bits[distance_symbol]) + cp_dist_base[distance_symbol];
			CUTE_PNG_CHECK(s->out - backwards_distance >= s->begin, "Attempted to write before out buffer (invalid backwards distance).");
			CUTE_PNG_CHECK(s->out + length <= s->out_end, "Attempted to overwrite out buffer while outputting a string.");
			char* src = s->out - backwards_distance;
			char* dst = s->out;
			s->out += length;

			switch (backwards_distance)
			{
			case 1: // very common in images
				CUTE_PNG_MEMSET(dst, *src, length);
				break;
			default: while (length--) *dst++ = *src++;
			}
		}

		else break;
	}

	return 1;

cp_err:
	return 0;
}

// 3.2.3
int cp_inflate(void* in, int in_bytes, void* out, int out_bytes)
{
	cp_state_t* s = (cp_state_t*)CUTE_PNG_CALLOC(1, sizeof(cp_state_t));
	s->bits = 0;
	s->count = 0;
	s->word_index = 0;
	s->bits_left = in_bytes * 8;

	// s->words is the in-pointer rounded up to a multiple of 4
	int first_bytes = (int) ((( (size_t) in + 3) & ~3) - (size_t) in);
	s->words = (uint32_t*)((char*)in + first_bytes);
	s->word_count = (in_bytes - first_bytes) / 4;
	int last_bytes = ((in_bytes - first_bytes) & 3);

	for (int i = 0; i < first_bytes; ++i)
		s->bits |= (uint64_t)(((uint8_t*)in)[i]) << (i * 8);

	s->final_word_available = last_bytes ? 1 : 0;
	s->final_word = 0;
	for(int i = 0; i < last_bytes; i++) 
		s->final_word |= ((uint8_t*)in)[in_bytes - last_bytes+i] << (i * 8);

	s->count = first_bytes * 8;

	s->out = (char*)out;
	s->out_end = s->out + out_bytes;
	s->begin = (char*)out;

	int count = 0;
	int bfinal;
	do
	{
		bfinal = cp_read_bits(s, 1);
		int btype = cp_read_bits(s, 2);

		switch (btype)
		{
		case 0: CUTE_PNG_CALL(cp_stored(s)); break;
		case 1: cp_fixed(s); CUTE_PNG_CALL(cp_block(s)); break;
		case 2: cp_dynamic(s); CUTE_PNG_CALL(cp_block(s)); break;
		case 3: CUTE_PNG_CHECK(0, "Detected unknown block type within input stream.");
		}

		++count;
	}
	while (!bfinal);

	CUTE_PNG_FREE(s);
	return 1;

cp_err:
	CUTE_PNG_FREE(s);
	return 0;
}

static uint8_t cp_paeth(uint8_t a, uint8_t b, uint8_t c)
{
	int p = a + b - c;
	int pa = abs(p - a);
	int pb = abs(p - b);
	int pc = abs(p - c);
	return (pa <= pb && pa <= pc) ? a : (pb <= pc) ? b : c;
}

typedef struct cp_save_png_data_t
{
	uint32_t crc;
	uint32_t adler;
	uint32_t bits;
	uint32_t prev;
	uint32_t runlen;
	int buflen;
	int bufcap;
	char* buffer;
} cp_save_png_data_t;

uint32_t CP_CRC_TABLE[] = {
	0, 0x1db71064, 0x3b6e20c8, 0x26d930ac, 0x76dc4190, 0x6b6b51f4, 0x4db26158, 0x5005713c,
	0xedb88320, 0xf00f9344, 0xd6d6a3e8, 0xcb61b38c, 0x9b64c2b0, 0x86d3d2d4, 0xa00ae278, 0xbdbdf21c
};

static void cp_put8(cp_save_png_data_t* s, uint32_t a)
{
	if (s->buflen >= s->bufcap)
	{
		s->bufcap *= 2;
		s->buffer = (char*)CUTE_PNG_REALLOC(s->buffer, s->bufcap);
	}
	s->buffer[s->buflen++] = a;
	s->crc = (s->crc >> 4) ^ CP_CRC_TABLE[(s->crc & 15) ^ (a & 15)];
	s->crc = (s->crc >> 4) ^ CP_CRC_TABLE[(s->crc & 15) ^ (a >> 4)];
}

static void cp_update_adler(cp_save_png_data_t* s, uint32_t v)
{
	uint32_t s1 = s->adler & 0xFFFF;
	uint32_t s2 = (s->adler >> 16) & 0xFFFF;
	s1 = (s1 + v) % 65521;
	s2 = (s2 + s1) % 65521;
	s->adler = (s2 << 16) + s1;
}

static void cp_put32(cp_save_png_data_t* s, uint32_t v)
{
	cp_put8(s, (v >> 24) & 0xFF);
	cp_put8(s, (v >> 16) & 0xFF);
	cp_put8(s, (v >> 8) & 0xFF);
	cp_put8(s, v & 0xFF);
}

static void cp_put_bits(cp_save_png_data_t* s, uint32_t data, uint32_t bitcount)
{
	while (bitcount--)
	{
		uint32_t prev = s->bits;
		s->bits = (s->bits >> 1) | ((data & 1) << 7);
		data >>= 1;

		if (prev & 1)
		{
			cp_put8(s, s->bits);
			s->bits = 0x80;
		}
	}
}

static void cp_put_bitsr(cp_save_png_data_t* s, uint32_t data, uint32_t bitcount)
{
	while (bitcount--)
		cp_put_bits(s, data >> bitcount, 1);
}

static void cp_begin_chunk(cp_save_png_data_t* s, const char* id, uint32_t len)
{
	cp_put32(s, len);
	s->crc = 0xFFFFFFFF;
	cp_put8(s, (unsigned char)id[0]);
	cp_put8(s, (unsigned char)id[1]);
	cp_put8(s, (unsigned char)id[2]);
	cp_put8(s, (unsigned char)id[3]);
}

static void cp_encode_literal(cp_save_png_data_t* s, uint32_t v)
{
	// Encode a literal/length using the built-in tables.
	// Could do better with a custom table but whatever.
	     if (v < 144) cp_put_bitsr(s, 0x030 + v -   0, 8);
	else if (v < 256) cp_put_bitsr(s, 0x190 + v - 144, 9);
	else if (v < 280) cp_put_bitsr(s, 0x000 + v - 256, 7);
	else              cp_put_bitsr(s, 0x0c0 + v - 280, 8);
}

static void cp_encode_len(cp_save_png_data_t* s, uint32_t code, uint32_t bits, uint32_t len)
{
	cp_encode_literal(s, code + (len >> bits));
	cp_put_bits(s, len, bits);
	cp_put_bits(s, 0, 5);
}

static void cp_end_run(cp_save_png_data_t* s)
{
	s->runlen--;
	cp_encode_literal(s, s->prev);

	if (s->runlen >= 67) cp_encode_len(s, 277, 4, s->runlen - 67);
	else if (s->runlen >= 35) cp_encode_len(s, 273, 3, s->runlen - 35);
	else if (s->runlen >= 19) cp_encode_len(s, 269, 2, s->runlen - 19);
	else if (s->runlen >= 11) cp_encode_len(s, 265, 1, s->runlen - 11);
	else if (s->runlen >= 3) cp_encode_len(s, 257, 0, s->runlen - 3);
	else while (s->runlen--) cp_encode_literal(s, s->prev);
}

static void cp_encode_byte(cp_save_png_data_t *s, uint8_t v)
{
	cp_update_adler(s, v);

	// Simple RLE compression. We could do better by doing a search
	// to find matches, but this works pretty well TBH.
	if (s->prev == v && s->runlen < 115) s->runlen++;

	else
	{
		if (s->runlen) cp_end_run(s);

		s->prev = v;
		s->runlen = 1;
	}
}

static void cp_save_header(cp_save_png_data_t* s, cp_image_t* img)
{
	const unsigned char* hdr = (const unsigned char*)"\211PNG\r\n\032\n";
	for (int i = 0; i < 8; ++i) {
		cp_put8(s, *hdr++);
	}
	cp_begin_chunk(s, "IHDR", 13);
	cp_put32(s, img->w);
	cp_put32(s, img->h);
	cp_put8(s, 8); // bit depth
	cp_put8(s, 6); // RGBA
	cp_put8(s, 0); // compression (deflate)
	cp_put8(s, 0); // filter (standard)
	cp_put8(s, 0); // interlace off
	cp_put32(s, ~s->crc);
}

static void cp_save_data(cp_save_png_data_t* s, cp_image_t* img, long dataPos, long* dataSize)
{
	cp_begin_chunk(s, "IDAT", 0);
	cp_put8(s, 0x08); // zlib compression method
	cp_put8(s, 0x1D); // zlib compression flags
	cp_put_bits(s, 3, 3); // zlib last block + fixed dictionary

	for (int y = 0; y < img->h; ++y)
	{
		cp_pixel_t *row = &img->pix[y * img->w];
		cp_pixel_t prev = cp_make_pixel_a(0, 0, 0, 0);

		cp_encode_byte(s, 1); // sub filter
		for (int x = 0; x < img->w; ++x)
		{
			cp_encode_byte(s, row[x].r - prev.r);
			cp_encode_byte(s, row[x].g - prev.g);
			cp_encode_byte(s, row[x].b - prev.b);
			cp_encode_byte(s, row[x].a - prev.a);
			prev = row[x];
		}
	}

	cp_end_run(s);
	cp_encode_literal(s, 256); // terminator
	while (s->bits != 0x80) cp_put_bits(s, 0, 1);
	cp_put32(s, s->adler);
	*dataSize = (s->buflen - dataPos) - 8;
	cp_put32(s, ~s->crc);
}

cp_saved_png_t cp_save_png_to_memory(const cp_image_t* img)
{
	cp_saved_png_t result = { 0 };
	cp_save_png_data_t s = { 0 };
	long dataPos, dataSize, fileSize;
	if (!img) return result;

	s.adler = 1;
	s.bits = 0x80;
	s.prev = 0xFFFF;
	s.bufcap = 1024;
	s.buffer = (char*)CUTE_PNG_ALLOC(1024);

	cp_save_header(&s, (cp_image_t*)img);
	dataPos = s.buflen;
	cp_save_data(&s, (cp_image_t*)img, dataPos, &dataSize);

	// End chunk.
	cp_begin_chunk(&s, "IEND", 0);
	cp_put32(&s, ~s.crc);

	// Write back payload size.
	fileSize = s.buflen;
	s.buflen = dataPos;
	cp_put32(&s, dataSize);

	result.size = fileSize;
	result.data = s.buffer;
	return result;
}

int cp_save_png(const char* file_name, const cp_image_t* img)
{
	cp_saved_png_t s;
	long err;
	CUTE_PNG_FILE* fp = CUTE_PNG_FOPEN(file_name, "wb");
	if (!fp) return 1;
	s = cp_save_png_to_memory(img);
	CUTE_PNG_FWRITE(s.data, s.size, 1, fp);
	err = CUTE_PNG_FERROR(fp);
	CUTE_PNG_FCLOSE(fp);
	CUTE_PNG_FREE(s.data);
	return !err;
}

typedef struct cp_raw_png_t
{
	const uint8_t* p;
	const uint8_t* end;
} cp_raw_png_t;

static uint32_t cp_make32(const uint8_t* s)
{
	return (s[0] << 24) | (s[1] << 16) | (s[2] << 8) | s[3];
}

static const uint8_t* cp_chunk(cp_raw_png_t* png, const char* chunk, uint32_t minlen)
{
	uint32_t len = cp_make32(png->p);
	const uint8_t* start = png->p;

	if (!CUTE_PNG_MEMCMP(start + 4, chunk, 4) && len >= minlen)
	{
		int offset = len + 12;

		if (png->p + offset <= png->end)
		{
			png->p += offset;
			return start + 8;
		}
	}

	return 0;
}

static const uint8_t* cp_find(cp_raw_png_t* png, const char* chunk, uint32_t minlen)
{
	const uint8_t *start;
	while (png->p < png->end)
	{
		uint32_t len = cp_make32(png->p);
		start = png->p;
		png->p += len + 12;

		if (!CUTE_PNG_MEMCMP(start+4, chunk, 4) && len >= minlen && png->p <= png->end)
			return start + 8;
	}

	return 0;
}

static int cp_unfilter(int w, int h, int bpp, uint8_t* raw)
{
	int len = w * bpp;
	uint8_t *prev;
	int x;

	if (h > 0)
	{
#define FILTER_LOOP_FIRST(A) for (x = bpp; x < len; x++) raw[x] += A; break
		switch (*raw++)
		{
		case 0: break;
		case 1: FILTER_LOOP_FIRST(raw[x - bpp]);
		case 2: break;
		case 3: FILTER_LOOP_FIRST(raw[x - bpp] / 2);
		case 4: FILTER_LOOP_FIRST(cp_paeth(raw[x - bpp], 0, 0));
		default: return 0;
		}
#undef FILTER_LOOP_FIRST
	}

	prev = raw;
	raw += len;

	for (int y = 1; y < h; y++, prev = raw, raw += len)
	{
#define FILTER_LOOP(A, B) for (x = 0 ; x < bpp; x++) raw[x] += A; for (; x < len; x++) raw[x] += B; break
		switch (*raw++)
		{
		case 0: break;
		case 1: FILTER_LOOP(0          , raw[x - bpp] );
		case 2: FILTER_LOOP(prev[x]    , prev[x]);
		case 3: FILTER_LOOP(prev[x] / 2, (raw[x - bpp] + prev[x]) / 2);
		case 4: FILTER_LOOP(prev[x]    , cp_paeth(raw[x - bpp], prev[x], prev[x -bpp]));
		default: return 0;
		}
#undef FILTER_LOOP
	}

	return 1;
}

static void cp_convert(int bpp, int w, int h, uint8_t* src, cp_pixel_t* dst)
{
	for (int y = 0; y < h; y++)
	{
		// skip filter byte
		src++;

		for (int x = 0; x < w; x++, src += bpp)
		{
			switch (bpp)
			{
				case 1: *dst++ = cp_make_pixel(src[0], src[0], src[0]); break;
				case 2: *dst++ = cp_make_pixel_a(src[0], src[0], src[0], src[1]); break;
				case 3: *dst++ = cp_make_pixel(src[0], src[1], src[2]); break;
				case 4: *dst++ = cp_make_pixel_a(src[0], src[1], src[2], src[3]); break;
			}
		}
	}
}

// http://www.libpng.org/pub/png/spec/1.2/PNG-Chunks.html#C.tRNS
static uint8_t cp_get_alpha_for_indexed_image(int index, const uint8_t* trns, uint32_t trns_len)
{
	if (!trns) return 255;
	else if ((uint32_t)index >= trns_len) return 255;
	else return trns[index];
}

static void cp_depalette(int w, int h, uint8_t* src, cp_pixel_t* dst, const uint8_t* plte, const uint8_t* trns, uint32_t trns_len)
{
	for (int y = 0; y < h; ++y)
	{
		// skip filter byte
		++src;

		for (int x = 0; x < w; ++x, ++src)
		{
			int c = *src;
			uint8_t r = plte[c * 3];
			uint8_t g = plte[c * 3 + 1];
			uint8_t b = plte[c * 3 + 2];
			uint8_t a = cp_get_alpha_for_indexed_image(c, trns, trns_len);
			*dst++ = cp_make_pixel_a(r, g, b, a);
		}
	}
}

static uint32_t cp_get_chunk_byte_length(const uint8_t* chunk)
{
	return cp_make32(chunk - 8);
}

static int cp_out_size(cp_image_t* img, int bpp)
{
	return (img->w + 1) * img->h * bpp;
}

cp_image_t cp_load_png_mem(const void* png_data, int png_length)
{
	const char* sig = "\211PNG\r\n\032\n";
	const uint8_t* ihdr, *first, *plte, *trns;
	int bit_depth, color_type, bpp, w, h, pix_bytes;
	int compression, filter, interlace;
	int datalen, offset;
	uint8_t* out;
	cp_image_t img = { 0 };
	uint8_t* data = 0;
	cp_raw_png_t png;
	png.p = (uint8_t*)png_data;
	png.end = (uint8_t*)png_data + png_length;

	CUTE_PNG_CHECK(!CUTE_PNG_MEMCMP(png.p, sig, 8), "incorrect file signature (is this a png file?)");
	png.p += 8;

	ihdr = cp_chunk(&png, "IHDR", 13);
	CUTE_PNG_CHECK(ihdr, "unable to find IHDR chunk");
	bit_depth = ihdr[8];
	color_type = ihdr[9];
	CUTE_PNG_CHECK(bit_depth == 8, "only bit-depth of 8 is supported");

	switch (color_type)
	{
		case 0: bpp = 1; break; // greyscale
		case 2: bpp = 3; break; // RGB
		case 3: bpp = 1; break; // paletted
		case 4: bpp = 2; break; // grey+alpha
		case 6: bpp = 4; break; // RGBA
		default: CUTE_PNG_CHECK(0, "unknown color type");
	}

	// +1 for filter byte (which is dumb! just stick this at file header...)
	w = cp_make32(ihdr) + 1;
	h = cp_make32(ihdr + 4);
	CUTE_PNG_CHECK(w >= 1, "invalid IHDR chunk found, image width was less than 1");
	CUTE_PNG_CHECK(h >= 1, "invalid IHDR chunk found, image height was less than 1");
        CUTE_PNG_CHECK((int64_t) w * h * sizeof(cp_pixel_t) < INT_MAX, "image too large");
	pix_bytes = w * h * sizeof(cp_pixel_t);
	img.w = w - 1;
	img.h = h;
	img.pix = (cp_pixel_t*)CUTE_PNG_ALLOC(pix_bytes);
	CUTE_PNG_CHECK(img.pix, "unable to allocate raw image space");

	compression = ihdr[10];
	filter = ihdr[11];
	interlace = ihdr[12];
	CUTE_PNG_CHECK(!compression, "only standard compression DEFLATE is supported");
	CUTE_PNG_CHECK(!filter, "only standard adaptive filtering is supported");
	CUTE_PNG_CHECK(!interlace, "interlacing is not supported");

	// PLTE must come before any IDAT chunk
	first = png.p;
	plte = cp_find(&png, "PLTE", 0);
	if (!plte) png.p = first;
	else first = png.p;

	// tRNS can come after PLTE
	trns = cp_find(&png, "tRNS", 0);
	if (!trns) png.p = first;
	else first = png.p;

	// Compute length of the DEFLATE stream through IDAT chunk data sizes
	datalen = 0;
	for (const uint8_t* idat = cp_find(&png, "IDAT", 0); idat; idat = cp_chunk(&png, "IDAT", 0))
	{
		uint32_t len = cp_get_chunk_byte_length(idat);
		datalen += len;
	}

	// Copy in IDAT chunk data sections to form the compressed DEFLATE stream
	png.p = first;
	data = (uint8_t*)CUTE_PNG_ALLOC(datalen);
	offset = 0;
	for (const uint8_t* idat = cp_find(&png, "IDAT", 0); idat; idat = cp_chunk(&png, "IDAT", 0))
	{
		uint32_t len = cp_get_chunk_byte_length(idat);
		CUTE_PNG_MEMCPY(data + offset, idat, len);
		offset += len;
	}

	// check for proper zlib structure in DEFLATE stream
	CUTE_PNG_CHECK(data && datalen >= 6, "corrupt zlib structure in DEFLATE stream");
	CUTE_PNG_CHECK((data[0] & 0x0f) == 0x08, "only zlib compression method (RFC 1950) is supported");
	CUTE_PNG_CHECK((data[0] & 0xf0) <= 0x70, "innapropriate window size detected");
	CUTE_PNG_CHECK(!(data[1] & 0x20), "preset dictionary is present and not supported");

	// check for integer overflow
	CUTE_PNG_CHECK(cp_out_size(&img, 4) >= 1, "invalid image size found");
	CUTE_PNG_CHECK(cp_out_size(&img, bpp) >= 1, "invalid image size found");

	out = (uint8_t*)img.pix + cp_out_size(&img, 4) - cp_out_size(&img, bpp);
	CUTE_PNG_CHECK(cp_inflate(data + 2, datalen - 6, out, pix_bytes), "DEFLATE algorithm failed");
	CUTE_PNG_CHECK(cp_unfilter(img.w, img.h, bpp, out), "invalid filter byte found");

	if (color_type == 3)
	{
		CUTE_PNG_CHECK(plte, "color type of indexed requires a PLTE chunk");
		uint32_t trns_len = trns ? cp_get_chunk_byte_length(trns) : 0;
		cp_depalette(img.w, img.h, out, img.pix, plte, trns, trns_len);
	}
	else cp_convert(bpp, img.w, img.h, out, img.pix);

	CUTE_PNG_FREE(data);
	return img;

cp_err:
	CUTE_PNG_FREE(data);
	CUTE_PNG_FREE(img.pix);
	img.pix = 0;

	return img;
}

cp_image_t cp_load_blank(int w, int h)
{
	cp_image_t img;
	img.w = w;
	img.h = h;
	img.pix = (cp_pixel_t*)CUTE_PNG_ALLOC(w * h * sizeof(cp_pixel_t));
	return img;
}

cp_image_t cp_load_png(const char *file_name)
{
	cp_image_t img = { 0 };
	int len;
	void* data = cp_read_file_to_memory(file_name, &len);
	if (!data) return img;
	img = cp_load_png_mem(data, len);
	CUTE_PNG_FREE(data);
	return img;
}

void cp_free_png(cp_image_t* img)
{
	CUTE_PNG_FREE(img->pix);
	img->pix = 0;
	img->w = img->h = 0;
}

void cp_flip_image_horizontal(cp_image_t* img)
{
	cp_pixel_t* pix = img->pix;
	int w = img->w;
	int h = img->h;
	int flips = h / 2;
	for (int i = 0; i < flips; ++i)
	{
		cp_pixel_t* a = pix + w * i;
		cp_pixel_t* b = pix + w * (h - i - 1);
		for (int j = 0; j < w; ++j)
		{
			cp_pixel_t t = *a;
			*a = *b;
			*b = t;
			++a;
			++b;
		}
	}
}

void cp_load_png_wh(const void* png_data, int png_length, int* w_out, int* h_out)
{
	const char* sig = "\211PNG\r\n\032\n";
	const uint8_t* ihdr;
	cp_raw_png_t png;
	int w, h;
	png.p = (uint8_t*)png_data;
	png.end = (uint8_t*)png_data + png_length;

	if (w_out) *w_out = 0;
	if (h_out) *h_out = 0;

	CUTE_PNG_CHECK(!CUTE_PNG_MEMCMP(png.p, sig, 8), "incorrect file signature (is this a png file?)");
	png.p += 8;

	ihdr = cp_chunk(&png, "IHDR", 13);
	CUTE_PNG_CHECK(ihdr, "unable to find IHDR chunk");

	// +1 for filter byte (which is dumb! just stick this at file header...)
	w = cp_make32(ihdr) + 1;
	h = cp_make32(ihdr + 4);
	if (w_out) *w_out = w - 1;
	if (h_out) *h_out = h;

	cp_err:;
}

cp_indexed_image_t cp_load_indexed_png(const char* file_name)
{
	cp_indexed_image_t img = { 0 };
	int len;
	void* data = cp_read_file_to_memory(file_name, &len);
	if (!data) return img;
	img = cp_load_indexed_png_mem(data, len);
	CUTE_PNG_FREE(data);
	return img;
}

static void cp_unpack_indexed_rows(int w, int h, uint8_t* src, uint8_t* dst)
{
	for (int y = 0; y < h; ++y)
	{
		// skip filter byte
		++src;

		for (int x = 0; x < w; ++x, ++src)
		{
			*dst++ = *src;
		}
	}
}

void cp_unpack_palette(cp_pixel_t* dst, const uint8_t* plte, int plte_len, const uint8_t* trns, int trns_len)
{
	for (int i = 0; i < plte_len * 3; i += 3)
	{
		unsigned char r = plte[i];
		unsigned char g = plte[i + 1];
		unsigned char b = plte[i + 2];
		unsigned char a = cp_get_alpha_for_indexed_image(i / 3, trns, trns_len);
		cp_pixel_t p = cp_make_pixel_a(r, g, b, a);
		*dst++ = p;
	}
}

cp_indexed_image_t cp_load_indexed_png_mem(const void *png_data, int png_length)
{
	const char* sig = "\211PNG\r\n\032\n";
	const uint8_t* ihdr, *first, *plte, *trns;
	int bit_depth, color_type, bpp, w, h, pix_bytes;
	int compression, filter, interlace;
	int datalen, offset;
	int plte_len;
	uint8_t* out;
	cp_indexed_image_t img = { 0 };
	uint8_t* data = 0;
	cp_raw_png_t png;
	png.p = (uint8_t*)png_data;
	png.end = (uint8_t*)png_data + png_length;

	CUTE_PNG_CHECK(!CUTE_PNG_MEMCMP(png.p, sig, 8), "incorrect file signature (is this a png file?)");
	png.p += 8;

	ihdr = cp_chunk(&png, "IHDR", 13);
	CUTE_PNG_CHECK(ihdr, "unable to find IHDR chunk");
	bit_depth = ihdr[8];
	color_type = ihdr[9];
	bpp = 1; // bytes per pixel
	CUTE_PNG_CHECK(bit_depth == 8, "only bit-depth of 8 is supported");
	CUTE_PNG_CHECK(color_type == 3, "only indexed png images (images with a palette) are valid for cp_load_indexed_png_mem");

	// +1 for filter byte (which is dumb! just stick this at file header...)
	w = cp_make32(ihdr) + 1;
	h = cp_make32(ihdr + 4);
        CUTE_PNG_CHECK((int64_t) w * h * sizeof(uint8_t) < INT_MAX, "image too large");
	pix_bytes = w * h * sizeof(uint8_t);
	img.w = w - 1;
	img.h = h;
	img.pix = (uint8_t*)CUTE_PNG_ALLOC(pix_bytes);
	CUTE_PNG_CHECK(img.pix, "unable to allocate raw image space");

	compression = ihdr[10];
	filter = ihdr[11];
	interlace = ihdr[12];
	CUTE_PNG_CHECK(!compression, "only standard compression DEFLATE is supported");
	CUTE_PNG_CHECK(!filter, "only standard adaptive filtering is supported");
	CUTE_PNG_CHECK(!interlace, "interlacing is not supported");

	// PLTE must come before any IDAT chunk
	first = png.p;
	plte = cp_find(&png, "PLTE", 0);
	if (!plte) png.p = first;
	else first = png.p;

	// tRNS can come after PLTE
	trns = cp_find(&png, "tRNS", 0);
	if (!trns) png.p = first;
	else first = png.p;

	// Compute length of the DEFLATE stream through IDAT chunk data sizes
	datalen = 0;
	for (const uint8_t* idat = cp_find(&png, "IDAT", 0); idat; idat = cp_chunk(&png, "IDAT", 0))
	{
		uint32_t len = cp_get_chunk_byte_length(idat);
		datalen += len;
	}

	// Copy in IDAT chunk data sections to form the compressed DEFLATE stream
	png.p = first;
	data = (uint8_t*)CUTE_PNG_ALLOC(datalen);
	offset = 0;
	for (const uint8_t* idat = cp_find(&png, "IDAT", 0); idat; idat = cp_chunk(&png, "IDAT", 0))
	{
		uint32_t len = cp_get_chunk_byte_length(idat);
		CUTE_PNG_MEMCPY(data + offset, idat, len);
		offset += len;
	}

	// check for proper zlib structure in DEFLATE stream
	CUTE_PNG_CHECK(data && datalen >= 6, "corrupt zlib structure in DEFLATE stream");
	CUTE_PNG_CHECK((data[0] & 0x0f) == 0x08, "only zlib compression method (RFC 1950) is supported");
	CUTE_PNG_CHECK((data[0] & 0xf0) <= 0x70, "innapropriate window size detected");
	CUTE_PNG_CHECK(!(data[1] & 0x20), "preset dictionary is present and not supported");

	out = img.pix;
	CUTE_PNG_CHECK(cp_inflate(data + 2, datalen - 6, out, pix_bytes), "DEFLATE algorithm failed");
	CUTE_PNG_CHECK(cp_unfilter(img.w, img.h, bpp, out), "invalid filter byte found");
	cp_unpack_indexed_rows(img.w, img.h, out, img.pix);

	plte_len = cp_get_chunk_byte_length(plte) / 3;
	cp_unpack_palette(img.palette, plte, plte_len, trns, cp_get_chunk_byte_length(trns));
	img.palette_len = (uint8_t)plte_len;

	CUTE_PNG_FREE(data);
	return img;

cp_err:
	CUTE_PNG_FREE(data);
	CUTE_PNG_FREE(img.pix);
	img.pix = 0;

	return img;
}

void cp_free_indexed_png(cp_indexed_image_t* img)
{
	CUTE_PNG_FREE(img->pix);
	img->pix = 0;
	img->w = img->h = 0;
}

cp_image_t cp_depallete_indexed_image(cp_indexed_image_t* img)
{
	cp_image_t out = { 0 };
	out.w = img->w;
	out.h = img->h;
	out.pix = (cp_pixel_t*)CUTE_PNG_ALLOC(sizeof(cp_pixel_t) * out.w * out.h);

	cp_pixel_t* dst = out.pix;
	uint8_t* src = img->pix;

	for (int y = 0; y < out.h; ++y)
	{
		for (int x = 0; x < out.w; ++x)
		{
			int index = *src++;
			cp_pixel_t p = img->palette[index];
			*dst++ = p;
		}
	}

	return out;
}

typedef struct cp_v2i_t
{
	int x;
	int y;
} cp_v2i_t;

typedef struct cp_integer_image_t
{
	int img_index;
	cp_v2i_t size;
	cp_v2i_t min;
	cp_v2i_t max;
	int fit;
} cp_integer_image_t;

static cp_v2i_t cp_v2i(int x, int y)
{
	cp_v2i_t v;
	v.x = x;
	v.y = y;
	return v;
}

static cp_v2i_t cp_sub(cp_v2i_t a, cp_v2i_t b)
{
	cp_v2i_t v;
	v.x = a.x - b.x;
	v.y = a.y - b.y;
	return v;
}

static cp_v2i_t cp_add(cp_v2i_t a, cp_v2i_t b)
{
	cp_v2i_t v;
	v.x = a.x + b.x;
	v.y = a.y + b.y;
	return v;
}

typedef struct cp_atlas_node_t
{
	cp_v2i_t size;
	cp_v2i_t min;
	cp_v2i_t max;
} cp_atlas_node_t;

static cp_atlas_node_t* cp_best_fit(int sp, const cp_image_t* png, cp_atlas_node_t* nodes)
{
	int bestVolume = INT_MAX;
	cp_atlas_node_t *best_node = 0;
	int width = png->w;
	int height = png->h;
	int png_volume = width * height;

	for (int i = 0; i < sp; ++i)
	{
		cp_atlas_node_t *node = nodes + i;
		int can_contain = node->size.x >= width && node->size.y >= height;
		if (can_contain)
		{
			int node_volume = node->size.x * node->size.y;
			if (node_volume == png_volume) return node;
			if (node_volume < bestVolume)
			{
				bestVolume = node_volume;
				best_node = node;
			}
		}
	}

	return best_node;
}

static int cp_perimeter_pred(cp_integer_image_t* a, cp_integer_image_t* b)
{
	int perimeterA = 2 * (a->size.x + a->size.y);
	int perimeterB = 2 * (b->size.x + b->size.y);
	return perimeterB < perimeterA;
}

void cp_premultiply(cp_image_t* img)
{
	int w = img->w;
	int h = img->h;
	int stride = w * sizeof(cp_pixel_t);
	uint8_t* data = (uint8_t*)img->pix;

	for(int i = 0; i < (int)stride * h; i += sizeof(cp_pixel_t))
	{
		float a = (float)data[i + 3] / 255.0f;
		float r = (float)data[i + 0] / 255.0f;
		float g = (float)data[i + 1] / 255.0f;
		float b = (float)data[i + 2] / 255.0f;
		r *= a;
		g *= a;
		b *= a;
		data[i + 0] = (uint8_t)(r * 255.0f);
		data[i + 1] = (uint8_t)(g * 255.0f);
		data[i + 2] = (uint8_t)(b * 255.0f);
	}
}

static void cp_qsort(cp_integer_image_t* items, int count)
{
	if (count <= 1) return;

	cp_integer_image_t pivot = items[count - 1];
	int low = 0;
	for (int i = 0; i < count - 1; ++i)
	{
		if (cp_perimeter_pred(items + i, &pivot))
		{
			cp_integer_image_t tmp = items[i];
			items[i] = items[low];
			items[low] = tmp;
			low++;
		}
	}

	items[count - 1] = items[low];
	items[low] = pivot;
	cp_qsort(items, low);
	cp_qsort(items + low + 1, count - 1 - low);
}

static void cp_write_pixel(char* mem, long color) {
	mem[0] = (color >> 24) & 0xFF;
	mem[1] = (color >> 16) & 0xFF;
	mem[2] = (color >>  8) & 0xFF;
	mem[3] = (color >>  0) & 0xFF;
}

cp_image_t cp_make_atlas(int atlas_width, int atlas_height, const cp_image_t* pngs, int png_count, cp_atlas_image_t* imgs_out)
{
	float w0, h0, div, wTol, hTol;
	int atlas_image_size, atlas_stride, sp;
	void* atlas_pixels = 0;
	int atlas_node_capacity = png_count * 2;
	cp_image_t atlas_image;
	cp_integer_image_t* images = 0;
	cp_atlas_node_t* nodes = 0;

	atlas_image.w = atlas_width;
	atlas_image.h = atlas_height;
	atlas_image.pix = 0;

	CUTE_PNG_CHECK(pngs, "pngs array was NULL");
	CUTE_PNG_CHECK(imgs_out, "imgs_out array was NULL");

	images = (cp_integer_image_t*)CUTE_PNG_ALLOCA(sizeof(cp_integer_image_t) * png_count);
	nodes = (cp_atlas_node_t*)CUTE_PNG_ALLOC(sizeof(cp_atlas_node_t) * atlas_node_capacity);
	CUTE_PNG_CHECK(images, "out of mem");
	CUTE_PNG_CHECK(nodes, "out of mem");

	for (int i = 0; i < png_count; ++i)
	{
		const cp_image_t* png = pngs + i;
		cp_integer_image_t* image = images + i;
		image->fit = 0;
		image->size = cp_v2i(png->w, png->h);
		image->img_index = i;
	}

	// Sort PNGs from largest to smallest
	cp_qsort(images, png_count);

	// stack pointer, the stack is the nodes array which we will
	// allocate nodes from as necessary.
	sp = 1;

	nodes[0].min = cp_v2i(0, 0);
	nodes[0].max = cp_v2i(atlas_width, atlas_height);
	nodes[0].size = cp_v2i(atlas_width, atlas_height);

	// Nodes represent empty space in the atlas. Placing a texture into the
	// atlas involves splitting a node into two smaller pieces (or, if a
	// perfect fit is found, deleting the node).
	for (int i = 0; i < png_count; ++i)
	{
		cp_integer_image_t* image = images + i;
		const cp_image_t* png = pngs + image->img_index;
		int width = png->w;
		int height = png->h;
		cp_atlas_node_t *best_fit = cp_best_fit(sp, png, nodes);
		if (CUTE_PNG_ATLAS_MUST_FIT) CUTE_PNG_CHECK(best_fit, "Not enough room to place image in atlas.");
		else if (!best_fit) 
		{
			image->fit = 0;
			continue;
		}

		image->min = best_fit->min;
		image->max = cp_add(image->min, image->size);

		if (best_fit->size.x == width && best_fit->size.y == height)
		{
			cp_atlas_node_t* last_node = nodes + --sp;
			*best_fit = *last_node;
			image->fit = 1;

			continue;
		}

		image->fit = 1;

		if (sp == atlas_node_capacity)
		{
			int new_capacity = atlas_node_capacity * 2;
			cp_atlas_node_t* new_nodes = (cp_atlas_node_t*)CUTE_PNG_ALLOC(sizeof(cp_atlas_node_t) * new_capacity);
			CUTE_PNG_CHECK(new_nodes, "out of mem");
			CUTE_PNG_MEMCPY(new_nodes, nodes, sizeof(cp_atlas_node_t) * sp);
			CUTE_PNG_FREE(nodes);
			// best_fit became a dangling pointer, so relocate it
			best_fit = new_nodes + (best_fit - nodes);
			nodes = new_nodes;
			atlas_node_capacity = new_capacity;
		}

		cp_atlas_node_t* new_node = nodes + sp++;
		new_node->min = best_fit->min;

		// Split bestFit along x or y, whichever minimizes
		// fragmentation of empty space
		cp_v2i_t d = cp_sub(best_fit->size, cp_v2i(width, height));
		if (d.x < d.y)
		{
			new_node->size.x = d.x;
			new_node->size.y = height;
			new_node->min.x += width;

			best_fit->size.y = d.y;
			best_fit->min.y += height;
		}

		else
		{
			new_node->size.x = width;
			new_node->size.y = d.y;
			new_node->min.y += height;

			best_fit->size.x = d.x;
			best_fit->min.x += width;
		}

		new_node->max = cp_add(new_node->min, new_node->size);
	}

	// Write the final atlas image, use CUTE_PNG_ATLAS_EMPTY_COLOR as base color
	atlas_stride = atlas_width * sizeof(cp_pixel_t);
	atlas_image_size = atlas_width * atlas_height * sizeof(cp_pixel_t);
	atlas_pixels = CUTE_PNG_ALLOC(atlas_image_size);
	CUTE_PNG_CHECK(atlas_pixels, "out of mem");
	
	for(int i = 0; i < atlas_image_size; i += sizeof(cp_pixel_t)) {
		cp_write_pixel((char*)atlas_pixels + i, CUTE_PNG_ATLAS_EMPTY_COLOR);
	}

	for (int i = 0; i < png_count; ++i)
	{
		cp_integer_image_t* image = images + i;

		if (image->fit)
		{
			const cp_image_t* png = pngs + image->img_index;
			char* pixels = (char*)png->pix;
			cp_v2i_t min = image->min;
			cp_v2i_t max = image->max;
			int atlas_offset = min.x * sizeof(cp_pixel_t);
			int tex_stride = png->w * sizeof(cp_pixel_t);

			for (int row = min.y, y = 0; row < max.y; ++row, ++y)
			{
				void* row_ptr = (char*)atlas_pixels + (row * atlas_stride + atlas_offset);
				CUTE_PNG_MEMCPY(row_ptr, pixels + y * tex_stride, tex_stride);
			}
		}
	}

	atlas_image.pix = (cp_pixel_t*)atlas_pixels;

	// squeeze UVs inward by 128th of a pixel
	// this prevents atlas bleeding. tune as necessary for good results.
	w0 = 1.0f / (float)(atlas_width);
	h0 = 1.0f / (float)(atlas_height);
	div = 1.0f / 128.0f;
	wTol = w0 * div;
	hTol = h0 * div;

	for (int i = 0; i < png_count; ++i)
	{
		cp_integer_image_t* image = images + i;
		cp_atlas_image_t* img_out = imgs_out + i;

		img_out->img_index = image->img_index;
		img_out->w = image->size.x;
		img_out->h = image->size.y;
		img_out->fit = image->fit;

		if (image->fit)
		{
			cp_v2i_t min = image->min;
			cp_v2i_t max = image->max;

			float min_x = (float)min.x * w0 + wTol;
			float min_y = (float)min.y * h0 + hTol;
			float max_x = (float)max.x * w0 - wTol;
			float max_y = (float)max.y * h0 - hTol;

			// flip image on y axis
			if (CUTE_PNG_ATLAS_FLIP_Y_AXIS_FOR_UV)
			{
				float tmp = min_y;
				min_y = max_y;
				max_y = tmp;
			}

			img_out->minx = min_x;
			img_out->miny = min_y;
			img_out->maxx = max_x;
			img_out->maxy = max_y;
		}
	}

	CUTE_PNG_FREE(nodes);
	return atlas_image;

cp_err:
	CUTE_PNG_FREE(atlas_pixels);
	CUTE_PNG_FREE(nodes);
	atlas_image.pix = 0;
	return atlas_image;
}

int cp_default_save_atlas(const char* out_path_image, const char* out_path_atlas_txt, const cp_image_t* atlas, const cp_atlas_image_t* imgs, int img_count, const char** names)
{
	CUTE_PNG_FILE* fp = CUTE_PNG_FOPEN(out_path_atlas_txt, "wt");
	CUTE_PNG_CHECK(fp, "unable to open out_path_atlas_txt in cp_default_save_atlas");

	CUTE_PNG_FPRINTF(fp, "%s\n%d\n\n", out_path_image, img_count);

	for (int i = 0; i < img_count; ++i)
	{
		const cp_atlas_image_t* image = imgs + i;
		const char* name = names ? names[image->img_index] : 0;

		if (image->fit)
		{
			int width = image->w;
			int height = image->h;
			float min_x = image->minx;
			float min_y = image->miny;
			float max_x = image->maxx;
			float max_y = image->maxy;

			if (name) CUTE_PNG_FPRINTF(fp, "{ \"%s\", w = %d, h = %d, u = { %.10f, %.10f }, v = { %.10f, %.10f } }\n", name, width, height, min_x, min_y, max_x, max_y);
			else CUTE_PNG_FPRINTF(fp, "{ w = %d, h = %d, u = { %.10f, %.10f }, v = { %.10f, %.10f } }\n", width, height, min_x, min_y, max_x, max_y);
		}
	}

	// Save atlas image PNG to disk
	CUTE_PNG_CHECK(cp_save_png(out_path_image, atlas), "failed to save atlas image to disk");

cp_err:
	CUTE_PNG_FCLOSE(fp);
	return 0;
}

#endif // CUTE_PNG_IMPLEMENTATION_ONCE
#endif // CUTE_PNG_IMPLEMENTATION

/*
	------------------------------------------------------------------------------
	This software is available under 2 licenses - you may choose the one you like.
	------------------------------------------------------------------------------
	ALTERNATIVE A - zlib license
	Copyright (c) 2019 Randy Gaul http://www.randygaul.net
	This software is provided 'as-is', without any express or implied warranty.
	In no event will the authors be held liable for any damages arising from
	the use of this software.
	Permission is granted to anyone to use this software for any purpose,
	including commercial applications, and to alter it and redistribute it
	freely, subject to the following restrictions:
	  1. The origin of this software must not be misrepresented; you must not
	     claim that you wrote the original software. If you use this software
	     in a product, an acknowledgment in the product documentation would be
	     appreciated but is not required.
	  2. Altered source versions must be plainly marked as such, and must not
	     be misrepresented as being the original software.
	  3. This notice may not be removed or altered from any source distribution.
	------------------------------------------------------------------------------
	ALTERNATIVE B - Public Domain (www.unlicense.org)
	This is free and unencumbered software released into the public domain.
	Anyone is free to copy, modify, publish, use, compile, sell, or distribute this 
	software, either in source code form or as a compiled binary, for any purpose, 
	commercial or non-commercial, and by any means.
	In jurisdictions that recognize copyright laws, the author or authors of this 
	software dedicate any and all copyright interest in the software to the public 
	domain. We make this dedication for the benefit of the public at large and to 
	the detriment of our heirs and successors. We intend this dedication to be an 
	overt act of relinquishment in perpetuity of all present and future rights to 
	this software under copyright law.
	THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR 
	IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, 
	FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE 
	AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN 
	ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION 
	WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
	------------------------------------------------------------------------------
*/
//FILE_END
//FILE_START:deps/qoi.h
/*

Copyright (c) 2021, Dominic Szablewski - https://phoboslab.org
SPDX-License-Identifier: MIT


QOI - The "Quite OK Image" format for fast, lossless image compression

-- About

QOI encodes and decodes images in a lossless format. Compared to stb_image and
stb_image_write QOI offers 20x-50x faster encoding, 3x-4x faster decoding and
20% better compression.


-- Synopsis

// Define `QOI_IMPLEMENTATION` in *one* C/C++ file before including this
// library to create the implementation.

#define QOI_IMPLEMENTATION
#include "qoi.h"

// Encode and store an RGBA buffer to the file system. The qoi_desc describes
// the input pixel data.
qoi_write("image_new.qoi", rgba_pixels, &(qoi_desc){
	.width = 1920,
	.height = 1080,
	.channels = 4,
	.colorspace = QOI_SRGB
});

// Load and decode a QOI image from the file system into a 32bbp RGBA buffer.
// The qoi_desc struct will be filled with the width, height, number of channels
// and colorspace read from the file header.
qoi_desc desc;
void *rgba_pixels = qoi_read("image.qoi", &desc, 4);



-- Documentation

This library provides the following functions;
- qoi_read    -- read and decode a QOI file
- qoi_decode  -- decode the raw bytes of a QOI image from memory
- qoi_write   -- encode and write a QOI file
- qoi_encode  -- encode an rgba buffer into a QOI image in memory

See the function declaration below for the signature and more information.

If you don't want/need the qoi_read and qoi_write functions, you can define
QOI_NO_STDIO before including this library.

This library uses malloc() and free(). To supply your own malloc implementation
you can define QOI_MALLOC and QOI_FREE before including this library.

This library uses memset() to zero-initialize the index. To supply your own
implementation you can define QOI_ZEROARR before including this library.


-- Data Format

A QOI file has a 14 byte header, followed by any number of data "chunks" and an
8-byte end marker.

struct qoi_header_t {
	char     magic[4];   // magic bytes "qoif"
	uint32_t width;      // image width in pixels (BE)
	uint32_t height;     // image height in pixels (BE)
	uint8_t  channels;   // 3 = RGB, 4 = RGBA
	uint8_t  colorspace; // 0 = sRGB with linear alpha, 1 = all channels linear
};

Images are encoded row by row, left to right, top to bottom. The decoder and
encoder start with {r: 0, g: 0, b: 0, a: 255} as the previous pixel value. An
image is complete when all pixels specified by width * height have been covered.

Pixels are encoded as
 - a run of the previous pixel
 - an index into an array of previously seen pixels
 - a difference to the previous pixel value in r,g,b
 - full r,g,b or r,g,b,a values

The color channels are assumed to not be premultiplied with the alpha channel
("un-premultiplied alpha").

A running array[64] (zero-initialized) of previously seen pixel values is
maintained by the encoder and decoder. Each pixel that is seen by the encoder
and decoder is put into this array at the position formed by a hash function of
the color value. In the encoder, if the pixel value at the index matches the
current pixel, this index position is written to the stream as QOI_OP_INDEX.
The hash function for the index is:

	index_position = (r * 3 + g * 5 + b * 7 + a * 11) % 64

Each chunk starts with a 2- or 8-bit tag, followed by a number of data bits. The
bit length of chunks is divisible by 8 - i.e. all chunks are byte aligned. All
values encoded in these data bits have the most significant bit on the left.

The 8-bit tags have precedence over the 2-bit tags. A decoder must check for the
presence of an 8-bit tag first.

The byte stream's end is marked with 7 0x00 bytes followed a single 0x01 byte.


The possible chunks are:


.- QOI_OP_INDEX ----------.
|         Byte[0]         |
|  7  6  5  4  3  2  1  0 |
|-------+-----------------|
|  0  0 |     index       |
`-------------------------`
2-bit tag b00
6-bit index into the color index array: 0..63

A valid encoder must not issue 2 or more consecutive QOI_OP_INDEX chunks to the
same index. QOI_OP_RUN should be used instead.


.- QOI_OP_DIFF -----------.
|         Byte[0]         |
|  7  6  5  4  3  2  1  0 |
|-------+-----+-----+-----|
|  0  1 |  dr |  dg |  db |
`-------------------------`
2-bit tag b01
2-bit   red channel difference from the previous pixel between -2..1
2-bit green channel difference from the previous pixel between -2..1
2-bit  blue channel difference from the previous pixel between -2..1

The difference to the current channel values are using a wraparound operation,
so "1 - 2" will result in 255, while "255 + 1" will result in 0.

Values are stored as unsigned integers with a bias of 2. E.g. -2 is stored as
0 (b00). 1 is stored as 3 (b11).

The alpha value remains unchanged from the previous pixel.


.- QOI_OP_LUMA -------------------------------------.
|         Byte[0]         |         Byte[1]         |
|  7  6  5  4  3  2  1  0 |  7  6  5  4  3  2  1  0 |
|-------+-----------------+-------------+-----------|
|  1  0 |  green diff     |   dr - dg   |  db - dg  |
`---------------------------------------------------`
2-bit tag b10
6-bit green channel difference from the previous pixel -32..31
4-bit   red channel difference minus green channel difference -8..7
4-bit  blue channel difference minus green channel difference -8..7

The green channel is used to indicate the general direction of change and is
encoded in 6 bits. The red and blue channels (dr and db) base their diffs off
of the green channel difference and are encoded in 4 bits. I.e.:
	dr_dg = (cur_px.r - prev_px.r) - (cur_px.g - prev_px.g)
	db_dg = (cur_px.b - prev_px.b) - (cur_px.g - prev_px.g)

The difference to the current channel values are using a wraparound operation,
so "10 - 13" will result in 253, while "250 + 7" will result in 1.

Values are stored as unsigned integers with a bias of 32 for the green channel
and a bias of 8 for the red and blue channel.

The alpha value remains unchanged from the previous pixel.


.- QOI_OP_RUN ------------.
|         Byte[0]         |
|  7  6  5  4  3  2  1  0 |
|-------+-----------------|
|  1  1 |       run       |
`-------------------------`
2-bit tag b11
6-bit run-length repeating the previous pixel: 1..62

The run-length is stored with a bias of -1. Note that the run-lengths 63 and 64
(b111110 and b111111) are illegal as they are occupied by the QOI_OP_RGB and
QOI_OP_RGBA tags.


.- QOI_OP_RGB ------------------------------------------.
|         Byte[0]         | Byte[1] | Byte[2] | Byte[3] |
|  7  6  5  4  3  2  1  0 | 7 .. 0  | 7 .. 0  | 7 .. 0  |
|-------------------------+---------+---------+---------|
|  1  1  1  1  1  1  1  0 |   red   |  green  |  blue   |
`-------------------------------------------------------`
8-bit tag b11111110
8-bit   red channel value
8-bit green channel value
8-bit  blue channel value

The alpha value remains unchanged from the previous pixel.


.- QOI_OP_RGBA ---------------------------------------------------.
|         Byte[0]         | Byte[1] | Byte[2] | Byte[3] | Byte[4] |
|  7  6  5  4  3  2  1  0 | 7 .. 0  | 7 .. 0  | 7 .. 0  | 7 .. 0  |
|-------------------------+---------+---------+---------+---------|
|  1  1  1  1  1  1  1  1 |   red   |  green  |  blue   |  alpha  |
`-----------------------------------------------------------------`
8-bit tag b11111111
8-bit   red channel value
8-bit green channel value
8-bit  blue channel value
8-bit alpha channel value

*/


/* -----------------------------------------------------------------------------
Header - Public functions */

#ifndef QOI_H
#define QOI_H

#ifdef __cplusplus
extern "C" {
#endif

/* A pointer to a qoi_desc struct has to be supplied to all of qoi's functions.
It describes either the input format (for qoi_write and qoi_encode), or is
filled with the description read from the file header (for qoi_read and
qoi_decode).

The colorspace in this qoi_desc is an enum where
	0 = sRGB, i.e. gamma scaled RGB channels and a linear alpha channel
	1 = all channels are linear
You may use the constants QOI_SRGB or QOI_LINEAR. The colorspace is purely
informative. It will be saved to the file header, but does not affect
how chunks are en-/decoded. */

#define QOI_SRGB   0
#define QOI_LINEAR 1

typedef struct {
	unsigned int width;
	unsigned int height;
	unsigned char channels;
	unsigned char colorspace;
} qoi_desc;

#ifndef QOI_NO_STDIO

/* Encode raw RGB or RGBA pixels into a QOI image and write it to the file
system. The qoi_desc struct must be filled with the image width, height,
number of channels (3 = RGB, 4 = RGBA) and the colorspace.

The function returns 0 on failure (invalid parameters, or fopen or malloc
failed) or the number of bytes written on success. */

int qoi_write(const char *filename, const void *data, const qoi_desc *desc);


/* Read and decode a QOI image from the file system. If channels is 0, the
number of channels from the file header is used. If channels is 3 or 4 the
output format will be forced into this number of channels.

The function either returns NULL on failure (invalid data, or malloc or fopen
failed) or a pointer to the decoded pixels. On success, the qoi_desc struct
will be filled with the description from the file header.

The returned pixel data should be free()d after use. */

void *qoi_read(const char *filename, qoi_desc *desc, int channels);

#endif /* QOI_NO_STDIO */


/* Encode raw RGB or RGBA pixels into a QOI image in memory.

The function either returns NULL on failure (invalid parameters or malloc
failed) or a pointer to the encoded data on success. On success the out_len
is set to the size in bytes of the encoded data.

The returned qoi data should be free()d after use. */

void *qoi_encode(const void *data, const qoi_desc *desc, int *out_len);


/* Decode a QOI image from memory.

The function either returns NULL on failure (invalid parameters or malloc
failed) or a pointer to the decoded pixels. On success, the qoi_desc struct
is filled with the description from the file header.

The returned pixel data should be free()d after use. */

void *qoi_decode(const void *data, int size, qoi_desc *desc, int channels);


#ifdef __cplusplus
}
#endif
#endif /* QOI_H */


/* -----------------------------------------------------------------------------
Implementation */

#ifdef QOI_IMPLEMENTATION
#include <stdlib.h>
#include <string.h>

#ifndef QOI_MALLOC
	#define QOI_MALLOC(sz) malloc(sz)
	#define QOI_FREE(p)    free(p)
#endif
#ifndef QOI_ZEROARR
	#define QOI_ZEROARR(a) memset((a),0,sizeof(a))
#endif

#define QOI_OP_INDEX  0x00 /* 00xxxxxx */
#define QOI_OP_DIFF   0x40 /* 01xxxxxx */
#define QOI_OP_LUMA   0x80 /* 10xxxxxx */
#define QOI_OP_RUN    0xc0 /* 11xxxxxx */
#define QOI_OP_RGB    0xfe /* 11111110 */
#define QOI_OP_RGBA   0xff /* 11111111 */

#define QOI_MASK_2    0xc0 /* 11000000 */

#define QOI_COLOR_HASH(C) (C.rgba.r*3 + C.rgba.g*5 + C.rgba.b*7 + C.rgba.a*11)
#define QOI_MAGIC \
	(((unsigned int)'q') << 24 | ((unsigned int)'o') << 16 | \
	 ((unsigned int)'i') <<  8 | ((unsigned int)'f'))
#define QOI_HEADER_SIZE 14

/* 2GB is the max file size that this implementation can safely handle. We guard
against anything larger than that, assuming the worst case with 5 bytes per
pixel, rounded down to a nice clean value. 400 million pixels ought to be
enough for anybody. */
#define QOI_PIXELS_MAX ((unsigned int)400000000)

typedef union {
	struct { unsigned char r, g, b, a; } rgba;
	unsigned int v;
} qoi_rgba_t;

static const unsigned char qoi_padding[8] = {0,0,0,0,0,0,0,1};

static void qoi_write_32(unsigned char *bytes, int *p, unsigned int v) {
	bytes[(*p)++] = (0xff000000 & v) >> 24;
	bytes[(*p)++] = (0x00ff0000 & v) >> 16;
	bytes[(*p)++] = (0x0000ff00 & v) >> 8;
	bytes[(*p)++] = (0x000000ff & v);
}

static unsigned int qoi_read_32(const unsigned char *bytes, int *p) {
	unsigned int a = bytes[(*p)++];
	unsigned int b = bytes[(*p)++];
	unsigned int c = bytes[(*p)++];
	unsigned int d = bytes[(*p)++];
	return a << 24 | b << 16 | c << 8 | d;
}

void *qoi_encode(const void *data, const qoi_desc *desc, int *out_len) {
	int i, max_size, p, run;
	int px_len, px_end, px_pos, channels;
	unsigned char *bytes;
	const unsigned char *pixels;
	qoi_rgba_t index[64];
	qoi_rgba_t px, px_prev;

	if (
		data == NULL || out_len == NULL || desc == NULL ||
		desc->width == 0 || desc->height == 0 ||
		desc->channels < 3 || desc->channels > 4 ||
		desc->colorspace > 1 ||
		desc->height >= QOI_PIXELS_MAX / desc->width
	) {
		return NULL;
	}

	max_size =
		desc->width * desc->height * (desc->channels + 1) +
		QOI_HEADER_SIZE + sizeof(qoi_padding);

	p = 0;
	bytes = (unsigned char *) QOI_MALLOC(max_size);
	if (!bytes) {
		return NULL;
	}

	qoi_write_32(bytes, &p, QOI_MAGIC);
	qoi_write_32(bytes, &p, desc->width);
	qoi_write_32(bytes, &p, desc->height);
	bytes[p++] = desc->channels;
	bytes[p++] = desc->colorspace;


	pixels = (const unsigned char *)data;

	QOI_ZEROARR(index);

	run = 0;
	px_prev.rgba.r = 0;
	px_prev.rgba.g = 0;
	px_prev.rgba.b = 0;
	px_prev.rgba.a = 255;
	px = px_prev;

	px_len = desc->width * desc->height * desc->channels;
	px_end = px_len - desc->channels;
	channels = desc->channels;

	for (px_pos = 0; px_pos < px_len; px_pos += channels) {
		px.rgba.r = pixels[px_pos + 0];
		px.rgba.g = pixels[px_pos + 1];
		px.rgba.b = pixels[px_pos + 2];

		if (channels == 4) {
			px.rgba.a = pixels[px_pos + 3];
		}

		if (px.v == px_prev.v) {
			run++;
			if (run == 62 || px_pos == px_end) {
				bytes[p++] = QOI_OP_RUN | (run - 1);
				run = 0;
			}
		}
		else {
			int index_pos;

			if (run > 0) {
				bytes[p++] = QOI_OP_RUN | (run - 1);
				run = 0;
			}

			index_pos = QOI_COLOR_HASH(px) & (64 - 1);

			if (index[index_pos].v == px.v) {
				bytes[p++] = QOI_OP_INDEX | index_pos;
			}
			else {
				index[index_pos] = px;

				if (px.rgba.a == px_prev.rgba.a) {
					signed char vr = px.rgba.r - px_prev.rgba.r;
					signed char vg = px.rgba.g - px_prev.rgba.g;
					signed char vb = px.rgba.b - px_prev.rgba.b;

					signed char vg_r = vr - vg;
					signed char vg_b = vb - vg;

					if (
						vr > -3 && vr < 2 &&
						vg > -3 && vg < 2 &&
						vb > -3 && vb < 2
					) {
						bytes[p++] = QOI_OP_DIFF | (vr + 2) << 4 | (vg + 2) << 2 | (vb + 2);
					}
					else if (
						vg_r >  -9 && vg_r <  8 &&
						vg   > -33 && vg   < 32 &&
						vg_b >  -9 && vg_b <  8
					) {
						bytes[p++] = QOI_OP_LUMA     | (vg   + 32);
						bytes[p++] = (vg_r + 8) << 4 | (vg_b +  8);
					}
					else {
						bytes[p++] = QOI_OP_RGB;
						bytes[p++] = px.rgba.r;
						bytes[p++] = px.rgba.g;
						bytes[p++] = px.rgba.b;
					}
				}
				else {
					bytes[p++] = QOI_OP_RGBA;
					bytes[p++] = px.rgba.r;
					bytes[p++] = px.rgba.g;
					bytes[p++] = px.rgba.b;
					bytes[p++] = px.rgba.a;
				}
			}
		}
		px_prev = px;
	}

	for (i = 0; i < (int)sizeof(qoi_padding); i++) {
		bytes[p++] = qoi_padding[i];
	}

	*out_len = p;
	return bytes;
}

void *qoi_decode(const void *data, int size, qoi_desc *desc, int channels) {
	const unsigned char *bytes;
	unsigned int header_magic;
	unsigned char *pixels;
	qoi_rgba_t index[64];
	qoi_rgba_t px;
	int px_len, chunks_len, px_pos;
	int p = 0, run = 0;

	if (
		data == NULL || desc == NULL ||
		(channels != 0 && channels != 3 && channels != 4) ||
		size < QOI_HEADER_SIZE + (int)sizeof(qoi_padding)
	) {
		return NULL;
	}

	bytes = (const unsigned char *)data;

	header_magic = qoi_read_32(bytes, &p);
	desc->width = qoi_read_32(bytes, &p);
	desc->height = qoi_read_32(bytes, &p);
	desc->channels = bytes[p++];
	desc->colorspace = bytes[p++];

	if (
		desc->width == 0 || desc->height == 0 ||
		desc->channels < 3 || desc->channels > 4 ||
		desc->colorspace > 1 ||
		header_magic != QOI_MAGIC ||
		desc->height >= QOI_PIXELS_MAX / desc->width
	) {
		return NULL;
	}

	if (channels == 0) {
		channels = desc->channels;
	}

	px_len = desc->width * desc->height * channels;
	pixels = (unsigned char *) QOI_MALLOC(px_len);
	if (!pixels) {
		return NULL;
	}

	QOI_ZEROARR(index);
	px.rgba.r = 0;
	px.rgba.g = 0;
	px.rgba.b = 0;
	px.rgba.a = 255;

	chunks_len = size - (int)sizeof(qoi_padding);
	for (px_pos = 0; px_pos < px_len; px_pos += channels) {
		if (run > 0) {
			run--;
		}
		else if (p < chunks_len) {
			int b1 = bytes[p++];

			if (b1 == QOI_OP_RGB) {
				px.rgba.r = bytes[p++];
				px.rgba.g = bytes[p++];
				px.rgba.b = bytes[p++];
			}
			else if (b1 == QOI_OP_RGBA) {
				px.rgba.r = bytes[p++];
				px.rgba.g = bytes[p++];
				px.rgba.b = bytes[p++];
				px.rgba.a = bytes[p++];
			}
			else if ((b1 & QOI_MASK_2) == QOI_OP_INDEX) {
				px = index[b1];
			}
			else if ((b1 & QOI_MASK_2) == QOI_OP_DIFF) {
				px.rgba.r += ((b1 >> 4) & 0x03) - 2;
				px.rgba.g += ((b1 >> 2) & 0x03) - 2;
				px.rgba.b += ( b1       & 0x03) - 2;
			}
			else if ((b1 & QOI_MASK_2) == QOI_OP_LUMA) {
				int b2 = bytes[p++];
				int vg = (b1 & 0x3f) - 32;
				px.rgba.r += vg - 8 + ((b2 >> 4) & 0x0f);
				px.rgba.g += vg;
				px.rgba.b += vg - 8 +  (b2       & 0x0f);
			}
			else if ((b1 & QOI_MASK_2) == QOI_OP_RUN) {
				run = (b1 & 0x3f);
			}

			index[QOI_COLOR_HASH(px) & (64 - 1)] = px;
		}

		pixels[px_pos + 0] = px.rgba.r;
		pixels[px_pos + 1] = px.rgba.g;
		pixels[px_pos + 2] = px.rgba.b;
		
		if (channels == 4) {
			pixels[px_pos + 3] = px.rgba.a;
		}
	}

	return pixels;
}

#ifndef QOI_NO_STDIO
#include <stdio.h>

int qoi_write(const char *filename, const void *data, const qoi_desc *desc) {
	FILE *f = fopen(filename, "wb");
	int size, err;
	void *encoded;

	if (!f) {
		return 0;
	}

	encoded = qoi_encode(data, desc, &size);
	if (!encoded) {
		fclose(f);
		return 0;
	}

	fwrite(encoded, 1, size, f);
	fflush(f);
	err = ferror(f);
	fclose(f);

	QOI_FREE(encoded);
	return err ? 0 : size;
}

void *qoi_read(const char *filename, qoi_desc *desc, int channels) {
	FILE *f = fopen(filename, "rb");
	int size, bytes_read;
	void *pixels, *data;

	if (!f) {
		return NULL;
	}

	fseek(f, 0, SEEK_END);
	size = ftell(f);
	if (size <= 0 || fseek(f, 0, SEEK_SET) != 0) {
		fclose(f);
		return NULL;
	}

	data = QOI_MALLOC(size);
	if (!data) {
		fclose(f);
		return NULL;
	}

	bytes_read = fread(data, 1, size, f);
	fclose(f);
	pixels = (bytes_read != size) ? NULL : qoi_decode(data, bytes_read, desc, channels);
	QOI_FREE(data);
	return pixels;
}

#endif /* QOI_NO_STDIO */
#endif /* QOI_IMPLEMENTATION */
//FILE_END
//FILE_START:deps/m3d.h
/*
 * m3d.h
 * https://gitlab.com/bztsrc/model3d
 *
 * Copyright (C) 2020 bzt (bztsrc@gitlab)
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
 * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
 * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * @brief ANSI C89 / C++11 single header importer / exporter SDK for the Model 3D (.M3D) format
 * https://gitlab.com/bztsrc/model3d
 *
 * PNG decompressor included from (with minor modifications to make it C89 valid):
 *  stb_image - v2.13 - public domain image loader - http://nothings.org/stb_image.h
 *
 * @version: 1.0.0
 */

#ifndef _M3D_H_
#define _M3D_H_

#ifdef  __cplusplus
extern "C" {
#endif

#include <stdint.h>

/*** configuration ***/
#ifndef M3D_MALLOC
# define M3D_MALLOC(sz)     malloc(sz)
#endif
#ifndef M3D_REALLOC
# define M3D_REALLOC(p,nsz) realloc(p,nsz)
#endif
#ifndef M3D_FREE
# define M3D_FREE(p)        free(p)
#endif
#ifndef M3D_LOG
# define M3D_LOG(x)
#endif
#ifndef M3D_APIVERSION
#define M3D_APIVERSION      0x0100
#ifndef M3D_DOUBLE
typedef float M3D_FLOAT;
#ifndef M3D_EPSILON
/* carefully choosen for IEEE 754 don't change */
#define M3D_EPSILON ((M3D_FLOAT)1e-7)
#endif
#else
typedef double M3D_FLOAT;
#ifndef M3D_EPSILON
#define M3D_EPSILON ((M3D_FLOAT)1e-14)
#endif
#endif
#if !defined(M3D_SMALLINDEX)
typedef uint32_t M3D_INDEX;
typedef uint16_t M3D_VOXEL;
#define M3D_UNDEF 0xffffffff
#define M3D_INDEXMAX 0xfffffffe
#define M3D_VOXUNDEF 0xffff
#define M3D_VOXCLEAR 0xfffe
#else
typedef uint16_t M3D_INDEX;
typedef uint8_t M3D_VOXEL;
#define M3D_UNDEF 0xffff
#define M3D_INDEXMAX 0xfffe
#define M3D_VOXUNDEF 0xff
#define M3D_VOXCLEAR 0xfe
#endif
#define M3D_NOTDEFINED 0xffffffff
#ifndef M3D_NUMBONE
#define M3D_NUMBONE 4
#endif
#ifndef M3D_BONEMAXLEVEL
#define M3D_BONEMAXLEVEL 64
#endif
#ifndef _MSC_VER
#ifndef _inline
#define _inline __inline__
#endif
#define _pack __attribute__((packed))
#define _unused __attribute__((unused))
#else
#define _inline
#define _pack
#define _unused __pragma(warning(suppress:4100))
#endif
#ifndef  __cplusplus
#define _register register
#else
#define _register
#endif

/*** File format structures ***/

/**
 * M3D file format structure
 *  3DMO m3dchunk_t file header chunk, may followed by compressed data
 *  PRVW preview chunk (optional)
 *  HEAD m3dhdr_t model header chunk
 *  n x m3dchunk_t more chunks follow
 *      CMAP color map chunk (optional)
 *      TMAP texture map chunk (optional)
 *      VRTS vertex data chunk (optional if it's a material library)
 *      BONE bind-pose skeleton, bone hierarchy chunk (optional)
 *          n x m3db_t contains propably more, but at least one bone
 *          n x m3ds_t skin group records
 *      MTRL* material chunk(s), can be more (optional)
 *          n x m3dp_t each material contains propapbly more, but at least one property
 *                     the properties are configurable with a static array, see m3d_propertytypes
 *      n x m3dchunk_t at least one, but maybe more face chunks
 *          PROC* procedural face, or
 *          MESH* triangle mesh (vertex index list) or
 *          VOXT, VOXD* voxel image (converted to mesh) or
 *          SHPE* mathematical shapes like parameterized surfaces
 *      LBLS* annotation label chunks, can be more (optional)
 *      ACTN* action chunk(s), animation-pose skeletons, can be more (optional)
 *          n x m3dfr_t each action contains probably more, but at least one frame
 *              n x m3dtr_t each frame contains probably more, but at least one transformation
 *      ASET* inlined asset chunk(s), can be more (optional)
 *  OMD3 end chunk
 *
 * Typical chunks for a game engine: 3DMO, HEAD, CMAP, TMAP, VRTS, BONE, MTRL, MESH, ACTN, OMD3
 * Typical chunks for distibution:   3DMO, PRVW, HEAD, CMAP, TMAP, VRTS, BONE, MTRL, MESH, ACTN, ASET, OMD3
 * Typical chunks for voxel image:   3DMO, HEAD, CMAP, MTRL, VOXT, VOXD, VOXD, VOXD, OMD3
 * Typical chunks for CAD software:  3DMO, PRVW, HEAD, CMAP, TMAP, VRTS, MTRL, SHPE, LBLS, OMD3
 */
#ifdef _MSC_VER
#pragma pack(push)
#pragma pack(1)
#endif

typedef struct {
    char magic[4];
    uint32_t length;
    float scale; /* deliberately not M3D_FLOAT */
    uint32_t types;
} _pack m3dhdr_t;

typedef struct {
    char magic[4];
    uint32_t length;
} _pack m3dchunk_t;

#ifdef _MSC_VER
#pragma pack(pop)
#endif

/*** in-memory model structure ***/

/* textmap entry */
typedef struct {
    M3D_FLOAT u;
    M3D_FLOAT v;
} m3dti_t;
#define m3d_textureindex_t m3dti_t

/* texture */
typedef struct {
    char *name;                 /* texture name */
    uint8_t *d;                 /* pixels data */
    uint16_t w;                 /* width */
    uint16_t h;                 /* height */
    uint8_t f;                  /* format, 1 = grayscale, 2 = grayscale+alpha, 3 = rgb, 4 = rgba */
} m3dtx_t;
#define m3d_texturedata_t m3dtx_t

typedef struct {
    M3D_INDEX vertexid;
    M3D_FLOAT weight;
} m3dw_t;
#define m3d_weight_t m3dw_t

/* bone entry */
typedef struct {
    M3D_INDEX parent;           /* parent bone index */
    char *name;                 /* name for this bone */
    M3D_INDEX pos;              /* vertex index position */
    M3D_INDEX ori;              /* vertex index orientation (quaternion) */
    M3D_INDEX numweight;        /* number of controlled vertices */
    m3dw_t *weight;             /* weights for those vertices */
    M3D_FLOAT mat4[16];         /* transformation matrix */
} m3db_t;
#define m3d_bone_t m3db_t

/* skin: bone per vertex entry */
typedef struct {
    M3D_INDEX boneid[M3D_NUMBONE];
    M3D_FLOAT weight[M3D_NUMBONE];
} m3ds_t;
#define m3d_skin_t m3ds_t

/* vertex entry */
typedef struct {
    M3D_FLOAT x;                /* 3D coordinates and weight */
    M3D_FLOAT y;
    M3D_FLOAT z;
    M3D_FLOAT w;
    uint32_t color;             /* default vertex color */
    M3D_INDEX skinid;           /* skin index */
#ifdef M3D_VERTEXTYPE
    uint8_t type;
#endif
} m3dv_t;
#define m3d_vertex_t m3dv_t

/* material property formats */
enum {
    m3dpf_color,
    m3dpf_uint8,
    m3dpf_uint16,
    m3dpf_uint32,
    m3dpf_float,
    m3dpf_map
};
typedef struct {
    uint8_t format;
    uint8_t id;
#ifdef M3D_ASCII
#define M3D_PROPERTYDEF(f,i,n) { (f), (i), (char*)(n) }
    char *key;
#endif
#ifndef M3D_ASCII
#define M3D_PROPERTYDEF(f,i,n) { (f), (i) }
#endif
} m3dpd_t;

/* material property types */
/* You shouldn't change the first 8 display and first 4 physical property. Assign the rest as you like. */
enum {
    m3dp_Kd = 0,                /* scalar display properties */
    m3dp_Ka,
    m3dp_Ks,
    m3dp_Ns,
    m3dp_Ke,
    m3dp_Tf,
    m3dp_Km,
    m3dp_d,
    m3dp_il,

    m3dp_Pr = 64,               /* scalar physical properties */
    m3dp_Pm,
    m3dp_Ps,
    m3dp_Ni,
    m3dp_Nt,

    m3dp_map_Kd = 128,          /* textured display map properties */
    m3dp_map_Ka,
    m3dp_map_Ks,
    m3dp_map_Ns,
    m3dp_map_Ke,
    m3dp_map_Tf,
    m3dp_map_Km, /* bump map */
    m3dp_map_D,
    m3dp_map_N,  /* normal map */

    m3dp_map_Pr = 192,          /* textured physical map properties */
    m3dp_map_Pm,
    m3dp_map_Ps,
    m3dp_map_Ni,
    m3dp_map_Nt
};
enum {                          /* aliases */
    m3dp_bump = m3dp_map_Km,
    m3dp_map_il = m3dp_map_N,
    m3dp_refl = m3dp_map_Pm
};

/* material property */
typedef struct {
    uint8_t type;               /* property type, see "m3dp_*" enumeration */
    union {
        uint32_t color;         /* if value is a color, m3dpf_color */
        uint32_t num;           /* if value is a number, m3dpf_uint8, m3pf_uint16, m3dpf_uint32 */
        float    fnum;          /* if value is a floating point number, m3dpf_float */
        M3D_INDEX textureid;    /* if value is a texture, m3dpf_map */
    } value;
} m3dp_t;
#define m3d_property_t m3dp_t

/* material entry */
typedef struct {
    char *name;                 /* name of the material */
    uint8_t numprop;            /* number of properties */
    m3dp_t *prop;               /* properties array */
} m3dm_t;
#define m3d_material_t m3dm_t

/* face entry */
typedef struct {
    M3D_INDEX materialid;       /* material index */
    M3D_INDEX vertex[3];        /* 3D points of the triangle in CCW order */
    M3D_INDEX normal[3];        /* normal vectors */
    M3D_INDEX texcoord[3];      /* UV coordinates */
#ifdef M3D_VERTEXMAX
    M3D_INDEX paramid;          /* parameter index */
    M3D_INDEX vertmax[3];       /* maximum 3D points of the triangle in CCW order */
#endif
} m3df_t;
#define m3d_face_t m3df_t

typedef struct {
    uint16_t count;
    char *name;
} m3dvi_t;
#define m3d_voxelitem_t m3dvi_t
#define m3d_parameter_t m3dvi_t

/* voxel types (voxel palette) */
typedef struct {
    char *name;                 /* technical name of the voxel */
    uint8_t rotation;           /* rotation info */
    uint16_t voxshape;          /* voxel shape */
    M3D_INDEX materialid;       /* material index */
    uint32_t color;             /* default voxel color */
    M3D_INDEX skinid;           /* skin index */
    uint8_t numitem;            /* number of sub-voxels */
    m3dvi_t *item;              /* list of sub-voxels */
} m3dvt_t;
#define m3d_voxeltype_t m3dvt_t

/* voxel data blocks */
typedef struct {
    char *name;                 /* name of the block */
    int32_t x, y, z;            /* position */
    uint32_t w, h, d;           /* dimension */
    uint8_t uncertain;          /* probability */
    uint8_t groupid;            /* block group id */
    M3D_VOXEL *data;            /* voxel data, indices to voxel type */
} m3dvx_t;
#define m3d_voxel_t m3dvx_t

/* shape command types. must match the row in m3d_commandtypes */
enum {
    /* special commands */
    m3dc_use = 0,               /* use material */
    m3dc_inc,                   /* include another shape */
    m3dc_mesh,                  /* include part of polygon mesh */
    /* approximations */
    m3dc_div,                   /* subdivision by constant resolution for both u, v */
    m3dc_sub,                   /* subdivision by constant, different for u and v */
    m3dc_len,                   /* spacial subdivision by maxlength */
    m3dc_dist,                  /* subdivision by maxdistance and maxangle */
    /* modifiers */
    m3dc_degu,                  /* degree for both u, v */
    m3dc_deg,                   /* separate degree for u and v */
    m3dc_rangeu,                /* range for u */
    m3dc_range,                 /* range for u and v */
    m3dc_paru,                  /* u parameters (knots) */
    m3dc_parv,                  /* v parameters */
    m3dc_trim,                  /* outer trimming curve */
    m3dc_hole,                  /* inner trimming curve */
    m3dc_scrv,                  /* spacial curve */
    m3dc_sp,                    /* special points */
    /* helper curves */
    m3dc_bez1,                  /* Bezier 1D */
    m3dc_bsp1,                  /* B-spline 1D */
    m3dc_bez2,                  /* bezier 2D */
    m3dc_bsp2,                  /* B-spline 2D */
    /* surfaces */
    m3dc_bezun,                 /* Bezier 3D with control, UV, normal */
    m3dc_bezu,                  /* with control and UV */
    m3dc_bezn,                  /* with control and normal */
    m3dc_bez,                   /* control points only */
    m3dc_nurbsun,               /* B-spline 3D */
    m3dc_nurbsu,
    m3dc_nurbsn,
    m3dc_nurbs,
    m3dc_conn,                 /* connect surfaces */
    /* geometrical */
    m3dc_line,
    m3dc_polygon,
    m3dc_circle,
    m3dc_cylinder,
    m3dc_shpere,
    m3dc_torus,
    m3dc_cone,
    m3dc_cube
};

/* shape command argument types */
enum {
    m3dcp_mi_t = 1,             /* material index */
    m3dcp_hi_t,                 /* shape index */
    m3dcp_fi_t,                 /* face index */
    m3dcp_ti_t,                 /* texture map index */
    m3dcp_vi_t,                 /* vertex index */
    m3dcp_qi_t,                 /* vertex index for quaternions */
    m3dcp_vc_t,                 /* coordinate or radius, float scalar */
    m3dcp_i1_t,                 /* int8 scalar */
    m3dcp_i2_t,                 /* int16 scalar */
    m3dcp_i4_t,                 /* int32 scalar */
    m3dcp_va_t                  /* variadic arguments */
};

#define M3D_CMDMAXARG 8         /* if you increase this, add more arguments to the macro below */
typedef struct {
#ifdef M3D_ASCII
#define M3D_CMDDEF(t,n,p,a,b,c,d,e,f,g,h) { (char*)(n), (p), { (a), (b), (c), (d), (e), (f), (g), (h) } }
    char *key;
#endif
#ifndef M3D_ASCII
#define M3D_CMDDEF(t,n,p,a,b,c,d,e,f,g,h) { (p), { (a), (b), (c), (d), (e), (f), (g), (h) } }
#endif
    uint8_t p;
    uint8_t a[M3D_CMDMAXARG];
} m3dcd_t;

/* shape command */
typedef struct {
    uint16_t type;              /* shape type */
    uint32_t *arg;              /* arguments array */
} m3dc_t;
#define m3d_shapecommand_t m3dc_t

/* shape entry */
typedef struct {
    char *name;                 /* name of the mathematical shape */
    M3D_INDEX group;            /* group this shape belongs to or -1 */
    uint32_t numcmd;            /* number of commands */
    m3dc_t *cmd;                /* commands array */
} m3dh_t;
#define m3d_shape_t m3dh_t

/* label entry */
typedef struct {
    char *name;                 /* name of the annotation layer or NULL */
    char *lang;                 /* language code or NULL */
    char *text;                 /* the label text */
    uint32_t color;             /* color */
    M3D_INDEX vertexid;         /* the vertex the label refers to */
} m3dl_t;
#define m3d_label_t m3dl_t

/* frame transformations / working copy skeleton entry */
typedef struct {
    M3D_INDEX boneid;           /* selects a node in bone hierarchy */
    M3D_INDEX pos;              /* vertex index new position */
    M3D_INDEX ori;              /* vertex index new orientation (quaternion) */
} m3dtr_t;
#define m3d_transform_t m3dtr_t

/* animation frame entry */
typedef struct {
    uint32_t msec;              /* frame's position on the timeline, timestamp */
    M3D_INDEX numtransform;     /* number of transformations in this frame */
    m3dtr_t *transform;         /* transformations */
} m3dfr_t;
#define m3d_frame_t m3dfr_t

/* model action entry */
typedef struct {
    char *name;                 /* name of the action */
    uint32_t durationmsec;      /* duration in millisec (1/1000 sec) */
    M3D_INDEX numframe;         /* number of frames in this animation */
    m3dfr_t *frame;             /* frames array */
} m3da_t;
#define m3d_action_t m3da_t

/* inlined asset */
typedef struct {
    char *name;                 /* asset name (same pointer as in texture[].name) */
    uint8_t *data;              /* compressed asset data */
    uint32_t length;            /* compressed data length */
} m3di_t;
#define m3d_inlinedasset_t m3di_t

/*** in-memory model structure ***/
#define M3D_FLG_FREERAW     (1<<0)
#define M3D_FLG_FREESTR     (1<<1)
#define M3D_FLG_MTLLIB      (1<<2)
#define M3D_FLG_GENNORM     (1<<3)

typedef struct m3d_t {
    m3dhdr_t *raw;              /* pointer to raw data */
    char flags;                 /* internal flags */
    signed char errcode;        /* returned error code */
    char vc_s, vi_s, si_s, ci_s, ti_s, bi_s, nb_s, sk_s, fc_s, hi_s, fi_s, vd_s, vp_s;  /* decoded sizes for types */
    char *name;                 /* name of the model, like "Utah teapot" */
    char *license;              /* usage condition or license, like "MIT", "LGPL" or "BSD-3clause" */
    char *author;               /* nickname, email, homepage or github URL etc. */
    char *desc;                 /* comments, descriptions. May contain '\n' newline character */
    M3D_FLOAT scale;            /* the model's bounding cube's size in SI meters */
    M3D_INDEX numcmap;
    uint32_t *cmap;             /* color map */
    M3D_INDEX numtmap;
    m3dti_t *tmap;              /* texture map indices */
    M3D_INDEX numtexture;
    m3dtx_t *texture;           /* uncompressed textures */
    M3D_INDEX numbone;
    m3db_t *bone;               /* bone hierarchy */
    M3D_INDEX numvertex;
    m3dv_t *vertex;             /* vertex data */
    M3D_INDEX numskin;
    m3ds_t *skin;               /* skin data */
    M3D_INDEX nummaterial;
    m3dm_t *material;           /* material list */
#ifdef M3D_VERTEXMAX
    M3D_INDEX numparam;
    m3dvi_t *param;             /* parameters and their values list */
#endif
    M3D_INDEX numface;
    m3df_t *face;               /* model face, polygon (triangle) mesh */
    M3D_INDEX numvoxtype;
    m3dvt_t *voxtype;           /* model face, voxel types */
    M3D_INDEX numvoxel;
    m3dvx_t *voxel;             /* model face, cubes compressed into voxels */
    M3D_INDEX numshape;
    m3dh_t *shape;              /* model face, shape commands */
    M3D_INDEX numlabel;
    m3dl_t *label;              /* annotation labels */
    M3D_INDEX numaction;
    m3da_t *action;             /* action animations */
    M3D_INDEX numinlined;
    m3di_t *inlined;            /* inlined assets */
    M3D_INDEX numextra;
    m3dchunk_t **extra;         /* unknown chunks, application / engine specific data probably */
    m3di_t preview;             /* preview chunk */
} m3d_t;

/*** export parameters ***/
#define M3D_EXP_INT8        0
#define M3D_EXP_INT16       1
#define M3D_EXP_FLOAT       2
#define M3D_EXP_DOUBLE      3

#define M3D_EXP_NOCMAP      (1<<0)
#define M3D_EXP_NOMATERIAL  (1<<1)
#define M3D_EXP_NOFACE      (1<<2)
#define M3D_EXP_NONORMAL    (1<<3)
#define M3D_EXP_NOTXTCRD    (1<<4)
#define M3D_EXP_FLIPTXTCRD  (1<<5)
#define M3D_EXP_NORECALC    (1<<6)
#define M3D_EXP_IDOSUCK     (1<<7)
#define M3D_EXP_NOBONE      (1<<8)
#define M3D_EXP_NOACTION    (1<<9)
#define M3D_EXP_INLINE      (1<<10)
#define M3D_EXP_EXTRA       (1<<11)
#define M3D_EXP_NOZLIB      (1<<14)
#define M3D_EXP_ASCII       (1<<15)
#define M3D_EXP_NOVRTMAX    (1<<16)

/*** error codes ***/
#define M3D_SUCCESS         0
#define M3D_ERR_ALLOC       -1
#define M3D_ERR_BADFILE     -2
#define M3D_ERR_UNIMPL      -65
#define M3D_ERR_UNKPROP     -66
#define M3D_ERR_UNKMESH     -67
#define M3D_ERR_UNKIMG      -68
#define M3D_ERR_UNKFRAME    -69
#define M3D_ERR_UNKCMD      -70
#define M3D_ERR_UNKVOX      -71
#define M3D_ERR_TRUNC       -72
#define M3D_ERR_CMAP        -73
#define M3D_ERR_TMAP        -74
#define M3D_ERR_VRTS        -75
#define M3D_ERR_BONE        -76
#define M3D_ERR_MTRL        -77
#define M3D_ERR_SHPE        -78
#define M3D_ERR_VOXT        -79

#define M3D_ERR_ISFATAL(x)  ((x) < 0 && (x) > -65)

/* callbacks */
typedef unsigned char *(*m3dread_t)(char *filename, unsigned int *size);                        /* read file contents into buffer */
typedef void (*m3dfree_t)(void *buffer);                                                        /* free file contents buffer */
typedef int (*m3dtxsc_t)(const char *name, const void *script, uint32_t len, m3dtx_t *output);  /* interpret texture script */
typedef int (*m3dprsc_t)(const char *name, const void *script, uint32_t len, m3d_t *model);     /* interpret surface script */
#endif /* ifndef M3D_APIVERSION */

/*** C prototypes ***/
/* import / export */
m3d_t *m3d_load(unsigned char *data, m3dread_t readfilecb, m3dfree_t freecb, m3d_t *mtllib);
unsigned char *m3d_save(m3d_t *model, int quality, int flags, unsigned int *size);
void m3d_free(m3d_t *model);
/* generate animation pose skeleton */
m3dtr_t *m3d_frame(m3d_t *model, M3D_INDEX actionid, M3D_INDEX frameid, m3dtr_t *skeleton);
m3db_t *m3d_pose(m3d_t *model, M3D_INDEX actionid, uint32_t msec);

/* private prototypes used by both importer and exporter */
char *_m3d_safestr(char *in, int morelines);

/*** C implementation ***/
#ifdef M3D_IMPLEMENTATION
#if !defined(M3D_NOIMPORTER) || defined(M3D_EXPORTER)
/* material property definitions */
static m3dpd_t m3d_propertytypes[] = {
    M3D_PROPERTYDEF(m3dpf_color, m3dp_Kd, "Kd"),    /* diffuse color */
    M3D_PROPERTYDEF(m3dpf_color, m3dp_Ka, "Ka"),    /* ambient color */
    M3D_PROPERTYDEF(m3dpf_color, m3dp_Ks, "Ks"),    /* specular color */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_Ns, "Ns"),    /* specular exponent */
    M3D_PROPERTYDEF(m3dpf_color, m3dp_Ke, "Ke"),    /* emissive (emitting light of this color) */
    M3D_PROPERTYDEF(m3dpf_color, m3dp_Tf, "Tf"),    /* transmission color */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_Km, "Km"),    /* bump strength */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_d,  "d"),     /* dissolve (transparency) */
    M3D_PROPERTYDEF(m3dpf_uint8, m3dp_il, "il"),    /* illumination model (informational, ignored by PBR-shaders) */

    M3D_PROPERTYDEF(m3dpf_float, m3dp_Pr, "Pr"),    /* roughness */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_Pm, "Pm"),    /* metallic, also reflection */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_Ps, "Ps"),    /* sheen */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_Ni, "Ni"),    /* index of refraction (optical density) */
    M3D_PROPERTYDEF(m3dpf_float, m3dp_Nt, "Nt"),    /* thickness of face in millimeter, for printing */

    /* aliases, note that "map_*" aliases are handled automatically */
    M3D_PROPERTYDEF(m3dpf_map, m3dp_map_Km, "bump"),
    M3D_PROPERTYDEF(m3dpf_map, m3dp_map_N, "map_N"),/* as normal map has no scalar version, it's counterpart is 'il' */
    M3D_PROPERTYDEF(m3dpf_map, m3dp_map_Pm, "refl")
};
/* shape command definitions. if more commands start with the same string, the longer must come first */
static m3dcd_t m3d_commandtypes[] = {
    /* technical */
    M3D_CMDDEF(m3dc_use,     "use",     1, m3dcp_mi_t, 0, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_inc,     "inc",     3, m3dcp_hi_t, m3dcp_vi_t, m3dcp_qi_t, m3dcp_vi_t, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_mesh,    "mesh",    1, m3dcp_fi_t, m3dcp_fi_t, m3dcp_vi_t, m3dcp_qi_t, m3dcp_vi_t, 0, 0, 0),
    /* approximations */
    M3D_CMDDEF(m3dc_div,     "div",     1, m3dcp_vc_t, 0, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_sub,     "sub",     2, m3dcp_vc_t, m3dcp_vc_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_len,     "len",     1, m3dcp_vc_t, 0, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_dist,    "dist",    2, m3dcp_vc_t, m3dcp_vc_t, 0, 0, 0, 0, 0, 0),
    /* modifiers */
    M3D_CMDDEF(m3dc_degu,    "degu",    1, m3dcp_i1_t, 0, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_deg,     "deg",     2, m3dcp_i1_t, m3dcp_i1_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_rangeu,  "rangeu",  1, m3dcp_ti_t, 0, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_range,   "range",   2, m3dcp_ti_t, m3dcp_ti_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_paru,    "paru",    2, m3dcp_va_t, m3dcp_vc_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_parv,    "parv",    2, m3dcp_va_t, m3dcp_vc_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_trim,    "trim",    3, m3dcp_va_t, m3dcp_ti_t, m3dcp_i2_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_hole,    "hole",    3, m3dcp_va_t, m3dcp_ti_t, m3dcp_i2_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_scrv,    "scrv",    3, m3dcp_va_t, m3dcp_ti_t, m3dcp_i2_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_sp,      "sp",      2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    /* helper curves */
    M3D_CMDDEF(m3dc_bez1,    "bez1",    2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_bsp1,    "bsp1",    2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_bez2,    "bez2",    2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_bsp2,    "bsp2",    2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    /* surfaces */
    M3D_CMDDEF(m3dc_bezun,   "bezun",   4, m3dcp_va_t, m3dcp_vi_t, m3dcp_ti_t, m3dcp_vi_t, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_bezu,    "bezu",    3, m3dcp_va_t, m3dcp_vi_t, m3dcp_ti_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_bezn,    "bezn",    3, m3dcp_va_t, m3dcp_vi_t, m3dcp_vi_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_bez,     "bez",     2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_nurbsun, "nurbsun", 4, m3dcp_va_t, m3dcp_vi_t, m3dcp_ti_t, m3dcp_vi_t, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_nurbsu,  "nurbsu",  3, m3dcp_va_t, m3dcp_vi_t, m3dcp_ti_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_nurbsn,  "nurbsn",  3, m3dcp_va_t, m3dcp_vi_t, m3dcp_vi_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_nurbs,   "nurbs",   2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_conn,    "conn",    6, m3dcp_i2_t, m3dcp_ti_t, m3dcp_i2_t, m3dcp_i2_t, m3dcp_ti_t, m3dcp_i2_t, 0, 0),
    /* geometrical */
    M3D_CMDDEF(m3dc_line,    "line",    2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_polygon, "polygon", 2, m3dcp_va_t, m3dcp_vi_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_circle,  "circle",  3, m3dcp_vi_t, m3dcp_qi_t, m3dcp_vc_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_cylinder,"cylinder",6, m3dcp_vi_t, m3dcp_qi_t, m3dcp_vc_t, m3dcp_vi_t, m3dcp_qi_t, m3dcp_vc_t, 0, 0),
    M3D_CMDDEF(m3dc_shpere,  "shpere",  2, m3dcp_vi_t, m3dcp_vc_t, 0, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_torus,   "torus",   4, m3dcp_vi_t, m3dcp_qi_t, m3dcp_vc_t, m3dcp_vc_t, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_cone,    "cone",    3, m3dcp_vi_t, m3dcp_vi_t, m3dcp_vi_t, 0, 0, 0, 0, 0),
    M3D_CMDDEF(m3dc_cube,    "cube",    3, m3dcp_vi_t, m3dcp_vi_t, m3dcp_vi_t, 0, 0, 0, 0, 0)
};
#endif

#include <stdlib.h>
#include <string.h>

/* we'll need this with M3D_NOTEXTURE */
char *stbi_zlib_decode_malloc_guesssize_headerflag(const char *buffer, int len, int initial_size, int *outlen, int parse_header);

#ifndef M3D_NOTEXTURE
#if !defined(M3D_NOIMPORTER) && !defined(STBI_INCLUDE_STB_IMAGE_H)
/* PNG decompressor from

   stb_image - v2.23 - public domain image loader - http://nothings.org/stb_image.h
*/
static const char *_m3dstbi__g_failure_reason;

enum
{
   STBI_default = 0,

   STBI_grey       = 1,
   STBI_grey_alpha = 2,
   STBI_rgb        = 3,
   STBI_rgb_alpha  = 4
};

enum
{
   STBI__SCAN_load=0,
   STBI__SCAN_type,
   STBI__SCAN_header
};

typedef unsigned short _m3dstbi_us;

typedef uint16_t _m3dstbi__uint16;
typedef int16_t  _m3dstbi__int16;
typedef uint32_t _m3dstbi__uint32;
typedef int32_t  _m3dstbi__int32;

typedef struct
{
   _m3dstbi__uint32 img_x, img_y;
   int img_n, img_out_n;

   void *io_user_data;

   int read_from_callbacks;
   int buflen;
   unsigned char buffer_start[128];

   unsigned char *img_buffer, *img_buffer_end;
   unsigned char *img_buffer_original, *img_buffer_original_end;
} _m3dstbi__context;

typedef struct
{
   int bits_per_channel;
   int num_channels;
   int channel_order;
} _m3dstbi__result_info;

#define STBI_ASSERT(v)
#define STBI_NOTUSED(v)  (void)sizeof(v)
#define STBI__BYTECAST(x)  ((unsigned char) ((x) & 255))
#define STBI_MALLOC(sz)           M3D_MALLOC(sz)
#define STBI_REALLOC(p,newsz)     M3D_REALLOC(p,newsz)
#define STBI_FREE(p)              M3D_FREE(p)
#define STBI_REALLOC_SIZED(p,oldsz,newsz) STBI_REALLOC(p,newsz)

_inline static unsigned char _m3dstbi__get8(_m3dstbi__context *s)
{
   if (s->img_buffer < s->img_buffer_end)
      return *s->img_buffer++;
   return 0;
}

_inline static int _m3dstbi__at_eof(_m3dstbi__context *s)
{
   return s->img_buffer >= s->img_buffer_end;
}

static void _m3dstbi__skip(_m3dstbi__context *s, int n)
{
   if (n < 0) {
      s->img_buffer = s->img_buffer_end;
      return;
   }
   s->img_buffer += n;
}

static int _m3dstbi__getn(_m3dstbi__context *s, unsigned char *buffer, int n)
{
   if (s->img_buffer+n <= s->img_buffer_end) {
      memcpy(buffer, s->img_buffer, n);
      s->img_buffer += n;
      return 1;
   } else
      return 0;
}

static int _m3dstbi__get16be(_m3dstbi__context *s)
{
   int z = _m3dstbi__get8(s);
   return (z << 8) + _m3dstbi__get8(s);
}

static _m3dstbi__uint32 _m3dstbi__get32be(_m3dstbi__context *s)
{
   _m3dstbi__uint32 z = _m3dstbi__get16be(s);
   return (z << 16) + _m3dstbi__get16be(s);
}

#define _m3dstbi__err(x,y)  _m3dstbi__errstr(y)
static int _m3dstbi__errstr(const char *str)
{
   _m3dstbi__g_failure_reason = str;
   return 0;
}

_inline static void *_m3dstbi__malloc(size_t size)
{
    return STBI_MALLOC(size);
}

static int _m3dstbi__addsizes_valid(int a, int b)
{
   if (b < 0) return 0;
   return a <= 2147483647 - b;
}

static int _m3dstbi__mul2sizes_valid(int a, int b)
{
   if (a < 0 || b < 0) return 0;
   if (b == 0) return 1;
   return a <= 2147483647/b;
}

static int _m3dstbi__mad2sizes_valid(int a, int b, int add)
{
   return _m3dstbi__mul2sizes_valid(a, b) && _m3dstbi__addsizes_valid(a*b, add);
}

static int _m3dstbi__mad3sizes_valid(int a, int b, int c, int add)
{
   return _m3dstbi__mul2sizes_valid(a, b) && _m3dstbi__mul2sizes_valid(a*b, c) &&
      _m3dstbi__addsizes_valid(a*b*c, add);
}

static void *_m3dstbi__malloc_mad2(int a, int b, int add)
{
   if (!_m3dstbi__mad2sizes_valid(a, b, add)) return NULL;
   return _m3dstbi__malloc(a*b + add);
}

static void *_m3dstbi__malloc_mad3(int a, int b, int c, int add)
{
   if (!_m3dstbi__mad3sizes_valid(a, b, c, add)) return NULL;
   return _m3dstbi__malloc(a*b*c + add);
}

static unsigned char _m3dstbi__compute_y(int r, int g, int b)
{
   return (unsigned char) (((r*77) + (g*150) +  (29*b)) >> 8);
}

static unsigned char *_m3dstbi__convert_format(unsigned char *data, int img_n, int req_comp, unsigned int x, unsigned int y)
{
   int i,j;
   unsigned char *good;

   if (req_comp == img_n) return data;
   STBI_ASSERT(req_comp >= 1 && req_comp <= 4);

   good = (unsigned char *) _m3dstbi__malloc_mad3(req_comp, x, y, 0);
   if (good == NULL) {
      STBI_FREE(data);
      _m3dstbi__err("outofmem", "Out of memory");
      return NULL;
   }

   for (j=0; j < (int) y; ++j) {
      unsigned char *src  = data + j * x * img_n   ;
      unsigned char *dest = good + j * x * req_comp;

      #define STBI__COMBO(a,b)  ((a)*8+(b))
      #define STBI__CASE(a,b)   case STBI__COMBO(a,b): for(i=x-1; i >= 0; --i, src += a, dest += b)
      switch (STBI__COMBO(img_n, req_comp)) {
         STBI__CASE(1,2) { dest[0]=src[0], dest[1]=255;                                     } break;
         STBI__CASE(1,3) { dest[0]=dest[1]=dest[2]=src[0];                                  } break;
         STBI__CASE(1,4) { dest[0]=dest[1]=dest[2]=src[0], dest[3]=255;                     } break;
         STBI__CASE(2,1) { dest[0]=src[0];                                                  } break;
         STBI__CASE(2,3) { dest[0]=dest[1]=dest[2]=src[0];                                  } break;
         STBI__CASE(2,4) { dest[0]=dest[1]=dest[2]=src[0], dest[3]=src[1];                  } break;
         STBI__CASE(3,4) { dest[0]=src[0],dest[1]=src[1],dest[2]=src[2],dest[3]=255;        } break;
         STBI__CASE(3,1) { dest[0]=_m3dstbi__compute_y(src[0],src[1],src[2]);                   } break;
         STBI__CASE(3,2) { dest[0]=_m3dstbi__compute_y(src[0],src[1],src[2]), dest[1] = 255;    } break;
         STBI__CASE(4,1) { dest[0]=_m3dstbi__compute_y(src[0],src[1],src[2]);                   } break;
         STBI__CASE(4,2) { dest[0]=_m3dstbi__compute_y(src[0],src[1],src[2]), dest[1] = src[3]; } break;
         STBI__CASE(4,3) { dest[0]=src[0],dest[1]=src[1],dest[2]=src[2];                    } break;
         default: STBI_ASSERT(0);
      }
      #undef STBI__CASE
   }

   STBI_FREE(data);
   return good;
}

static _m3dstbi__uint16 _m3dstbi__compute_y_16(int r, int g, int b)
{
   return (_m3dstbi__uint16) (((r*77) + (g*150) +  (29*b)) >> 8);
}

static _m3dstbi__uint16 *_m3dstbi__convert_format16(_m3dstbi__uint16 *data, int img_n, int req_comp, unsigned int x, unsigned int y)
{
   int i,j;
   _m3dstbi__uint16 *good;

   if (req_comp == img_n) return data;
   STBI_ASSERT(req_comp >= 1 && req_comp <= 4);

   good = (_m3dstbi__uint16 *) _m3dstbi__malloc(req_comp * x * y * 2);
   if (good == NULL) {
      STBI_FREE(data);
      _m3dstbi__err("outofmem", "Out of memory");
      return NULL;
   }

   for (j=0; j < (int) y; ++j) {
      _m3dstbi__uint16 *src  = data + j * x * img_n   ;
      _m3dstbi__uint16 *dest = good + j * x * req_comp;

      #define STBI__COMBO(a,b)  ((a)*8+(b))
      #define STBI__CASE(a,b)   case STBI__COMBO(a,b): for(i=x-1; i >= 0; --i, src += a, dest += b)
      switch (STBI__COMBO(img_n, req_comp)) {
         STBI__CASE(1,2) { dest[0]=src[0], dest[1]=0xffff;                                     } break;
         STBI__CASE(1,3) { dest[0]=dest[1]=dest[2]=src[0];                                     } break;
         STBI__CASE(1,4) { dest[0]=dest[1]=dest[2]=src[0], dest[3]=0xffff;                     } break;
         STBI__CASE(2,1) { dest[0]=src[0];                                                     } break;
         STBI__CASE(2,3) { dest[0]=dest[1]=dest[2]=src[0];                                     } break;
         STBI__CASE(2,4) { dest[0]=dest[1]=dest[2]=src[0], dest[3]=src[1];                     } break;
         STBI__CASE(3,4) { dest[0]=src[0],dest[1]=src[1],dest[2]=src[2],dest[3]=0xffff;        } break;
         STBI__CASE(3,1) { dest[0]=_m3dstbi__compute_y_16(src[0],src[1],src[2]);                   } break;
         STBI__CASE(3,2) { dest[0]=_m3dstbi__compute_y_16(src[0],src[1],src[2]), dest[1] = 0xffff; } break;
         STBI__CASE(4,1) { dest[0]=_m3dstbi__compute_y_16(src[0],src[1],src[2]);                   } break;
         STBI__CASE(4,2) { dest[0]=_m3dstbi__compute_y_16(src[0],src[1],src[2]), dest[1] = src[3]; } break;
         STBI__CASE(4,3) { dest[0]=src[0],dest[1]=src[1],dest[2]=src[2];                       } break;
         default: STBI_ASSERT(0);
      }
      #undef STBI__CASE
   }

   STBI_FREE(data);
   return good;
}

#define STBI__ZFAST_BITS  9
#define STBI__ZFAST_MASK  ((1 << STBI__ZFAST_BITS) - 1)

typedef struct
{
   _m3dstbi__uint16 fast[1 << STBI__ZFAST_BITS];
   _m3dstbi__uint16 firstcode[16];
   int maxcode[17];
   _m3dstbi__uint16 firstsymbol[16];
   unsigned char  size[288];
   _m3dstbi__uint16 value[288];
} _m3dstbi__zhuffman;

_inline static int _m3dstbi__bitreverse16(int n)
{
  n = ((n & 0xAAAA) >>  1) | ((n & 0x5555) << 1);
  n = ((n & 0xCCCC) >>  2) | ((n & 0x3333) << 2);
  n = ((n & 0xF0F0) >>  4) | ((n & 0x0F0F) << 4);
  n = ((n & 0xFF00) >>  8) | ((n & 0x00FF) << 8);
  return n;
}

_inline static int _m3dstbi__bit_reverse(int v, int bits)
{
   STBI_ASSERT(bits <= 16);
   return _m3dstbi__bitreverse16(v) >> (16-bits);
}

static int _m3dstbi__zbuild_huffman(_m3dstbi__zhuffman *z, unsigned char *sizelist, int num)
{
   int i,k=0;
   int code, next_code[16], sizes[17];

   memset(sizes, 0, sizeof(sizes));
   memset(z->fast, 0, sizeof(z->fast));
   for (i=0; i < num; ++i)
      ++sizes[sizelist[i]];
   sizes[0] = 0;
   for (i=1; i < 16; ++i)
      if (sizes[i] > (1 << i))
         return _m3dstbi__err("bad sizes", "Corrupt PNG");
   code = 0;
   for (i=1; i < 16; ++i) {
      next_code[i] = code;
      z->firstcode[i] = (_m3dstbi__uint16) code;
      z->firstsymbol[i] = (_m3dstbi__uint16) k;
      code = (code + sizes[i]);
      if (sizes[i])
         if (code-1 >= (1 << i)) return _m3dstbi__err("bad codelengths","Corrupt PNG");
      z->maxcode[i] = code << (16-i);
      code <<= 1;
      k += sizes[i];
   }
   z->maxcode[16] = 0x10000;
   for (i=0; i < num; ++i) {
      int s = sizelist[i];
      if (s) {
         int c = next_code[s] - z->firstcode[s] + z->firstsymbol[s];
         _m3dstbi__uint16 fastv = (_m3dstbi__uint16) ((s << 9) | i);
         z->size [c] = (unsigned char     ) s;
         z->value[c] = (_m3dstbi__uint16) i;
         if (s <= STBI__ZFAST_BITS) {
            int j = _m3dstbi__bit_reverse(next_code[s],s);
            while (j < (1 << STBI__ZFAST_BITS)) {
               z->fast[j] = fastv;
               j += (1 << s);
            }
         }
         ++next_code[s];
      }
   }
   return 1;
}

typedef struct
{
   unsigned char *zbuffer, *zbuffer_end;
   int num_bits;
   _m3dstbi__uint32 code_buffer;

   char *zout;
   char *zout_start;
   char *zout_end;
   int   z_expandable;

   _m3dstbi__zhuffman z_length, z_distance;
} _m3dstbi__zbuf;

_inline static unsigned char _m3dstbi__zget8(_m3dstbi__zbuf *z)
{
   if (z->zbuffer >= z->zbuffer_end) return 0;
   return *z->zbuffer++;
}

static void _m3dstbi__fill_bits(_m3dstbi__zbuf *z)
{
   do {
      STBI_ASSERT(z->code_buffer < (1U << z->num_bits));
      z->code_buffer |= (unsigned int) _m3dstbi__zget8(z) << z->num_bits;
      z->num_bits += 8;
   } while (z->num_bits <= 24);
}

_inline static unsigned int _m3dstbi__zreceive(_m3dstbi__zbuf *z, int n)
{
   unsigned int k;
   if (z->num_bits < n) _m3dstbi__fill_bits(z);
   k = z->code_buffer & ((1 << n) - 1);
   z->code_buffer >>= n;
   z->num_bits -= n;
   return k;
}

static int _m3dstbi__zhuffman_decode_slowpath(_m3dstbi__zbuf *a, _m3dstbi__zhuffman *z)
{
   int b,s,k;
   k = _m3dstbi__bit_reverse(a->code_buffer, 16);
   for (s=STBI__ZFAST_BITS+1; ; ++s)
      if (k < z->maxcode[s])
         break;
   if (s == 16) return -1;
   b = (k >> (16-s)) - z->firstcode[s] + z->firstsymbol[s];
   STBI_ASSERT(z->size[b] == s);
   a->code_buffer >>= s;
   a->num_bits -= s;
   return z->value[b];
}

_inline static int _m3dstbi__zhuffman_decode(_m3dstbi__zbuf *a, _m3dstbi__zhuffman *z)
{
   int b,s;
   if (a->num_bits < 16) _m3dstbi__fill_bits(a);
   b = z->fast[a->code_buffer & STBI__ZFAST_MASK];
   if (b) {
      s = b >> 9;
      a->code_buffer >>= s;
      a->num_bits -= s;
      return b & 511;
   }
   return _m3dstbi__zhuffman_decode_slowpath(a, z);
}

static int _m3dstbi__zexpand(_m3dstbi__zbuf *z, char *zout, int n)
{
   char *q;
   int cur, limit, old_limit;
   z->zout = zout;
   if (!z->z_expandable) return _m3dstbi__err("output buffer limit","Corrupt PNG");
   cur   = (int) (z->zout     - z->zout_start);
   limit = old_limit = (int) (z->zout_end - z->zout_start);
   while (cur + n > limit)
      limit *= 2;
   q = (char *) STBI_REALLOC_SIZED(z->zout_start, old_limit, limit);
   STBI_NOTUSED(old_limit);
   if (q == NULL) return _m3dstbi__err("outofmem", "Out of memory");
   z->zout_start = q;
   z->zout       = q + cur;
   z->zout_end   = q + limit;
   return 1;
}

static int _m3dstbi__zlength_base[31] = {
   3,4,5,6,7,8,9,10,11,13,
   15,17,19,23,27,31,35,43,51,59,
   67,83,99,115,131,163,195,227,258,0,0 };

static int _m3dstbi__zlength_extra[31]=
{ 0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0 };

static int _m3dstbi__zdist_base[32] = { 1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,
257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577,0,0};

static int _m3dstbi__zdist_extra[32] =
{ 0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13};

static int _m3dstbi__parse_huffman_block(_m3dstbi__zbuf *a)
{
   char *zout = a->zout;
   for(;;) {
      int z = _m3dstbi__zhuffman_decode(a, &a->z_length);
      if (z < 256) {
         if (z < 0) return _m3dstbi__err("bad huffman code","Corrupt PNG");
         if (zout >= a->zout_end) {
            if (!_m3dstbi__zexpand(a, zout, 1)) return 0;
            zout = a->zout;
         }
         *zout++ = (char) z;
      } else {
         unsigned char *p;
         int len,dist;
         if (z == 256) {
            a->zout = zout;
            return 1;
         }
         z -= 257;
         len = _m3dstbi__zlength_base[z];
         if (_m3dstbi__zlength_extra[z]) len += _m3dstbi__zreceive(a, _m3dstbi__zlength_extra[z]);
         z = _m3dstbi__zhuffman_decode(a, &a->z_distance);
         if (z < 0) return _m3dstbi__err("bad huffman code","Corrupt PNG");
         dist = _m3dstbi__zdist_base[z];
         if (_m3dstbi__zdist_extra[z]) dist += _m3dstbi__zreceive(a, _m3dstbi__zdist_extra[z]);
         if (zout - a->zout_start < dist) return _m3dstbi__err("bad dist","Corrupt PNG");
         if (zout + len > a->zout_end) {
            if (!_m3dstbi__zexpand(a, zout, len)) return 0;
            zout = a->zout;
         }
         p = (unsigned char *) (zout - dist);
         if (dist == 1) {
            unsigned char v = *p;
            if (len) { do *zout++ = v; while (--len); }
         } else {
            if (len) { do *zout++ = *p++; while (--len); }
         }
      }
   }
}

static int _m3dstbi__compute_huffman_codes(_m3dstbi__zbuf *a)
{
   static unsigned char length_dezigzag[19] = { 16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15 };
   _m3dstbi__zhuffman z_codelength;
   unsigned char lencodes[286+32+137];
   unsigned char codelength_sizes[19];
   int i,n;

   int hlit  = _m3dstbi__zreceive(a,5) + 257;
   int hdist = _m3dstbi__zreceive(a,5) + 1;
   int hclen = _m3dstbi__zreceive(a,4) + 4;
   int ntot  = hlit + hdist;

   memset(codelength_sizes, 0, sizeof(codelength_sizes));
   for (i=0; i < hclen; ++i) {
      int s = _m3dstbi__zreceive(a,3);
      codelength_sizes[length_dezigzag[i]] = (unsigned char) s;
   }
   if (!_m3dstbi__zbuild_huffman(&z_codelength, codelength_sizes, 19)) return 0;

   n = 0;
   while (n < ntot) {
      int c = _m3dstbi__zhuffman_decode(a, &z_codelength);
      if (c < 0 || c >= 19) return _m3dstbi__err("bad codelengths", "Corrupt PNG");
      if (c < 16)
         lencodes[n++] = (unsigned char) c;
      else {
         unsigned char fill = 0;
         if (c == 16) {
            c = _m3dstbi__zreceive(a,2)+3;
            if (n == 0) return _m3dstbi__err("bad codelengths", "Corrupt PNG");
            fill = lencodes[n-1];
         } else if (c == 17)
            c = _m3dstbi__zreceive(a,3)+3;
         else {
            STBI_ASSERT(c == 18);
            c = _m3dstbi__zreceive(a,7)+11;
         }
         if (ntot - n < c) return _m3dstbi__err("bad codelengths", "Corrupt PNG");
         memset(lencodes+n, fill, c);
         n += c;
      }
   }
   if (n != ntot) return _m3dstbi__err("bad codelengths","Corrupt PNG");
   if (!_m3dstbi__zbuild_huffman(&a->z_length, lencodes, hlit)) return 0;
   if (!_m3dstbi__zbuild_huffman(&a->z_distance, lencodes+hlit, hdist)) return 0;
   return 1;
}

_inline static int _m3dstbi__parse_uncompressed_block(_m3dstbi__zbuf *a)
{
   unsigned char header[4];
   int len,nlen,k;
   if (a->num_bits & 7)
      _m3dstbi__zreceive(a, a->num_bits & 7);
   k = 0;
   while (a->num_bits > 0) {
      header[k++] = (unsigned char) (a->code_buffer & 255);
      a->code_buffer >>= 8;
      a->num_bits -= 8;
   }
   STBI_ASSERT(a->num_bits == 0);
   while (k < 4)
      header[k++] = _m3dstbi__zget8(a);
   len  = header[1] * 256 + header[0];
   nlen = header[3] * 256 + header[2];
   if (nlen != (len ^ 0xffff)) return _m3dstbi__err("zlib corrupt","Corrupt PNG");
   if (a->zbuffer + len > a->zbuffer_end) return _m3dstbi__err("read past buffer","Corrupt PNG");
   if (a->zout + len > a->zout_end)
      if (!_m3dstbi__zexpand(a, a->zout, len)) return 0;
   memcpy(a->zout, a->zbuffer, len);
   a->zbuffer += len;
   a->zout += len;
   return 1;
}

static int _m3dstbi__parse_zlib_header(_m3dstbi__zbuf *a)
{
   int cmf   = _m3dstbi__zget8(a);
   int cm    = cmf & 15;
   /* int cinfo = cmf >> 4; */
   int flg   = _m3dstbi__zget8(a);
   if ((cmf*256+flg) % 31 != 0) return _m3dstbi__err("bad zlib header","Corrupt PNG");
   if (flg & 32) return _m3dstbi__err("no preset dict","Corrupt PNG");
   if (cm != 8) return _m3dstbi__err("bad compression","Corrupt PNG");
   return 1;
}

static unsigned char _m3dstbi__zdefault_length[288], _m3dstbi__zdefault_distance[32];
static void _m3dstbi__init_zdefaults(void)
{
   int i;
   for (i=0; i <= 143; ++i)     _m3dstbi__zdefault_length[i]   = 8;
   for (   ; i <= 255; ++i)     _m3dstbi__zdefault_length[i]   = 9;
   for (   ; i <= 279; ++i)     _m3dstbi__zdefault_length[i]   = 7;
   for (   ; i <= 287; ++i)     _m3dstbi__zdefault_length[i]   = 8;

   for (i=0; i <=  31; ++i)     _m3dstbi__zdefault_distance[i] = 5;
}

static int _m3dstbi__parse_zlib(_m3dstbi__zbuf *a, int parse_header)
{
   int final, type;
   if (parse_header)
      if (!_m3dstbi__parse_zlib_header(a)) return 0;
   a->num_bits = 0;
   a->code_buffer = 0;
   do {
      final = _m3dstbi__zreceive(a,1);
      type = _m3dstbi__zreceive(a,2);
      if (type == 0) {
         if (!_m3dstbi__parse_uncompressed_block(a)) return 0;
      } else if (type == 3) {
         return 0;
      } else {
         if (type == 1) {
            if (!_m3dstbi__zbuild_huffman(&a->z_length  , _m3dstbi__zdefault_length  , 288)) return 0;
            if (!_m3dstbi__zbuild_huffman(&a->z_distance, _m3dstbi__zdefault_distance,  32)) return 0;
         } else {
            if (!_m3dstbi__compute_huffman_codes(a)) return 0;
         }
         if (!_m3dstbi__parse_huffman_block(a)) return 0;
      }
   } while (!final);
   return 1;
}

static int _m3dstbi__do_zlib(_m3dstbi__zbuf *a, char *obuf, int olen, int exp, int parse_header)
{
   a->zout_start = obuf;
   a->zout       = obuf;
   a->zout_end   = obuf + olen;
   a->z_expandable = exp;
   _m3dstbi__init_zdefaults();
   return _m3dstbi__parse_zlib(a, parse_header);
}

char *_m3dstbi_zlib_decode_malloc_guesssize_headerflag(const char *buffer, int len, int initial_size, int *outlen, int parse_header)
{
   _m3dstbi__zbuf a;
   char *p = (char *) _m3dstbi__malloc(initial_size);
   if (p == NULL) return NULL;
   a.zbuffer = (unsigned char *) buffer;
   a.zbuffer_end = (unsigned char *) buffer + len;
   if (_m3dstbi__do_zlib(&a, p, initial_size, 1, parse_header)) {
      if (outlen) *outlen = (int) (a.zout - a.zout_start);
      return a.zout_start;
   } else {
      STBI_FREE(a.zout_start);
      return NULL;
   }
}

typedef struct
{
   _m3dstbi__uint32 length;
   _m3dstbi__uint32 type;
} _m3dstbi__pngchunk;

static _m3dstbi__pngchunk _m3dstbi__get_chunk_header(_m3dstbi__context *s)
{
   _m3dstbi__pngchunk c;
   c.length = _m3dstbi__get32be(s);
   c.type   = _m3dstbi__get32be(s);
   return c;
}

_inline static int _m3dstbi__check_png_header(_m3dstbi__context *s)
{
   static unsigned char png_sig[8] = { 137,80,78,71,13,10,26,10 };
   int i;
   for (i=0; i < 8; ++i)
      if (_m3dstbi__get8(s) != png_sig[i]) return _m3dstbi__err("bad png sig","Not a PNG");
   return 1;
}

typedef struct
{
   _m3dstbi__context *s;
   unsigned char *idata, *expanded, *out;
   int depth;
} _m3dstbi__png;


enum {
   STBI__F_none=0,
   STBI__F_sub=1,
   STBI__F_up=2,
   STBI__F_avg=3,
   STBI__F_paeth=4,
   STBI__F_avg_first,
   STBI__F_paeth_first
};

static unsigned char first_row_filter[5] =
{
   STBI__F_none,
   STBI__F_sub,
   STBI__F_none,
   STBI__F_avg_first,
   STBI__F_paeth_first
};

static int _m3dstbi__paeth(int a, int b, int c)
{
   int p = a + b - c;
   int pa = abs(p-a);
   int pb = abs(p-b);
   int pc = abs(p-c);
   if (pa <= pb && pa <= pc) return a;
   if (pb <= pc) return b;
   return c;
}

static unsigned char _m3dstbi__depth_scale_table[9] = { 0, 0xff, 0x55, 0, 0x11, 0,0,0, 0x01 };

static int _m3dstbi__create_png_image_raw(_m3dstbi__png *a, unsigned char *raw, _m3dstbi__uint32 raw_len, int out_n, _m3dstbi__uint32 x, _m3dstbi__uint32 y, int depth, int color)
{
   int bytes = (depth == 16? 2 : 1);
   _m3dstbi__context *s = a->s;
   _m3dstbi__uint32 i,j,stride = x*out_n*bytes;
   _m3dstbi__uint32 img_len, img_width_bytes;
   int k;
   int img_n = s->img_n;

   int output_bytes = out_n*bytes;
   int filter_bytes = img_n*bytes;
   int width = x;

   STBI_ASSERT(out_n == s->img_n || out_n == s->img_n+1);
   a->out = (unsigned char *) _m3dstbi__malloc_mad3(x, y, output_bytes, 0);
   if (!a->out) return _m3dstbi__err("outofmem", "Out of memory");

   if (!_m3dstbi__mad3sizes_valid(img_n, x, depth, 7)) return _m3dstbi__err("too large", "Corrupt PNG");
   img_width_bytes = (((img_n * x * depth) + 7) >> 3);
   img_len = (img_width_bytes + 1) * y;
   if (s->img_x == x && s->img_y == y) {
      if (raw_len != img_len) return _m3dstbi__err("not enough pixels","Corrupt PNG");
   } else {
      if (raw_len < img_len) return _m3dstbi__err("not enough pixels","Corrupt PNG");
   }

   for (j=0; j < y; ++j) {
      unsigned char *cur = a->out + stride*j;
      unsigned char *prior = cur - stride;
      int filter = *raw++;

      if (filter > 4)
         return _m3dstbi__err("invalid filter","Corrupt PNG");

      if (depth < 8) {
         STBI_ASSERT(img_width_bytes <= x);
         cur += x*out_n - img_width_bytes;
         filter_bytes = 1;
         width = img_width_bytes;
      }
      prior = cur - stride;

      if (j == 0) filter = first_row_filter[filter];

      for (k=0; k < filter_bytes; ++k) {
         switch (filter) {
            case STBI__F_none       : cur[k] = raw[k]; break;
            case STBI__F_sub        : cur[k] = raw[k]; break;
            case STBI__F_up         : cur[k] = STBI__BYTECAST(raw[k] + prior[k]); break;
            case STBI__F_avg        : cur[k] = STBI__BYTECAST(raw[k] + (prior[k]>>1)); break;
            case STBI__F_paeth      : cur[k] = STBI__BYTECAST(raw[k] + _m3dstbi__paeth(0,prior[k],0)); break;
            case STBI__F_avg_first  : cur[k] = raw[k]; break;
            case STBI__F_paeth_first: cur[k] = raw[k]; break;
         }
      }

      if (depth == 8) {
         if (img_n != out_n)
            cur[img_n] = 255;
         raw += img_n;
         cur += out_n;
         prior += out_n;
      } else if (depth == 16) {
         if (img_n != out_n) {
            cur[filter_bytes]   = 255;
            cur[filter_bytes+1] = 255;
         }
         raw += filter_bytes;
         cur += output_bytes;
         prior += output_bytes;
      } else {
         raw += 1;
         cur += 1;
         prior += 1;
      }

      if (depth < 8 || img_n == out_n) {
         int nk = (width - 1)*filter_bytes;
         #define STBI__CASE(f) \
             case f:     \
                for (k=0; k < nk; ++k)
         switch (filter) {
            case STBI__F_none:         memcpy(cur, raw, nk); break;
            STBI__CASE(STBI__F_sub)          { cur[k] = STBI__BYTECAST(raw[k] + cur[k-filter_bytes]); } break;
            STBI__CASE(STBI__F_up)           { cur[k] = STBI__BYTECAST(raw[k] + prior[k]); } break;
            STBI__CASE(STBI__F_avg)          { cur[k] = STBI__BYTECAST(raw[k] + ((prior[k] + cur[k-filter_bytes])>>1)); } break;
            STBI__CASE(STBI__F_paeth)        { cur[k] = STBI__BYTECAST(raw[k] + _m3dstbi__paeth(cur[k-filter_bytes],prior[k],prior[k-filter_bytes])); } break;
            STBI__CASE(STBI__F_avg_first)    { cur[k] = STBI__BYTECAST(raw[k] + (cur[k-filter_bytes] >> 1)); } break;
            STBI__CASE(STBI__F_paeth_first)  { cur[k] = STBI__BYTECAST(raw[k] + _m3dstbi__paeth(cur[k-filter_bytes],0,0)); } break;
         }
         #undef STBI__CASE
         raw += nk;
      } else {
         STBI_ASSERT(img_n+1 == out_n);
         #define STBI__CASE(f) \
             case f:     \
                for (i=x-1; i >= 1; --i, cur[filter_bytes]=255,raw+=filter_bytes,cur+=output_bytes,prior+=output_bytes) \
                   for (k=0; k < filter_bytes; ++k)
         switch (filter) {
            STBI__CASE(STBI__F_none)         { cur[k] = raw[k]; } break;
            STBI__CASE(STBI__F_sub)          { cur[k] = STBI__BYTECAST(raw[k] + cur[k- output_bytes]); } break;
            STBI__CASE(STBI__F_up)           { cur[k] = STBI__BYTECAST(raw[k] + prior[k]); } break;
            STBI__CASE(STBI__F_avg)          { cur[k] = STBI__BYTECAST(raw[k] + ((prior[k] + cur[k- output_bytes])>>1)); } break;
            STBI__CASE(STBI__F_paeth)        { cur[k] = STBI__BYTECAST(raw[k] + _m3dstbi__paeth(cur[k- output_bytes],prior[k],prior[k- output_bytes])); } break;
            STBI__CASE(STBI__F_avg_first)    { cur[k] = STBI__BYTECAST(raw[k] + (cur[k- output_bytes] >> 1)); } break;
            STBI__CASE(STBI__F_paeth_first)  { cur[k] = STBI__BYTECAST(raw[k] + _m3dstbi__paeth(cur[k- output_bytes],0,0)); } break;
         }
         #undef STBI__CASE

         if (depth == 16) {
            cur = a->out + stride*j;
            for (i=0; i < x; ++i,cur+=output_bytes) {
               cur[filter_bytes+1] = 255;
            }
         }
      }
   }

   if (depth < 8) {
      for (j=0; j < y; ++j) {
         unsigned char *cur = a->out + stride*j;
         unsigned char *in  = a->out + stride*j + x*out_n - img_width_bytes;
         unsigned char scale = (color == 0) ? _m3dstbi__depth_scale_table[depth] : 1;

         if (depth == 4) {
            for (k=x*img_n; k >= 2; k-=2, ++in) {
               *cur++ = scale * ((*in >> 4)       );
               *cur++ = scale * ((*in     ) & 0x0f);
            }
            if (k > 0) *cur++ = scale * ((*in >> 4)       );
         } else if (depth == 2) {
            for (k=x*img_n; k >= 4; k-=4, ++in) {
               *cur++ = scale * ((*in >> 6)       );
               *cur++ = scale * ((*in >> 4) & 0x03);
               *cur++ = scale * ((*in >> 2) & 0x03);
               *cur++ = scale * ((*in     ) & 0x03);
            }
            if (k > 0) *cur++ = scale * ((*in >> 6)       );
            if (k > 1) *cur++ = scale * ((*in >> 4) & 0x03);
            if (k > 2) *cur++ = scale * ((*in >> 2) & 0x03);
         } else if (depth == 1) {
            for (k=x*img_n; k >= 8; k-=8, ++in) {
               *cur++ = scale * ((*in >> 7)       );
               *cur++ = scale * ((*in >> 6) & 0x01);
               *cur++ = scale * ((*in >> 5) & 0x01);
               *cur++ = scale * ((*in >> 4) & 0x01);
               *cur++ = scale * ((*in >> 3) & 0x01);
               *cur++ = scale * ((*in >> 2) & 0x01);
               *cur++ = scale * ((*in >> 1) & 0x01);
               *cur++ = scale * ((*in     ) & 0x01);
            }
            if (k > 0) *cur++ = scale * ((*in >> 7)       );
            if (k > 1) *cur++ = scale * ((*in >> 6) & 0x01);
            if (k > 2) *cur++ = scale * ((*in >> 5) & 0x01);
            if (k > 3) *cur++ = scale * ((*in >> 4) & 0x01);
            if (k > 4) *cur++ = scale * ((*in >> 3) & 0x01);
            if (k > 5) *cur++ = scale * ((*in >> 2) & 0x01);
            if (k > 6) *cur++ = scale * ((*in >> 1) & 0x01);
         }
         if (img_n != out_n) {
            int q;
            cur = a->out + stride*j;
            if (img_n == 1) {
               for (q=x-1; q >= 0; --q) {
                  cur[q*2+1] = 255;
                  cur[q*2+0] = cur[q];
               }
            } else {
               STBI_ASSERT(img_n == 3);
               for (q=x-1; q >= 0; --q) {
                  cur[q*4+3] = 255;
                  cur[q*4+2] = cur[q*3+2];
                  cur[q*4+1] = cur[q*3+1];
                  cur[q*4+0] = cur[q*3+0];
               }
            }
         }
      }
   } else if (depth == 16) {
      unsigned char *cur = a->out;
      _m3dstbi__uint16 *cur16 = (_m3dstbi__uint16*)cur;

      for(i=0; i < x*y*out_n; ++i,cur16++,cur+=2) {
         *cur16 = (cur[0] << 8) | cur[1];
      }
   }

   return 1;
}

static int _m3dstbi__create_png_image(_m3dstbi__png *a, unsigned char *image_data, _m3dstbi__uint32 image_data_len, int out_n, int depth, int color, int interlaced)
{
   int bytes = (depth == 16 ? 2 : 1);
   int out_bytes = out_n * bytes;
   unsigned char *final;
   int p;
   if (!interlaced)
      return _m3dstbi__create_png_image_raw(a, image_data, image_data_len, out_n, a->s->img_x, a->s->img_y, depth, color);

   final = (unsigned char *) _m3dstbi__malloc_mad3(a->s->img_x, a->s->img_y, out_bytes, 0);
   for (p=0; p < 7; ++p) {
      int xorig[] = { 0,4,0,2,0,1,0 };
      int yorig[] = { 0,0,4,0,2,0,1 };
      int xspc[]  = { 8,8,4,4,2,2,1 };
      int yspc[]  = { 8,8,8,4,4,2,2 };
      int i,j,x,y;
      x = (a->s->img_x - xorig[p] + xspc[p]-1) / xspc[p];
      y = (a->s->img_y - yorig[p] + yspc[p]-1) / yspc[p];
      if (x && y) {
         _m3dstbi__uint32 img_len = ((((a->s->img_n * x * depth) + 7) >> 3) + 1) * y;
         if (!_m3dstbi__create_png_image_raw(a, image_data, image_data_len, out_n, x, y, depth, color)) {
            STBI_FREE(final);
            return 0;
         }
         for (j=0; j < y; ++j) {
            for (i=0; i < x; ++i) {
               int out_y = j*yspc[p]+yorig[p];
               int out_x = i*xspc[p]+xorig[p];
               memcpy(final + out_y*a->s->img_x*out_bytes + out_x*out_bytes,
                      a->out + (j*x+i)*out_bytes, out_bytes);
            }
         }
         STBI_FREE(a->out);
         image_data += img_len;
         image_data_len -= img_len;
      }
   }
   a->out = final;

   return 1;
}

static int _m3dstbi__compute_transparency(_m3dstbi__png *z, unsigned char tc[3], int out_n)
{
   _m3dstbi__context *s = z->s;
   _m3dstbi__uint32 i, pixel_count = s->img_x * s->img_y;
   unsigned char *p = z->out;

   STBI_ASSERT(out_n == 2 || out_n == 4);

   if (out_n == 2) {
      for (i=0; i < pixel_count; ++i) {
         p[1] = (p[0] == tc[0] ? 0 : 255);
         p += 2;
      }
   } else {
      for (i=0; i < pixel_count; ++i) {
         if (p[0] == tc[0] && p[1] == tc[1] && p[2] == tc[2])
            p[3] = 0;
         p += 4;
      }
   }
   return 1;
}

static int _m3dstbi__compute_transparency16(_m3dstbi__png *z, _m3dstbi__uint16 tc[3], int out_n)
{
   _m3dstbi__context *s = z->s;
   _m3dstbi__uint32 i, pixel_count = s->img_x * s->img_y;
   _m3dstbi__uint16 *p = (_m3dstbi__uint16*) z->out;

   STBI_ASSERT(out_n == 2 || out_n == 4);

   if (out_n == 2) {
      for (i = 0; i < pixel_count; ++i) {
         p[1] = (p[0] == tc[0] ? 0 : 65535);
         p += 2;
      }
   } else {
      for (i = 0; i < pixel_count; ++i) {
         if (p[0] == tc[0] && p[1] == tc[1] && p[2] == tc[2])
            p[3] = 0;
         p += 4;
      }
   }
   return 1;
}

static int _m3dstbi__expand_png_palette(_m3dstbi__png *a, unsigned char *palette, int len, int pal_img_n)
{
   _m3dstbi__uint32 i, pixel_count = a->s->img_x * a->s->img_y;
   unsigned char *p, *temp_out, *orig = a->out;

   p = (unsigned char *) _m3dstbi__malloc_mad2(pixel_count, pal_img_n, 0);
   if (p == NULL) return _m3dstbi__err("outofmem", "Out of memory");

   temp_out = p;

   if (pal_img_n == 3) {
      for (i=0; i < pixel_count; ++i) {
         int n = orig[i]*4;
         p[0] = palette[n  ];
         p[1] = palette[n+1];
         p[2] = palette[n+2];
         p += 3;
      }
   } else {
      for (i=0; i < pixel_count; ++i) {
         int n = orig[i]*4;
         p[0] = palette[n  ];
         p[1] = palette[n+1];
         p[2] = palette[n+2];
         p[3] = palette[n+3];
         p += 4;
      }
   }
   STBI_FREE(a->out);
   a->out = temp_out;

   STBI_NOTUSED(len);

   return 1;
}

#define STBI__PNG_TYPE(a,b,c,d)  (((unsigned) (a) << 24) + ((unsigned) (b) << 16) + ((unsigned) (c) << 8) + (unsigned) (d))

static int _m3dstbi__parse_png_file(_m3dstbi__png *z, int scan, int req_comp)
{
   unsigned char palette[1024], pal_img_n=0;
   unsigned char has_trans=0, tc[3];
   _m3dstbi__uint16 tc16[3];
   _m3dstbi__uint32 ioff=0, idata_limit=0, i, pal_len=0;
   int first=1,k,interlace=0, color=0;
   _m3dstbi__context *s = z->s;

   z->expanded = NULL;
   z->idata = NULL;
   z->out = NULL;

   if (!_m3dstbi__check_png_header(s)) return 0;

   if (scan == STBI__SCAN_type) return 1;

   for (;;) {
      _m3dstbi__pngchunk c = _m3dstbi__get_chunk_header(s);
      switch (c.type) {
         case STBI__PNG_TYPE('C','g','B','I'):
            _m3dstbi__skip(s, c.length);
            break;
         case STBI__PNG_TYPE('I','H','D','R'): {
            int comp,filter;
            if (!first) return _m3dstbi__err("multiple IHDR","Corrupt PNG");
            first = 0;
            if (c.length != 13) return _m3dstbi__err("bad IHDR len","Corrupt PNG");
            s->img_x = _m3dstbi__get32be(s); if (s->img_x > (1 << 24)) return _m3dstbi__err("too large","Very large image (corrupt?)");
            s->img_y = _m3dstbi__get32be(s); if (s->img_y > (1 << 24)) return _m3dstbi__err("too large","Very large image (corrupt?)");
            z->depth = _m3dstbi__get8(s);  if (z->depth != 1 && z->depth != 2 && z->depth != 4 && z->depth != 8 && z->depth != 16)  return _m3dstbi__err("1/2/4/8/16-bit only","PNG not supported: 1/2/4/8/16-bit only");
            color = _m3dstbi__get8(s);  if (color > 6)         return _m3dstbi__err("bad ctype","Corrupt PNG");
            if (color == 3 && z->depth == 16)                  return _m3dstbi__err("bad ctype","Corrupt PNG");
            if (color == 3) pal_img_n = 3; else if (color & 1) return _m3dstbi__err("bad ctype","Corrupt PNG");
            comp  = _m3dstbi__get8(s);  if (comp) return _m3dstbi__err("bad comp method","Corrupt PNG");
            filter= _m3dstbi__get8(s);  if (filter) return _m3dstbi__err("bad filter method","Corrupt PNG");
            interlace = _m3dstbi__get8(s); if (interlace>1) return _m3dstbi__err("bad interlace method","Corrupt PNG");
            if (!s->img_x || !s->img_y) return _m3dstbi__err("0-pixel image","Corrupt PNG");
            if (!pal_img_n) {
               s->img_n = (color & 2 ? 3 : 1) + (color & 4 ? 1 : 0);
               if ((1 << 30) / s->img_x / s->img_n < s->img_y) return _m3dstbi__err("too large", "Image too large to decode");
               if (scan == STBI__SCAN_header) return 1;
            } else {
               s->img_n = 1;
               if ((1 << 30) / s->img_x / 4 < s->img_y) return _m3dstbi__err("too large","Corrupt PNG");
            }
            break;
         }

         case STBI__PNG_TYPE('P','L','T','E'):  {
            if (first) return _m3dstbi__err("first not IHDR", "Corrupt PNG");
            if (c.length > 256*3) return _m3dstbi__err("invalid PLTE","Corrupt PNG");
            pal_len = c.length / 3;
            if (pal_len * 3 != c.length) return _m3dstbi__err("invalid PLTE","Corrupt PNG");
            for (i=0; i < pal_len; ++i) {
               palette[i*4+0] = _m3dstbi__get8(s);
               palette[i*4+1] = _m3dstbi__get8(s);
               palette[i*4+2] = _m3dstbi__get8(s);
               palette[i*4+3] = 255;
            }
            break;
         }

         case STBI__PNG_TYPE('t','R','N','S'): {
            if (first) return _m3dstbi__err("first not IHDR", "Corrupt PNG");
            if (z->idata) return _m3dstbi__err("tRNS after IDAT","Corrupt PNG");
            if (pal_img_n) {
               if (scan == STBI__SCAN_header) { s->img_n = 4; return 1; }
               if (pal_len == 0) return _m3dstbi__err("tRNS before PLTE","Corrupt PNG");
               if (c.length > pal_len) return _m3dstbi__err("bad tRNS len","Corrupt PNG");
               pal_img_n = 4;
               for (i=0; i < c.length; ++i)
                  palette[i*4+3] = _m3dstbi__get8(s);
            } else {
               if (!(s->img_n & 1)) return _m3dstbi__err("tRNS with alpha","Corrupt PNG");
               if (c.length != (_m3dstbi__uint32) s->img_n*2) return _m3dstbi__err("bad tRNS len","Corrupt PNG");
               has_trans = 1;
               if (z->depth == 16) {
                  for (k = 0; k < s->img_n; ++k) tc16[k] = (_m3dstbi__uint16)_m3dstbi__get16be(s);
               } else {
                  for (k = 0; k < s->img_n; ++k) tc[k] = (unsigned char)(_m3dstbi__get16be(s) & 255) * _m3dstbi__depth_scale_table[z->depth];
               }
            }
            break;
         }

         case STBI__PNG_TYPE('I','D','A','T'): {
            if (first) return _m3dstbi__err("first not IHDR", "Corrupt PNG");
            if (pal_img_n && !pal_len) return _m3dstbi__err("no PLTE","Corrupt PNG");
            if (scan == STBI__SCAN_header) { s->img_n = pal_img_n; return 1; }
            if ((int)(ioff + c.length) < (int)ioff) return 0;
            if (ioff + c.length > idata_limit) {
               _m3dstbi__uint32 idata_limit_old = idata_limit;
               unsigned char *p;
               if (idata_limit == 0) idata_limit = c.length > 4096 ? c.length : 4096;
               while (ioff + c.length > idata_limit)
                  idata_limit *= 2;
               STBI_NOTUSED(idata_limit_old);
               p = (unsigned char *) STBI_REALLOC_SIZED(z->idata, idata_limit_old, idata_limit); if (p == NULL) return _m3dstbi__err("outofmem", "Out of memory");
               z->idata = p;
            }
            if (!_m3dstbi__getn(s, z->idata+ioff,c.length)) return _m3dstbi__err("outofdata","Corrupt PNG");
            ioff += c.length;
            break;
         }

         case STBI__PNG_TYPE('I','E','N','D'): {
            _m3dstbi__uint32 raw_len, bpl;
            if (first) return _m3dstbi__err("first not IHDR", "Corrupt PNG");
            if (scan != STBI__SCAN_load) return 1;
            if (z->idata == NULL) return _m3dstbi__err("no IDAT","Corrupt PNG");
            bpl = (s->img_x * z->depth + 7) / 8;
            raw_len = bpl * s->img_y * s->img_n /* pixels */ + s->img_y /* filter mode per row */;
            z->expanded = (unsigned char *) _m3dstbi_zlib_decode_malloc_guesssize_headerflag((char *) z->idata, ioff, raw_len, (int *) &raw_len, 1);
            if (z->expanded == NULL) return 0;
            STBI_FREE(z->idata); z->idata = NULL;
            if ((req_comp == s->img_n+1 && req_comp != 3 && !pal_img_n) || has_trans)
               s->img_out_n = s->img_n+1;
            else
               s->img_out_n = s->img_n;
            if (!_m3dstbi__create_png_image(z, z->expanded, raw_len, s->img_out_n, z->depth, color, interlace)) return 0;
            if (has_trans) {
               if (z->depth == 16) {
                  if (!_m3dstbi__compute_transparency16(z, tc16, s->img_out_n)) return 0;
               } else {
                  if (!_m3dstbi__compute_transparency(z, tc, s->img_out_n)) return 0;
               }
            }
            if (pal_img_n) {
               s->img_n = pal_img_n;
               s->img_out_n = pal_img_n;
               if (req_comp >= 3) s->img_out_n = req_comp;
               if (!_m3dstbi__expand_png_palette(z, palette, pal_len, s->img_out_n))
                  return 0;
            } else if (has_trans) {
               ++s->img_n;
            }
            STBI_FREE(z->expanded); z->expanded = NULL;
            return 1;
         }

         default:
            if (first) return _m3dstbi__err("first not IHDR", "Corrupt PNG");
            if ((c.type & (1 << 29)) == 0) {
               return _m3dstbi__err("invalid_chunk", "PNG not supported: unknown PNG chunk type");
            }
            _m3dstbi__skip(s, c.length);
            break;
      }
      _m3dstbi__get32be(s);
   }
}

static void *_m3dstbi__do_png(_m3dstbi__png *p, int *x, int *y, int *n, int req_comp, _m3dstbi__result_info *ri)
{
   void *result=NULL;
   if (req_comp < 0 || req_comp > 4) { _m3dstbi__err("bad req_comp", "Internal error"); return NULL; }
   if (_m3dstbi__parse_png_file(p, STBI__SCAN_load, req_comp)) {
      if (p->depth < 8)
         ri->bits_per_channel = 8;
      else
         ri->bits_per_channel = p->depth;
      result = p->out;
      p->out = NULL;
      if (req_comp && req_comp != p->s->img_out_n) {
         if (ri->bits_per_channel == 8)
            result = _m3dstbi__convert_format((unsigned char *) result, p->s->img_out_n, req_comp, p->s->img_x, p->s->img_y);
         else
            result = _m3dstbi__convert_format16((_m3dstbi__uint16 *) result, p->s->img_out_n, req_comp, p->s->img_x, p->s->img_y);
         p->s->img_out_n = req_comp;
         if (result == NULL) return result;
      }
      *x = p->s->img_x;
      *y = p->s->img_y;
      if (n) *n = p->s->img_n;
   }
   STBI_FREE(p->out);      p->out      = NULL;
   STBI_FREE(p->expanded); p->expanded = NULL;
   STBI_FREE(p->idata);    p->idata    = NULL;

   return result;
}

static void *_m3dstbi__png_load(_m3dstbi__context *s, int *x, int *y, int *comp, int req_comp, _m3dstbi__result_info *ri)
{
   _m3dstbi__png p;
   p.s = s;
   return _m3dstbi__do_png(&p, x,y,comp,req_comp, ri);
}
#define stbi__context _m3dstbi__context
#define stbi__result_info _m3dstbi__result_info
#define stbi__png_load _m3dstbi__png_load
#define stbi_zlib_decode_malloc_guesssize_headerflag _m3dstbi_zlib_decode_malloc_guesssize_headerflag
#endif
#if !defined(M3D_NOIMPORTER) && defined(STBI_INCLUDE_STB_IMAGE_H) && !defined(STB_IMAGE_IMPLEMENTATION)
#error "stb_image.h included without STB_IMAGE_IMPLEMENTATION. Sorry, we need some stuff defined inside the ifguard for proper integration"
#endif
#else
#if !defined(STBI_INCLUDE_STB_IMAGE_H) || defined(STBI_NO_ZLIB)
#error "stb_image.h not included or STBI_NO_ZLIB defined. Sorry, we need its zlib implementation for proper integration"
#endif
#endif /* M3D_NOTEXTURE */

#if defined(M3D_EXPORTER) && !defined(INCLUDE_STB_IMAGE_WRITE_H)
/* zlib_compressor from

   stb_image_write - v1.13 - public domain - http://nothings.org/stb/stb_image_write.h
*/
typedef unsigned char _m3dstbiw__uc;
typedef unsigned short _m3dstbiw__us;

typedef uint16_t _m3dstbiw__uint16;
typedef int16_t  _m3dstbiw__int16;
typedef uint32_t _m3dstbiw__uint32;
typedef int32_t  _m3dstbiw__int32;

#define STBIW_MALLOC(s)     M3D_MALLOC(s)
#define STBIW_REALLOC(p,ns) M3D_REALLOC(p,ns)
#define STBIW_REALLOC_SIZED(p,oldsz,newsz) STBIW_REALLOC(p,newsz)
#define STBIW_FREE          M3D_FREE
#define STBIW_MEMMOVE       memmove
#define STBIW_UCHAR         (uint8_t)
#define STBIW_ASSERT(x)
#define _m3dstbiw___sbraw(a)     ((int *) (a) - 2)
#define _m3dstbiw___sbm(a)       _m3dstbiw___sbraw(a)[0]
#define _m3dstbiw___sbn(a)       _m3dstbiw___sbraw(a)[1]

#define _m3dstbiw___sbneedgrow(a,n)  ((a)==0 || _m3dstbiw___sbn(a)+n >= _m3dstbiw___sbm(a))
#define _m3dstbiw___sbmaybegrow(a,n) (_m3dstbiw___sbneedgrow(a,(n)) ? _m3dstbiw___sbgrow(a,n) : 0)
#define _m3dstbiw___sbgrow(a,n)  _m3dstbiw___sbgrowf((void **) &(a), (n), sizeof(*(a)))

#define _m3dstbiw___sbpush(a, v)      (_m3dstbiw___sbmaybegrow(a,1), (a)[_m3dstbiw___sbn(a)++] = (v))
#define _m3dstbiw___sbcount(a)        ((a) ? _m3dstbiw___sbn(a) : 0)
#define _m3dstbiw___sbfree(a)         ((a) ? STBIW_FREE(_m3dstbiw___sbraw(a)),0 : 0)

static void *_m3dstbiw___sbgrowf(void **arr, int increment, int itemsize)
{
   int m = *arr ? 2*_m3dstbiw___sbm(*arr)+increment : increment+1;
   void *p = STBIW_REALLOC_SIZED(*arr ? _m3dstbiw___sbraw(*arr) : 0, *arr ? (_m3dstbiw___sbm(*arr)*itemsize + sizeof(int)*2) : 0, itemsize * m + sizeof(int)*2);
   STBIW_ASSERT(p);
   if (p) {
      if (!*arr) ((int *) p)[1] = 0;
      *arr = (void *) ((int *) p + 2);
      _m3dstbiw___sbm(*arr) = m;
   }
   return *arr;
}

static unsigned char *_m3dstbiw___zlib_flushf(unsigned char *data, unsigned int *bitbuffer, int *bitcount)
{
   while (*bitcount >= 8) {
      _m3dstbiw___sbpush(data, STBIW_UCHAR(*bitbuffer));
      *bitbuffer >>= 8;
      *bitcount -= 8;
   }
   return data;
}

static int _m3dstbiw___zlib_bitrev(int code, int codebits)
{
   int res=0;
   while (codebits--) {
      res = (res << 1) | (code & 1);
      code >>= 1;
   }
   return res;
}

static unsigned int _m3dstbiw___zlib_countm(unsigned char *a, unsigned char *b, int limit)
{
   int i;
   for (i=0; i < limit && i < 258; ++i)
      if (a[i] != b[i]) break;
   return i;
}

static unsigned int _m3dstbiw___zhash(unsigned char *data)
{
   _m3dstbiw__uint32 hash = data[0] + (data[1] << 8) + (data[2] << 16);
   hash ^= hash << 3;
   hash += hash >> 5;
   hash ^= hash << 4;
   hash += hash >> 17;
   hash ^= hash << 25;
   hash += hash >> 6;
   return hash;
}

#define _m3dstbiw___zlib_flush() (out = _m3dstbiw___zlib_flushf(out, &bitbuf, &bitcount))
#define _m3dstbiw___zlib_add(code,codebits) \
      (bitbuf |= (code) << bitcount, bitcount += (codebits), _m3dstbiw___zlib_flush())
#define _m3dstbiw___zlib_huffa(b,c)  _m3dstbiw___zlib_add(_m3dstbiw___zlib_bitrev(b,c),c)
#define _m3dstbiw___zlib_huff1(n)  _m3dstbiw___zlib_huffa(0x30 + (n), 8)
#define _m3dstbiw___zlib_huff2(n)  _m3dstbiw___zlib_huffa(0x190 + (n)-144, 9)
#define _m3dstbiw___zlib_huff3(n)  _m3dstbiw___zlib_huffa(0 + (n)-256,7)
#define _m3dstbiw___zlib_huff4(n)  _m3dstbiw___zlib_huffa(0xc0 + (n)-280,8)
#define _m3dstbiw___zlib_huff(n)  ((n) <= 143 ? _m3dstbiw___zlib_huff1(n) : (n) <= 255 ? _m3dstbiw___zlib_huff2(n) : (n) <= 279 ? _m3dstbiw___zlib_huff3(n) : _m3dstbiw___zlib_huff4(n))
#define _m3dstbiw___zlib_huffb(n) ((n) <= 143 ? _m3dstbiw___zlib_huff1(n) : _m3dstbiw___zlib_huff2(n))

#define _m3dstbiw___ZHASH   16384

unsigned char * _m3dstbi_zlib_compress(unsigned char *data, int data_len, int *out_len, int quality)
{
   static unsigned short lengthc[] = { 3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258, 259 };
   static unsigned char  lengtheb[]= { 0,0,0,0,0,0,0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4,  4,  5,  5,  5,  5,  0 };
   static unsigned short distc[]   = { 1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577, 32768 };
   static unsigned char  disteb[]  = { 0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13 };
   unsigned int bitbuf=0;
   int i,j, bitcount=0;
   unsigned char *out = NULL;
   unsigned char ***hash_table = (unsigned char***) STBIW_MALLOC(_m3dstbiw___ZHASH * sizeof(char**));
   if (hash_table == NULL)
      return NULL;
   if (quality < 5) quality = 5;

   _m3dstbiw___sbpush(out, 0x78);
   _m3dstbiw___sbpush(out, 0x5e);
   _m3dstbiw___zlib_add(1,1);
   _m3dstbiw___zlib_add(1,2);

   for (i=0; i < _m3dstbiw___ZHASH; ++i)
      hash_table[i] = NULL;

   i=0;
   while (i < data_len-3) {
      int h = _m3dstbiw___zhash(data+i)&(_m3dstbiw___ZHASH-1), best=3;
      unsigned char *bestloc = 0;
      unsigned char **hlist = hash_table[h];
      int n = _m3dstbiw___sbcount(hlist);
      for (j=0; j < n; ++j) {
         if (hlist[j]-data > i-32768) {
            int d = _m3dstbiw___zlib_countm(hlist[j], data+i, data_len-i);
            if (d >= best) best=d,bestloc=hlist[j];
         }
      }
      if (hash_table[h] && _m3dstbiw___sbn(hash_table[h]) == 2*quality) {
         STBIW_MEMMOVE(hash_table[h], hash_table[h]+quality, sizeof(hash_table[h][0])*quality);
         _m3dstbiw___sbn(hash_table[h]) = quality;
      }
      _m3dstbiw___sbpush(hash_table[h],data+i);

      if (bestloc) {
         h = _m3dstbiw___zhash(data+i+1)&(_m3dstbiw___ZHASH-1);
         hlist = hash_table[h];
         n = _m3dstbiw___sbcount(hlist);
         for (j=0; j < n; ++j) {
            if (hlist[j]-data > i-32767) {
               int e = _m3dstbiw___zlib_countm(hlist[j], data+i+1, data_len-i-1);
               if (e > best) {
                  bestloc = NULL;
                  break;
               }
            }
         }
      }

      if (bestloc) {
         int d = (int) (data+i - bestloc);
         STBIW_ASSERT(d <= 32767 && best <= 258);
         for (j=0; best > lengthc[j+1]-1; ++j);
         _m3dstbiw___zlib_huff(j+257);
         if (lengtheb[j]) _m3dstbiw___zlib_add(best - lengthc[j], lengtheb[j]);
         for (j=0; d > distc[j+1]-1; ++j);
         _m3dstbiw___zlib_add(_m3dstbiw___zlib_bitrev(j,5),5);
         if (disteb[j]) _m3dstbiw___zlib_add(d - distc[j], disteb[j]);
         i += best;
      } else {
         _m3dstbiw___zlib_huffb(data[i]);
         ++i;
      }
   }
   for (;i < data_len; ++i)
      _m3dstbiw___zlib_huffb(data[i]);
   _m3dstbiw___zlib_huff(256);
   while (bitcount)
      _m3dstbiw___zlib_add(0,1);

   for (i=0; i < _m3dstbiw___ZHASH; ++i)
      (void) _m3dstbiw___sbfree(hash_table[i]);
   STBIW_FREE(hash_table);

   {
      unsigned int s1=1, s2=0;
      int blocklen = (int) (data_len % 5552);
      j=0;
      while (j < data_len) {
         for (i=0; i < blocklen; ++i) s1 += data[j+i], s2 += s1;
         s1 %= 65521, s2 %= 65521;
         j += blocklen;
         blocklen = 5552;
      }
      _m3dstbiw___sbpush(out, STBIW_UCHAR(s2 >> 8));
      _m3dstbiw___sbpush(out, STBIW_UCHAR(s2));
      _m3dstbiw___sbpush(out, STBIW_UCHAR(s1 >> 8));
      _m3dstbiw___sbpush(out, STBIW_UCHAR(s1));
   }
   *out_len = _m3dstbiw___sbn(out);
   STBIW_MEMMOVE(_m3dstbiw___sbraw(out), out, *out_len);
   return (unsigned char *) _m3dstbiw___sbraw(out);
}
#define stbi_zlib_compress _m3dstbi_zlib_compress
#else
unsigned char * _m3dstbi_zlib_compress(unsigned char *data, int data_len, int *out_len, int quality);
#endif

#define M3D_CHUNKMAGIC(m, a,b,c,d) ((m)[0]==(a) && (m)[1]==(b) && (m)[2]==(c) && (m)[3]==(d))

#ifdef M3D_ASCII
#include <stdio.h>          /* get sprintf */
#include <locale.h>         /* sprintf and strtod cares about number locale */
#endif
#ifdef M3D_PROFILING
#include <sys/time.h>
#endif

#if !defined(M3D_NOIMPORTER) && defined(M3D_ASCII)
/* helper functions for the ASCII parser */
static char *_m3d_findarg(char *s) {
    while(s && *s && *s != ' ' && *s != '\t' && *s != '\r' && *s != '\n') s++;
    while(s && *s && (*s == ' ' || *s == '\t')) s++;
    return s;
}
static char *_m3d_findnl(char *s) {
    while(s && *s && *s != '\r' && *s != '\n') s++;
    if(*s == '\r') s++;
    if(*s == '\n') s++;
    return s;
}
static char *_m3d_gethex(char *s, uint32_t *ret)
{
    if(*s == '#') s++;
    *ret = 0;
    for(; *s; s++) {
        if(*s >= '0' && *s <= '9') {      *ret <<= 4; *ret += (uint32_t)(*s-'0'); }
        else if(*s >= 'a' && *s <= 'f') { *ret <<= 4; *ret += (uint32_t)(*s-'a'+10); }
        else if(*s >= 'A' && *s <= 'F') { *ret <<= 4; *ret += (uint32_t)(*s-'A'+10); }
        else break;
    }
    return _m3d_findarg(s);
}
static char *_m3d_getint(char *s, uint32_t *ret)
{
    char *e = s;
    if(!s || !*s || *s == '\r' || *s == '\n') return s;
    for(; *e >= '0' && *e <= '9'; e++);
    *ret = atoi(s);
    return e;
}
static char *_m3d_getfloat(char *s, M3D_FLOAT *ret)
{
    char *e = s;
    if(!s || !*s || *s == '\r' || *s == '\n') return s;
    for(; *e == '-' || *e == '+' || *e == '.' || (*e >= '0' && *e <= '9') || *e == 'e' || *e == 'E'; e++);
    *ret = (M3D_FLOAT)strtod(s, NULL);
    return _m3d_findarg(e);
}
#endif
#if !defined(M3D_NODUP) && (!defined(M3D_NOIMPORTER) || defined(M3D_ASCII) || defined(M3D_EXPORTER))
/* helper function to create safe strings */
char *_m3d_safestr(char *in, int morelines)
{
    char *out, *o, *i = in;
    int l;
    if(!in || !*in) {
        out = (char*)M3D_MALLOC(1);
        if(!out) return NULL;
        out[0] =0;
    } else {
        for(o = in, l = 0; *o && ((morelines & 1) || (*o != '\r' && *o != '\n')) && l < 256; o++, l++);
        out = o = (char*)M3D_MALLOC(l+1);
        if(!out) return NULL;
        while(*i == ' ' || *i == '\t' || *i == '\r' || (morelines && *i == '\n')) i++;
        for(; *i && (morelines || (*i != '\r' && *i != '\n')); i++) {
            if(*i == '\r') continue;
            if(*i == '\n') {
                if(morelines >= 3 && o > out && *(o-1) == '\n') break;
                if(i > in && *(i-1) == '\n') continue;
                if(morelines & 1) {
                    if(morelines == 1) *o++ = '\r';
                    *o++ = '\n';
                } else
                    break;
            } else
            if(*i == ' ' || *i == '\t') {
                *o++ = morelines? ' ' : '_';
            } else
                *o++ = !morelines && (*i == '/' || *i == '\\') ? '_' : *i;
        }
        for(; o > out && (*(o-1) == ' ' || *(o-1) == '\t' || *(o-1) == '\r' || *(o-1) == '\n'); o--);
        *o = 0;
        out = (char*)M3D_REALLOC(out, (uintptr_t)o - (uintptr_t)out + 1);
    }
    return out;
}
#endif
#ifndef M3D_NOIMPORTER
/* helper function to load and decode/generate a texture */
M3D_INDEX _m3d_gettx(m3d_t *model, m3dread_t readfilecb, m3dfree_t freecb, char *fn)
{
    unsigned int i, len = 0;
    unsigned char *buff = NULL;
    char *fn2;
#ifndef M3D_NOTEXTURE
    unsigned int w, h;
    stbi__context s;
    stbi__result_info ri;
#endif

    /* failsafe */
    if(!fn || !*fn) return M3D_UNDEF;
    /* do we have loaded this texture already? */
    for(i = 0; i < model->numtexture; i++)
        if(!strcmp(fn, model->texture[i].name)) return i;
    /* see if it's inlined in the model */
    if(model->inlined) {
        for(i = 0; i < model->numinlined; i++)
            if(!strcmp(fn, model->inlined[i].name)) {
                buff = model->inlined[i].data;
                len = model->inlined[i].length;
                freecb = NULL;
                break;
            }
    }
    /* try to load from external source */
    if(!buff && readfilecb) {
        i = (unsigned int)strlen(fn);
        if(i < 5 || fn[i - 4] != '.') {
            fn2 = (char*)M3D_MALLOC(i + 5);
            if(!fn2) { model->errcode = M3D_ERR_ALLOC; return M3D_UNDEF; }
            memcpy(fn2, fn, i);
            memcpy(fn2+i, ".png", 5);
            buff = (*readfilecb)(fn2, &len);
            M3D_FREE(fn2);
        }
        if(!buff) {
            buff = (*readfilecb)(fn, &len);
            if(!buff) return M3D_UNDEF;
        }
    }
    /* add to textures array */
    i = model->numtexture++;
    model->texture = (m3dtx_t*)M3D_REALLOC(model->texture, model->numtexture * sizeof(m3dtx_t));
    if(!model->texture) {
        if(buff && freecb) (*freecb)(buff);
        model->errcode = M3D_ERR_ALLOC;
        model->numtexture = 0;
        return M3D_UNDEF;
    }
    memset(&model->texture[i], 0, sizeof(m3dtx_t));
    model->texture[i].name = fn;
    if(buff) {
        if(buff[0] == 0x89 && buff[1] == 'P' && buff[2] == 'N' && buff[3] == 'G') {
#ifndef M3D_NOTEXTURE
            /* return pixel buffer of the decoded texture */
            memset(&s, 0, sizeof(s));
            memset(&ri, 0, sizeof(ri));
            s.img_buffer = s.img_buffer_original = (unsigned char *) buff;
            s.img_buffer_end = s.img_buffer_original_end = (unsigned char *) buff+len;
            /* don't use model->texture[i].w directly, it's a uint16_t */
            w = h = len = 0;
            ri.bits_per_channel = 8;
            model->texture[i].d = (uint8_t*)stbi__png_load(&s, (int*)&w, (int*)&h, (int*)&len, 0, &ri);
            model->texture[i].w = w;
            model->texture[i].h = h;
            model->texture[i].f = (uint8_t)len;
#else
            /* return only the raw undecoded texture */
            if((model->texture[i].d = (uint8_t*)M3D_MALLOC(len))) {
                memcpy(model->texture[i].d, buff, len);
                model->texture[i].w = len & 0xffff;
                model->texture[i].h = (len >> 16) & 0xffff;
                model->texture[i].f = 0;
            } else
                model->errcode = M3D_ERR_ALLOC;
#endif
        } else {
#ifdef M3D_TX_INTERP
            if((model->errcode = M3D_TX_INTERP(fn, buff, len, &model->texture[i])) != M3D_SUCCESS) {
                M3D_LOG("Unable to generate texture");
                M3D_LOG(fn);
            }
#else
            M3D_LOG("Unimplemented interpreter");
            M3D_LOG(fn);
#endif
        }
        if(freecb) (*freecb)(buff);
    }
    if(!model->texture[i].d)
        model->errcode = M3D_ERR_UNKIMG;
    return i;
}

/* helper function to load and generate a procedural surface */
void _m3d_getpr(m3d_t *model, _unused m3dread_t readfilecb, _unused  m3dfree_t freecb, _unused char *fn)
{
#ifdef M3D_PR_INTERP
    unsigned int i, len = 0;
    unsigned char *buff = readfilecb && fn && *fn ? (*readfilecb)(fn, &len) : NULL;

    if(!buff && fn && *fn && model->inlined) {
        for(i = 0; i < model->numinlined; i++)
            if(!strcmp(fn, model->inlined[i].name)) {
                buff = model->inlined[i].data;
                len = model->inlined[i].length;
                freecb = NULL;
                break;
            }
    }
    if(!buff || !len || (model->errcode = M3D_PR_INTERP(fn, buff, len, model)) != M3D_SUCCESS) {
        M3D_LOG("Unable to generate procedural surface");
        M3D_LOG(fn);
        model->errcode = M3D_ERR_UNKIMG;
    }
    if(freecb && buff) (*freecb)(buff);
#else
    (void)readfilecb;
    (void)freecb;
    (void)fn;
    M3D_LOG("Unimplemented interpreter");
    M3D_LOG(fn);
    model->errcode = M3D_ERR_UNIMPL;
#endif
}
/* helpers to read indices from data stream */
#define M3D_GETSTR(x) do{offs=0;data=_m3d_getidx(data,model->si_s,&offs);x=offs?((char*)model->raw+16+offs):NULL;}while(0)
_inline static unsigned char *_m3d_getidx(unsigned char *data, char type, M3D_INDEX *idx)
{
    switch(type) {
        case 1: *idx = data[0] > 253 ? (int8_t)data[0] : data[0]; data++; break;
        case 2: *idx = *((uint16_t*)data) > 65533 ? *((int16_t*)data) : *((uint16_t*)data); data += 2; break;
        case 4: *idx = *((int32_t*)data); data += 4; break;
    }
    return data;
}

#ifndef M3D_NOANIMATION
/* multiply 4 x 4 matrices. Do not use float *r[16] as argument, because some compilers misinterpret that as
 * 16 pointers each pointing to a float, but we need a single pointer to 16 floats. */
void _m3d_mul(M3D_FLOAT *r, M3D_FLOAT *a, M3D_FLOAT *b)
{
    r[ 0] = b[ 0] * a[ 0] + b[ 4] * a[ 1] + b[ 8] * a[ 2] + b[12] * a[ 3];
    r[ 1] = b[ 1] * a[ 0] + b[ 5] * a[ 1] + b[ 9] * a[ 2] + b[13] * a[ 3];
    r[ 2] = b[ 2] * a[ 0] + b[ 6] * a[ 1] + b[10] * a[ 2] + b[14] * a[ 3];
    r[ 3] = b[ 3] * a[ 0] + b[ 7] * a[ 1] + b[11] * a[ 2] + b[15] * a[ 3];
    r[ 4] = b[ 0] * a[ 4] + b[ 4] * a[ 5] + b[ 8] * a[ 6] + b[12] * a[ 7];
    r[ 5] = b[ 1] * a[ 4] + b[ 5] * a[ 5] + b[ 9] * a[ 6] + b[13] * a[ 7];
    r[ 6] = b[ 2] * a[ 4] + b[ 6] * a[ 5] + b[10] * a[ 6] + b[14] * a[ 7];
    r[ 7] = b[ 3] * a[ 4] + b[ 7] * a[ 5] + b[11] * a[ 6] + b[15] * a[ 7];
    r[ 8] = b[ 0] * a[ 8] + b[ 4] * a[ 9] + b[ 8] * a[10] + b[12] * a[11];
    r[ 9] = b[ 1] * a[ 8] + b[ 5] * a[ 9] + b[ 9] * a[10] + b[13] * a[11];
    r[10] = b[ 2] * a[ 8] + b[ 6] * a[ 9] + b[10] * a[10] + b[14] * a[11];
    r[11] = b[ 3] * a[ 8] + b[ 7] * a[ 9] + b[11] * a[10] + b[15] * a[11];
    r[12] = b[ 0] * a[12] + b[ 4] * a[13] + b[ 8] * a[14] + b[12] * a[15];
    r[13] = b[ 1] * a[12] + b[ 5] * a[13] + b[ 9] * a[14] + b[13] * a[15];
    r[14] = b[ 2] * a[12] + b[ 6] * a[13] + b[10] * a[14] + b[14] * a[15];
    r[15] = b[ 3] * a[12] + b[ 7] * a[13] + b[11] * a[14] + b[15] * a[15];
}
/* calculate 4 x 4 matrix inverse */
void _m3d_inv(M3D_FLOAT *m)
{
    M3D_FLOAT r[16];
    M3D_FLOAT det =
          m[ 0]*m[ 5]*m[10]*m[15] - m[ 0]*m[ 5]*m[11]*m[14] + m[ 0]*m[ 6]*m[11]*m[13] - m[ 0]*m[ 6]*m[ 9]*m[15]
        + m[ 0]*m[ 7]*m[ 9]*m[14] - m[ 0]*m[ 7]*m[10]*m[13] - m[ 1]*m[ 6]*m[11]*m[12] + m[ 1]*m[ 6]*m[ 8]*m[15]
        - m[ 1]*m[ 7]*m[ 8]*m[14] + m[ 1]*m[ 7]*m[10]*m[12] - m[ 1]*m[ 4]*m[10]*m[15] + m[ 1]*m[ 4]*m[11]*m[14]
        + m[ 2]*m[ 7]*m[ 8]*m[13] - m[ 2]*m[ 7]*m[ 9]*m[12] + m[ 2]*m[ 4]*m[ 9]*m[15] - m[ 2]*m[ 4]*m[11]*m[13]
        + m[ 2]*m[ 5]*m[11]*m[12] - m[ 2]*m[ 5]*m[ 8]*m[15] - m[ 3]*m[ 4]*m[ 9]*m[14] + m[ 3]*m[ 4]*m[10]*m[13]
        - m[ 3]*m[ 5]*m[10]*m[12] + m[ 3]*m[ 5]*m[ 8]*m[14] - m[ 3]*m[ 6]*m[ 8]*m[13] + m[ 3]*m[ 6]*m[ 9]*m[12];
    if(det == (M3D_FLOAT)0.0 || det == (M3D_FLOAT)-0.0) det = (M3D_FLOAT)1.0; else det = (M3D_FLOAT)1.0 / det;
    r[ 0] = det *(m[ 5]*(m[10]*m[15] - m[11]*m[14]) + m[ 6]*(m[11]*m[13] - m[ 9]*m[15]) + m[ 7]*(m[ 9]*m[14] - m[10]*m[13]));
    r[ 1] = -det*(m[ 1]*(m[10]*m[15] - m[11]*m[14]) + m[ 2]*(m[11]*m[13] - m[ 9]*m[15]) + m[ 3]*(m[ 9]*m[14] - m[10]*m[13]));
    r[ 2] = det *(m[ 1]*(m[ 6]*m[15] - m[ 7]*m[14]) + m[ 2]*(m[ 7]*m[13] - m[ 5]*m[15]) + m[ 3]*(m[ 5]*m[14] - m[ 6]*m[13]));
    r[ 3] = -det*(m[ 1]*(m[ 6]*m[11] - m[ 7]*m[10]) + m[ 2]*(m[ 7]*m[ 9] - m[ 5]*m[11]) + m[ 3]*(m[ 5]*m[10] - m[ 6]*m[ 9]));
    r[ 4] = -det*(m[ 4]*(m[10]*m[15] - m[11]*m[14]) + m[ 6]*(m[11]*m[12] - m[ 8]*m[15]) + m[ 7]*(m[ 8]*m[14] - m[10]*m[12]));
    r[ 5] = det *(m[ 0]*(m[10]*m[15] - m[11]*m[14]) + m[ 2]*(m[11]*m[12] - m[ 8]*m[15]) + m[ 3]*(m[ 8]*m[14] - m[10]*m[12]));
    r[ 6] = -det*(m[ 0]*(m[ 6]*m[15] - m[ 7]*m[14]) + m[ 2]*(m[ 7]*m[12] - m[ 4]*m[15]) + m[ 3]*(m[ 4]*m[14] - m[ 6]*m[12]));
    r[ 7] = det *(m[ 0]*(m[ 6]*m[11] - m[ 7]*m[10]) + m[ 2]*(m[ 7]*m[ 8] - m[ 4]*m[11]) + m[ 3]*(m[ 4]*m[10] - m[ 6]*m[ 8]));
    r[ 8] = det *(m[ 4]*(m[ 9]*m[15] - m[11]*m[13]) + m[ 5]*(m[11]*m[12] - m[ 8]*m[15]) + m[ 7]*(m[ 8]*m[13] - m[ 9]*m[12]));
    r[ 9] = -det*(m[ 0]*(m[ 9]*m[15] - m[11]*m[13]) + m[ 1]*(m[11]*m[12] - m[ 8]*m[15]) + m[ 3]*(m[ 8]*m[13] - m[ 9]*m[12]));
    r[10] = det *(m[ 0]*(m[ 5]*m[15] - m[ 7]*m[13]) + m[ 1]*(m[ 7]*m[12] - m[ 4]*m[15]) + m[ 3]*(m[ 4]*m[13] - m[ 5]*m[12]));
    r[11] = -det*(m[ 0]*(m[ 5]*m[11] - m[ 7]*m[ 9]) + m[ 1]*(m[ 7]*m[ 8] - m[ 4]*m[11]) + m[ 3]*(m[ 4]*m[ 9] - m[ 5]*m[ 8]));
    r[12] = -det*(m[ 4]*(m[ 9]*m[14] - m[10]*m[13]) + m[ 5]*(m[10]*m[12] - m[ 8]*m[14]) + m[ 6]*(m[ 8]*m[13] - m[ 9]*m[12]));
    r[13] = det *(m[ 0]*(m[ 9]*m[14] - m[10]*m[13]) + m[ 1]*(m[10]*m[12] - m[ 8]*m[14]) + m[ 2]*(m[ 8]*m[13] - m[ 9]*m[12]));
    r[14] = -det*(m[ 0]*(m[ 5]*m[14] - m[ 6]*m[13]) + m[ 1]*(m[ 6]*m[12] - m[ 4]*m[14]) + m[ 2]*(m[ 4]*m[13] - m[ 5]*m[12]));
    r[15] = det *(m[ 0]*(m[ 5]*m[10] - m[ 6]*m[ 9]) + m[ 1]*(m[ 6]*m[ 8] - m[ 4]*m[10]) + m[ 2]*(m[ 4]*m[ 9] - m[ 5]*m[ 8]));
    memcpy(m, &r, sizeof(r));
}
/* compose a coloumn major 4 x 4 matrix from vec3 position and vec4 orientation/rotation quaternion */
void _m3d_mat(M3D_FLOAT *r, m3dv_t *p, m3dv_t *q)
{
    if(q->x == (M3D_FLOAT)0.0 && q->y == (M3D_FLOAT)0.0 && q->z >=(M3D_FLOAT) 0.7071065 && q->z <= (M3D_FLOAT)0.7071075 &&
        q->w == (M3D_FLOAT)0.0) {
        r[ 1] = r[ 2] = r[ 4] = r[ 6] = r[ 8] = r[ 9] = (M3D_FLOAT)0.0;
        r[ 0] = r[ 5] = r[10] = (M3D_FLOAT)-1.0;
    } else {
        r[ 0] = 1 - 2 * (q->y * q->y + q->z * q->z); if(r[ 0]>-M3D_EPSILON && r[ 0]<M3D_EPSILON) r[ 0]=(M3D_FLOAT)0.0;
        r[ 1] = 2 * (q->x * q->y - q->z * q->w);     if(r[ 1]>-M3D_EPSILON && r[ 1]<M3D_EPSILON) r[ 1]=(M3D_FLOAT)0.0;
        r[ 2] = 2 * (q->x * q->z + q->y * q->w);     if(r[ 2]>-M3D_EPSILON && r[ 2]<M3D_EPSILON) r[ 2]=(M3D_FLOAT)0.0;
        r[ 4] = 2 * (q->x * q->y + q->z * q->w);     if(r[ 4]>-M3D_EPSILON && r[ 4]<M3D_EPSILON) r[ 4]=(M3D_FLOAT)0.0;
        r[ 5] = 1 - 2 * (q->x * q->x + q->z * q->z); if(r[ 5]>-M3D_EPSILON && r[ 5]<M3D_EPSILON) r[ 5]=(M3D_FLOAT)0.0;
        r[ 6] = 2 * (q->y * q->z - q->x * q->w);     if(r[ 6]>-M3D_EPSILON && r[ 6]<M3D_EPSILON) r[ 6]=(M3D_FLOAT)0.0;
        r[ 8] = 2 * (q->x * q->z - q->y * q->w);     if(r[ 8]>-M3D_EPSILON && r[ 8]<M3D_EPSILON) r[ 8]=(M3D_FLOAT)0.0;
        r[ 9] = 2 * (q->y * q->z + q->x * q->w);     if(r[ 9]>-M3D_EPSILON && r[ 9]<M3D_EPSILON) r[ 9]=(M3D_FLOAT)0.0;
        r[10] = 1 - 2 * (q->x * q->x + q->y * q->y); if(r[10]>-M3D_EPSILON && r[10]<M3D_EPSILON) r[10]=(M3D_FLOAT)0.0;
    }
    r[ 3] = p->x; r[ 7] = p->y; r[11] = p->z;
    r[12] = 0; r[13] = 0; r[14] = 0; r[15] = 1;
}
#endif
#if !defined(M3D_NOANIMATION) || !defined(M3D_NONORMALS)
/* portable fast inverse square root calculation. returns 1/sqrt(x) */
static M3D_FLOAT _m3d_rsq(M3D_FLOAT x)
{
#ifdef M3D_DOUBLE
    return ((M3D_FLOAT)15.0/(M3D_FLOAT)8.0) + ((M3D_FLOAT)-5.0/(M3D_FLOAT)4.0)*x + ((M3D_FLOAT)3.0/(M3D_FLOAT)8.0)*x*x;
#else
    /* John Carmack's */
    float x2 = x * 0.5f;
    uint32_t *i = (uint32_t*)&x;
    *i = (0x5f3759df - (*i >> 1));
    return x * (1.5f - (x2 * x * x));
#endif
}
#endif

/**
 * Function to decode a Model 3D into in-memory format
 */
m3d_t *m3d_load(unsigned char *data, m3dread_t readfilecb, m3dfree_t freecb, m3d_t *mtllib)
{
    unsigned char *end, *chunk, *buff, weights[8];
    unsigned int i, j, k, l, n, am, len = 0, reclen, offs;
#ifndef M3D_NOVOXELS
    int32_t min_x, min_y, min_z, max_x, max_y, max_z, sx, sy, sz, x, y, z;
    M3D_INDEX edge[8], enorm;
#endif
    char *name, *lang;
    float f;
    m3d_t *model;
    M3D_INDEX mi;
#ifdef M3D_VERTEXMAX
    M3D_INDEX pi;
#endif
    M3D_FLOAT w;
    m3dcd_t *cd;
    m3dtx_t *tx;
    m3dh_t *h;
    m3dm_t *m;
    m3da_t *a;
    m3di_t *t;
#ifndef M3D_NONORMALS
    char neednorm = 0;
    m3dv_t *norm = NULL, *v0, *v1, *v2, va, vb;
#endif
#ifndef M3D_NOANIMATION
    M3D_FLOAT r[16];
#endif
#if !defined(M3D_NOWEIGHTS) || !defined(M3D_NOANIMATION)
    m3db_t *b;
#endif
#ifndef M3D_NOWEIGHTS
    m3ds_t *sk;
#endif
#ifdef M3D_ASCII
    m3ds_t s;
    M3D_INDEX bi[M3D_BONEMAXLEVEL+1], level;
    const char *ol;
    char *ptr, *pe, *fn;
#endif
#ifdef M3D_PROFILING
    struct timeval tv0, tv1, tvd;
    gettimeofday(&tv0, NULL);
#endif

    if(!data || (!M3D_CHUNKMAGIC(data, '3','D','M','O')
#ifdef M3D_ASCII
        && !M3D_CHUNKMAGIC(data, '3','d','m','o')
#endif
        )) return NULL;
    model = (m3d_t*)M3D_MALLOC(sizeof(m3d_t));
    if(!model) {
        M3D_LOG("Out of memory");
        return NULL;
    }
    memset(model, 0, sizeof(m3d_t));

    if(mtllib) {
        model->nummaterial = mtllib->nummaterial;
        model->material = mtllib->material;
        model->numtexture = mtllib->numtexture;
        model->texture = mtllib->texture;
        model->flags |= M3D_FLG_MTLLIB;
    }
#ifdef M3D_ASCII
    /* ASCII variant? */
    if(M3D_CHUNKMAGIC(data, '3','d','m','o')) {
        model->errcode = M3D_ERR_BADFILE;
        model->flags |= M3D_FLG_FREESTR;
        model->raw = (m3dhdr_t*)data;
        ptr = (char*)data;
        ol = setlocale(LC_NUMERIC, NULL);
        setlocale(LC_NUMERIC, "C");
        /* parse header. Don't use sscanf, that's incredibly slow */
        ptr = _m3d_findarg(ptr);
        if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
        pe = _m3d_findnl(ptr);
        model->scale = (float)strtod(ptr, NULL); ptr = pe;
        if(model->scale <= (M3D_FLOAT)0.0) model->scale = (M3D_FLOAT)1.0;
        model->name = _m3d_safestr(ptr, 2); ptr = _m3d_findnl(ptr);
        if(!*ptr) goto asciiend;
        model->license = _m3d_safestr(ptr, 2); ptr = _m3d_findnl(ptr);
        if(!*ptr) goto asciiend;
        model->author = _m3d_safestr(ptr, 2); ptr = _m3d_findnl(ptr);
        if(!*ptr) goto asciiend;
        if(*ptr != '\r' && *ptr != '\n')
            model->desc = _m3d_safestr(ptr, 3);
        while(*ptr) {
            while(*ptr && *ptr!='\n') ptr++;
            ptr++; if(*ptr=='\r') ptr++;
            if(*ptr == '\n') break;
        }

        /* the main chunk reader loop */
        while(*ptr) {
            while(*ptr && (*ptr == '\r' || *ptr == '\n')) ptr++;
            if(!*ptr || (ptr[0]=='E' && ptr[1]=='n' && ptr[2]=='d')) break;
            /* make sure there's at least one data row */
            pe = ptr; ptr = _m3d_findnl(ptr);
            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
            /* Preview chunk */
            if(!memcmp(pe, "Preview", 7)) {
                if(readfilecb) {
                    pe = _m3d_safestr(ptr, 0);
                    if(!pe || !*pe) goto asciiend;
                    model->preview.data = (*readfilecb)(pe, &model->preview.length);
                    M3D_FREE(pe);
                }
                while(*ptr && *ptr != '\r' && *ptr != '\n')
                    ptr = _m3d_findnl(ptr);
            } else
            /* texture map chunk */
            if(!memcmp(pe, "Textmap", 7)) {
                if(model->tmap) { M3D_LOG("More texture map chunks, should be unique"); goto asciiend; }
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    i = model->numtmap++;
                    model->tmap = (m3dti_t*)M3D_REALLOC(model->tmap, model->numtmap * sizeof(m3dti_t));
                    if(!model->tmap) goto memerr;
                    ptr = _m3d_getfloat(ptr, &model->tmap[i].u);
                    if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    _m3d_getfloat(ptr, &model->tmap[i].v);
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* vertex chunk */
            if(!memcmp(pe, "Vertex", 6)) {
                if(model->vertex) { M3D_LOG("More vertex chunks, should be unique"); goto asciiend; }
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    i = model->numvertex++;
                    model->vertex = (m3dv_t*)M3D_REALLOC(model->vertex, model->numvertex * sizeof(m3dv_t));
                    if(!model->vertex) goto memerr;
                    memset(&model->vertex[i], 0, sizeof(m3dv_t));
                    model->vertex[i].skinid = M3D_UNDEF;
                    model->vertex[i].color = 0;
                    model->vertex[i].w = (M3D_FLOAT)1.0;
                    ptr = _m3d_getfloat(ptr, &model->vertex[i].x);
                    if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    ptr = _m3d_getfloat(ptr, &model->vertex[i].y);
                    if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    ptr = _m3d_getfloat(ptr, &model->vertex[i].z);
                    if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    ptr = _m3d_getfloat(ptr, &model->vertex[i].w);
                    if(!*ptr) goto asciiend;
                    if(*ptr == '#') {
                        ptr = _m3d_gethex(ptr, &model->vertex[i].color);
                        if(!*ptr) goto asciiend;
                    }
                    /* parse skin */
                    memset(&s, 0, sizeof(m3ds_t));
                    for(j = 0, w = (M3D_FLOAT)0.0; j < M3D_NUMBONE && *ptr && *ptr != '\r' && *ptr != '\n'; j++) {
                        ptr = _m3d_findarg(ptr);
                        if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                        ptr = _m3d_getint(ptr, &k);
                        s.boneid[j] = (M3D_INDEX)k;
                        if(*ptr == ':') {
                            ptr++;
                            ptr = _m3d_getfloat(ptr, &s.weight[j]);
                            w += s.weight[j];
                        } else if(!j)
                            s.weight[j] = (M3D_FLOAT)1.0;
                        if(!*ptr) goto asciiend;
                    }
                    if(s.boneid[0] != M3D_UNDEF && s.weight[0] > (M3D_FLOAT)0.0) {
                        if(w != (M3D_FLOAT)1.0 && w != (M3D_FLOAT)0.0)
                            for(j = 0; j < M3D_NUMBONE && s.weight[j] > (M3D_FLOAT)0.0; j++)
                                s.weight[j] /= w;
                        k = M3D_NOTDEFINED;
                        if(model->skin) {
                            for(j = 0; j < model->numskin; j++)
                                if(!memcmp(&model->skin[j], &s, sizeof(m3ds_t))) { k = j; break; }
                        }
                        if(k == M3D_NOTDEFINED) {
                            k = model->numskin++;
                            model->skin = (m3ds_t*)M3D_REALLOC(model->skin, model->numskin * sizeof(m3ds_t));
                            if(!model->skin) goto memerr;
                            memcpy(&model->skin[k], &s, sizeof(m3ds_t));
                        }
                        model->vertex[i].skinid = (M3D_INDEX)k;
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* Skeleton, bone hierarchy */
            if(!memcmp(pe, "Bones", 5)) {
                if(model->bone) { M3D_LOG("More bones chunks, should be unique"); goto asciiend; }
                bi[0] = M3D_UNDEF;
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    i = model->numbone++;
                    model->bone = (m3db_t*)M3D_REALLOC(model->bone, model->numbone * sizeof(m3db_t));
                    if(!model->bone) goto memerr;
                    for(level = 0; *ptr == '/'; ptr++, level++);
                    if(level > M3D_BONEMAXLEVEL || !*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    bi[level+1] = i;
                    model->bone[i].numweight = 0;
                    model->bone[i].weight = NULL;
                    model->bone[i].parent = bi[level];
                    ptr = _m3d_getint(ptr, &k);
                    ptr = _m3d_findarg(ptr);
                    if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    model->bone[i].pos = (M3D_INDEX)k;
                    ptr = _m3d_getint(ptr, &k);
                    ptr = _m3d_findarg(ptr);
                    if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                    model->bone[i].ori = (M3D_INDEX)k;
                    model->vertex[k].skinid = M3D_INDEXMAX;
                    pe = _m3d_safestr(ptr, 0);
                    if(!pe || !*pe) goto asciiend;
                    model->bone[i].name = pe;
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* material chunk */
            if(!memcmp(pe, "Material", 8)) {
                pe = _m3d_findarg(pe);
                if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                pe = _m3d_safestr(pe, 0);
                if(!pe || !*pe) goto asciiend;
                for(i = 0; i < model->nummaterial; i++)
                    if(!strcmp(pe, model->material[i].name)) {
                        M3D_LOG("Multiple definitions for material");
                        M3D_LOG(pe);
                        M3D_FREE(pe);
                        pe = NULL;
                        while(*ptr && *ptr != '\r' && *ptr != '\n') ptr = _m3d_findnl(ptr);
                        break;
                    }
                if(!pe) continue;
                i = model->nummaterial++;
                if(model->flags & M3D_FLG_MTLLIB) {
                    m = model->material;
                    model->material = (m3dm_t*)M3D_MALLOC(model->nummaterial * sizeof(m3dm_t));
                    if(!model->material) goto memerr;
                    memcpy(model->material, m, (model->nummaterial - 1) * sizeof(m3dm_t));
                    if(model->texture) {
                        tx = model->texture;
                        model->texture = (m3dtx_t*)M3D_MALLOC(model->numtexture * sizeof(m3dtx_t));
                        if(!model->texture) goto memerr;
                        memcpy(model->texture, tx, model->numtexture * sizeof(m3dm_t));
                    }
                    model->flags &= ~M3D_FLG_MTLLIB;
                } else {
                    model->material = (m3dm_t*)M3D_REALLOC(model->material, model->nummaterial * sizeof(m3dm_t));
                    if(!model->material) goto memerr;
                }
                m = &model->material[i];
                m->name = pe;
                m->numprop = 0;
                m->prop = NULL;
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    k = n = 256;
                    if(*ptr == 'm' && *(ptr+1) == 'a' && *(ptr+2) == 'p' && *(ptr+3) == '_') {
                        k = m3dpf_map;
                        ptr += 4;
                    }
                    for(j = 0; j < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); j++)
                        if(!memcmp(ptr, m3d_propertytypes[j].key, strlen(m3d_propertytypes[j].key))) {
                            n = m3d_propertytypes[j].id;
                            if(k != m3dpf_map) k = m3d_propertytypes[j].format;
                            break;
                        }
                    if(n != 256 && k != 256) {
                        ptr = _m3d_findarg(ptr);
                        if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                        j = m->numprop++;
                        m->prop = (m3dp_t*)M3D_REALLOC(m->prop, m->numprop * sizeof(m3dp_t));
                        if(!m->prop) goto memerr;
                        m->prop[j].type = n + (k == m3dpf_map && n < 128 ? 128 : 0);
                        switch(k) {
                            case m3dpf_color: ptr = _m3d_gethex(ptr, &m->prop[j].value.color); break;
                            case m3dpf_uint8:
                            case m3dpf_uint16:
                            case m3dpf_uint32: ptr = _m3d_getint(ptr, &m->prop[j].value.num); break;
                            case m3dpf_float:  ptr = _m3d_getfloat(ptr, &m->prop[j].value.fnum); break;
                            case m3dpf_map:
                                pe = _m3d_safestr(ptr, 0);
                                if(!pe || !*pe) goto asciiend;
                                m->prop[j].value.textureid = _m3d_gettx(model, readfilecb, freecb, pe);
                                if(model->errcode == M3D_ERR_ALLOC) { M3D_FREE(pe); goto memerr; }
                                /* this error code only returned if readfilecb was specified */
                                if(m->prop[j].value.textureid == M3D_UNDEF) {
                                    M3D_LOG("Texture not found");
                                    M3D_LOG(pe);
                                    m->numprop--;
                                }
                                M3D_FREE(pe);
                            break;
                        }
                    } else {
                        M3D_LOG("Unknown material property in");
                        M3D_LOG(m->name);
                        model->errcode = M3D_ERR_UNKPROP;
                    }
                    ptr = _m3d_findnl(ptr);
                }
                if(!m->numprop) model->nummaterial--;
            } else
            /* procedural */
            if(!memcmp(pe, "Procedural", 10)) {
                pe = _m3d_safestr(ptr, 0);
                _m3d_getpr(model, readfilecb, freecb, pe);
                M3D_FREE(pe);
                while(*ptr && *ptr != '\r' && *ptr != '\n') ptr = _m3d_findnl(ptr);
            } else
            /* mesh */
            if(!memcmp(pe, "Mesh", 4)) {
                mi = M3D_UNDEF;
#ifdef M3D_VERTEXMAX
                pi = M3D_UNDEF;
#endif
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    if(*ptr == 'u') {
                        ptr = _m3d_findarg(ptr);
                        if(!*ptr) goto asciiend;
                        mi = M3D_UNDEF;
                        if(*ptr != '\r' && *ptr != '\n') {
                            pe = _m3d_safestr(ptr, 0);
                            if(!pe || !*pe) goto asciiend;
                            for(j = 0; j < model->nummaterial; j++)
                                if(!strcmp(pe, model->material[j].name)) { mi = (M3D_INDEX)j; break; }
                            if(mi == M3D_UNDEF && !(model->flags & M3D_FLG_MTLLIB)) {
                                mi = model->nummaterial++;
                                model->material = (m3dm_t*)M3D_REALLOC(model->material, model->nummaterial * sizeof(m3dm_t));
                                if(!model->material) goto memerr;
                                model->material[mi].name = pe;
                                model->material[mi].numprop = 1;
                                model->material[mi].prop = NULL;
                            } else
                                M3D_FREE(pe);
                        }
                    } else
                    if(*ptr == 'p') {
                        ptr = _m3d_findarg(ptr);
                        if(!*ptr) goto asciiend;
#ifdef M3D_VERTEXMAX
                        pi = M3D_UNDEF;
                        if(*ptr != '\r' && *ptr != '\n') {
                            pe = _m3d_safestr(ptr, 0);
                            if(!pe || !*pe) goto asciiend;
                            for(j = 0; j < model->numparam; j++)
                                if(!strcmp(pe, model->param[j].name)) { pi = (M3D_INDEX)j; break; }
                            if(pi == M3D_UNDEF) {
                                pi = model->numparam++;
                                model->param = (m3dvi_t*)M3D_REALLOC(model->param, model->numparam * sizeof(m3dvi_t));
                                if(!model->param) goto memerr;
                                model->param[pi].name = pe;
                                model->param[pi].count = 0;
                            } else
                                M3D_FREE(pe);
                        }
#endif
                    } else {
                        i = model->numface++;
                        model->face = (m3df_t*)M3D_REALLOC(model->face, model->numface * sizeof(m3df_t));
                        if(!model->face) goto memerr;
                        memset(&model->face[i], 255, sizeof(m3df_t)); /* set all index to -1 by default */
                        model->face[i].materialid = mi;
#ifdef M3D_VERTEXMAX
                        model->face[i].paramid = pi;
#endif
                        /* hardcoded triangles. */
                        for(j = 0; j < 3; j++) {
                            /* vertex */
                            ptr = _m3d_getint(ptr, &k);
                            model->face[i].vertex[j] = (M3D_INDEX)k;
                            if(!*ptr) goto asciiend;
                            if(*ptr == '/') {
                                ptr++;
                                if(*ptr != '/') {
                                    /* texcoord */
                                    ptr = _m3d_getint(ptr, &k);
                                    model->face[i].texcoord[j] = (M3D_INDEX)k;
                                    if(!*ptr) goto asciiend;
                                }
                                if(*ptr == '/') {
                                    ptr++;
                                    /* normal */
                                    ptr = _m3d_getint(ptr, &k);
                                    model->face[i].normal[j] = (M3D_INDEX)k;
                                    if(!*ptr) goto asciiend;
                                }
                                if(*ptr == '/') {
                                    ptr++;
                                    /* maximum */
                                    ptr = _m3d_getint(ptr, &k);
#ifdef M3D_VERTEXMAX
                                    model->face[i].vertmax[j] = (M3D_INDEX)k;
#endif
                                    if(!*ptr) goto asciiend;
                                }
                            }
#ifndef M3D_NONORMALS
                            if(model->face[i].normal[j] == M3D_UNDEF) neednorm = 1;
#endif
                            ptr = _m3d_findarg(ptr);
                        }
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* voxel types chunk */
            if(!memcmp(pe, "VoxTypes", 8) || !memcmp(pe, "Voxtypes", 8)) {
                if(model->voxtype) { M3D_LOG("More voxel types chunks, should be unique"); goto asciiend; }
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    i = model->numvoxtype++;
                    model->voxtype = (m3dvt_t*)M3D_REALLOC(model->voxtype, model->numvoxtype * sizeof(m3dvt_t));
                    if(!model->voxtype) goto memerr;
                    memset(&model->voxtype[i], 0, sizeof(m3dvt_t));
                    model->voxtype[i].materialid = M3D_UNDEF;
                    model->voxtype[i].skinid = M3D_UNDEF;
                    ptr = _m3d_gethex(ptr, &model->voxtype[i].color);
                    if(!*ptr) goto asciiend;
                    if(*ptr == '/') {
                        ptr = _m3d_gethex(ptr, &k);
                        model->voxtype[i].rotation = k;
                        if(!*ptr) goto asciiend;
                        if(*ptr == '/') {
                            ptr = _m3d_gethex(ptr, &k);
                            model->voxtype[i].voxshape = k;
                            if(!*ptr) goto asciiend;
                        }
                    }
                    while(*ptr == ' ' || *ptr == '\t') ptr++;
                    if(*ptr == '\r' || *ptr == '\n') { ptr = _m3d_findnl(ptr); continue; }
                    /* name */
                    if(*ptr != '-') {
                        pe = _m3d_safestr(ptr, 0);
                        if(!pe || !*pe) goto asciiend;
                        model->voxtype[i].name = pe;
                        for(j = 0; j < model->nummaterial; j++)
                            if(!strcmp(pe, model->material[j].name)) { model->voxtype[i].materialid = (M3D_INDEX)j; break; }
                    }
                    ptr = _m3d_findarg(ptr);
                    /* parse skin */
                    memset(&s, 0, sizeof(m3ds_t));
                    for(j = 0, w = (M3D_FLOAT)0.0; j < M3D_NUMBONE && *ptr && *ptr != '{' && *ptr != '\r' && *ptr != '\n'; j++) {
                        ptr = _m3d_getint(ptr, &k);
                        s.boneid[j] = (M3D_INDEX)k;
                        if(*ptr == ':') {
                            ptr++;
                            ptr = _m3d_getfloat(ptr, &s.weight[j]);
                            w += s.weight[j];
                        } else if(!j)
                            s.weight[j] = (M3D_FLOAT)1.0;
                        if(!*ptr) goto asciiend;
                        ptr = _m3d_findarg(ptr);
                    }
                    if(s.boneid[0] != M3D_UNDEF && s.weight[0] > (M3D_FLOAT)0.0) {
                        if(w != (M3D_FLOAT)1.0 && w != (M3D_FLOAT)0.0)
                            for(j = 0; j < M3D_NUMBONE && s.weight[j] > (M3D_FLOAT)0.0; j++)
                                s.weight[j] /= w;
                        k = M3D_NOTDEFINED;
                        if(model->skin) {
                            for(j = 0; j < model->numskin; j++)
                                if(!memcmp(&model->skin[j], &s, sizeof(m3ds_t))) { k = j; break; }
                        }
                        if(k == M3D_NOTDEFINED) {
                            k = model->numskin++;
                            model->skin = (m3ds_t*)M3D_REALLOC(model->skin, model->numskin * sizeof(m3ds_t));
                            if(!model->skin) goto memerr;
                            memcpy(&model->skin[k], &s, sizeof(m3ds_t));
                        }
                        model->voxtype[i].skinid = (M3D_INDEX)k;
                    }
                    /* parse item list */
                    if(*ptr == '{') {
                        while(*ptr == '{' || *ptr == ' ' || *ptr == '\t') ptr++;
                        while(*ptr && *ptr != '}' && *ptr != '\r' && *ptr != '\n') {
                            ptr = _m3d_getint(ptr, &k);
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '}' || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            pe = _m3d_safestr(ptr, 0);
                            if(!pe || !*pe) goto asciiend;
                            ptr = _m3d_findarg(ptr);
                            j = model->voxtype[i].numitem++;
                            model->voxtype[i].item = (m3dvi_t*)M3D_REALLOC(model->voxtype[i].item,
                                model->voxtype[i].numitem * sizeof(m3dvi_t));
                            if(!model->voxtype[i].item) goto memerr;
                            model->voxtype[i].item[j].count = k;
                            model->voxtype[i].item[j].name = pe;
                        }
                        if(*ptr != '}') goto asciiend;
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* voxel data */
            if(!memcmp(pe, "Voxel", 5)) {
                if(!model->voxtype) { M3D_LOG("No voxel type chunk before voxel data"); goto asciiend; }
                pe = _m3d_findarg(pe);
                if(!*pe) goto asciiend;
                if(*pe == '\r' || *pe == '\n') pe = NULL;
                else pe = _m3d_safestr(pe, 0);
                i = model->numvoxel++;
                model->voxel = (m3dvx_t*)M3D_REALLOC(model->voxel, model->numvoxel * sizeof(m3dvx_t));
                if(!model->voxel) goto memerr;
                memset(&model->voxel[i], 0, sizeof(m3dvx_t));
                model->voxel[i].name = pe;
                k = l = 0;
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    switch(*ptr) {
                        case 'u':
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].uncertain = ((n > 0 && n < 256 ? n : 0) * 255) / 100;
                            ptr = _m3d_findarg(ptr);
                            if(*ptr && *ptr != '\r' && *ptr != '\n') {
                                ptr = _m3d_getint(ptr, &n);
                                model->voxel[i].groupid = n > 0 && n < 256 ? n : 0;
                            }
                        break;
                        case 'p':
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].x = n;
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].y = n;
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].z = n;
                        break;
                        case 'd':
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].w = n;
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].h = n;
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                            ptr = _m3d_getint(ptr, &n);
                            model->voxel[i].d = n;
                        break;
                        case 'l':
                            if(model->voxel[i].data) { l++; k = 0; }
                            else {
                                if(!model->voxel[i].w || !model->voxel[i].h || !model->voxel[i].d) {
                                    M3D_LOG("No voxel dimension before layer data");
                                    goto asciiend;
                                }
                                model->voxel[i].data = (M3D_VOXEL*)M3D_MALLOC(
                                    model->voxel[i].w * model->voxel[i].h * model->voxel[i].d * sizeof(M3D_VOXEL));
                                if(!model->voxel[i].data) goto memerr;
                            }
                        break;
                        default:
                            if(!model->voxel[i].data || l >= model->voxel[i].h || k >= model->voxel[i].d) {
                                M3D_LOG("Missing voxel attributes or out of bound data");
                                goto asciiend;
                            }
                            for(n = l * model->voxel[i].w * model->voxel[i].d + k * model->voxel[i].w;
                                j < model->voxel[i].w && *ptr && *ptr != '\r' && *ptr != '\n'; j++) {
                                ptr = _m3d_getint(ptr, &am);
                                if(am >= model->numvoxtype) goto asciiend;
                                model->voxel[i].data[n + j] = am;
                            }
                            k++;
                        break;
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* mathematical shape */
            if(!memcmp(pe, "Shape", 5)) {
                pe = _m3d_findarg(pe);
                if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                pe = _m3d_safestr(pe, 0);
                if(!pe || !*pe) goto asciiend;
                i = model->numshape++;
                model->shape = (m3dh_t*)M3D_REALLOC(model->shape, model->numshape * sizeof(m3ds_t));
                if(!model->shape) goto memerr;
                h = &model->shape[i];
                h->name = pe;
                h->group = M3D_UNDEF;
                h->numcmd = 0;
                h->cmd = NULL;
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    if(!memcmp(ptr, "group", 5)) {
                        ptr = _m3d_findarg(ptr);
                        ptr = _m3d_getint(ptr, &h->group);
                        ptr = _m3d_findnl(ptr);
                        if(h->group != M3D_UNDEF && h->group >= model->numbone) {
                            M3D_LOG("Unknown bone id as shape group in shape");
                            M3D_LOG(pe);
                            h->group = M3D_UNDEF;
                            model->errcode = M3D_ERR_SHPE;
                        }
                        continue;
                    }
                    for(cd = NULL, k = 0; k < (unsigned int)(sizeof(m3d_commandtypes)/sizeof(m3d_commandtypes[0])); k++) {
                        j = (unsigned int)strlen(m3d_commandtypes[k].key);
                        if(!memcmp(ptr, m3d_commandtypes[k].key, j) && (ptr[j] == ' ' || ptr[j] == '\r' || ptr[j] == '\n'))
                            { cd = &m3d_commandtypes[k]; break; }
                    }
                    if(cd) {
                        j = h->numcmd++;
                        h->cmd = (m3dc_t*)M3D_REALLOC(h->cmd, h->numcmd * sizeof(m3dc_t));
                        if(!h->cmd) goto memerr;
                        h->cmd[j].type = k;
                        h->cmd[j].arg = (uint32_t*)M3D_MALLOC(cd->p * sizeof(uint32_t));
                        if(!h->cmd[j].arg) goto memerr;
                        memset(h->cmd[j].arg, 0, cd->p * sizeof(uint32_t));
                        for(k = n = 0, l = cd->p; k < l; k++) {
                            ptr = _m3d_findarg(ptr);
                            if(!*ptr) goto asciiend;
                            if(*ptr == '[') {
                                ptr = _m3d_findarg(ptr + 1);
                                if(!*ptr) goto asciiend;
                            }
                            if(*ptr == ']' || *ptr == '\r' || *ptr == '\n') break;
                            switch(cd->a[((k - n) % (cd->p - n)) + n]) {
                                case m3dcp_mi_t:
                                    mi = M3D_UNDEF;
                                    if(*ptr != '\r' && *ptr != '\n') {
                                        pe = _m3d_safestr(ptr, 0);
                                        if(!pe || !*pe) goto asciiend;
                                        for(n = 0; n < model->nummaterial; n++)
                                            if(!strcmp(pe, model->material[n].name)) { mi = (M3D_INDEX)n; break; }
                                        if(mi == M3D_UNDEF && !(model->flags & M3D_FLG_MTLLIB)) {
                                            mi = model->nummaterial++;
                                            model->material = (m3dm_t*)M3D_REALLOC(model->material,
                                                model->nummaterial * sizeof(m3dm_t));
                                            if(!model->material) goto memerr;
                                            model->material[mi].name = pe;
                                            model->material[mi].numprop = 1;
                                            model->material[mi].prop = NULL;
                                        } else
                                            M3D_FREE(pe);
                                    }
                                    h->cmd[j].arg[k] = mi;
                                break;
                                case m3dcp_vc_t:
#ifdef M3D_DOUBLE
                                    _m3d_getfloat(ptr, &w); f = w;
                                    memcpy(&h->cmd[j].arg[k], &f, 4);
#else
                                    _m3d_getfloat(ptr, (float*)&h->cmd[j].arg[k]);
#endif
                                break;
                                case m3dcp_va_t:
                                    ptr = _m3d_getint(ptr, &h->cmd[j].arg[k]);
                                    n = k + 1; l += (h->cmd[j].arg[k] - 1) * (cd->p - k - 1);
                                    h->cmd[j].arg = (uint32_t*)M3D_REALLOC(h->cmd[j].arg, l * sizeof(uint32_t));
                                    if(!h->cmd[j].arg) goto memerr;
                                    memset(&h->cmd[j].arg[k + 1], 0, (l - k - 1) * sizeof(uint32_t));
                                break;
                                case m3dcp_qi_t:
                                    ptr = _m3d_getint(ptr, &h->cmd[j].arg[k]);
                                    model->vertex[h->cmd[i].arg[k]].skinid = M3D_INDEXMAX;
                                break;
                                default:
                                    ptr = _m3d_getint(ptr, &h->cmd[j].arg[k]);
                                break;
                            }
                        }
                    } else {
                        M3D_LOG("Unknown shape command in");
                        M3D_LOG(h->name);
                        model->errcode = M3D_ERR_UNKCMD;
                    }
                    ptr = _m3d_findnl(ptr);
                }
                if(!h->numcmd) model->numshape--;
            } else
            /* annotation labels */
            if(!memcmp(pe, "Labels", 6)) {
                pe = _m3d_findarg(pe);
                if(!*pe) goto asciiend;
                if(*pe == '\r' || *pe == '\n') pe = NULL;
                else pe = _m3d_safestr(pe, 0);
                k = 0; fn = NULL;
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    if(*ptr == 'c') {
                        ptr = _m3d_findarg(ptr);
                        if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                        ptr = _m3d_gethex(ptr, &k);
                    } else
                    if(*ptr == 'l') {
                        ptr = _m3d_findarg(ptr);
                        if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                        fn = _m3d_safestr(ptr, 2);
                    } else {
                        i = model->numlabel++;
                        model->label = (m3dl_t*)M3D_REALLOC(model->label, model->numlabel * sizeof(m3dl_t));
                        if(!model->label) goto memerr;
                        model->label[i].name = pe;
                        model->label[i].lang = fn;
                        model->label[i].color = k;
                        ptr = _m3d_getint(ptr, &j);
                        model->label[i].vertexid = (M3D_INDEX)j;
                        ptr = _m3d_findarg(ptr);
                        if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                        model->label[i].text = _m3d_safestr(ptr, 2);
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* action */
            if(!memcmp(pe, "Action", 6)) {
                pe = _m3d_findarg(pe);
                if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                pe = _m3d_getint(pe, &k);
                pe = _m3d_findarg(pe);
                if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                pe = _m3d_safestr(pe, 0);
                if(!pe || !*pe) goto asciiend;
                i = model->numaction++;
                model->action = (m3da_t*)M3D_REALLOC(model->action, model->numaction * sizeof(m3da_t));
                if(!model->action) goto memerr;
                a = &model->action[i];
                a->name = pe;
                a->durationmsec = k;
                /* skip the first frame marker as there's always at least one frame */
                a->numframe = 1;
                a->frame = (m3dfr_t*)M3D_MALLOC(sizeof(m3dfr_t));
                if(!a->frame) goto memerr;
                a->frame[0].msec = 0;
                a->frame[0].numtransform = 0;
                a->frame[0].transform = NULL;
                i = 0;
                if(*ptr == 'f')
                    ptr = _m3d_findnl(ptr);
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    if(*ptr == 'f') {
                        i = a->numframe++;
                        a->frame = (m3dfr_t*)M3D_REALLOC(a->frame, a->numframe * sizeof(m3dfr_t));
                        if(!a->frame) goto memerr;
                        ptr = _m3d_findarg(ptr);
                        ptr = _m3d_getint(ptr, &a->frame[i].msec);
                        a->frame[i].numtransform = 0;
                        a->frame[i].transform = NULL;
                    } else {
                        j = a->frame[i].numtransform++;
                        a->frame[i].transform = (m3dtr_t*)M3D_REALLOC(a->frame[i].transform,
                            a->frame[i].numtransform * sizeof(m3dtr_t));
                        if(!a->frame[i].transform) goto memerr;
                        ptr = _m3d_getint(ptr, &k);
                        ptr = _m3d_findarg(ptr);
                        if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                        a->frame[i].transform[j].boneid = (M3D_INDEX)k;
                        ptr = _m3d_getint(ptr, &k);
                        ptr = _m3d_findarg(ptr);
                        if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                        a->frame[i].transform[j].pos = (M3D_INDEX)k;
                        ptr = _m3d_getint(ptr, &k);
                        if(!*ptr || *ptr == '\r' || *ptr == '\n') goto asciiend;
                        a->frame[i].transform[j].ori = (M3D_INDEX)k;
                        model->vertex[k].skinid = M3D_INDEXMAX;
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* inlined assets chunk */
            if(!memcmp(pe, "Assets", 6)) {
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    if(readfilecb) {
                        pe = _m3d_safestr(ptr, 2);
                        if(!pe || !*pe) goto asciiend;
                        i = model->numinlined++;
                        model->inlined = (m3di_t*)M3D_REALLOC(model->inlined, model->numinlined * sizeof(m3di_t));
                        if(!model->inlined) goto memerr;
                        t = &model->inlined[i];
                        model->inlined[i].data = (*readfilecb)(pe, &model->inlined[i].length);
                        if(model->inlined[i].data) {
                            fn = strrchr(pe, '.');
                            if(fn && (fn[1] == 'p' || fn[1] == 'P') && (fn[2] == 'n' || fn[2] == 'N') &&
                                (fn[3] == 'g' || fn[3] == 'G')) *fn = 0;
                            fn = strrchr(pe, '/');
                            if(!fn) fn = strrchr(pe, '\\');
                            if(!fn) fn = pe; else fn++;
                            model->inlined[i].name = _m3d_safestr(fn, 0);
                        } else
                            model->numinlined--;
                        M3D_FREE(pe);
                    }
                    ptr = _m3d_findnl(ptr);
                }
            } else
            /* extra chunks */
            if(!memcmp(pe, "Extra", 5)) {
                pe = _m3d_findarg(pe);
                if(!*pe || *pe == '\r' || *pe == '\n') goto asciiend;
                buff = (unsigned char*)_m3d_findnl(ptr);
                k = ((uint32_t)((uintptr_t)buff - (uintptr_t)ptr) / 3) + 1;
                i = model->numextra++;
                model->extra = (m3dchunk_t**)M3D_REALLOC(model->extra, model->numextra * sizeof(m3dchunk_t*));
                if(!model->extra) goto memerr;
                model->extra[i] = (m3dchunk_t*)M3D_MALLOC(k + sizeof(m3dchunk_t));
                if(!model->extra[i]) goto memerr;
                memcpy(&model->extra[i]->magic, pe, 4);
                model->extra[i]->length = sizeof(m3dchunk_t);
                pe = (char*)model->extra[i] + sizeof(m3dchunk_t);
                while(*ptr && *ptr != '\r' && *ptr != '\n') {
                    ptr = _m3d_gethex(ptr, &k);
                    *pe++ = (uint8_t)k;
                    model->extra[i]->length++;
                }
            } else
                goto asciiend;
        }
        model->errcode = M3D_SUCCESS;
asciiend:
        setlocale(LC_NUMERIC, ol);
        goto postprocess;
    }
#endif
    /* Binary variant */
    len = ((m3dhdr_t*)data)->length - 8;
    data += 8;
    if(M3D_CHUNKMAGIC(data, 'P','R','V','W')) {
        /* optional preview chunk */
        model->preview.length = ((m3dchunk_t*)data)->length;
        model->preview.data = data + sizeof(m3dchunk_t);
        data += model->preview.length;
        len -= model->preview.length;
    }
    if(!M3D_CHUNKMAGIC(data, 'H','E','A','D')) {
        buff = (unsigned char *)stbi_zlib_decode_malloc_guesssize_headerflag((const char*)data, len, 4096, (int*)&len, 1);
        if(!buff || !len || !M3D_CHUNKMAGIC(buff, 'H','E','A','D')) {
            if(buff) M3D_FREE(buff);
            M3D_FREE(model);
            return NULL;
        }
        buff = (unsigned char*)M3D_REALLOC(buff, len);
        model->flags |= M3D_FLG_FREERAW; /* mark that we have to free the raw buffer */
        data = buff;
#ifdef M3D_PROFILING
        gettimeofday(&tv1, NULL);
        tvd.tv_sec = tv1.tv_sec - tv0.tv_sec;
        tvd.tv_usec = tv1.tv_usec - tv0.tv_usec;
        if(tvd.tv_usec < 0) { tvd.tv_sec--; tvd.tv_usec += 1000000L; }
        printf("  Deflate model   %ld.%06ld sec\n", tvd.tv_sec, tvd.tv_usec);
        memcpy(&tv0, &tv1, sizeof(struct timeval));
#endif
    }
    model->raw = (m3dhdr_t*)data;
    end = data + len;

    /* parse header */
    data += sizeof(m3dhdr_t);
    M3D_LOG((char*)data);
    model->name = (char*)data;
    for(; data < end && *data; data++) {}; data++;
    model->license = (char*)data;
    for(; data < end && *data; data++) {}; data++;
    model->author = (char*)data;
    for(; data < end && *data; data++) {}; data++;
    model->desc = (char*)data;
    chunk = (unsigned char*)model->raw + model->raw->length;
    model->scale = (M3D_FLOAT)model->raw->scale;
    if(model->scale <= (M3D_FLOAT)0.0) model->scale = (M3D_FLOAT)1.0;
    model->vc_s = 1 << ((model->raw->types >> 0) & 3);  /* vertex coordinate size */
    model->vi_s = 1 << ((model->raw->types >> 2) & 3);  /* vertex index size */
    model->si_s = 1 << ((model->raw->types >> 4) & 3);  /* string offset size */
    model->ci_s = 1 << ((model->raw->types >> 6) & 3);  /* color index size */
    model->ti_s = 1 << ((model->raw->types >> 8) & 3);  /* tmap index size */
    model->bi_s = 1 << ((model->raw->types >>10) & 3);  /* bone index size */
    model->nb_s = 1 << ((model->raw->types >>12) & 3);  /* number of bones per vertex */
    model->sk_s = 1 << ((model->raw->types >>14) & 3);  /* skin index size */
    model->fc_s = 1 << ((model->raw->types >>16) & 3);  /* frame counter size */
    model->hi_s = 1 << ((model->raw->types >>18) & 3);  /* shape index size */
    model->fi_s = 1 << ((model->raw->types >>20) & 3);  /* face index size */
    model->vd_s = 1 << ((model->raw->types >>22) & 3);  /* voxel dimension size */
    model->vp_s = 1 << ((model->raw->types >>24) & 3);  /* voxel pixel size */
    if(model->ci_s == 8) model->ci_s = 0;               /* optional indices */
    if(model->ti_s == 8) model->ti_s = 0;
    if(model->bi_s == 8) model->bi_s = 0;
    if(model->sk_s == 8) model->sk_s = 0;
    if(model->fc_s == 8) model->fc_s = 0;
    if(model->hi_s == 8) model->hi_s = 0;
    if(model->fi_s == 8) model->fi_s = 0;

    /* variable limit checks */
    if(sizeof(M3D_FLOAT) == 4 && model->vc_s > 4) {
        M3D_LOG("Double precision coordinates not supported, truncating to float...");
        model->errcode = M3D_ERR_TRUNC;
    }
    if((sizeof(M3D_INDEX) == 2 && (model->vi_s > 2 || model->si_s > 2 || model->ci_s > 2 || model->ti_s > 2 ||
        model->bi_s > 2 || model->sk_s > 2 || model->fc_s > 2 || model->hi_s > 2 || model->fi_s > 2)) ||
       (sizeof(M3D_VOXEL) < (size_t)model->vp_s && model->vp_s != 8)) {
        M3D_LOG("32 bit indices not supported, unable to load model");
        M3D_FREE(model);
        return NULL;
    }
    if(model->vi_s > 4 || model->si_s > 4 || model->vp_s == 4) {
        M3D_LOG("Invalid index size, unable to load model");
        M3D_FREE(model);
        return NULL;
    }
    if(!M3D_CHUNKMAGIC(end - 4, 'O','M','D','3')) {
        M3D_LOG("Missing end chunk");
        M3D_FREE(model);
        return NULL;
    }
    if(model->nb_s > M3D_NUMBONE) {
        M3D_LOG("Model has more bones per vertex than what importer was configured to support");
        model->errcode = M3D_ERR_TRUNC;
    }

    /* look for inlined assets in advance, material and procedural chunks may need them */
    buff = chunk;
    while(buff < end && !M3D_CHUNKMAGIC(buff, 'O','M','D','3')) {
        data = buff;
        len = ((m3dchunk_t*)data)->length;
        buff += len;
        if(len < sizeof(m3dchunk_t) || buff >= end) {
            M3D_LOG("Invalid chunk size");
            break;
        }
        len -= sizeof(m3dchunk_t) + model->si_s;

        /* inlined assets */
        if(M3D_CHUNKMAGIC(data, 'A','S','E','T') && len > 0) {
            M3D_LOG("Inlined asset");
            i = model->numinlined++;
            model->inlined = (m3di_t*)M3D_REALLOC(model->inlined, model->numinlined * sizeof(m3di_t));
            if(!model->inlined) {
memerr:         M3D_LOG("Out of memory");
                model->errcode = M3D_ERR_ALLOC;
                return model;
            }
            data += sizeof(m3dchunk_t);
            t = &model->inlined[i];
            M3D_GETSTR(t->name);
            M3D_LOG(t->name);
            t->data = (uint8_t*)data;
            t->length = len;
        }
    }

    /* parse chunks */
    while(chunk < end && !M3D_CHUNKMAGIC(chunk, 'O','M','D','3')) {
        data = chunk;
        len = ((m3dchunk_t*)chunk)->length;
        chunk += len;
        if(len < sizeof(m3dchunk_t) || chunk >= end) {
            M3D_LOG("Invalid chunk size");
            break;
        }
        len -= sizeof(m3dchunk_t);

        /* color map */
        if(M3D_CHUNKMAGIC(data, 'C','M','A','P')) {
            M3D_LOG("Color map");
            if(model->cmap) { M3D_LOG("More color map chunks, should be unique"); model->errcode = M3D_ERR_CMAP; continue; }
            if(!model->ci_s) { M3D_LOG("Color map chunk, shouldn't be any"); model->errcode = M3D_ERR_CMAP; continue; }
            model->numcmap = len / sizeof(uint32_t);
            model->cmap = (uint32_t*)(data + sizeof(m3dchunk_t));
        } else
        /* texture map */
        if(M3D_CHUNKMAGIC(data, 'T','M','A','P')) {
            M3D_LOG("Texture map");
            if(model->tmap) { M3D_LOG("More texture map chunks, should be unique"); model->errcode = M3D_ERR_TMAP; continue; }
            if(!model->ti_s) { M3D_LOG("Texture map chunk, shouldn't be any"); model->errcode = M3D_ERR_TMAP; continue; }
            reclen = model->vc_s + model->vc_s;
            model->numtmap = len / reclen;
            model->tmap = (m3dti_t*)M3D_MALLOC(model->numtmap * sizeof(m3dti_t));
            if(!model->tmap) goto memerr;
            for(i = 0, data += sizeof(m3dchunk_t); data < chunk; i++) {
                switch(model->vc_s) {
                    case 1:
                        model->tmap[i].u = (M3D_FLOAT)((uint8_t)data[0]) / (M3D_FLOAT)255.0;
                        model->tmap[i].v = (M3D_FLOAT)((uint8_t)data[1]) / (M3D_FLOAT)255.0;
                    break;
                    case 2:
                        model->tmap[i].u = (M3D_FLOAT)(*((uint16_t*)(data+0))) / (M3D_FLOAT)65535.0;
                        model->tmap[i].v = (M3D_FLOAT)(*((uint16_t*)(data+2))) / (M3D_FLOAT)65535.0;
                    break;
                    case 4:
                        model->tmap[i].u = (M3D_FLOAT)(*((float*)(data+0)));
                        model->tmap[i].v = (M3D_FLOAT)(*((float*)(data+4)));
                    break;
                    case 8:
                        model->tmap[i].u = (M3D_FLOAT)(*((double*)(data+0)));
                        model->tmap[i].v = (M3D_FLOAT)(*((double*)(data+8)));
                    break;
                }
                data += reclen;
            }
        } else
        /* vertex list */
        if(M3D_CHUNKMAGIC(data, 'V','R','T','S')) {
            M3D_LOG("Vertex list");
            if(model->vertex) { M3D_LOG("More vertex chunks, should be unique"); model->errcode = M3D_ERR_VRTS; continue; }
            if(model->ci_s && model->ci_s < 4 && !model->cmap) model->errcode = M3D_ERR_CMAP;
            reclen = model->ci_s + model->sk_s + 4 * model->vc_s;
            model->numvertex = len / reclen;
            model->vertex = (m3dv_t*)M3D_MALLOC(model->numvertex * sizeof(m3dv_t));
            if(!model->vertex) goto memerr;
            memset(model->vertex, 0, model->numvertex * sizeof(m3dv_t));
            for(i = 0, data += sizeof(m3dchunk_t); data < chunk && i < model->numvertex; i++) {
                switch(model->vc_s) {
                    case 1:
                        model->vertex[i].x = (M3D_FLOAT)((int8_t)data[0]) / (M3D_FLOAT)127.0;
                        model->vertex[i].y = (M3D_FLOAT)((int8_t)data[1]) / (M3D_FLOAT)127.0;
                        model->vertex[i].z = (M3D_FLOAT)((int8_t)data[2]) / (M3D_FLOAT)127.0;
                        model->vertex[i].w = (M3D_FLOAT)((int8_t)data[3]) / (M3D_FLOAT)127.0;
                        data += 4;
                    break;
                    case 2:
                        model->vertex[i].x = (M3D_FLOAT)(*((int16_t*)(data+0))) / (M3D_FLOAT)32767.0;
                        model->vertex[i].y = (M3D_FLOAT)(*((int16_t*)(data+2))) / (M3D_FLOAT)32767.0;
                        model->vertex[i].z = (M3D_FLOAT)(*((int16_t*)(data+4))) / (M3D_FLOAT)32767.0;
                        model->vertex[i].w = (M3D_FLOAT)(*((int16_t*)(data+6))) / (M3D_FLOAT)32767.0;
                        data += 8;
                    break;
                    case 4:
                        model->vertex[i].x = (M3D_FLOAT)(*((float*)(data+0)));
                        model->vertex[i].y = (M3D_FLOAT)(*((float*)(data+4)));
                        model->vertex[i].z = (M3D_FLOAT)(*((float*)(data+8)));
                        model->vertex[i].w = (M3D_FLOAT)(*((float*)(data+12)));
                        data += 16;
                    break;
                    case 8:
                        model->vertex[i].x = (M3D_FLOAT)(*((double*)(data+0)));
                        model->vertex[i].y = (M3D_FLOAT)(*((double*)(data+8)));
                        model->vertex[i].z = (M3D_FLOAT)(*((double*)(data+16)));
                        model->vertex[i].w = (M3D_FLOAT)(*((double*)(data+24)));
                        data += 32;
                    break;
                }
                switch(model->ci_s) {
                    case 1: model->vertex[i].color = model->cmap ? model->cmap[data[0]] : 0; data++; break;
                    case 2: model->vertex[i].color = model->cmap ? model->cmap[*((uint16_t*)data)] : 0; data += 2; break;
                    case 4: model->vertex[i].color = *((uint32_t*)data); data += 4; break;
                    /* case 8: break; */
                }
                model->vertex[i].skinid = M3D_UNDEF;
                data = _m3d_getidx(data, model->sk_s, &model->vertex[i].skinid);
            }
        } else
        /* skeleton: bone hierarchy and skin */
        if(M3D_CHUNKMAGIC(data, 'B','O','N','E')) {
            M3D_LOG("Skeleton");
            if(model->bone) { M3D_LOG("More bone chunks, should be unique"); model->errcode = M3D_ERR_BONE; continue; }
            if(!model->bi_s) { M3D_LOG("Bone chunk, shouldn't be any"); model->errcode=M3D_ERR_BONE; continue; }
            if(!model->vertex) { M3D_LOG("No vertex chunk before bones"); model->errcode = M3D_ERR_VRTS; break; }
            data += sizeof(m3dchunk_t);
            model->numbone = 0;
            data = _m3d_getidx(data, model->bi_s, &model->numbone);
            if(model->numbone) {
                model->bone = (m3db_t*)M3D_MALLOC(model->numbone * sizeof(m3db_t));
                if(!model->bone) goto memerr;
            }
            model->numskin = 0;
            data = _m3d_getidx(data, model->sk_s, &model->numskin);
            /* read bone hierarchy */
            for(i = 0; data < chunk && i < model->numbone; i++) {
                data = _m3d_getidx(data, model->bi_s, &model->bone[i].parent);
                M3D_GETSTR(model->bone[i].name);
                data = _m3d_getidx(data, model->vi_s, &model->bone[i].pos);
                data = _m3d_getidx(data, model->vi_s, &model->bone[i].ori);
                model->bone[i].numweight = 0;
                model->bone[i].weight = NULL;
            }
            if(i != model->numbone) { M3D_LOG("Truncated bone chunk"); model->numbone = i; model->numskin = 0; model->errcode = M3D_ERR_BONE; }
            /* read skin definitions */
            if(model->numskin) {
                model->skin = (m3ds_t*)M3D_MALLOC(model->numskin * sizeof(m3ds_t));
                if(!model->skin) goto memerr;
                for(i = 0; data < chunk && i < model->numskin; i++) {
                    for(j = 0; j < M3D_NUMBONE; j++) {
                        model->skin[i].boneid[j] = M3D_UNDEF;
                        model->skin[i].weight[j] = (M3D_FLOAT)0.0;
                    }
                    memset(&weights, 0, sizeof(weights));
                    if(model->nb_s == 1) weights[0] = 255;
                    else {
                        memcpy(&weights, data, model->nb_s);
                        data += model->nb_s;
                    }
                    for(j = 0, w = (M3D_FLOAT)0.0; j < (unsigned int)model->nb_s; j++) {
                        if(weights[j]) {
                            if(j >= M3D_NUMBONE)
                                data += model->bi_s;
                            else {
                                model->skin[i].weight[j] = (M3D_FLOAT)(weights[j]) / (M3D_FLOAT)255.0;
                                w += model->skin[i].weight[j];
                                data = _m3d_getidx(data, model->bi_s, &model->skin[i].boneid[j]);
                            }
                        }
                    }
                    /* this can occur if model has more bones than what the importer is configured to handle */
                    if(w != (M3D_FLOAT)1.0 && w != (M3D_FLOAT)0.0) {
                        for(j = 0; j < M3D_NUMBONE; j++)
                            model->skin[i].weight[j] /= w;
                    }
                }
                if(i != model->numskin) { M3D_LOG("Truncated skin in bone chunk"); model->numskin = i; model->errcode = M3D_ERR_BONE; }
            }
        } else
        /* material */
        if(M3D_CHUNKMAGIC(data, 'M','T','R','L')) {
            data += sizeof(m3dchunk_t);
            M3D_GETSTR(name);
            M3D_LOG("Material");
            M3D_LOG(name);
            if(model->ci_s < 4 && !model->numcmap) model->errcode = M3D_ERR_CMAP;
            for(i = 0; i < model->nummaterial; i++)
                if(!strcmp(name, model->material[i].name)) {
                    model->errcode = M3D_ERR_MTRL;
                    M3D_LOG("Multiple definitions for material");
                    M3D_LOG(name);
                    name = NULL;
                    break;
                }
            if(name) {
                i = model->nummaterial++;
                if(model->flags & M3D_FLG_MTLLIB) {
                    m = model->material;
                    model->material = (m3dm_t*)M3D_MALLOC(model->nummaterial * sizeof(m3dm_t));
                    if(!model->material) goto memerr;
                    memcpy(model->material, m, (model->nummaterial - 1) * sizeof(m3dm_t));
                    if(model->texture) {
                        tx = model->texture;
                        model->texture = (m3dtx_t*)M3D_MALLOC(model->numtexture * sizeof(m3dtx_t));
                        if(!model->texture) goto memerr;
                        memcpy(model->texture, tx, model->numtexture * sizeof(m3dm_t));
                    }
                    model->flags &= ~M3D_FLG_MTLLIB;
                } else {
                    model->material = (m3dm_t*)M3D_REALLOC(model->material, model->nummaterial * sizeof(m3dm_t));
                    if(!model->material) goto memerr;
                }
                m = &model->material[i];
                m->numprop = 0;
                m->name = name;
                m->prop = (m3dp_t*)M3D_MALLOC((len / 2) * sizeof(m3dp_t));
                if(!m->prop) goto memerr;
                while(data < chunk) {
                    i = m->numprop++;
                    m->prop[i].type = *data++;
                    m->prop[i].value.num = 0;
                    if(m->prop[i].type >= 128)
                        k = m3dpf_map;
                    else {
                        for(k = 256, j = 0; j < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); j++)
                            if(m->prop[i].type == m3d_propertytypes[j].id) { k = m3d_propertytypes[j].format; break; }
                    }
                    switch(k) {
                        case m3dpf_color:
                            switch(model->ci_s) {
                                case 1: m->prop[i].value.color = model->cmap ? model->cmap[data[0]] : 0; data++; break;
                                case 2: m->prop[i].value.color = model->cmap ? model->cmap[*((uint16_t*)data)] : 0; data += 2; break;
                                case 4: m->prop[i].value.color = *((uint32_t*)data); data += 4; break;
                            }
                        break;

                        case m3dpf_uint8: m->prop[i].value.num = *data++; break;
                        case m3dpf_uint16:m->prop[i].value.num = *((uint16_t*)data); data += 2; break;
                        case m3dpf_uint32:m->prop[i].value.num = *((uint32_t*)data); data += 4; break;
                        case m3dpf_float: m->prop[i].value.fnum = *((float*)data); data += 4; break;

                        case m3dpf_map:
                            M3D_GETSTR(name);
                            m->prop[i].value.textureid = _m3d_gettx(model, readfilecb, freecb, name);
                            if(model->errcode == M3D_ERR_ALLOC) goto memerr;
                            /* this error code only returned if readfilecb was specified */
                            if(m->prop[i].value.textureid == M3D_UNDEF) {
                                M3D_LOG("Texture not found");
                                M3D_LOG(m->name);
                                m->numprop--;
                            }
                        break;

                        default:
                            M3D_LOG("Unknown material property in");
                            M3D_LOG(m->name);
                            model->errcode = M3D_ERR_UNKPROP;
                            data = chunk;
                        break;
                    }
                }
                m->prop = (m3dp_t*)M3D_REALLOC(m->prop, m->numprop * sizeof(m3dp_t));
                if(!m->prop) goto memerr;
            }
        } else
        /* face */
        if(M3D_CHUNKMAGIC(data, 'P','R','O','C')) {
            /* procedural surface */
            M3D_GETSTR(name);
            M3D_LOG("Procedural surface");
            M3D_LOG(name);
            _m3d_getpr(model, readfilecb, freecb, name);
        } else
        if(M3D_CHUNKMAGIC(data, 'M','E','S','H')) {
            M3D_LOG("Mesh data");
            if(!model->vertex) { M3D_LOG("No vertex chunk before mesh"); model->errcode = M3D_ERR_VRTS; }
            /* mesh */
            data += sizeof(m3dchunk_t);
            mi = M3D_UNDEF;
#ifdef M3D_VERTEXMAX
            pi = M3D_UNDEF;
#endif
            am = model->numface;
            while(data < chunk) {
                k = *data++;
                n = k >> 4;
                k &= 15;
                if(!n) {
                    if(!k) {
                        /* use material */
                        mi = M3D_UNDEF;
                        M3D_GETSTR(name);
                        if(name) {
                            for(j = 0; j < model->nummaterial; j++)
                                if(!strcmp(name, model->material[j].name)) {
                                    mi = (M3D_INDEX)j;
                                    break;
                                }
                            if(mi == M3D_UNDEF) model->errcode = M3D_ERR_MTRL;
                        }
                    } else {
                        /* use parameter */
                        M3D_GETSTR(name);
#ifdef M3D_VERTEXMAX
                        pi = M3D_UNDEF;
                        if(name) {
                            for(j = 0; j < model->numparam; j++)
                                if(!strcmp(name, model->param[j].name)) {
                                    pi = (M3D_INDEX)j;
                                    break;
                                }
                            if(pi == M3D_UNDEF) {
                                pi = model->numparam++;
                                model->param = (m3dvi_t*)M3D_REALLOC(model->param, model->numparam * sizeof(m3dvi_t));
                                if(!model->param) goto memerr;
                                model->param[pi].name = name;
                                model->param[pi].count = 0;
                            }
                        }
#endif
                    }
                    continue;
                }
                if(n != 3) { M3D_LOG("Only triangle mesh supported for now"); model->errcode = M3D_ERR_UNKMESH; return model; }
                i = model->numface++;
                if(model->numface > am) {
                    am = model->numface + 4095;
                    model->face = (m3df_t*)M3D_REALLOC(model->face, am * sizeof(m3df_t));
                    if(!model->face) goto memerr;
                }
                memset(&model->face[i], 255, sizeof(m3df_t)); /* set all index to -1 by default */
                model->face[i].materialid = mi;
#ifdef M3D_VERTEXMAX
                model->face[i].paramid = pi;
#endif
                for(j = 0; data < chunk && j < n; j++) {
                    /* vertex */
                    data = _m3d_getidx(data, model->vi_s, &model->face[i].vertex[j]);
                    /* texcoord */
                    if(k & 1)
                        data = _m3d_getidx(data, model->ti_s, &model->face[i].texcoord[j]);
                    /* normal */
                    if(k & 2)
                        data = _m3d_getidx(data, model->vi_s, &model->face[i].normal[j]);
#ifndef M3D_NONORMALS
                    if(model->face[i].normal[j] == M3D_UNDEF) neednorm = 1;
#endif
                    /* maximum */
                    if(k & 4)
#ifdef M3D_VERTEXMAX
                        data = _m3d_getidx(data, model->vi_s, &model->face[i].vertmax[j]);
#else
                        data += model->vi_s;
#endif
                }
                if(j != n) { M3D_LOG("Invalid mesh"); model->numface = 0; model->errcode = M3D_ERR_UNKMESH; return model; }
            }
            model->face = (m3df_t*)M3D_REALLOC(model->face, model->numface * sizeof(m3df_t));
        } else
        if(M3D_CHUNKMAGIC(data, 'V','O','X','T')) {
            /* voxel types */
            M3D_LOG("Voxel types list");
            if(model->voxtype) { M3D_LOG("More voxel type chunks, should be unique"); model->errcode = M3D_ERR_VOXT; continue; }
            if(model->ci_s && model->ci_s < 4 && !model->cmap) model->errcode = M3D_ERR_CMAP;
            reclen = model->ci_s + model->si_s + 3 + model->sk_s;
            k = len / reclen;
            model->voxtype = (m3dvt_t*)M3D_MALLOC(k * sizeof(m3dvt_t));
            if(!model->voxtype) goto memerr;
            memset(model->voxtype, 0, k * sizeof(m3dvt_t));
            model->numvoxtype = 0;
            for(i = 0, data += sizeof(m3dchunk_t); data < chunk && i < k; i++) {
                switch(model->ci_s) {
                    case 1: model->voxtype[i].color = model->cmap ? model->cmap[data[0]] : 0; data++; break;
                    case 2: model->voxtype[i].color = model->cmap ? model->cmap[*((uint16_t*)data)] : 0; data += 2; break;
                    case 4: model->voxtype[i].color = *((uint32_t*)data); data += 4; break;
                    /* case 8: break; */
                }
                M3D_GETSTR(name);
                model->voxtype[i].materialid = M3D_UNDEF;
                if(name) {
                    model->voxtype[i].name = name;
/*
                    for(j = 0; j < model->nummaterial; j++)
                        if(!strcmp(name, model->material[j].name)) {
                            model->voxtype[i].materialid = (M3D_INDEX)j;
                            break;
                        }
*/
                }
                j = *data++;
                model->voxtype[i].rotation = j & 0xBF;
                model->voxtype[i].voxshape = ((j & 0x40) << 2) | *data++;
                model->voxtype[i].numitem = *data++;
                model->voxtype[i].skinid = M3D_UNDEF;
                data = _m3d_getidx(data, model->sk_s, &model->voxtype[i].skinid);
                if(model->voxtype[i].numitem) {
                    model->voxtype[i].item = (m3dvi_t*)M3D_MALLOC(model->voxtype[i].numitem * sizeof(m3dvi_t));
                    if(!model->voxtype[i].item) goto memerr;
                    memset(model->voxtype[i].item, 0, model->voxtype[i].numitem * sizeof(m3dvi_t));
                    for(j = 0; j < model->voxtype[i].numitem; j++) {
                        model->voxtype[i].item[j].count = *data++;
                        model->voxtype[i].item[j].count |= (*data++) << 8;
                        M3D_GETSTR(model->voxtype[i].item[j].name);
                    }
                }
            }
            model->numvoxtype = i;
            if(k != model->numvoxtype) {
                model->voxtype = (m3dvt_t*)M3D_REALLOC(model->voxtype, model->numvoxtype * sizeof(m3dvt_t));
                if(!model->voxtype) goto memerr;
            }
        } else
        if(M3D_CHUNKMAGIC(data, 'V','O','X','D')) {
            /* voxel data */
            data += sizeof(m3dchunk_t);
            M3D_GETSTR(name);
            M3D_LOG("Voxel Data Layer");
            M3D_LOG(name);
            if(model->vd_s > 4 || model->vp_s > 2) { M3D_LOG("No voxel index size"); model->errcode = M3D_ERR_UNKVOX; continue; }
            if(!model->voxtype) { M3D_LOG("No voxel type chunk before voxel data"); model->errcode = M3D_ERR_VOXT; }
            i = model->numvoxel++;
            model->voxel = (m3dvx_t*)M3D_REALLOC(model->voxel, model->numvoxel * sizeof(m3dvx_t));
            if(!model->voxel) goto memerr;
            memset(&model->voxel[i], 0, sizeof(m3dvx_t));
            model->voxel[i].name = name;
            switch(model->vd_s) {
                case 1:
                    model->voxel[i].x = (int32_t)((int8_t)data[0]);
                    model->voxel[i].y = (int32_t)((int8_t)data[1]);
                    model->voxel[i].z = (int32_t)((int8_t)data[2]);
                    model->voxel[i].w = (uint32_t)(data[3]);
                    model->voxel[i].h = (uint32_t)(data[4]);
                    model->voxel[i].d = (uint32_t)(data[5]);
                    data += 6;
                break;
                case 2:
                    model->voxel[i].x = (int32_t)(*((int16_t*)(data+0)));
                    model->voxel[i].y = (int32_t)(*((int16_t*)(data+2)));
                    model->voxel[i].z = (int32_t)(*((int16_t*)(data+4)));
                    model->voxel[i].w = (uint32_t)(*((uint16_t*)(data+6)));
                    model->voxel[i].h = (uint32_t)(*((uint16_t*)(data+8)));
                    model->voxel[i].d = (uint32_t)(*((uint16_t*)(data+10)));
                    data += 12;
                break;
                case 4:
                    model->voxel[i].x = *((int32_t*)(data+0));
                    model->voxel[i].y = *((int32_t*)(data+4));
                    model->voxel[i].z = *((int32_t*)(data+8));
                    model->voxel[i].w = *((uint32_t*)(data+12));
                    model->voxel[i].h = *((uint32_t*)(data+16));
                    model->voxel[i].d = *((uint32_t*)(data+20));
                    data += 24;
                break;
            }
            model->voxel[i].uncertain = *data++;
            model->voxel[i].groupid = *data++;
            k = model->voxel[i].w * model->voxel[i].h * model->voxel[i].d;
            model->voxel[i].data = (M3D_VOXEL*)M3D_MALLOC(k * sizeof(M3D_VOXEL));
            if(!model->voxel[i].data) goto memerr;
            memset(model->voxel[i].data, 0xff, k * sizeof(M3D_VOXEL));
            for(j = 0; data < chunk && j < k;) {
                l = ((*data++) & 0x7F) + 1;
                if(data[-1] & 0x80) {
                    data = _m3d_getidx(data, model->vp_s, &mi);
                    while(l-- && j < k) model->voxel[i].data[j++] = (M3D_VOXEL)mi;
                } else
                    while(l-- && j < k) {
                        data = _m3d_getidx(data, model->vp_s, &mi);
                        model->voxel[i].data[j++] = (M3D_VOXEL)mi;
                    }
            }
        } else
        if(M3D_CHUNKMAGIC(data, 'S','H','P','E')) {
            /* mathematical shape */
            data += sizeof(m3dchunk_t);
            M3D_GETSTR(name);
            M3D_LOG("Mathematical Shape");
            M3D_LOG(name);
            i = model->numshape++;
            model->shape = (m3dh_t*)M3D_REALLOC(model->shape, model->numshape * sizeof(m3dh_t));
            if(!model->shape) goto memerr;
            h = &model->shape[i];
            h->numcmd = 0;
            h->cmd = NULL;
            h->name = name;
            h->group = M3D_UNDEF;
            data = _m3d_getidx(data, model->bi_s, &h->group);
            if(h->group != M3D_UNDEF && h->group >= model->numbone) {
                M3D_LOG("Unknown bone id as shape group in shape");
                M3D_LOG(name);
                h->group = M3D_UNDEF;
                model->errcode = M3D_ERR_SHPE;
            }
            while(data < chunk) {
                i = h->numcmd++;
                h->cmd = (m3dc_t*)M3D_REALLOC(h->cmd, h->numcmd * sizeof(m3dc_t));
                if(!h->cmd) goto memerr;
                h->cmd[i].type = *data++;
                if(h->cmd[i].type & 0x80) {
                    h->cmd[i].type &= 0x7F;
                    h->cmd[i].type |= (*data++ << 7);
                }
                if(h->cmd[i].type >= (unsigned int)(sizeof(m3d_commandtypes)/sizeof(m3d_commandtypes[0]))) {
                    M3D_LOG("Unknown shape command in");
                    M3D_LOG(h->name);
                    model->errcode = M3D_ERR_UNKCMD;
                    break;
                }
                cd = &m3d_commandtypes[h->cmd[i].type];
                h->cmd[i].arg = (uint32_t*)M3D_MALLOC(cd->p * sizeof(uint32_t));
                if(!h->cmd[i].arg) goto memerr;
                memset(h->cmd[i].arg, 0, cd->p * sizeof(uint32_t));
                for(k = n = 0, l = cd->p; k < l; k++)
                    switch(cd->a[((k - n) % (cd->p - n)) + n]) {
                        case m3dcp_mi_t:
                            h->cmd[i].arg[k] = M3D_NOTDEFINED;
                            M3D_GETSTR(name);
                            if(name) {
                                for(n = 0; n < model->nummaterial; n++)
                                    if(!strcmp(name, model->material[n].name)) {
                                        h->cmd[i].arg[k] = n;
                                        break;
                                    }
                                if(h->cmd[i].arg[k] == M3D_NOTDEFINED) model->errcode = M3D_ERR_MTRL;
                            }
                        break;
                        case m3dcp_vc_t:
                            f = 0.0f;
                            switch(model->vc_s) {
                                case 1: f = (float)((int8_t)data[0]) / 127; break;
                                case 2: f = (float)(*((int16_t*)(data+0))) / 32767; break;
                                case 4: f = (float)(*((float*)(data+0))); break;
                                case 8: f = (float)(*((double*)(data+0))); break;
                            }
                            memcpy(&h->cmd[i].arg[k], &f, 4);
                            data += model->vc_s;
                        break;
                        case m3dcp_hi_t: data = _m3d_getidx(data, model->hi_s, &h->cmd[i].arg[k]); break;
                        case m3dcp_fi_t: data = _m3d_getidx(data, model->fi_s, &h->cmd[i].arg[k]); break;
                        case m3dcp_ti_t: data = _m3d_getidx(data, model->ti_s, &h->cmd[i].arg[k]); break;
                        case m3dcp_qi_t:
                        case m3dcp_vi_t: data = _m3d_getidx(data, model->vi_s, &h->cmd[i].arg[k]); break;
                        case m3dcp_i1_t: data = _m3d_getidx(data, 1, &h->cmd[i].arg[k]); break;
                        case m3dcp_i2_t: data = _m3d_getidx(data, 2, &h->cmd[i].arg[k]); break;
                        case m3dcp_i4_t: data = _m3d_getidx(data, 4, &h->cmd[i].arg[k]); break;
                        case m3dcp_va_t: data = _m3d_getidx(data, 4, &h->cmd[i].arg[k]);
                            n = k + 1; l += (h->cmd[i].arg[k] - 1) * (cd->p - k - 1);
                            h->cmd[i].arg = (uint32_t*)M3D_REALLOC(h->cmd[i].arg, l * sizeof(uint32_t));
                            if(!h->cmd[i].arg) goto memerr;
                            memset(&h->cmd[i].arg[k + 1], 0, (l - k - 1) * sizeof(uint32_t));
                        break;
                    }
            }
        } else
        /* annotation label list */
        if(M3D_CHUNKMAGIC(data, 'L','B','L','S')) {
            data += sizeof(m3dchunk_t);
            M3D_GETSTR(name);
            M3D_GETSTR(lang);
            M3D_LOG("Label list");
            if(name) { M3D_LOG(name); }
            if(lang) { M3D_LOG(lang); }
            if(model->ci_s && model->ci_s < 4 && !model->cmap) model->errcode = M3D_ERR_CMAP;
            k = 0;
            switch(model->ci_s) {
                case 1: k = model->cmap ? model->cmap[data[0]] : 0; data++; break;
                case 2: k = model->cmap ? model->cmap[*((uint16_t*)data)] : 0; data += 2; break;
                case 4: k = *((uint32_t*)data); data += 4; break;
                /* case 8: break; */
            }
            reclen = model->vi_s + model->si_s;
            i = model->numlabel; model->numlabel += len / reclen;
            model->label = (m3dl_t*)M3D_REALLOC(model->label, model->numlabel * sizeof(m3dl_t));
            if(!model->label) goto memerr;
            memset(&model->label[i], 0, (model->numlabel - i) * sizeof(m3dl_t));
            for(; data < chunk && i < model->numlabel; i++) {
                model->label[i].name = name;
                model->label[i].lang = lang;
                model->label[i].color = k;
                data = _m3d_getidx(data, model->vi_s, &model->label[i].vertexid);
                M3D_GETSTR(model->label[i].text);
            }
        } else
        /* action */
        if(M3D_CHUNKMAGIC(data, 'A','C','T','N')) {
            M3D_LOG("Action");
            i = model->numaction++;
            model->action = (m3da_t*)M3D_REALLOC(model->action, model->numaction * sizeof(m3da_t));
            if(!model->action) goto memerr;
            a = &model->action[i];
            data += sizeof(m3dchunk_t);
            M3D_GETSTR(a->name);
            M3D_LOG(a->name);
            a->numframe = *((uint16_t*)data); data += 2;
            if(a->numframe < 1) {
                model->numaction--;
            } else {
                a->durationmsec = *((uint32_t*)data); data += 4;
                a->frame = (m3dfr_t*)M3D_MALLOC(a->numframe * sizeof(m3dfr_t));
                if(!a->frame) goto memerr;
                for(i = 0; data < chunk && i < a->numframe; i++) {
                    a->frame[i].msec = *((uint32_t*)data); data += 4;
                    a->frame[i].numtransform = 0; a->frame[i].transform = NULL;
                    data = _m3d_getidx(data, model->fc_s, &a->frame[i].numtransform);
                    if(a->frame[i].numtransform > 0) {
                        a->frame[i].transform = (m3dtr_t*)M3D_MALLOC(a->frame[i].numtransform * sizeof(m3dtr_t));
                        for(j = 0; j < a->frame[i].numtransform; j++) {
                            data = _m3d_getidx(data, model->bi_s, &a->frame[i].transform[j].boneid);
                            data = _m3d_getidx(data, model->vi_s, &a->frame[i].transform[j].pos);
                            data = _m3d_getidx(data, model->vi_s, &a->frame[i].transform[j].ori);
                        }
                    }
                }
            }
        } else {
            i = model->numextra++;
            model->extra = (m3dchunk_t**)M3D_REALLOC(model->extra, model->numextra * sizeof(m3dchunk_t*));
            if(!model->extra) goto memerr;
            model->extra[i] = (m3dchunk_t*)data;
        }
    }
    /* calculate normals, normalize skin weights, create bone/vertex cross-references and calculate transform matrices */
#ifdef M3D_ASCII
postprocess:
#endif
    if(model) {
        M3D_LOG("Post-process");
#ifdef M3D_PROFILING
        gettimeofday(&tv1, NULL);
        tvd.tv_sec = tv1.tv_sec - tv0.tv_sec;
        tvd.tv_usec = tv1.tv_usec - tv0.tv_usec;
        if(tvd.tv_usec < 0) { tvd.tv_sec--; tvd.tv_usec += 1000000L; }
        printf("  Parsing chunks  %ld.%06ld sec\n", tvd.tv_sec, tvd.tv_usec);
#endif
#ifndef M3D_NOVOXELS
        if(model->numvoxel && model->voxel) {
            M3D_LOG("Converting voxels into vertices and mesh");
            /* add normals */
            enorm = model->numvertex; model->numvertex += 6;
            model->vertex = (m3dv_t*)M3D_REALLOC(model->vertex, model->numvertex * sizeof(m3dv_t));
            if(!model->vertex) goto memerr;
            memset(&model->vertex[enorm], 0, 6 * sizeof(m3dv_t));
            for(l = 0; l < 6; l++)
                model->vertex[enorm+l].skinid = M3D_UNDEF;
            model->vertex[enorm+0].y = (M3D_FLOAT)-1.0;
            model->vertex[enorm+1].z = (M3D_FLOAT)-1.0;
            model->vertex[enorm+2].x = (M3D_FLOAT)-1.0;
            model->vertex[enorm+3].y = (M3D_FLOAT)1.0;
            model->vertex[enorm+4].z = (M3D_FLOAT)1.0;
            model->vertex[enorm+5].x = (M3D_FLOAT)1.0;
            /* this is a fast, not so memory efficient version, only basic face culling used */
            min_x = min_y = min_z = 2147483647L;
            max_x = max_y = max_z = -2147483647L;
            for(i = 0; i < model->numvoxel; i++) {
                if(model->voxel[i].x + (int32_t)model->voxel[i].w > max_x) max_x = model->voxel[i].x + (int32_t)model->voxel[i].w;
                if(model->voxel[i].x < min_x) min_x = model->voxel[i].x;
                if(model->voxel[i].y + (int32_t)model->voxel[i].h > max_y) max_y = model->voxel[i].y + (int32_t)model->voxel[i].h;
                if(model->voxel[i].y < min_y) min_y = model->voxel[i].y;
                if(model->voxel[i].z + (int32_t)model->voxel[i].d > max_z) max_z = model->voxel[i].z + (int32_t)model->voxel[i].d;
                if(model->voxel[i].z < min_z) min_z = model->voxel[i].z;
            }
            i = (-min_x > max_x ? -min_x : max_x);
            j = (-min_y > max_y ? -min_y : max_y);
            k = (-min_z > max_z ? -min_z : max_z);
            if(j > i) i = j;
            if(k > i) i = k;
            if(i <= 1) i = 1;
            w = (M3D_FLOAT)1.0 / (M3D_FLOAT)i;
            if(i >= 254) model->vc_s = 2;
            if(i >= 65534) model->vc_s = 4;
            for(i = 0; i < model->numvoxel; i++) {
                sx = model->voxel[i].w; sz = model->voxel[i].d; sy = model->voxel[i].h;
                for(y = 0, j = 0; y < sy; y++)
                    for(z = 0; z < sz; z++)
                        for(x = 0; x < sx; x++, j++)
                            if(model->voxel[i].data[j] < model->numvoxtype) {
                                k = 0;
                                /*  16__32     ____
                                 *  /|  /|    /|2 /|
                                 *64_128 |   /_8_/ 32
                                 * | 1_|_2   |4|_|_|
                                 * |/  |/    |/ 1|/
                                 * 4___8     |16_|    */
                                k = n = am = 0;
                                if(!y || model->voxel[i].data[j - sx*sz] >= model->numvoxtype) { n++; am |= 1; k |= 1|2|4|8; }
                                if(!z || model->voxel[i].data[j - sx] >= model->numvoxtype) { n++; am |= 2; k |= 1|2|16|32; }
                                if(!x || model->voxel[i].data[j - 1] >= model->numvoxtype) { n++; am |= 4; k |= 1|4|16|64; }
                                if(y == sy-1 || model->voxel[i].data[j + sx*sz] >= model->numvoxtype) { n++; am |= 8; k |= 16|32|64|128; }
                                if(z == sz-1 || model->voxel[i].data[j + sx] >= model->numvoxtype) { n++; am |= 16; k |= 4|8|64|128; }
                                if(x == sx-1 || model->voxel[i].data[j + 1] >= model->numvoxtype) { n++; am |= 32; k |= 2|8|32|128; }
                                if(k) {
                                    memset(edge, 255, sizeof(edge));
                                    for(l = 0, len = 1, reclen = model->numvertex; l < 8; l++, len <<= 1)
                                        if(k & len) edge[l] = model->numvertex++;
                                    model->vertex = (m3dv_t*)M3D_REALLOC(model->vertex, model->numvertex * sizeof(m3dv_t));
                                    if(!model->vertex) goto memerr;
                                    memset(&model->vertex[reclen], 0, (model->numvertex-reclen) * sizeof(m3dv_t));
                                    for(l = reclen; l < model->numvertex; l++) {
                                        model->vertex[l].skinid = model->voxtype[model->voxel[i].data[j]].skinid;
                                        model->vertex[l].color = model->voxtype[model->voxel[i].data[j]].color;
                                    }
                                    l = reclen;
                                    if(k & 1) {
                                        model->vertex[l].x = (model->voxel[i].x + x) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z) * w;
                                        l++;
                                    }
                                    if(k & 2) {
                                        model->vertex[l].x = (model->voxel[i].x + x + 1) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z) * w;
                                        l++;
                                    }
                                    if(k & 4) {
                                        model->vertex[l].x = (model->voxel[i].x + x) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z + 1) * w;
                                        l++;
                                    }
                                    if(k & 8) {
                                        model->vertex[l].x = (model->voxel[i].x + x + 1) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z + 1) * w;
                                        l++;
                                    }
                                    if(k & 16) {
                                        model->vertex[l].x = (model->voxel[i].x + x) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y + 1) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z) * w;
                                        l++;
                                    }
                                    if(k & 32) {
                                        model->vertex[l].x = (model->voxel[i].x + x + 1) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y + 1) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z) * w;
                                        l++;
                                    }
                                    if(k & 64) {
                                        model->vertex[l].x = (model->voxel[i].x + x) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y + 1) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z + 1) * w;
                                        l++;
                                    }
                                    if(k & 128) {
                                        model->vertex[l].x = (model->voxel[i].x + x + 1) * w;
                                        model->vertex[l].y = (model->voxel[i].y + y + 1) * w;
                                        model->vertex[l].z = (model->voxel[i].z + z + 1) * w;
                                        l++;
                                    }
                                    n <<= 1;
                                    l = model->numface; model->numface += n;
                                    model->face = (m3df_t*)M3D_REALLOC(model->face, model->numface * sizeof(m3df_t));
                                    if(!model->face) goto memerr;
                                    memset(&model->face[l], 255, n * sizeof(m3df_t));
                                    for(reclen = l; reclen < model->numface; reclen++)
                                        model->face[reclen].materialid = model->voxtype[model->voxel[i].data[j]].materialid;
                                    if(am & 1) {            /* bottom */
                                        model->face[l].vertex[0] = edge[0];   model->face[l].vertex[1] = edge[1];   model->face[l].vertex[2] = edge[2];
                                        model->face[l+1].vertex[0] = edge[2]; model->face[l+1].vertex[1] = edge[1]; model->face[l+1].vertex[2] = edge[3];
                                        model->face[l].normal[0] = model->face[l].normal[1] = model->face[l].normal[2] =
                                        model->face[l+1].normal[0] = model->face[l+1].normal[1] = model->face[l+1].normal[2] = enorm;
                                        l += 2;
                                    }
                                    if(am & 2) {            /* north */
                                        model->face[l].vertex[0] = edge[0];   model->face[l].vertex[1] = edge[4];   model->face[l].vertex[2] = edge[1];
                                        model->face[l+1].vertex[0] = edge[1]; model->face[l+1].vertex[1] = edge[4]; model->face[l+1].vertex[2] = edge[5];
                                        model->face[l].normal[0] = model->face[l].normal[1] = model->face[l].normal[2] =
                                        model->face[l+1].normal[0] = model->face[l+1].normal[1] = model->face[l+1].normal[2] = enorm+1;
                                        l += 2;
                                    }
                                    if(am & 4) {            /* west */
                                        model->face[l].vertex[0] = edge[0];   model->face[l].vertex[1] = edge[2];   model->face[l].vertex[2] = edge[4];
                                        model->face[l+1].vertex[0] = edge[2]; model->face[l+1].vertex[1] = edge[6]; model->face[l+1].vertex[2] = edge[4];
                                        model->face[l].normal[0] = model->face[l].normal[1] = model->face[l].normal[2] =
                                        model->face[l+1].normal[0] = model->face[l+1].normal[1] = model->face[l+1].normal[2] = enorm+2;
                                        l += 2;
                                    }
                                    if(am & 8) {            /* top */
                                        model->face[l].vertex[0] = edge[4];   model->face[l].vertex[1] = edge[6];   model->face[l].vertex[2] = edge[5];
                                        model->face[l+1].vertex[0] = edge[5]; model->face[l+1].vertex[1] = edge[6]; model->face[l+1].vertex[2] = edge[7];
                                        model->face[l].normal[0] = model->face[l].normal[1] = model->face[l].normal[2] =
                                        model->face[l+1].normal[0] = model->face[l+1].normal[1] = model->face[l+1].normal[2] = enorm+3;
                                        l += 2;
                                    }
                                    if(am & 16) {           /* south */
                                        model->face[l].vertex[0] = edge[2];   model->face[l].vertex[1] = edge[7];   model->face[l].vertex[2] = edge[6];
                                        model->face[l+1].vertex[0] = edge[7]; model->face[l+1].vertex[1] = edge[2]; model->face[l+1].vertex[2] = edge[3];
                                        model->face[l].normal[0] = model->face[l].normal[1] = model->face[l].normal[2] =
                                        model->face[l+1].normal[0] = model->face[l+1].normal[1] = model->face[l+1].normal[2] = enorm+4;
                                        l += 2;
                                    }
                                    if(am & 32) {           /* east */
                                        model->face[l].vertex[0] = edge[1];   model->face[l].vertex[1] = edge[5];   model->face[l].vertex[2] = edge[7];
                                        model->face[l+1].vertex[0] = edge[1]; model->face[l+1].vertex[1] = edge[7]; model->face[l+1].vertex[2] = edge[3];
                                        model->face[l].normal[0] = model->face[l].normal[1] = model->face[l].normal[2] =
                                        model->face[l+1].normal[0] = model->face[l+1].normal[1] = model->face[l+1].normal[2] = enorm+5;
                                        l += 2;
                                    }
                                }
                            }
            }
        }
#endif
#ifndef M3D_NONORMALS
        if(model->numface && model->face && neednorm) {
            /* if they are missing, calculate triangle normals into a temporary buffer */
            norm = (m3dv_t*)M3D_MALLOC(model->numface * sizeof(m3dv_t));
            if(!norm) goto memerr;
            for(i = 0, n = model->numvertex; i < model->numface; i++)
                if(model->face[i].normal[0] == M3D_UNDEF) {
                    v0 = &model->vertex[model->face[i].vertex[0]];
                    v1 = &model->vertex[model->face[i].vertex[1]];
                    v2 = &model->vertex[model->face[i].vertex[2]];
                    va.x = v1->x - v0->x; va.y = v1->y - v0->y; va.z = v1->z - v0->z;
                    vb.x = v2->x - v0->x; vb.y = v2->y - v0->y; vb.z = v2->z - v0->z;
                    v0 = &norm[i];
                    v0->x = (va.y * vb.z) - (va.z * vb.y);
                    v0->y = (va.z * vb.x) - (va.x * vb.z);
                    v0->z = (va.x * vb.y) - (va.y * vb.x);
                    w = _m3d_rsq((v0->x * v0->x) + (v0->y * v0->y) + (v0->z * v0->z));
                    v0->x *= w; v0->y *= w; v0->z *= w;
                    model->face[i].normal[0] = model->face[i].vertex[0] + n;
                    model->face[i].normal[1] = model->face[i].vertex[1] + n;
                    model->face[i].normal[2] = model->face[i].vertex[2] + n;
                }
            /* this is the fast way, we don't care if a normal is repeated in model->vertex */
            M3D_LOG("Generating normals");
            model->flags |= M3D_FLG_GENNORM;
            model->numvertex <<= 1;
            model->vertex = (m3dv_t*)M3D_REALLOC(model->vertex, model->numvertex * sizeof(m3dv_t));
            if(!model->vertex) goto memerr;
            memset(&model->vertex[n], 0, n * sizeof(m3dv_t));
            for(i = 0; i < model->numface; i++)
                for(j = 0; j < 3; j++) {
                    v0 = &model->vertex[model->face[i].vertex[j] + n];
                    v0->x += norm[i].x;
                    v0->y += norm[i].y;
                    v0->z += norm[i].z;
                }
            /* for each vertex, take the average of the temporary normals and use that */
            for(i = 0, v0 = &model->vertex[n]; i < n; i++, v0++) {
                w = _m3d_rsq((v0->x * v0->x) + (v0->y * v0->y) + (v0->z * v0->z));
                v0->x *= w; v0->y *= w; v0->z *= w;
                v0->skinid = M3D_UNDEF;
            }
            M3D_FREE(norm);
        }
#endif
        if(model->numbone && model->bone && model->numskin && model->skin && model->numvertex && model->vertex) {
#ifndef M3D_NOWEIGHTS
            M3D_LOG("Generating weight cross-reference");
            for(i = 0; i < model->numvertex; i++) {
                if(model->vertex[i].skinid < model->numskin) {
                    sk = &model->skin[model->vertex[i].skinid];
                    w = (M3D_FLOAT)0.0;
                    for(j = 0; j < M3D_NUMBONE && sk->boneid[j] != M3D_UNDEF && sk->weight[j] > (M3D_FLOAT)0.0; j++)
                        w += sk->weight[j];
                    for(j = 0; j < M3D_NUMBONE && sk->boneid[j] != M3D_UNDEF && sk->weight[j] > (M3D_FLOAT)0.0; j++) {
                        sk->weight[j] /= w;
                        b = &model->bone[sk->boneid[j]];
                        k = b->numweight++;
                        b->weight = (m3dw_t*)M3D_REALLOC(b->weight, b->numweight * sizeof(m3da_t));
                        if(!b->weight) goto memerr;
                        b->weight[k].vertexid = i;
                        b->weight[k].weight = sk->weight[j];
                    }
                }
            }
#endif
#ifndef M3D_NOANIMATION
            M3D_LOG("Calculating bone transformation matrices");
            for(i = 0; i < model->numbone; i++) {
                b = &model->bone[i];
                if(model->bone[i].parent == M3D_UNDEF) {
                    _m3d_mat((M3D_FLOAT*)&b->mat4, &model->vertex[b->pos], &model->vertex[b->ori]);
                } else {
                    _m3d_mat((M3D_FLOAT*)&r, &model->vertex[b->pos], &model->vertex[b->ori]);
                    _m3d_mul((M3D_FLOAT*)&b->mat4, (M3D_FLOAT*)&model->bone[b->parent].mat4, (M3D_FLOAT*)&r);
                }
            }
            for(i = 0; i < model->numbone; i++)
                _m3d_inv((M3D_FLOAT*)&model->bone[i].mat4);
#endif
        }
#ifdef M3D_PROFILING
        gettimeofday(&tv0, NULL);
        tvd.tv_sec = tv0.tv_sec - tv1.tv_sec;
        tvd.tv_usec = tv0.tv_usec - tv1.tv_usec;
        if(tvd.tv_usec < 0) { tvd.tv_sec--; tvd.tv_usec += 1000000L; }
        printf("  Post-process    %ld.%06ld sec\n", tvd.tv_sec, tvd.tv_usec);
#endif
    }
    return model;
}

/**
 * Calculates skeletons for animation frames, returns a working copy (should be freed after use)
 */
m3dtr_t *m3d_frame(m3d_t *model, M3D_INDEX actionid, M3D_INDEX frameid, m3dtr_t *skeleton)
{
    unsigned int i;
    M3D_INDEX s = frameid;
    m3dfr_t *fr;

    if(!model || !model->numbone || !model->bone || (actionid != M3D_UNDEF && (!model->action ||
        actionid >= model->numaction || frameid >= model->action[actionid].numframe))) {
            model->errcode = M3D_ERR_UNKFRAME;
            return skeleton;
    }
    model->errcode = M3D_SUCCESS;
    if(!skeleton) {
        skeleton = (m3dtr_t*)M3D_MALLOC(model->numbone * sizeof(m3dtr_t));
        if(!skeleton) {
            model->errcode = M3D_ERR_ALLOC;
            return NULL;
        }
        goto gen;
    }
    if(actionid == M3D_UNDEF || !frameid) {
gen:    s = 0;
        for(i = 0; i < model->numbone; i++) {
            skeleton[i].boneid = i;
            skeleton[i].pos = model->bone[i].pos;
            skeleton[i].ori = model->bone[i].ori;
        }
    }
    if(actionid < model->numaction && (frameid || !model->action[actionid].frame[0].msec)) {
        for(; s <= frameid; s++) {
            fr = &model->action[actionid].frame[s];
            for(i = 0; i < fr->numtransform; i++) {
                skeleton[fr->transform[i].boneid].pos = fr->transform[i].pos;
                skeleton[fr->transform[i].boneid].ori = fr->transform[i].ori;
            }
        }
    }
    return skeleton;
}

#ifndef M3D_NOANIMATION
/**
 * Returns interpolated animation-pose, a working copy (should be freed after use)
 */
m3db_t *m3d_pose(m3d_t *model, M3D_INDEX actionid, uint32_t msec)
{
    unsigned int i, j, l;
    M3D_FLOAT r[16], t, c, d, s;
    m3db_t *ret;
    m3dv_t *v, *p, *f;
    m3dtr_t *tmp;
    m3dfr_t *fr;

    if(!model || !model->numbone || !model->bone) {
        model->errcode = M3D_ERR_UNKFRAME;
        return NULL;
    }
    ret = (m3db_t*)M3D_MALLOC(model->numbone * sizeof(m3db_t));
    if(!ret) {
        model->errcode = M3D_ERR_ALLOC;
        return NULL;
    }
    memcpy(ret, model->bone, model->numbone * sizeof(m3db_t));
    for(i = 0; i < model->numbone; i++)
        _m3d_inv((M3D_FLOAT*)&ret[i].mat4);
    if(!model->action || actionid >= model->numaction) {
        model->errcode = M3D_ERR_UNKFRAME;
        return ret;
    }
    msec %= model->action[actionid].durationmsec;
    model->errcode = M3D_SUCCESS;
    fr = &model->action[actionid].frame[0];
    for(j = l = 0; j < model->action[actionid].numframe && model->action[actionid].frame[j].msec <= msec; j++) {
        fr = &model->action[actionid].frame[j];
        l = fr->msec;
        for(i = 0; i < fr->numtransform; i++) {
            ret[fr->transform[i].boneid].pos = fr->transform[i].pos;
            ret[fr->transform[i].boneid].ori = fr->transform[i].ori;
        }
    }
    if(l != msec) {
        model->vertex = (m3dv_t*)M3D_REALLOC(model->vertex, (model->numvertex + 2 * model->numbone) * sizeof(m3dv_t));
        if(!model->vertex) {
            M3D_FREE(ret);
            model->errcode = M3D_ERR_ALLOC;
            return NULL;
        }
        tmp = (m3dtr_t*)M3D_MALLOC(model->numbone * sizeof(m3dtr_t));
        if(tmp) {
            for(i = 0; i < model->numbone; i++) {
                tmp[i].pos = ret[i].pos;
                tmp[i].ori = ret[i].ori;
            }
            fr = &model->action[actionid].frame[j % model->action[actionid].numframe];
            t = l >= fr->msec ? (M3D_FLOAT)1.0 : (M3D_FLOAT)(msec - l) / (M3D_FLOAT)(fr->msec - l);
            for(i = 0; i < fr->numtransform; i++) {
                tmp[fr->transform[i].boneid].pos = fr->transform[i].pos;
                tmp[fr->transform[i].boneid].ori = fr->transform[i].ori;
            }
            for(i = 0, j = model->numvertex; i < model->numbone; i++) {
                /* interpolation of position */
                if(ret[i].pos != tmp[i].pos) {
                    p = &model->vertex[ret[i].pos];
                    f = &model->vertex[tmp[i].pos];
                    v = &model->vertex[j];
                    v->x = p->x + t * (f->x - p->x);
                    v->y = p->y + t * (f->y - p->y);
                    v->z = p->z + t * (f->z - p->z);
                    ret[i].pos = j++;
                }
                /* interpolation of orientation */
                if(ret[i].ori != tmp[i].ori) {
                    p = &model->vertex[ret[i].ori];
                    f = &model->vertex[tmp[i].ori];
                    v = &model->vertex[j];
                    d = p->w * f->w + p->x * f->x + p->y * f->y + p->z * f->z;
                    if(d < 0) { d = -d; s = (M3D_FLOAT)-1.0; } else s = (M3D_FLOAT)1.0;
#if 0
                    /* don't use SLERP, requires two more variables, libm linkage and it is slow (but nice) */
                    a = (M3D_FLOAT)1.0 - t; b = t;
                    if(d < (M3D_FLOAT)0.999999) { c = acosf(d); b = 1 / sinf(c); a = sinf(a * c) * b; b *= sinf(t * c) * s; }
                    v->x = p->x * a + f->x * b;
                    v->y = p->y * a + f->y * b;
                    v->z = p->z * a + f->z * b;
                    v->w = p->w * a + f->w * b;
#else
                    /* approximated NLERP, original approximation by Arseny Kapoulkine, heavily optimized by me */
                    c = t - (M3D_FLOAT)0.5; t += t * c * (t - (M3D_FLOAT)1.0) * (((M3D_FLOAT)1.0904 + d * ((M3D_FLOAT)-3.2452 +
                        d * ((M3D_FLOAT)3.55645 - d * (M3D_FLOAT)1.43519))) * c * c + ((M3D_FLOAT)0.848013 + d *
                        ((M3D_FLOAT)-1.06021 + d * (M3D_FLOAT)0.215638)));
                    v->x = p->x + t * (s * f->x - p->x);
                    v->y = p->y + t * (s * f->y - p->y);
                    v->z = p->z + t * (s * f->z - p->z);
                    v->w = p->w + t * (s * f->w - p->w);
                    d = _m3d_rsq(v->w * v->w + v->x * v->x + v->y * v->y + v->z * v->z);
                    v->x *= d; v->y *= d; v->z *= d; v->w *= d;
#endif
                    ret[i].ori = j++;
                }
            }
            M3D_FREE(tmp);
        }
    }
    for(i = 0; i < model->numbone; i++) {
        if(ret[i].parent == M3D_UNDEF) {
            _m3d_mat((M3D_FLOAT*)&ret[i].mat4, &model->vertex[ret[i].pos], &model->vertex[ret[i].ori]);
        } else {
            _m3d_mat((M3D_FLOAT*)&r, &model->vertex[ret[i].pos], &model->vertex[ret[i].ori]);
            _m3d_mul((M3D_FLOAT*)&ret[i].mat4, (M3D_FLOAT*)&ret[ret[i].parent].mat4, (M3D_FLOAT*)&r);
        }
    }
    return ret;
}

#endif /* M3D_NOANIMATION */

#endif /* M3D_IMPLEMENTATION */

#if !defined(M3D_NODUP) && (!defined(M3D_NOIMPORTER) || defined(M3D_EXPORTER))
/**
 * Free the in-memory model
 */
void m3d_free(m3d_t *model)
{
    unsigned int i, j;

    if(!model) return;
#ifdef M3D_ASCII
    /* if model imported from ASCII, we have to free all strings as well */
    if(model->flags & M3D_FLG_FREESTR) {
        if(model->name) M3D_FREE(model->name);
        if(model->license) M3D_FREE(model->license);
        if(model->author) M3D_FREE(model->author);
        if(model->desc) M3D_FREE(model->desc);
        if(model->bone)
            for(i = 0; i < model->numbone; i++)
                if(model->bone[i].name)
                    M3D_FREE(model->bone[i].name);
        if(model->shape)
            for(i = 0; i < model->numshape; i++)
                if(model->shape[i].name)
                    M3D_FREE(model->shape[i].name);
        if(model->numvoxtype)
            for(i = 0; i < model->numvoxtype; i++) {
                if(model->voxtype[i].name)
                    M3D_FREE(model->voxtype[i].name);
                for(j = 0; j < model->voxtype[i].numitem; j++)
                    if(model->voxtype[i].item[j].name)
                        M3D_FREE(model->voxtype[i].item[j].name);
            }
        if(model->numvoxel)
            for(i = 0; i < model->numvoxel; i++)
                if(model->voxel[i].name)
                    M3D_FREE(model->voxel[i].name);
        if(model->material)
            for(i = 0; i < model->nummaterial; i++)
                if(model->material[i].name)
                    M3D_FREE(model->material[i].name);
        if(model->action)
            for(i = 0; i < model->numaction; i++)
                if(model->action[i].name)
                    M3D_FREE(model->action[i].name);
        if(model->texture)
            for(i = 0; i < model->numtexture; i++)
                if(model->texture[i].name)
                    M3D_FREE(model->texture[i].name);
        if(model->inlined)
            for(i = 0; i < model->numinlined; i++) {
                if(model->inlined[i].name)
                    M3D_FREE(model->inlined[i].name);
                if(model->inlined[i].data)
                    M3D_FREE(model->inlined[i].data);
            }
        if(model->extra)
            for(i = 0; i < model->numextra; i++)
                if(model->extra[i])
                    M3D_FREE(model->extra[i]);
        if(model->label)
            for(i = 0; i < model->numlabel; i++) {
                if(model->label[i].name) {
                    for(j = i + 1; j < model->numlabel; j++)
                        if(model->label[j].name == model->label[i].name)
                            model->label[j].name = NULL;
                    M3D_FREE(model->label[i].name);
                }
                if(model->label[i].lang) {
                    for(j = i + 1; j < model->numlabel; j++)
                        if(model->label[j].lang == model->label[i].lang)
                            model->label[j].lang = NULL;
                    M3D_FREE(model->label[i].lang);
                }
                if(model->label[i].text)
                    M3D_FREE(model->label[i].text);
            }
        if(model->preview.data)
            M3D_FREE(model->preview.data);
    }
#endif
    if(model->flags & M3D_FLG_FREERAW) M3D_FREE(model->raw);

    if(model->tmap) M3D_FREE(model->tmap);
    if(model->bone) {
        for(i = 0; i < model->numbone; i++)
            if(model->bone[i].weight)
                M3D_FREE(model->bone[i].weight);
        M3D_FREE(model->bone);
    }
    if(model->skin) M3D_FREE(model->skin);
    if(model->vertex) M3D_FREE(model->vertex);
    if(model->face) M3D_FREE(model->face);
    if(model->voxtype) {
        for(i = 0; i < model->numvoxtype; i++)
            if(model->voxtype[i].item)
                M3D_FREE(model->voxtype[i].item);
        M3D_FREE(model->voxtype);
    }
    if(model->voxel) {
        for(i = 0; i < model->numvoxel; i++)
            if(model->voxel[i].data)
                M3D_FREE(model->voxel[i].data);
        M3D_FREE(model->voxel);
    }
    if(model->shape) {
        for(i = 0; i < model->numshape; i++) {
            if(model->shape[i].cmd) {
                for(j = 0; j < model->shape[i].numcmd; j++)
                    if(model->shape[i].cmd[j].arg) M3D_FREE(model->shape[i].cmd[j].arg);
                M3D_FREE(model->shape[i].cmd);
            }
        }
        M3D_FREE(model->shape);
    }
    if(model->material && !(model->flags & M3D_FLG_MTLLIB)) {
        for(i = 0; i < model->nummaterial; i++)
            if(model->material[i].prop) M3D_FREE(model->material[i].prop);
        M3D_FREE(model->material);
    }
    if(model->texture) {
        for(i = 0; i < model->numtexture; i++)
            if(model->texture[i].d) M3D_FREE(model->texture[i].d);
        M3D_FREE(model->texture);
    }
    if(model->action) {
        for(i = 0; i < model->numaction; i++) {
            if(model->action[i].frame) {
                for(j = 0; j < model->action[i].numframe; j++)
                    if(model->action[i].frame[j].transform) M3D_FREE(model->action[i].frame[j].transform);
                M3D_FREE(model->action[i].frame);
            }
        }
        M3D_FREE(model->action);
    }
    if(model->label) M3D_FREE(model->label);
    if(model->inlined) M3D_FREE(model->inlined);
    if(model->extra) M3D_FREE(model->extra);
    M3D_FREE(model);
}
#endif

#ifdef M3D_EXPORTER
typedef struct {
    char *str;
    uint32_t offs;
} m3dstr_t;

typedef struct {
    m3dti_t data;
    M3D_INDEX oldidx;
    M3D_INDEX newidx;
} m3dtisave_t;

typedef struct {
    m3dv_t data;
    M3D_INDEX oldidx;
    M3D_INDEX newidx;
    unsigned char norm;
} m3dvsave_t;

typedef struct {
    m3ds_t data;
    M3D_INDEX oldidx;
    M3D_INDEX newidx;
} m3dssave_t;

typedef struct {
    m3df_t data;
    int group;
    uint8_t opacity;
} m3dfsave_t;

/* create unique list of strings */
static m3dstr_t *_m3d_addstr(m3dstr_t *str, uint32_t *numstr, char *s)
{
    uint32_t i;
    if(!s || !*s) return str;
    if(str) {
        for(i = 0; i < *numstr; i++)
            if(str[i].str == s || !strcmp(str[i].str, s)) return str;
    }
    str = (m3dstr_t*)M3D_REALLOC(str, ((*numstr) + 1) * sizeof(m3dstr_t));
    str[*numstr].str = s;
    str[*numstr].offs = 0;
    (*numstr)++;
    return str;
}

/* add strings to header */
m3dhdr_t *_m3d_addhdr(m3dhdr_t *h, m3dstr_t *s)
{
    int i;
    char *safe = _m3d_safestr(s->str, 0);
    i = (int)strlen(safe);
    h = (m3dhdr_t*)M3D_REALLOC(h, h->length + i+1);
    if(!h) { M3D_FREE(safe); return NULL; }
    memcpy((uint8_t*)h + h->length, safe, i+1);
    s->offs = h->length - 16;
    h->length += i+1;
    M3D_FREE(safe);
    return h;
}

/* return offset of string */
static uint32_t _m3d_stridx(m3dstr_t *str, uint32_t numstr, char *s)
{
    uint32_t i;
    char *safe;
    if(!s || !*s) return 0;
    if(str) {
        safe = _m3d_safestr(s, 0);
        if(!safe) return 0;
        if(!*safe) {
            M3D_FREE(safe);
            return 0;
        }
        for(i = 0; i < numstr; i++)
            if(!strcmp(str[i].str, s)) {
                M3D_FREE(safe);
                return str[i].offs;
            }
        M3D_FREE(safe);
    }
    return 0;
}

/* compare to faces by their material */
static int _m3d_facecmp(const void *a, const void *b) {
    const m3dfsave_t *A = (const m3dfsave_t*)a, *B = (const m3dfsave_t*)b;
    return A->group != B->group ? A->group - B->group : (A->opacity != B->opacity ? (int)B->opacity - (int)A->opacity :
        (int)A->data.materialid - (int)B->data.materialid);
}
/* compare face groups */
static int _m3d_grpcmp(const void *a, const void *b) { return *((uint32_t*)a) - *((uint32_t*)b); }
/* compare UVs */
static int _m3d_ticmp(const void *a, const void *b) { return memcmp(a, b, sizeof(m3dti_t)); }
/* compare skin groups */
static int _m3d_skincmp(const void *a, const void *b) { return memcmp(a, b, sizeof(m3ds_t)); }
/* compare vertices */
static int _m3d_vrtxcmp(const void *a, const void *b) {
    int c = memcmp(a, b, 3 * sizeof(M3D_FLOAT));
    if(c) return c;
    c = ((m3dvsave_t*)a)->norm - ((m3dvsave_t*)b)->norm;
    if(c) return c;
    return memcmp(a, b, sizeof(m3dv_t));
}
/* compare labels */
static _inline int _m3d_strcmp(char *a, char *b)
{
    if(a == NULL && b != NULL) return -1;
    if(a != NULL && b == NULL) return 1;
    if(a == NULL && b == NULL) return 0;
    return strcmp(a, b);
}
static int _m3d_lblcmp(const void *a, const void *b) {
    const m3dl_t *A = (const m3dl_t*)a, *B = (const m3dl_t*)b;
    int c = _m3d_strcmp(A->lang, B->lang);
    if(!c) c = _m3d_strcmp(A->name, B->name);
    if(!c) c = _m3d_strcmp(A->text, B->text);
    return c;
}
/* compare two colors by HSV value */
_inline static int _m3d_cmapcmp(const void *a, const void *b)
{
    uint8_t *A = (uint8_t*)a,  *B = (uint8_t*)b;
    _register int m, vA, vB;
    /* get HSV value for A */
    m = A[2] < A[1]? A[2] : A[1]; if(A[0] < m) m = A[0];
    vA = A[2] > A[1]? A[2] : A[1]; if(A[0] > vA) vA = A[0];
    /* get HSV value for B */
    m = B[2] < B[1]? B[2] : B[1]; if(B[0] < m) m = B[0];
    vB = B[2] > B[1]? B[2] : B[1]; if(B[0] > vB) vB = B[0];
    return vA - vB;
}

/* create sorted list of colors */
static uint32_t *_m3d_addcmap(uint32_t *cmap, uint32_t *numcmap, uint32_t color)
{
    uint32_t i;
    if(cmap) {
        for(i = 0; i < *numcmap; i++)
            if(cmap[i] == color) return cmap;
    }
    cmap = (uint32_t*)M3D_REALLOC(cmap, ((*numcmap) + 1) * sizeof(uint32_t));
    for(i = 0; i < *numcmap && _m3d_cmapcmp(&color, &cmap[i]) > 0; i++);
    if(i < *numcmap) memmove(&cmap[i+1], &cmap[i], ((*numcmap) - i)*sizeof(uint32_t));
    cmap[i] = color;
    (*numcmap)++;
    return cmap;
}

/* look up a color and return its index */
static uint32_t _m3d_cmapidx(uint32_t *cmap, uint32_t numcmap, uint32_t color)
{
    uint32_t i;
    if(numcmap >= 65536)
        return color;
    for(i = 0; i < numcmap; i++)
        if(cmap[i] == color) return i;
    return 0;
}

/* add index to output */
static unsigned char *_m3d_addidx(unsigned char *out, char type, uint32_t idx) {
    switch(type) {
        case 1: *out++ = (uint8_t)(idx); break;
        case 2: *((uint16_t*)out) = (uint16_t)(idx); out += 2; break;
        case 4: *((uint32_t*)out) = (uint32_t)(idx); out += 4; break;
        /* case 0: case 8: break; */
    }
    return out;
}

/* round a vertex position */
static void _m3d_round(int quality, m3dv_t *src, m3dv_t *dst)
{
    _register int t;
    /* copy additional attributes */
    if(src != dst) memcpy(dst, src, sizeof(m3dv_t));
    /* round according to quality */
    switch(quality) {
        case M3D_EXP_INT8:
            t = (int)(src->x * 127 + (src->x >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->x = (M3D_FLOAT)t / (M3D_FLOAT)127.0;
            t = (int)(src->y * 127 + (src->y >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->y = (M3D_FLOAT)t / (M3D_FLOAT)127.0;
            t = (int)(src->z * 127 + (src->z >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->z = (M3D_FLOAT)t / (M3D_FLOAT)127.0;
            t = (int)(src->w * 127 + (src->w >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->w = (M3D_FLOAT)t / (M3D_FLOAT)127.0;
        break;
        case M3D_EXP_INT16:
            t = (int)(src->x * 32767 + (src->x >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->x = (M3D_FLOAT)t / (M3D_FLOAT)32767.0;
            t = (int)(src->y * 32767 + (src->y >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->y = (M3D_FLOAT)t / (M3D_FLOAT)32767.0;
            t = (int)(src->z * 32767 + (src->z >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->z = (M3D_FLOAT)t / (M3D_FLOAT)32767.0;
            t = (int)(src->w * 32767 + (src->w >= 0 ? (M3D_FLOAT)0.5 : (M3D_FLOAT)-0.5)); dst->w = (M3D_FLOAT)t / (M3D_FLOAT)32767.0;
        break;
    }
    if(dst->x == (M3D_FLOAT)-0.0) dst->x = (M3D_FLOAT)0.0;
    if(dst->y == (M3D_FLOAT)-0.0) dst->y = (M3D_FLOAT)0.0;
    if(dst->z == (M3D_FLOAT)-0.0) dst->z = (M3D_FLOAT)0.0;
    if(dst->w == (M3D_FLOAT)-0.0) dst->w = (M3D_FLOAT)0.0;
}

#ifdef M3D_ASCII
/* add a bone to ascii output */
static char *_m3d_prtbone(char *ptr, m3db_t *bone, M3D_INDEX numbone, M3D_INDEX parent, uint32_t level, M3D_INDEX *vrtxidx)
{
    uint32_t i, j;
    char *sn;

    if(level > M3D_BONEMAXLEVEL || !bone) return ptr;
    for(i = 0; i < numbone; i++) {
        if(bone[i].parent == parent) {
            for(j = 0; j < level; j++) *ptr++ = '/';
            sn = _m3d_safestr(bone[i].name, 0);
            ptr += sprintf(ptr, "%d %d %s\r\n", vrtxidx[bone[i].pos], vrtxidx[bone[i].ori], sn);
            M3D_FREE(sn);
            ptr = _m3d_prtbone(ptr, bone, numbone, i, level + 1, vrtxidx);
        }
    }
    return ptr;
}
#endif

/**
 * Function to encode an in-memory model into on storage Model 3D format
 */
unsigned char *m3d_save(m3d_t *model, int quality, int flags, unsigned int *size)
{
#ifdef M3D_ASCII
    const char *ol;
    char *ptr;
#endif
    char vc_s, vi_s, si_s, ci_s, ti_s, bi_s, nb_s, sk_s, fc_s, hi_s, fi_s, vd_s, vp_s;
    char *sn = NULL, *sl = NULL, *sa = NULL, *sd = NULL;
    unsigned char *out = NULL, *z = NULL, weights[M3D_NUMBONE < 8 ? 8 : M3D_NUMBONE], *norm = NULL;
    unsigned int i, j, k, l, n, o, len, chunklen, *length;
    int maxvox = 0, minvox = 0;
    M3D_FLOAT scale = (M3D_FLOAT)0.0, min_x, max_x, min_y, max_y, min_z, max_z, mw;
    M3D_INDEX last, *vrtxidx = NULL, *mtrlidx = NULL, *tmapidx = NULL, *skinidx = NULL;
#ifdef M3D_VERTEXMAX
    M3D_INDEX lastp;
#endif
    uint32_t idx, numcmap = 0, *cmap = NULL, numvrtx = 0, maxvrtx = 0, numtmap = 0, maxtmap = 0, numproc = 0;
    uint32_t numskin = 0, maxskin = 0, numstr = 0, maxt = 0, maxbone = 0, numgrp = 0, maxgrp = 0, *grpidx = NULL;
    uint8_t *opa = NULL;
    m3dcd_t *cd;
    m3dc_t *cmd;
    m3dstr_t *str = NULL;
    m3dvsave_t *vrtx = NULL, vertex;
    m3dtisave_t *tmap = NULL, tcoord;
    m3dssave_t *skin = NULL, sk;
    m3dfsave_t *face = NULL;
    m3dhdr_t *h = NULL;
    m3dm_t *m;
    m3da_t *a;

    if(!model) {
        if(size) *size = 0;
        return NULL;
    }
    model->errcode = M3D_SUCCESS;
#ifdef M3D_ASCII
    if(flags & M3D_EXP_ASCII) quality = M3D_EXP_DOUBLE;
#endif
    vrtxidx = (M3D_INDEX*)M3D_MALLOC(model->numvertex * sizeof(M3D_INDEX));
    if(!vrtxidx) goto memerr;
    memset(vrtxidx, 255, model->numvertex * sizeof(M3D_INDEX));
    if(model->numvertex && !(flags & M3D_EXP_NONORMAL)){
        norm = (unsigned char*)M3D_MALLOC(model->numvertex * sizeof(unsigned char));
        if(!norm) goto memerr;
        memset(norm, 0, model->numvertex * sizeof(unsigned char));
    }
    if(model->nummaterial && !(flags & M3D_EXP_NOMATERIAL)) {
        mtrlidx = (M3D_INDEX*)M3D_MALLOC(model->nummaterial * sizeof(M3D_INDEX));
        if(!mtrlidx) goto memerr;
        memset(mtrlidx, 255, model->nummaterial * sizeof(M3D_INDEX));
        opa = (uint8_t*)M3D_MALLOC(model->nummaterial * 2 * sizeof(M3D_INDEX));
        if(!opa) goto memerr;
        memset(opa, 255, model->nummaterial * 2 * sizeof(M3D_INDEX));
    }
    if(model->numtmap && !(flags & M3D_EXP_NOTXTCRD)) {
        tmapidx = (M3D_INDEX*)M3D_MALLOC(model->numtmap * sizeof(M3D_INDEX));
        if(!tmapidx) goto memerr;
        memset(tmapidx, 255, model->numtmap * sizeof(M3D_INDEX));
    }
    /** collect array elements that are actually referenced **/
    if(!(flags & M3D_EXP_NOFACE)) {
        /* face */
        if(model->numface && model->face) {
            M3D_LOG("Processing mesh face");
            face = (m3dfsave_t*)M3D_MALLOC(model->numface * sizeof(m3dfsave_t));
            if(!face) goto memerr;
            for(i = 0; i < model->numface; i++) {
                memcpy(&face[i].data, &model->face[i], sizeof(m3df_t));
                face[i].group = 0;
                face[i].opacity = 255;
                if(!(flags & M3D_EXP_NOMATERIAL) && model->face[i].materialid < model->nummaterial) {
                    if(model->material[model->face[i].materialid].numprop) {
                        mtrlidx[model->face[i].materialid] = 0;
                        if(opa[model->face[i].materialid * 2]) {
                            m = &model->material[model->face[i].materialid];
                            for(j = 0; j < m->numprop; j++)
                                if(m->prop[j].type == m3dp_Kd) {
                                    opa[model->face[i].materialid * 2 + 1] = ((uint8_t*)&m->prop[j].value.color)[3];
                                    break;
                                }
                            for(j = 0; j < m->numprop; j++)
                                if(m->prop[j].type == m3dp_d) {
                                    opa[model->face[i].materialid * 2 + 1] = (uint8_t)(m->prop[j].value.fnum * 255);
                                    break;
                                }
                            opa[model->face[i].materialid * 2] = 0;
                        }
                        face[i].opacity = opa[model->face[i].materialid * 2 + 1];
                    } else
                        face[i].data.materialid = M3D_UNDEF;
                }
                for(j = 0; j < 3; j++) {
                    k = model->face[i].vertex[j];
                    if(k < model->numvertex)
                        vrtxidx[k] = 0;
                    if(!(flags & M3D_EXP_NOCMAP)) {
                        cmap = _m3d_addcmap(cmap, &numcmap, model->vertex[k].color);
                        if(!cmap) goto memerr;
                    }
                    k = model->face[i].normal[j];
                    if(k < model->numvertex && !(flags & M3D_EXP_NONORMAL)) {
                        vrtxidx[k] = 0;
                        norm[k] = 1;
                    }
                    k = model->face[i].texcoord[j];
                    if(k < model->numtmap && !(flags & M3D_EXP_NOTXTCRD))
                        tmapidx[k] = 0;
#ifdef M3D_VERTEXMAX
                    k = model->face[i].vertmax[j];
                    if(k < model->numvertex && !(flags & M3D_EXP_NOVRTMAX))
                        vrtxidx[k] = 0;
#endif
                }
                /* convert from CW to CCW */
                if(flags & M3D_EXP_IDOSUCK) {
                    j = face[i].data.vertex[1];
                    face[i].data.vertex[1] = face[i].data.vertex[2];
                    face[i].data.vertex[2] = j;
                    j = face[i].data.normal[1];
                    face[i].data.normal[1] = face[i].data.normal[2];
                    face[i].data.normal[2] = j;
                    j = face[i].data.texcoord[1];
                    face[i].data.texcoord[1] = face[i].data.texcoord[2];
                    face[i].data.texcoord[2] = j;
#ifdef M3D_VERTEXMAX
                    j = face[i].data.vertmax[1];
                    face[i].data.vertmax[1] = face[i].data.vertmax[2];
                    face[i].data.vertmax[2] = j;
#endif
                }
            }
        }
        if((model->numvoxtype && model->voxtype) || (model->numvoxel && model->voxel)) {
            M3D_LOG("Processing voxel face");
            for(i = 0; i < model->numvoxtype; i++) {
                str = _m3d_addstr(str, &numstr, model->voxtype[i].name);
                if(model->voxtype[i].name && !str) goto memerr;
                if(!(flags & M3D_EXP_NOCMAP)) {
                    cmap = _m3d_addcmap(cmap, &numcmap, model->voxtype[i].color);
                    if(!cmap) goto memerr;
                }
                for(j = 0; j < model->voxtype[i].numitem; j++) {
                    str = _m3d_addstr(str, &numstr, model->voxtype[i].item[j].name);
                    if(model->voxtype[i].item[j].name && !str) goto memerr;
                }
            }
            for(i = 0; i < model->numvoxel; i++) {
                str = _m3d_addstr(str, &numstr, model->voxel[i].name);
                if(model->voxel[i].name && !str) goto memerr;
                if(model->voxel[i].x < minvox) minvox = model->voxel[i].x;
                if(model->voxel[i].x + (int)model->voxel[i].w > maxvox) maxvox = model->voxel[i].x + model->voxel[i].w;
                if(model->voxel[i].y < minvox) minvox = model->voxel[i].y;
                if(model->voxel[i].y + (int)model->voxel[i].h > maxvox) maxvox = model->voxel[i].y + model->voxel[i].h;
                if(model->voxel[i].z < minvox) minvox = model->voxel[i].z;
                if(model->voxel[i].z + (int)model->voxel[i].d > maxvox) maxvox = model->voxel[i].z + model->voxel[i].d;
            }
        }
        if(model->numshape && model->shape) {
            M3D_LOG("Processing shape face");
            for(i = 0; i < model->numshape; i++) {
                if(!model->shape[i].numcmd) continue;
                str = _m3d_addstr(str, &numstr, model->shape[i].name);
                if(model->shape[i].name && !str) goto memerr;
                for(j = 0; j < model->shape[i].numcmd; j++) {
                    cmd = &model->shape[i].cmd[j];
                    if(cmd->type >= (unsigned int)(sizeof(m3d_commandtypes)/sizeof(m3d_commandtypes[0])) || !cmd->arg)
                        continue;
                    if(cmd->type == m3dc_mesh) {
                        if(numgrp + 2 < maxgrp) {
                            maxgrp += 1024;
                            grpidx = (uint32_t*)M3D_REALLOC(grpidx, maxgrp * sizeof(uint32_t));
                            if(!grpidx) goto memerr;
                            if(!numgrp) {
                                grpidx[0] = 0;
                                grpidx[1] = model->numface;
                                numgrp += 2;
                            }
                        }
                        grpidx[numgrp + 0] = cmd->arg[0];
                        grpidx[numgrp + 1] = cmd->arg[0] + cmd->arg[1];
                        numgrp += 2;
                    }
                    cd = &m3d_commandtypes[cmd->type];
                    for(k = n = 0, l = cd->p; k < l; k++)
                        switch(cd->a[((k - n) % (cd->p - n)) + n]) {
                            case m3dcp_mi_t:
                                if(!(flags & M3D_EXP_NOMATERIAL) && cmd->arg[k] < model->nummaterial)
                                    mtrlidx[cmd->arg[k]] = 0;
                            break;
                            case m3dcp_ti_t:
                                if(!(flags & M3D_EXP_NOTXTCRD) && cmd->arg[k] < model->numtmap)
                                    tmapidx[cmd->arg[k]] = 0;
                            break;
                            case m3dcp_qi_t:
                            case m3dcp_vi_t:
                                if(cmd->arg[k] < model->numvertex)
                                    vrtxidx[cmd->arg[k]] = 0;
                            break;
                            case m3dcp_va_t:
                                n = k + 1; l += (cmd->arg[k] - 1) * (cd->p - k - 1);
                            break;
                        }
                }
            }
        }
        if(model->numface && face) {
            if(numgrp && grpidx) {
                qsort(grpidx, numgrp, sizeof(uint32_t), _m3d_grpcmp);
                for(i = j = 0; i < model->numface && j < numgrp; i++) {
                    while(j < numgrp && grpidx[j] < i) j++;
                    face[i].group = j;
                }
            }
            qsort(face, model->numface, sizeof(m3dfsave_t), _m3d_facecmp);
        }
        if(grpidx) { M3D_FREE(grpidx); grpidx = NULL; }
        if(model->numlabel && model->label) {
            M3D_LOG("Processing annotation labels");
            for(i = 0; i < model->numlabel; i++) {
                str = _m3d_addstr(str, &numstr, model->label[i].name);
                str = _m3d_addstr(str, &numstr, model->label[i].lang);
                str = _m3d_addstr(str, &numstr, model->label[i].text);
                if(!(flags & M3D_EXP_NOCMAP)) {
                    cmap = _m3d_addcmap(cmap, &numcmap, model->label[i].color);
                    if(!cmap) goto memerr;
                }
                if(model->label[i].vertexid < model->numvertex)
                    vrtxidx[model->label[i].vertexid] = 0;
            }
            qsort(model->label, model->numlabel, sizeof(m3dl_t), _m3d_lblcmp);
        }
    } else if(!(flags & M3D_EXP_NOMATERIAL)) {
        /* without a face, simply add all materials, because it can be an mtllib */
        for(i = 0; i < model->nummaterial; i++)
            mtrlidx[i] = i;
    }
    /* bind-pose skeleton */
    if(model->numbone && model->bone && !(flags & M3D_EXP_NOBONE)) {
        M3D_LOG("Processing bones");
        for(i = 0; i < model->numbone; i++) {
            str = _m3d_addstr(str, &numstr, model->bone[i].name);
            if(!str) goto memerr;
            k = model->bone[i].pos;
            if(k < model->numvertex)
                vrtxidx[k] = 0;
            k = model->bone[i].ori;
            if(k < model->numvertex)
                vrtxidx[k] = 0;
        }
    }
    /* actions, animated skeleton poses */
    if(model->numaction && model->action && !(flags & M3D_EXP_NOACTION)) {
        M3D_LOG("Processing action list");
        for(j = 0; j < model->numaction; j++) {
            a = &model->action[j];
            str = _m3d_addstr(str, &numstr, a->name);
            if(!str) goto memerr;
            if(a->numframe > 65535) a->numframe = 65535;
            for(i = 0; i < a->numframe; i++) {
                for(l = 0; l < a->frame[i].numtransform; l++) {
                    k = a->frame[i].transform[l].pos;
                    if(k < model->numvertex)
                        vrtxidx[k] = 0;
                    k = a->frame[i].transform[l].ori;
                    if(k < model->numvertex)
                        vrtxidx[k] = 0;
                }
                if(l > maxt) maxt = l;
            }
        }
    }
    /* add colors to color map and texture names to string table */
    if(!(flags & M3D_EXP_NOMATERIAL)) {
        M3D_LOG("Processing materials");
        for(i = k = 0; i < model->nummaterial; i++) {
            if(mtrlidx[i] == M3D_UNDEF || !model->material[i].numprop) continue;
            mtrlidx[i] = k++;
            m = &model->material[i];
            str = _m3d_addstr(str, &numstr, m->name);
            if(!str) goto memerr;
            if(m->prop)
                for(j = 0; j < m->numprop; j++) {
                    if(!(flags & M3D_EXP_NOCMAP) && m->prop[j].type < 128) {
                        for(l = 0; l < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); l++) {
                            if(m->prop[j].type == m3d_propertytypes[l].id && m3d_propertytypes[l].format == m3dpf_color) {
                                ((uint8_t*)&m->prop[j].value.color)[3] = opa[i * 2 + 1];
                                cmap = _m3d_addcmap(cmap, &numcmap, m->prop[j].value.color);
                                if(!cmap) goto memerr;
                                break;
                            }
                        }
                    }
                    if(m->prop[j].type >= 128 && m->prop[j].value.textureid < model->numtexture &&
                        model->texture[m->prop[j].value.textureid].name) {
                        str = _m3d_addstr(str, &numstr, model->texture[m->prop[j].value.textureid].name);
                        if(!str) goto memerr;
                    }
                }
        }
    }
    /* if there's only one black color, don't store it */
    if(numcmap == 1 && cmap && !cmap[0]) numcmap = 0;

    /** compress lists **/
    if(model->numtmap && !(flags & M3D_EXP_NOTXTCRD)) {
        M3D_LOG("Compressing tmap");
        tmap = (m3dtisave_t*)M3D_MALLOC(model->numtmap * sizeof(m3dtisave_t));
        if(!tmap) goto memerr;
        for(i = 0; i < model->numtmap; i++) {
            if(tmapidx[i] == M3D_UNDEF) continue;
            switch(quality) {
                case M3D_EXP_INT8:
                    l = (unsigned int)(model->tmap[i].u * 255); tcoord.data.u = (M3D_FLOAT)l / (M3D_FLOAT)255.0;
                    l = (unsigned int)(model->tmap[i].v * 255); tcoord.data.v = (M3D_FLOAT)l / (M3D_FLOAT)255.0;
                break;
                case M3D_EXP_INT16:
                    l = (unsigned int)(model->tmap[i].u * 65535); tcoord.data.u = (M3D_FLOAT)l / (M3D_FLOAT)65535.0;
                    l = (unsigned int)(model->tmap[i].v * 65535); tcoord.data.v = (M3D_FLOAT)l / (M3D_FLOAT)65535.0;
                break;
                default:
                    tcoord.data.u = model->tmap[i].u;
                    tcoord.data.v = model->tmap[i].v;
                break;
            }
            if(flags & M3D_EXP_FLIPTXTCRD)
                tcoord.data.v = (M3D_FLOAT)1.0 - tcoord.data.v;
            tcoord.oldidx = i;
            memcpy(&tmap[numtmap++], &tcoord, sizeof(m3dtisave_t));
        }
        if(numtmap) {
            qsort(tmap, numtmap, sizeof(m3dtisave_t), _m3d_ticmp);
            memcpy(&tcoord.data, &tmap[0], sizeof(m3dti_t));
            for(i = 0; i < numtmap; i++) {
                if(memcmp(&tcoord.data, &tmap[i].data, sizeof(m3dti_t))) {
                    memcpy(&tcoord.data, &tmap[i].data, sizeof(m3dti_t));
                    maxtmap++;
                }
                tmap[i].newidx = maxtmap;
                tmapidx[tmap[i].oldidx] = maxtmap;
            }
            maxtmap++;
        }
    }
    if(model->numskin && model->skin && !(flags & M3D_EXP_NOBONE)) {
        M3D_LOG("Compressing skin");
        skinidx = (M3D_INDEX*)M3D_MALLOC(model->numskin * sizeof(M3D_INDEX));
        if(!skinidx) goto memerr;
        skin = (m3dssave_t*)M3D_MALLOC(model->numskin * sizeof(m3dssave_t));
        if(!skin) goto memerr;
        memset(skinidx, 255, model->numskin * sizeof(M3D_INDEX));
        for(i = 0; i < model->numvertex; i++) {
            if(vrtxidx[i] != M3D_UNDEF && model->vertex[i].skinid < model->numskin)
                skinidx[model->vertex[i].skinid] = 0;
        }
        for(i = 0; i < model->numskin; i++) {
            if(skinidx[i] == M3D_UNDEF) continue;
            memset(&sk, 0, sizeof(m3dssave_t));
            for(j = 0, min_x = (M3D_FLOAT)0.0; j < M3D_NUMBONE && model->skin[i].boneid[j] != M3D_UNDEF; j++) {
                    sk.data.boneid[j] = model->skin[i].boneid[j];
                    sk.data.weight[j] = model->skin[i].weight[j] > (M3D_FLOAT)0.0 ? model->skin[i].weight[j] : (M3D_FLOAT)0.01;
                    min_x += sk.data.weight[j];
            }
            if(j > maxbone) maxbone = j;
            if(min_x != (M3D_FLOAT)1.0 && min_x != (M3D_FLOAT)0.0)
                for(j = 0; j < M3D_NUMBONE && sk.data.weight[j] > (M3D_FLOAT)0.0; j++)
                    sk.data.weight[j] /= min_x;
            sk.oldidx = i;
            memcpy(&skin[numskin++], &sk, sizeof(m3dssave_t));
        }
        if(numskin) {
            qsort(skin, numskin, sizeof(m3dssave_t), _m3d_skincmp);
            memcpy(&sk.data, &skin[0].data, sizeof(m3ds_t));
            for(i = 0; i < numskin; i++) {
                if(memcmp(&sk.data, &skin[i].data, sizeof(m3ds_t))) {
                    memcpy(&sk.data, &skin[i].data, sizeof(m3ds_t));
                    maxskin++;
                }
                skin[i].newidx = maxskin;
                skinidx[skin[i].oldidx] = maxskin;
            }
            maxskin++;
        }
    }

    M3D_LOG("Compressing vertex list");
    min_x = min_y = min_z = (M3D_FLOAT)1e10;
    max_x = max_y = max_z = (M3D_FLOAT)-1e10;
    if(vrtxidx) {
        vrtx = (m3dvsave_t*)M3D_MALLOC(model->numvertex * sizeof(m3dvsave_t));
        if(!vrtx) goto memerr;
        for(i = numvrtx = 0; i < model->numvertex; i++) {
            if(vrtxidx[i] == M3D_UNDEF) continue;
            _m3d_round(quality, &model->vertex[i], &vertex.data);
            vertex.norm = norm ? norm[i] : 0;
            if(vertex.data.skinid != M3D_INDEXMAX && !vertex.norm) {
                vertex.data.skinid = vertex.data.skinid != M3D_UNDEF && skinidx ? skinidx[vertex.data.skinid] : M3D_UNDEF;
                if(vertex.data.x > max_x) max_x = vertex.data.x;
                if(vertex.data.x < min_x) min_x = vertex.data.x;
                if(vertex.data.y > max_y) max_y = vertex.data.y;
                if(vertex.data.y < min_y) min_y = vertex.data.y;
                if(vertex.data.z > max_z) max_z = vertex.data.z;
                if(vertex.data.z < min_z) min_z = vertex.data.z;
            }
#ifdef M3D_VERTEXTYPE
            vertex.data.type = 0;
#endif
            vertex.oldidx = i;
            memcpy(&vrtx[numvrtx++], &vertex, sizeof(m3dvsave_t));
        }
        if(numvrtx) {
            qsort(vrtx, numvrtx, sizeof(m3dvsave_t), _m3d_vrtxcmp);
            memcpy(&vertex.data, &vrtx[0].data, sizeof(m3dv_t));
            for(i = 0; i < numvrtx; i++) {
                if(memcmp(&vertex.data, &vrtx[i].data, vrtx[i].norm ? 3 * sizeof(M3D_FLOAT) : sizeof(m3dv_t))) {
                    memcpy(&vertex.data, &vrtx[i].data, sizeof(m3dv_t));
                    maxvrtx++;
                }
                vrtx[i].newidx = maxvrtx;
                vrtxidx[vrtx[i].oldidx] = maxvrtx;
            }
            maxvrtx++;
        }
    }
    if(norm) { M3D_FREE(norm); norm = NULL; }

    /* normalize to bounding cube */
    if(numvrtx && !(flags & M3D_EXP_NORECALC)) {
        M3D_LOG("Normalizing coordinates");
        if(min_x < (M3D_FLOAT)0.0) min_x = -min_x;
        if(max_x < (M3D_FLOAT)0.0) max_x = -max_x;
        if(min_y < (M3D_FLOAT)0.0) min_y = -min_y;
        if(max_y < (M3D_FLOAT)0.0) max_y = -max_y;
        if(min_z < (M3D_FLOAT)0.0) min_z = -min_z;
        if(max_z < (M3D_FLOAT)0.0) max_z = -max_z;
        scale = min_x;
        if(max_x > scale) scale = max_x;
        if(min_y > scale) scale = min_y;
        if(max_y > scale) scale = max_y;
        if(min_z > scale) scale = min_z;
        if(max_z > scale) scale = max_z;
        if(scale <= (M3D_FLOAT)0.0) scale = (M3D_FLOAT)1.0;
        if(scale != (M3D_FLOAT)1.0) {
            for(i = 0; i < numvrtx; i++) {
                if(vrtx[i].data.skinid == M3D_INDEXMAX) continue;
                vrtx[i].data.x /= scale;
                vrtx[i].data.y /= scale;
                vrtx[i].data.z /= scale;
            }
        }
    }
    if(model->scale > (M3D_FLOAT)0.0) scale = model->scale;
    if(scale <= (M3D_FLOAT)0.0) scale = (M3D_FLOAT)1.0;

    /* meta info */
    sn = _m3d_safestr(model->name && *model->name ? model->name : (char*)"(noname)", 2);
    sl = _m3d_safestr(model->license ? model->license : (char*)"MIT", 2);
    sa = _m3d_safestr(model->author ? model->author : getenv("LOGNAME"), 2);
    if(!sn || !sl || !sa) {
memerr: if(vrtxidx) M3D_FREE(vrtxidx);
        if(mtrlidx) M3D_FREE(mtrlidx);
        if(tmapidx) M3D_FREE(tmapidx);
        if(skinidx) M3D_FREE(skinidx);
        if(grpidx) M3D_FREE(grpidx);
        if(norm) M3D_FREE(norm);
        if(face) M3D_FREE(face);
        if(cmap) M3D_FREE(cmap);
        if(tmap) M3D_FREE(tmap);
        if(skin) M3D_FREE(skin);
        if(str) M3D_FREE(str);
        if(vrtx) M3D_FREE(vrtx);
        if(sn) M3D_FREE(sn);
        if(sl) M3D_FREE(sl);
        if(sa) M3D_FREE(sa);
        if(sd) M3D_FREE(sd);
        if(out) M3D_FREE(out);
        if(opa) M3D_FREE(opa);
        if(h) M3D_FREE(h);
        M3D_LOG("Out of memory");
        model->errcode = M3D_ERR_ALLOC;
        return NULL;
    }

    M3D_LOG("Serializing model");
#ifdef M3D_ASCII
    if(flags & M3D_EXP_ASCII) {
        /* use CRLF to make model creators on Win happy... */
        sd = _m3d_safestr(model->desc, 1);
        if(!sd) goto memerr;
        ol = setlocale(LC_NUMERIC, NULL);
        setlocale(LC_NUMERIC, "C");
        /* header */
        len = 64 + (unsigned int)(strlen(sn) + strlen(sl) + strlen(sa) + strlen(sd));
        out = (unsigned char*)M3D_MALLOC(len);
        if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
        ptr = (char*)out;
        ptr += sprintf(ptr, "3dmodel %g\r\n%s\r\n%s\r\n%s\r\n%s\r\n\r\n", scale,
            sn, sl, sa, sd);
        M3D_FREE(sl); M3D_FREE(sa); M3D_FREE(sd);
        sl = sa = sd = NULL;
        /* preview chunk */
        if(model->preview.data && model->preview.length) {
            sl = _m3d_safestr(sn, 0);
            if(sl) {
/* gcc thinks that "ptr is used after free", well, gcc is simply wrong. */
#ifdef __GNUC__
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wuse-after-free"
#endif
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)20 + strlen(sl));
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
#ifdef __GNUC__
#pragma GCC diagnostic pop
#endif
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Preview\r\n%s.png\r\n\r\n", sl);
                M3D_FREE(sl); sl = NULL;
            }
        }
        M3D_FREE(sn);  sn = NULL;
        /* texture map */
        if(numtmap && tmap && !(flags & M3D_EXP_NOTXTCRD) && !(flags & M3D_EXP_NOFACE)) {
/* interestingly gcc does not complain about "ptr is used after free" here, although the code is 100% the same */
            ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)(maxtmap * 32) + (uintptr_t)12);
            out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
            if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
            ptr += sprintf(ptr, "Textmap\r\n");
            last = M3D_UNDEF;
            for(i = 0; i < numtmap; i++) {
                if(tmap[i].newidx == last) continue;
                last = tmap[i].newidx;
                ptr += sprintf(ptr, "%g %g\r\n", tmap[i].data.u, tmap[i].data.v);
            }
            ptr += sprintf(ptr, "\r\n");
        }
        /* vertex chunk */
        if(numvrtx && vrtx && !(flags & M3D_EXP_NOFACE)) {
            ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)(maxvrtx * 128) + (uintptr_t)10);
            out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
            if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
            ptr += sprintf(ptr, "Vertex\r\n");
            last = M3D_UNDEF;
            for(i = 0; i < numvrtx; i++) {
                if(vrtx[i].newidx == last) continue;
                last = vrtx[i].newidx;
                ptr += sprintf(ptr, "%g %g %g %g", vrtx[i].data.x, vrtx[i].data.y, vrtx[i].data.z, vrtx[i].data.w);
                if(!(flags & M3D_EXP_NOCMAP) && vrtx[i].data.color)
                    ptr += sprintf(ptr, " #%08x", vrtx[i].data.color);
                if(!(flags & M3D_EXP_NOBONE) && model->numbone && maxskin && vrtx[i].data.skinid < M3D_INDEXMAX) {
                    if(skin[vrtx[i].data.skinid].data.weight[0] == (M3D_FLOAT)1.0)
                        ptr += sprintf(ptr, " %d", skin[vrtx[i].data.skinid].data.boneid[0]);
                    else
                        for(j = 0; j < M3D_NUMBONE && skin[vrtx[i].data.skinid].data.boneid[j] != M3D_UNDEF &&
                            skin[vrtx[i].data.skinid].data.weight[j] > (M3D_FLOAT)0.0; j++)
                            ptr += sprintf(ptr, " %d:%g", skin[vrtx[i].data.skinid].data.boneid[j],
                                skin[vrtx[i].data.skinid].data.weight[j]);
                }
                ptr += sprintf(ptr, "\r\n");
            }
            ptr += sprintf(ptr, "\r\n");
        }
        /* bones chunk */
        if(model->numbone && model->bone && !(flags & M3D_EXP_NOBONE)) {
            ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)9);
            for(i = 0; i < model->numbone; i++) {
                len += (unsigned int)strlen(model->bone[i].name) + 128;
            }
            out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
            if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
            ptr += sprintf(ptr, "Bones\r\n");
            ptr = _m3d_prtbone(ptr, model->bone, model->numbone, M3D_UNDEF, 0, vrtxidx);
            ptr += sprintf(ptr, "\r\n");
        }
        /* materials */
        if(model->nummaterial && !(flags & M3D_EXP_NOMATERIAL)) {
            for(j = 0; j < model->nummaterial; j++) {
                if(mtrlidx[j] == M3D_UNDEF || !model->material[j].numprop || !model->material[j].prop) continue;
                m = &model->material[j];
                sn = _m3d_safestr(m->name, 0);
                if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)strlen(sn) + (uintptr_t)12);
                for(i = 0; i < m->numprop; i++) {
                    if(m->prop[i].type < 128)
                        len += 32;
                    else if(m->prop[i].value.textureid < model->numtexture && model->texture[m->prop[i].value.textureid].name)
                        len += (unsigned int)strlen(model->texture[m->prop[i].value.textureid].name) + 16;
                }
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Material %s\r\n", sn);
                M3D_FREE(sn); sn = NULL;
                for(i = 0; i < m->numprop; i++) {
                    k = 256;
                    if(m->prop[i].type >= 128) {
                        for(l = 0; l < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); l++)
                            if(m->prop[i].type == m3d_propertytypes[l].id) {
                                sn = m3d_propertytypes[l].key;
                                break;
                            }
                        if(!sn)
                            for(l = 0; l < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); l++)
                                if(m->prop[i].type - 128 == m3d_propertytypes[l].id) {
                                    sn = m3d_propertytypes[l].key;
                                    break;
                                }
                        k = sn ? m3dpf_map : 256;
                    } else {
                        for(l = 0; l < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); l++)
                            if(m->prop[i].type == m3d_propertytypes[l].id) {
                                sn = m3d_propertytypes[l].key;
                                k = m3d_propertytypes[l].format;
                                break;
                            }
                    }
                    switch(k) {
                        case m3dpf_color: ptr += sprintf(ptr, "%s #%08x\r\n", sn, m->prop[i].value.color); break;
                        case m3dpf_uint8:
                        case m3dpf_uint16:
                        case m3dpf_uint32: ptr += sprintf(ptr, "%s %d\r\n", sn, m->prop[i].value.num); break;
                        case m3dpf_float:  ptr += sprintf(ptr, "%s %g\r\n", sn, m->prop[i].value.fnum); break;
                        case m3dpf_map:
                            if(m->prop[i].value.textureid < model->numtexture &&
                                model->texture[m->prop[i].value.textureid].name) {
                                sl = _m3d_safestr(model->texture[m->prop[i].value.textureid].name, 0);
                                if(!sl) { setlocale(LC_NUMERIC, ol); goto memerr; }
                                if(*sl)
                                    ptr += sprintf(ptr, "map_%s %s\r\n", sn, sl);
                                M3D_FREE(sn); M3D_FREE(sl); sl = NULL;
                            }
                        break;
                    }
                    sn = NULL;
                }
                ptr += sprintf(ptr, "\r\n");
            }
        }
        /* procedural face */
        if(model->numinlined && model->inlined && !(flags & M3D_EXP_NOFACE)) {
            /* all inlined assets which are not textures should be procedural surfaces */
            for(j = 0; j < model->numinlined; j++) {
                if(!model->inlined[j].name || !*model->inlined[j].name || !model->inlined[j].length || !model->inlined[j].data ||
                 (model->inlined[j].data[1] == 'P' && model->inlined[j].data[2] == 'N' && model->inlined[j].data[3] == 'G'))
                    continue;
                for(i = k = 0; i < model->numtexture; i++) {
                    if(!strcmp(model->inlined[j].name, model->texture[i].name)) { k = 1; break; }
                }
                if(k) continue;
                sn = _m3d_safestr(model->inlined[j].name, 0);
                if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)strlen(sn) + (uintptr_t)18);
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Procedural\r\n%s\r\n\r\n", sn);
                M3D_FREE(sn); sn = NULL;
            }
        }
        /* mesh face */
        if(model->numface && face && !(flags & M3D_EXP_NOFACE)) {
            ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)(model->numface * 128) + (uintptr_t)6);
            last = M3D_UNDEF;
#ifdef M3D_VERTEXMAX
            lastp = M3D_UNDEF;
#endif
            if(!(flags & M3D_EXP_NOMATERIAL))
                for(i = 0; i < model->numface; i++) {
                    j = face[i].data.materialid < model->nummaterial ? face[i].data.materialid : M3D_UNDEF;
                    if(j != last) {
                        last = j;
                        if(last < model->nummaterial)
                            len += (unsigned int)strlen(model->material[last].name);
                        len += 6;
                    }
#ifdef M3D_VERTEXMAX
                    j = face[i].data.paramid < model->numparam ? face[i].data.paramid : M3D_UNDEF;
                    if(j != lastp) {
                        lastp = j;
                        if(lastp < model->numparam)
                            len += (unsigned int)strlen(model->param[lastp].name);
                        len += 6;
                    }
#endif
                }
            out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
            if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
            ptr += sprintf(ptr, "Mesh\r\n");
            last = M3D_UNDEF;
#ifdef M3D_VERTEXMAX
            lastp = M3D_UNDEF;
#endif
            for(i = 0; i < model->numface; i++) {
                j = face[i].data.materialid < model->nummaterial ? face[i].data.materialid : M3D_UNDEF;
                if(!(flags & M3D_EXP_NOMATERIAL) && j != last) {
                    last = j;
                    if(last < model->nummaterial) {
                        sn = _m3d_safestr(model->material[last].name, 0);
                        if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                        ptr += sprintf(ptr, "use %s\r\n", sn);
                        M3D_FREE(sn); sn = NULL;
                    } else
                        ptr += sprintf(ptr, "use\r\n");
                }
#ifdef M3D_VERTEXMAX
                j = face[i].data.paramid < model->numparam ? face[i].data.paramid : M3D_UNDEF;
                if(!(flags & M3D_EXP_NOVRTMAX) && j != lastp) {
                    lastp = j;
                    if(lastp < model->numparam) {
                        sn = _m3d_safestr(model->param[lastp].name, 0);
                        if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                        ptr += sprintf(ptr, "par %s\r\n", sn);
                        M3D_FREE(sn); sn = NULL;
                    } else
                        ptr += sprintf(ptr, "par\r\n");
                }
#endif
                /* hardcoded triangles. Should be repeated as many times as the number of edges in polygon */
                for(j = 0; j < 3; j++) {
                    ptr += sprintf(ptr, "%s%d", j?" ":"", vrtxidx[face[i].data.vertex[j]]);
                    k = l = M3D_NOTDEFINED;
                    if(!(flags & M3D_EXP_NOTXTCRD) && (face[i].data.texcoord[j] != M3D_UNDEF) &&
                        (tmapidx[face[i].data.texcoord[j]] != M3D_UNDEF)) {
                            k = tmapidx[face[i].data.texcoord[j]];
                            ptr += sprintf(ptr, "/%d", k);
                    }
                    if(!(flags & M3D_EXP_NONORMAL) && (face[i].data.normal[j] != M3D_UNDEF)) {
                        l = vrtxidx[face[i].data.normal[j]];
                        ptr += sprintf(ptr, "%s/%d", k == M3D_NOTDEFINED? "/" : "", l);
                    }
#ifdef M3D_VERTEXMAX
                    if(!(flags & M3D_EXP_NOVRTMAX) && (face[i].data.vertmax[j] != M3D_UNDEF)) {
                        ptr += sprintf(ptr, "%s%s/%d", k == M3D_NOTDEFINED? "/" : "", l == M3D_NOTDEFINED? "/" : "",
                            vrtxidx[face[i].data.vertmax[j]]);
                    }
#endif
                }
                ptr += sprintf(ptr, "\r\n");
            }
            ptr += sprintf(ptr, "\r\n");
        }
        /* voxel face */
        if(model->numvoxtype && model->voxtype && !(flags & M3D_EXP_NOFACE)) {
            ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)(model->numvoxtype * 128) + (uintptr_t)10);
            for(i = 0; i < model->numvoxtype; i++) {
                if(model->voxtype[i].name) len += (unsigned int)strlen(model->voxtype[i].name);
                for(j = 0; j < model->voxtype[i].numitem; j++)
                    if(model->voxtype[i].item[j].name)
                        len += (unsigned int)strlen(model->voxtype[i].item[j].name) + 6;
            }
            out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
            if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
            ptr += sprintf(ptr, "VoxTypes\r\n");
            for(i = 0; i < model->numvoxtype; i++) {
                ptr += sprintf(ptr, "#%08x", model->voxtype[i].color);
                if(model->voxtype[i].rotation)
                    ptr += sprintf(ptr, "/%02x", model->voxtype[i].rotation);
                if(model->voxtype[i].voxshape)
                    ptr += sprintf(ptr, "%s/%03x", model->voxtype[i].rotation ? "" : "/", model->voxtype[i].voxshape);
                sn = _m3d_safestr(model->voxtype[i].name, 0);
                if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, " %s", sn && sn[0] ? sn : "-");
                M3D_FREE(sn); sn = NULL;
                if(!(flags & M3D_EXP_NOBONE) && model->numbone && maxskin && model->voxtype[i].skinid < M3D_INDEXMAX) {
                    if(skin[skinidx[model->voxtype[i].skinid]].data.weight[0] == (M3D_FLOAT)1.0)
                        ptr += sprintf(ptr, " %d", skin[skinidx[model->voxtype[i].skinid]].data.boneid[0]);
                    else
                        for(j = 0; j < M3D_NUMBONE && skin[skinidx[model->voxtype[i].skinid]].data.boneid[j] != M3D_UNDEF &&
                            skin[skinidx[model->voxtype[i].skinid]].data.weight[j] > (M3D_FLOAT)0.0; j++)
                            ptr += sprintf(ptr, " %d:%g", skin[skinidx[model->voxtype[i].skinid]].data.boneid[j],
                                skin[skinidx[model->voxtype[i].skinid]].data.weight[j]);
                }
                if(model->voxtype[i].numitem && model->voxtype[i].item) {
                    for(j = k = 0; j < model->voxtype[i].numitem; j++) {
                        if(!model->voxtype[i].item[j].count || !model->voxtype[i].item[j].name ||
                            !model->voxtype[i].item[j].name[0]) continue;
                        if(!k) { ptr += sprintf(ptr, " {"); k = 1; }
                        sn = _m3d_safestr(model->voxtype[i].item[j].name, 0);
                        if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                        ptr += sprintf(ptr, " %d %s", model->voxtype[i].item[j].count, sn);
                        M3D_FREE(sn); sn = NULL;
                    }
                    if(k) ptr += sprintf(ptr, " }");
                }
                while(ptr[-1] == '-' || ptr[-1] == ' ') ptr--;
                ptr += sprintf(ptr, "\r\n");
            }
            ptr += sprintf(ptr, "\r\n");
        }
        if(model->numvoxel && model->voxel && !(flags & M3D_EXP_NOFACE)) {
            for(i = 0; i < model->numvoxel; i++) {
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)128);
                if(model->voxel[i].name) len += (unsigned int)strlen(model->voxel[i].name);
                len += model->voxel[i].h * ((model->voxel[i].w * 6 + 2) * model->voxel[i].d + 9);
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Voxel");
                sn = _m3d_safestr(model->voxel[i].name, 0);
                if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                if(sn && sn[0])
                    ptr += sprintf(ptr, " %s", sn);
                M3D_FREE(sn); sn = NULL;
                ptr += sprintf(ptr, "\r\n");
                if(model->voxel[i].uncertain)
                    ptr += sprintf(ptr, "uncertain %d %d\r\n", (model->voxel[i].uncertain * 100) / 255, model->voxel[i].groupid);
                if(model->voxel[i].x || model->voxel[i].y || model->voxel[i].z)
                    ptr += sprintf(ptr, "pos %d %d %d\r\n", model->voxel[i].x, model->voxel[i].y, model->voxel[i].z);
                ptr += sprintf(ptr, "dim %d %d %d\r\n", model->voxel[i].w, model->voxel[i].h, model->voxel[i].d);
                for(j = n = 0; j < model->voxel[i].h; j++) {
                    ptr += sprintf(ptr, "layer\r\n");
                    for(k = 0; k < model->voxel[i].d; k++) {
                        for(l = 0; l < model->voxel[i].w; l++, n++) {
                            switch(model->voxel[i].data[n]) {
                                case M3D_VOXCLEAR: *ptr++ = '-'; break;
                                case M3D_VOXUNDEF: *ptr++ = '.'; break;
                                default: ptr += sprintf(ptr, "%d", model->voxel[i].data[n]); break;
                            }
                            *ptr++ = ' ';
                        }
                        ptr--;
                        ptr += sprintf(ptr, "\r\n");
                    }
                }
                ptr += sprintf(ptr, "\r\n");
            }
        }
        /* mathematical shapes face */
        if(model->numshape && model->numshape && !(flags & M3D_EXP_NOFACE)) {
            for(j = 0; j < model->numshape; j++) {
                sn = _m3d_safestr(model->shape[j].name, 0);
                if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)strlen(sn) + (uintptr_t)33);
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Shape %s\r\n", sn);
                M3D_FREE(sn); sn = NULL;
                if(model->shape[j].group != M3D_UNDEF && !(flags & M3D_EXP_NOBONE))
                    ptr += sprintf(ptr, "group %d\r\n", model->shape[j].group);
                for(i = 0; i < model->shape[j].numcmd; i++) {
                    cmd = &model->shape[j].cmd[i];
                    if(cmd->type >= (unsigned int)(sizeof(m3d_commandtypes)/sizeof(m3d_commandtypes[0])) || !cmd->arg)
                        continue;
                    cd = &m3d_commandtypes[cmd->type];
                    ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)strlen(cd->key) + (uintptr_t)3);
                    for(k = 0; k < cd->p; k++)
                        switch(cd->a[k]) {
                            case m3dcp_mi_t: if(cmd->arg[k] != M3D_NOTDEFINED) { len += (unsigned int)strlen(model->material[cmd->arg[k]].name) + 1; } break;
                            case m3dcp_va_t: len += cmd->arg[k] * (cd->p - k - 1) * 16; k = cd->p; break;
                            default: len += 16; break;
                        }
                    out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                    if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                    ptr += sprintf(ptr, "%s", cd->key);
                    for(k = n = 0, l = cd->p; k < l; k++) {
                        switch(cd->a[((k - n) % (cd->p - n)) + n]) {
                            case m3dcp_mi_t:
                                if(cmd->arg[k] != M3D_NOTDEFINED) {
                                    sn = _m3d_safestr(model->material[cmd->arg[k]].name, 0);
                                    if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                                    ptr += sprintf(ptr, " %s", sn);
                                    M3D_FREE(sn); sn = NULL;
                                }
                            break;
                            case m3dcp_vc_t: ptr += sprintf(ptr, " %g", *((float*)&cmd->arg[k])); break;
                            case m3dcp_va_t: ptr += sprintf(ptr, " %d[", cmd->arg[k]);
                                n = k + 1; l += (cmd->arg[k] - 1) * (cd->p - k - 1);
                            break;
                            default: ptr += sprintf(ptr, " %d", cmd->arg[k]); break;
                        }
                    }
                    ptr += sprintf(ptr, "%s\r\n", l > cd->p ? " ]" : "");
                }
                ptr += sprintf(ptr, "\r\n");
            }
        }
        /* annotation labels */
        if(model->numlabel && model->label && !(flags & M3D_EXP_NOFACE)) {
            for(i = 0, j = 3, length = NULL; i < model->numlabel; i++) {
                if(model->label[i].name) j += (unsigned int)strlen(model->label[i].name);
                if(model->label[i].lang) j += (unsigned int)strlen(model->label[i].lang);
                if(model->label[i].text) j += (unsigned int)strlen(model->label[i].text);
                j += 40;
            }
            ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)j);
            out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
            if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
            for(i = 0; i < model->numlabel; i++) {
                if(!i || _m3d_strcmp(sl, model->label[i].lang) || _m3d_strcmp(sn, model->label[i].name)) {
                    sl = model->label[i].lang;
                    sn = model->label[i].name;
                    sd = _m3d_safestr(sn, 0);
                    if(!sd) { setlocale(LC_NUMERIC, ol); sn = sl = NULL; goto memerr; }
                    if(i) ptr += sprintf(ptr, "\r\n");
                    ptr += sprintf(ptr, "Labels %s\r\n", sd);
                    M3D_FREE(sd); sd = NULL;
                    if(model->label[i].color)
                        ptr += sprintf(ptr, "color #0x%08x\r\n", model->label[i].color);
                    if(sl && *sl) {
                        sd = _m3d_safestr(sl, 0);
                        if(!sd) { setlocale(LC_NUMERIC, ol); sn = sl = NULL; goto memerr; }
                        ptr += sprintf(ptr, "lang %s\r\n", sd);
                        M3D_FREE(sd); sd = NULL;
                    }
                }
                sd = _m3d_safestr(model->label[i].text, 2);
                if(!sd) { setlocale(LC_NUMERIC, ol); sn = sl = NULL; goto memerr; }
                ptr += sprintf(ptr, "%d %s\r\n", model->label[i].vertexid, sd);
                M3D_FREE(sd); sd = NULL;
            }
            ptr += sprintf(ptr, "\r\n");
            sn = sl = NULL;
        }
        /* actions */
        if(model->numaction && model->action && !(flags & M3D_EXP_NOACTION)) {
            for(j = 0; j < model->numaction; j++) {
                a = &model->action[j];
                sn = _m3d_safestr(a->name, 0);
                if(!sn) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)strlen(sn) + (uintptr_t)48);
                for(i = 0; i < a->numframe; i++)
                    len += a->frame[i].numtransform * 128 + 8;
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Action %d %s\r\n", a->durationmsec, sn);
                M3D_FREE(sn); sn = NULL;
                for(i = 0; i < a->numframe; i++) {
                    ptr += sprintf(ptr, "frame %d\r\n", a->frame[i].msec);
                    for(k = 0; k < a->frame[i].numtransform; k++) {
                        ptr += sprintf(ptr, "%d %d %d\r\n", a->frame[i].transform[k].boneid,
                            vrtxidx[a->frame[i].transform[k].pos], vrtxidx[a->frame[i].transform[k].ori]);
                    }
                }
                ptr += sprintf(ptr, "\r\n");
            }
        }
        /* inlined assets */
        if(model->numinlined && model->inlined) {
            for(i = j = 0; i < model->numinlined; i++)
                if(model->inlined[i].name)
                    j += (unsigned int)strlen(model->inlined[i].name) + 6;
            if(j > 0) {
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)j + (uintptr_t)16);
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Assets\r\n");
                for(i = 0; i < model->numinlined; i++)
                    if(model->inlined[i].name)
                        ptr += sprintf(ptr, "%s%s\r\n", model->inlined[i].name, strrchr(model->inlined[i].name, '.') ? "" : ".png");
                ptr += sprintf(ptr, "\r\n");
            }
        }
        /* extra info */
        if(model->numextra && (flags & M3D_EXP_EXTRA)) {
            for(i = 0; i < model->numextra; i++) {
                if(model->extra[i]->length < 9) continue;
                ptr -= (uintptr_t)out; len = (unsigned int)((uintptr_t)ptr + (uintptr_t)17 + (uintptr_t)(model->extra[i]->length * 3));
                out = (unsigned char*)M3D_REALLOC(out, len); ptr += (uintptr_t)out;
                if(!out) { setlocale(LC_NUMERIC, ol); goto memerr; }
                ptr += sprintf(ptr, "Extra %c%c%c%c\r\n",
                    model->extra[i]->magic[0] > ' ' ? model->extra[i]->magic[0] : '_',
                    model->extra[i]->magic[1] > ' ' ? model->extra[i]->magic[1] : '_',
                    model->extra[i]->magic[2] > ' ' ? model->extra[i]->magic[2] : '_',
                    model->extra[i]->magic[3] > ' ' ? model->extra[i]->magic[3] : '_');
                for(j = 0; j < model->extra[i]->length; j++)
                    ptr += sprintf(ptr, "%02x ", *((unsigned char *)model->extra + sizeof(m3dchunk_t) + j));
                ptr--;
                ptr += sprintf(ptr, "\r\n\r\n");
            }
        }
        setlocale(LC_NUMERIC, ol);
        len = (unsigned int)((uintptr_t)ptr - (uintptr_t)out);
        out = (unsigned char*)M3D_REALLOC(out, len + 1);
        if(!out) goto memerr;
        out[len] = 0;
    } else
#endif
    {
        /* stricly only use LF (newline) in binary */
        sd = _m3d_safestr(model->desc, 3);
        if(!sd) goto memerr;
        /* header */
        h = (m3dhdr_t*)M3D_MALLOC(sizeof(m3dhdr_t) + strlen(sn) + strlen(sl) + strlen(sa) + strlen(sd) + 4);
        if(!h) goto memerr;
        memcpy((uint8_t*)h, "HEAD", 4);
        h->length = sizeof(m3dhdr_t);
        h->scale = scale;
        i = (unsigned int)strlen(sn); memcpy((uint8_t*)h + h->length, sn, i+1); h->length += i+1; M3D_FREE(sn);
        i = (unsigned int)strlen(sl); memcpy((uint8_t*)h + h->length, sl, i+1); h->length += i+1; M3D_FREE(sl);
        i = (unsigned int)strlen(sa); memcpy((uint8_t*)h + h->length, sa, i+1); h->length += i+1; M3D_FREE(sa);
        i = (unsigned int)strlen(sd); memcpy((uint8_t*)h + h->length, sd, i+1); h->length += i+1; M3D_FREE(sd);
        sn = sl = sa = sd = NULL;
        if(model->inlined)
            for(i = 0; i < model->numinlined; i++) {
                if(model->inlined[i].name && *model->inlined[i].name && model->inlined[i].length > 0) {
                    str = _m3d_addstr(str, &numstr, model->inlined[i].name);
                    if(!str) goto memerr;
                }
            }
        if(str)
            for(i = 0; i < numstr; i++) {
                h = _m3d_addhdr(h, &str[i]);
                if(!h) goto memerr;
            }
        vc_s = quality == M3D_EXP_INT8? 1 : (quality == M3D_EXP_INT16? 2 : (quality == M3D_EXP_DOUBLE? 8 : 4));
        vi_s = maxvrtx < 254 ? 1 : (maxvrtx < 65534 ? 2 : 4);
        si_s = h->length - 16 < 254 ? 1 : (h->length - 16 < 65534 ? 2 : 4);
        ci_s = !numcmap || !cmap ? 0 : (numcmap < 254 ? 1 : (numcmap < 65534 ? 2 : 4));
        ti_s = !maxtmap || !tmap ? 0 : (maxtmap < 254 ? 1 : (maxtmap < 65534 ? 2 : 4));
        bi_s = !model->numbone || !model->bone || (flags & M3D_EXP_NOBONE)? 0 : (model->numbone < 254 ? 1 :
            (model->numbone < 65534 ? 2 : 4));
        nb_s = maxbone < 2 ? 1 : (maxbone == 2 ? 2 : (maxbone <= 4 ? 4 : 8));
        sk_s = !bi_s || !maxskin || !skin ? 0 : (maxskin < 254 ? 1 : (maxskin < 65534 ? 2 : 4));
        fc_s = maxt < 254 ? 1 : (maxt < 65534 ? 2 : 4);
        hi_s = !model->numshape || !model->shape || (flags & M3D_EXP_NOFACE)? 0 : (model->numshape < 254 ? 1 :
            (model->numshape < 65534 ? 2 : 4));
        fi_s = !model->numface || !model->face || (flags & M3D_EXP_NOFACE)? 0 : (model->numface < 254 ? 1 :
            (model->numface < 65534 ? 2 : 4));
        vd_s = !model->numvoxel || !model->voxel || (flags & M3D_EXP_NOFACE)? 0 : (minvox >= -128 && maxvox <= 127 ? 1 :
            (minvox >= -32768 && maxvox <= 32767 ? 2 : 4));
        vp_s = !model->numvoxtype || !model->voxtype || (flags & M3D_EXP_NOFACE)? 0 : (model->numvoxtype < 254 ? 1 :
            (model->numvoxtype < 65534 ? 2 : 4));
        h->types =  (vc_s == 8 ? (3<<0) : (vc_s == 2 ? (1<<0) : (vc_s == 1 ? (0<<0) : (2<<0)))) |
                    (vi_s == 2 ? (1<<2) : (vi_s == 1 ? (0<<2) : (2<<2))) |
                    (si_s == 2 ? (1<<4) : (si_s == 1 ? (0<<4) : (2<<4))) |
                    (ci_s == 2 ? (1<<6) : (ci_s == 1 ? (0<<6) : (ci_s == 4 ? (2<<6) : (3<<6)))) |
                    (ti_s == 2 ? (1<<8) : (ti_s == 1 ? (0<<8) : (ti_s == 4 ? (2<<8) : (3<<8)))) |
                    (bi_s == 2 ? (1<<10): (bi_s == 1 ? (0<<10): (bi_s == 4 ? (2<<10) : (3<<10)))) |
                    (nb_s == 2 ? (1<<12): (nb_s == 1 ? (0<<12): (2<<12))) |
                    (sk_s == 2 ? (1<<14): (sk_s == 1 ? (0<<14): (sk_s == 4 ? (2<<14) : (3<<14)))) |
                    (fc_s == 2 ? (1<<16): (fc_s == 1 ? (0<<16): (2<<16))) |
                    (hi_s == 2 ? (1<<18): (hi_s == 1 ? (0<<18): (hi_s == 4 ? (2<<18) : (3<<18)))) |
                    (fi_s == 2 ? (1<<20): (fi_s == 1 ? (0<<20): (fi_s == 4 ? (2<<20) : (3<<20)))) |
                    (vd_s == 2 ? (1<<22): (vd_s == 1 ? (0<<22): (vd_s == 4 ? (2<<22) : (3<<22)))) |
                    (vp_s == 2 ? (1<<24): (vp_s == 1 ? (0<<24): (vp_s == 4 ? (2<<24) : (3<<24))));
        len = h->length;
        /* color map */
        if(numcmap && cmap && ci_s < 4 && !(flags & M3D_EXP_NOCMAP)) {
            chunklen = 8 + numcmap * sizeof(uint32_t);
            h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
            if(!h) goto memerr;
            memcpy((uint8_t*)h + len, "CMAP", 4);
            *((uint32_t*)((uint8_t*)h + len + 4)) = chunklen;
            memcpy((uint8_t*)h + len + 8, cmap, chunklen - 8);
            len += chunklen;
        } else numcmap = 0;
        /* texture map */
        if(numtmap && tmap && !(flags & M3D_EXP_NOTXTCRD) && !(flags & M3D_EXP_NOFACE)) {
            chunklen = 8 + maxtmap * vc_s * 2;
            h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
            if(!h) goto memerr;
            memcpy((uint8_t*)h + len, "TMAP", 4);
            length = (uint32_t*)((uint8_t*)h + len + 4);
            out = (uint8_t*)h + len + 8;
            last = M3D_UNDEF;
            for(i = 0; i < numtmap; i++) {
                if(tmap[i].newidx == last) continue;
                last = tmap[i].newidx;
                switch(vc_s) {
                    case 1: *out++ = (uint8_t)(tmap[i].data.u * 255); *out++ = (uint8_t)(tmap[i].data.v * 255); break;
                    case 2:
                        *((uint16_t*)out) = (uint16_t)(tmap[i].data.u * 65535); out += 2;
                        *((uint16_t*)out) = (uint16_t)(tmap[i].data.v * 65535); out += 2;
                    break;
                    case 4:  *((float*)out) = tmap[i].data.u; out += 4;  *((float*)out) = tmap[i].data.v; out += 4; break;
                    case 8: *((double*)out) = tmap[i].data.u; out += 8; *((double*)out) = tmap[i].data.v; out += 8; break;
                }
            }
            *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
            out = NULL;
            len += *length;
        }
        /* vertex */
        if(numvrtx && vrtx) {
            chunklen = 8 + maxvrtx * (ci_s + sk_s + 4 * vc_s);
            h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
            if(!h) goto memerr;
            memcpy((uint8_t*)h + len, "VRTS", 4);
            length = (uint32_t*)((uint8_t*)h + len + 4);
            out = (uint8_t*)h + len + 8;
            last = M3D_UNDEF;
            for(i = 0; i < numvrtx; i++) {
                if(vrtx[i].newidx == last) continue;
                last = vrtx[i].newidx;
                switch(vc_s) {
                    case 1:
                        *out++ = (int8_t)(vrtx[i].data.x * 127);
                        *out++ = (int8_t)(vrtx[i].data.y * 127);
                        *out++ = (int8_t)(vrtx[i].data.z * 127);
                        *out++ = (int8_t)(vrtx[i].data.w * 127);
                    break;
                    case 2:
                        *((int16_t*)out) = (int16_t)(vrtx[i].data.x * 32767); out += 2;
                        *((int16_t*)out) = (int16_t)(vrtx[i].data.y * 32767); out += 2;
                        *((int16_t*)out) = (int16_t)(vrtx[i].data.z * 32767); out += 2;
                        *((int16_t*)out) = (int16_t)(vrtx[i].data.w * 32767); out += 2;
                    break;
                    case 4:
                        *((float*)out) = vrtx[i].data.x; out += 4;
                        *((float*)out) = vrtx[i].data.y; out += 4;
                        *((float*)out) = vrtx[i].data.z; out += 4;
                        *((float*)out) = vrtx[i].data.w; out += 4;
                    break;
                    case 8:
                        *((double*)out) = vrtx[i].data.x; out += 8;
                        *((double*)out) = vrtx[i].data.y; out += 8;
                        *((double*)out) = vrtx[i].data.z; out += 8;
                        *((double*)out) = vrtx[i].data.w; out += 8;
                    break;
                }
                idx = _m3d_cmapidx(cmap, numcmap, vrtx[i].data.color);
                switch(ci_s) {
                    case 1: *out++ = (uint8_t)(idx); break;
                    case 2: *((uint16_t*)out) = (uint16_t)(idx); out += 2; break;
                    case 4: *((uint32_t*)out) = vrtx[i].data.color; out += 4; break;
                }
                out = _m3d_addidx(out, sk_s, vrtx[i].data.skinid);
            }
            *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
            out = NULL;
            len += *length;
        }
        /* bones chunk */
        if(model->numbone && model->bone && !(flags & M3D_EXP_NOBONE)) {
            i = 8 + bi_s + sk_s + model->numbone * (bi_s + si_s + 2*vi_s);
            chunklen = i + numskin * nb_s * (bi_s + 1);
            h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
            if(!h) goto memerr;
            memcpy((uint8_t*)h + len, "BONE", 4);
            length = (uint32_t*)((uint8_t*)h + len + 4);
            out = (uint8_t*)h + len + 8;
            out = _m3d_addidx(out, bi_s, model->numbone);
            out = _m3d_addidx(out, sk_s, maxskin);
            for(i = 0; i < model->numbone; i++) {
                out = _m3d_addidx(out, bi_s, model->bone[i].parent);
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->bone[i].name));
                out = _m3d_addidx(out, vi_s, vrtxidx[model->bone[i].pos]);
                out = _m3d_addidx(out, vi_s, vrtxidx[model->bone[i].ori]);
            }
            if(numskin && skin && sk_s) {
                last = M3D_UNDEF;
                for(i = 0; i < numskin; i++) {
                    if(skin[i].newidx == last) continue;
                    last = skin[i].newidx;
                    memset(&weights, 0, nb_s);
                    for(j = k = l = 0, mw = 0.0; j < (uint32_t)nb_s && skin[i].data.boneid[j] != M3D_UNDEF &&
                        skin[i].data.weight[j] > (M3D_FLOAT)0.0; j++) {
                            if(mw < skin[i].data.weight[j]) { mw = skin[i].data.weight[j]; k = j; }
                            weights[j] = (uint8_t)(skin[i].data.weight[j] * 255);
                            if(!weights[j]) { weights[j]++; l--; }
                        }
                    weights[k] += l;
                    switch(nb_s) {
                        case 1: weights[0] = 255; break;
                        case 2: memcpy(out, weights, 2); out += 2; break;
                        case 4: memcpy(out, weights, 4); out += 4; break;
                        case 8: memcpy(out, weights, 8); out += 8; break;
                    }
                    for(j = 0; j < (uint32_t)nb_s && skin[i].data.boneid[j] != M3D_UNDEF && weights[j]; j++) {
                        out = _m3d_addidx(out, bi_s, skin[i].data.boneid[j]);
                        *length += bi_s;
                    }
                }
            }
            *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
            out = NULL;
            len += *length;
        }
        /* materials */
        if(model->nummaterial && !(flags & M3D_EXP_NOMATERIAL)) {
            for(j = 0; j < model->nummaterial; j++) {
                if(mtrlidx[j] == M3D_UNDEF || !model->material[j].numprop || !model->material[j].prop) continue;
                m = &model->material[j];
                chunklen = 12 + si_s + m->numprop * 5;
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, "MTRL", 4);
                length = (uint32_t*)((uint8_t*)h + len + 4);
                out = (uint8_t*)h + len + 8;
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, m->name));
                for(i = 0; i < m->numprop; i++) {
                    if(m->prop[i].type >= 128) {
                        if(m->prop[i].value.textureid >= model->numtexture ||
                            !model->texture[m->prop[i].value.textureid].name) continue;
                        k = m3dpf_map;
                    } else {
                        for(k = 256, l = 0; l < sizeof(m3d_propertytypes)/sizeof(m3d_propertytypes[0]); l++)
                            if(m->prop[i].type == m3d_propertytypes[l].id) { k = m3d_propertytypes[l].format; break; }
                    }
                    if(k == 256) continue;
                    *out++ = m->prop[i].type;
                    switch(k) {
                        case m3dpf_color:
                            if(!(flags & M3D_EXP_NOCMAP)) {
                                idx = _m3d_cmapidx(cmap, numcmap, m->prop[i].value.color);
                                switch(ci_s) {
                                    case 1: *out++ = (uint8_t)(idx); break;
                                    case 2: *((uint16_t*)out) = (uint16_t)(idx); out += 2; break;
                                    case 4: *((uint32_t*)out) = (uint32_t)(m->prop[i].value.color); out += 4; break;
                                }
                            } else out--;
                        break;
                        case m3dpf_uint8:  *out++ = m->prop[i].value.num; break;
                        case m3dpf_uint16: *((uint16_t*)out) = m->prop[i].value.num; out += 2; break;
                        case m3dpf_uint32: *((uint32_t*)out) = m->prop[i].value.num; out += 4; break;
                        case m3dpf_float:  *((float*)out) = m->prop[i].value.fnum; out += 4; break;

                        case m3dpf_map:
                            idx = _m3d_stridx(str, numstr, model->texture[m->prop[i].value.textureid].name);
                            out = _m3d_addidx(out, si_s, idx);
                        break;
                    }
                }
                *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
                len += *length;
                out = NULL;
            }
        }
        /* procedural face */
        if(model->numinlined && model->inlined && !(flags & M3D_EXP_NOFACE)) {
            /* all inlined assets which are not textures should be procedural surfaces */
            for(j = 0; j < model->numinlined; j++) {
                if(!model->inlined[j].name || !model->inlined[j].name[0] || model->inlined[j].length < 4 ||
                    !model->inlined[j].data || (model->inlined[j].data[1] == 'P' && model->inlined[j].data[2] == 'N' &&
                    model->inlined[j].data[3] == 'G'))
                    continue;
                for(i = k = 0; i < model->numtexture; i++) {
                    if(!strcmp(model->inlined[j].name, model->texture[i].name)) { k = 1; break; }
                }
                if(k) continue;
                numproc++;
                chunklen = 8 + si_s;
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, "PROC", 4);
                *((uint32_t*)((uint8_t*)h + len + 4)) = chunklen;
                out = (uint8_t*)h + len + 8;
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->inlined[j].name));
                out = NULL;
                len += chunklen;
            }
        }
        /* mesh face */
        if(model->numface && face && !(flags & M3D_EXP_NOFACE)) {
            chunklen = 8 + si_s + model->numface * (9 * vi_s + 3 * ti_s + si_s + 1);
            h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
            if(!h) goto memerr;
            memcpy((uint8_t*)h + len, "MESH", 4);
            length = (uint32_t*)((uint8_t*)h + len + 4);
            out = (uint8_t*)h + len + 8;
            last = M3D_UNDEF;
#ifdef M3D_VERTEXMAX
            lastp = M3D_UNDEF;
#endif
            for(i = 0; i < model->numface; i++) {
                if(!(flags & M3D_EXP_NOMATERIAL) && face[i].data.materialid != last) {
                    last = face[i].data.materialid;
                    idx = last < model->nummaterial ? _m3d_stridx(str, numstr, model->material[last].name) : 0;
                    *out++ = 0;
                    out = _m3d_addidx(out, si_s, idx);
                }
#ifdef M3D_VERTEXMAX
                if(!(flags & M3D_EXP_NOVRTMAX) && face[i].data.paramid != lastp) {
                    lastp = face[i].data.paramid;
                    idx = lastp < model->numparam ? _m3d_stridx(str, numstr, model->param[lastp].name) : 0;
                    *out++ = 0;
                    out = _m3d_addidx(out, si_s, idx);
                }
#endif
                /* hardcoded triangles. */
                k = (3 << 4) |
                    (((flags & M3D_EXP_NOTXTCRD) || !ti_s || face[i].data.texcoord[0] == M3D_UNDEF ||
                    face[i].data.texcoord[1] == M3D_UNDEF || face[i].data.texcoord[2] == M3D_UNDEF) ? 0 : 1) |
                    (((flags & M3D_EXP_NONORMAL) || face[i].data.normal[0] == M3D_UNDEF ||
                    face[i].data.normal[1] == M3D_UNDEF || face[i].data.normal[2] == M3D_UNDEF) ? 0 : 2)
#ifdef M3D_VERTEXMAX
                    | (((flags & M3D_EXP_NOVRTMAX) || face[i].data.vertmax[0] == M3D_UNDEF ||
                    face[i].data.vertmax[1] == M3D_UNDEF || face[i].data.vertmax[2] == M3D_UNDEF) ? 0 : 4)
#endif
                    ;
                *out++ = k;
                for(j = 0; j < 3; j++) {
                    out = _m3d_addidx(out, vi_s, vrtxidx[face[i].data.vertex[j]]);
                    if(k & 1)
                        out = _m3d_addidx(out, ti_s, tmapidx[face[i].data.texcoord[j]]);
                    if(k & 2)
                        out = _m3d_addidx(out, vi_s, vrtxidx[face[i].data.normal[j]]);
#ifdef M3D_VERTEXMAX
                    if(k & 4)
                        out = _m3d_addidx(out, vi_s, vrtxidx[face[i].data.vertmax[j]]);
#endif
                }
            }
            *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
            len += *length;
            out = NULL;
        }
        /* voxel face */
        if(model->numvoxtype && model->voxtype && !(flags & M3D_EXP_NOFACE)) {
            chunklen = 8 + si_s + model->numvoxtype * (ci_s + si_s + 3 + sk_s);
            for(i = 0; i < model->numvoxtype; i++)
                chunklen += model->voxtype[i].numitem * (2 + si_s);
            h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
            if(!h) goto memerr;
            memcpy((uint8_t*)h + len, "VOXT", 4);
            length = (uint32_t*)((uint8_t*)h + len + 4);
            out = (uint8_t*)h + len + 8;
            for(i = 0; i < model->numvoxtype; i++) {
                if(!(flags & M3D_EXP_NOCMAP)) {
                    idx = _m3d_cmapidx(cmap, numcmap, model->voxtype[i].color);
                    switch(ci_s) {
                        case 1: *out++ = (uint8_t)(idx); break;
                        case 2: *((uint16_t*)out) = (uint16_t)(idx); out += 2; break;
                        case 4: *((uint32_t*)out) = (uint32_t)(model->voxtype[i].color); out += 4; break;
                    }
                }
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->voxtype[i].name));
                *out++ = (model->voxtype[i].rotation & 0xBF) | (((model->voxtype[i].voxshape >> 8) & 1) << 6);
                *out++ = model->voxtype[i].voxshape;
                *out++ = model->voxtype[i].numitem;
                if(!(flags & M3D_EXP_NOBONE) && model->numbone && maxskin)
                    out = _m3d_addidx(out, sk_s, skinidx[model->voxtype[i].skinid]);
                for(j = 0; j < model->voxtype[i].numitem; j++) {
                    out = _m3d_addidx(out, 2, model->voxtype[i].item[j].count);
                    out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->voxtype[i].item[j].name));
                }
            }
            *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
            len += *length;
            out = NULL;
        }
        if(model->numvoxel && model->voxel && !(flags & M3D_EXP_NOFACE)) {
            for(j = 0; j < model->numvoxel; j++) {
                chunklen = 8 + si_s + 6 * vd_s + 2 + model->voxel[j].w * model->voxel[j].h * model->voxel[j].d * 3;
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, "VOXD", 4);
                length = (uint32_t*)((uint8_t*)h + len + 4);
                out = (uint8_t*)h + len + 8;
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->voxel[j].name));
                out = _m3d_addidx(out, vd_s, model->voxel[j].x);
                out = _m3d_addidx(out, vd_s, model->voxel[j].y);
                out = _m3d_addidx(out, vd_s, model->voxel[j].z);
                out = _m3d_addidx(out, vd_s, model->voxel[j].w);
                out = _m3d_addidx(out, vd_s, model->voxel[j].h);
                out = _m3d_addidx(out, vd_s, model->voxel[j].d);
                *out++ = model->voxel[j].uncertain;
                *out++ = model->voxel[j].groupid;
                /* RLE compress voxel data */
                n = model->voxel[j].w * model->voxel[j].h * model->voxel[j].d;
                k = o = 0; out[o++] = 0;
                for(i = 0; i < n; i++) {
                    for(l = 1; l < 128 && i + l < n && model->voxel[j].data[i] == model->voxel[j].data[i + l]; l++);
                    if(l > 1) {
                        l--;
                        if(out[k]) { out[k]--; out[o++] = 0x80 | l; }
                        else out[k] = 0x80 | l;
                        switch(vp_s) {
                            case 1: out[o++] = model->voxel[j].data[i]; break;
                            default: *((uint16_t*)(out + o)) = model->voxel[j].data[i]; o += 2; break;
                        }
                        k = o; out[o++] = 0;
                        i += l;
                        continue;
                    }
                    out[k]++;
                    switch(vp_s) {
                        case 1: out[o++] = model->voxel[j].data[i]; break;
                        default: *((uint16_t*)(out + o)) = model->voxel[j].data[i]; o += 2; break;
                    }
                    if(out[k] > 127) { out[k]--; k = o; out[o++] = 0; }
                }
                if(!(out[k] & 0x80)) { if(out[k]) out[k]--; else o--; }
                *length = (uint32_t)((uintptr_t)out + (uintptr_t)o - (uintptr_t)((uint8_t*)h + len));
                len += *length;
                out = NULL;
            }
        }
        /* mathematical shapes face */
        if(model->numshape && model->shape && !(flags & M3D_EXP_NOFACE)) {
            for(j = 0; j < model->numshape; j++) {
                chunklen = 12 + si_s + model->shape[j].numcmd * (M3D_CMDMAXARG + 1) * 4;
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, "SHPE", 4);
                length = (uint32_t*)((uint8_t*)h + len + 4);
                out = (uint8_t*)h + len + 8;
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->shape[j].name));
                out = _m3d_addidx(out, bi_s, model->shape[j].group);
                for(i = 0; i < model->shape[j].numcmd; i++) {
                    cmd = &model->shape[j].cmd[i];
                    if(cmd->type >= (unsigned int)(sizeof(m3d_commandtypes)/sizeof(m3d_commandtypes[0])) || !cmd->arg)
                        continue;
                    cd = &m3d_commandtypes[cmd->type];
                    *out++ = (cmd->type & 0x7F) | (cmd->type > 127 ? 0x80 : 0);
                    if(cmd->type > 127) *out++ = (cmd->type >> 7) & 0xff;
                    for(k = n = 0, l = cd->p; k < l; k++) {
                        switch(cd->a[((k - n) % (cd->p - n)) + n]) {
                            case m3dcp_mi_t:
                                out = _m3d_addidx(out, si_s, cmd->arg[k] < model->nummaterial ?
                                    _m3d_stridx(str, numstr, model->material[cmd->arg[k]].name) : 0);
                            break;
                            case m3dcp_vc_t:
                                min_x = *((float*)&cmd->arg[k]);
                                switch(vc_s) {
                                    case 1: *out++ = (int8_t)(min_x * 127); break;
                                    case 2: *((int16_t*)out) = (int16_t)(min_x * 32767); out += 2; break;
                                    case 4: *((float*)out) = min_x; out += 4; break;
                                    case 8: *((double*)out) = min_x; out += 8; break;
                                }
                            break;
                            case m3dcp_hi_t: out = _m3d_addidx(out, hi_s, cmd->arg[k]); break;
                            case m3dcp_fi_t: out = _m3d_addidx(out, fi_s, cmd->arg[k]); break;
                            case m3dcp_ti_t: out = _m3d_addidx(out, ti_s, cmd->arg[k]); break;
                            case m3dcp_qi_t:
                            case m3dcp_vi_t: out = _m3d_addidx(out, vi_s, cmd->arg[k]); break;
                            case m3dcp_i1_t: out = _m3d_addidx(out, 1, cmd->arg[k]); break;
                            case m3dcp_i2_t: out = _m3d_addidx(out, 2, cmd->arg[k]); break;
                            case m3dcp_i4_t: out = _m3d_addidx(out, 4, cmd->arg[k]); break;
                            case m3dcp_va_t: out = _m3d_addidx(out, 4, cmd->arg[k]);
                                n = k + 1; l += (cmd->arg[k] - 1) * (cd->p - k - 1);
                            break;
                        }
                    }
                }
                *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
                len += *length;
                out = NULL;
            }
        }
        /* annotation labels */
        if(model->numlabel && model->label) {
            for(i = 0, length = NULL; i < model->numlabel; i++) {
                if(!i || _m3d_strcmp(sl, model->label[i].lang) || _m3d_strcmp(sn, model->label[i].name)) {
                    sl = model->label[i].lang;
                    sn = model->label[i].name;
                    if(length) {
                        *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
                        len += *length;
                    }
                    chunklen = 8 + 2 * si_s + ci_s + model->numlabel * (vi_s + si_s);
                    h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                    if(!h) { sn = NULL; sl = NULL; goto memerr; }
                    memcpy((uint8_t*)h + len, "LBLS", 4);
                    length = (uint32_t*)((uint8_t*)h + len + 4);
                    out = (uint8_t*)h + len + 8;
                    out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->label[l].name));
                    out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->label[l].lang));
                    idx = _m3d_cmapidx(cmap, numcmap, model->label[i].color);
                    switch(ci_s) {
                        case 1: *out++ = (uint8_t)(idx); break;
                        case 2: *((uint16_t*)out) = (uint16_t)(idx); out += 2; break;
                        case 4: *((uint32_t*)out) = model->label[i].color; out += 4; break;
                    }
                }
                out = _m3d_addidx(out, vi_s, vrtxidx[model->label[i].vertexid]);
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->label[l].text));
            }
            if(length) {
                *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
                len += *length;
            }
            out = NULL;
            sn = sl = NULL;
        }
        /* actions */
        if(model->numaction && model->action && model->numbone && model->bone && !(flags & M3D_EXP_NOACTION)) {
            for(j = 0; j < model->numaction; j++) {
                a = &model->action[j];
                chunklen = 14 + si_s + a->numframe * (4 + fc_s + maxt * (bi_s + 2 * vi_s));
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, "ACTN", 4);
                length = (uint32_t*)((uint8_t*)h + len + 4);
                out = (uint8_t*)h + len + 8;
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, a->name));
                *((uint16_t*)out) = (uint16_t)(a->numframe); out += 2;
                *((uint32_t*)out) = (uint32_t)(a->durationmsec); out += 4;
                for(i = 0; i < a->numframe; i++) {
                    *((uint32_t*)out) = (uint32_t)(a->frame[i].msec); out += 4;
                    out = _m3d_addidx(out, fc_s, a->frame[i].numtransform);
                    for(k = 0; k < a->frame[i].numtransform; k++) {
                        out = _m3d_addidx(out, bi_s, a->frame[i].transform[k].boneid);
                        out = _m3d_addidx(out, vi_s, vrtxidx[a->frame[i].transform[k].pos]);
                        out = _m3d_addidx(out, vi_s, vrtxidx[a->frame[i].transform[k].ori]);
                    }
                }
                *length = (uint32_t)((uintptr_t)out - (uintptr_t)((uint8_t*)h + len));
                len += *length;
                out = NULL;
            }
        }
        /* inlined assets */
        if(model->numinlined && model->inlined && (numproc || (flags & M3D_EXP_INLINE))) {
            for(j = 0; j < model->numinlined; j++) {
                if(!model->inlined[j].name || !model->inlined[j].name[0] || model->inlined[j].length<4 || !model->inlined[j].data)
                    continue;
                if(!(flags & M3D_EXP_INLINE)) {
                    if(model->inlined[j].data[1] == 'P' && model->inlined[j].data[2] == 'N' && model->inlined[j].data[3] == 'G')
                        continue;
                    for(i = k = 0; i < model->numtexture; i++) {
                        if(!strcmp(model->inlined[j].name, model->texture[i].name)) { k = 1; break; }
                    }
                    if(k) continue;
                }
                chunklen = 8 + si_s + model->inlined[j].length;
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, "ASET", 4);
                *((uint32_t*)((uint8_t*)h + len + 4)) = chunklen;
                out = (uint8_t*)h + len + 8;
                out = _m3d_addidx(out, si_s, _m3d_stridx(str, numstr, model->inlined[j].name));
                memcpy(out, model->inlined[j].data, model->inlined[j].length);
                out = NULL;
                len += chunklen;
            }
        }
        /* extra chunks */
        if(model->numextra && model->extra && (flags & M3D_EXP_EXTRA)) {
            for(j = 0; j < model->numextra; j++) {
                if(!model->extra[j] || model->extra[j]->length < 8)
                    continue;
                chunklen = model->extra[j]->length;
                h = (m3dhdr_t*)M3D_REALLOC(h, len + chunklen);
                if(!h) goto memerr;
                memcpy((uint8_t*)h + len, model->extra[j], chunklen);
                len += chunklen;
            }
        }
        /* add end chunk */
        h = (m3dhdr_t*)M3D_REALLOC(h, len + 4);
        if(!h) goto memerr;
        memcpy((uint8_t*)h + len, "OMD3", 4);
        len += 4;
        /* zlib compress */
        if(!(flags & M3D_EXP_NOZLIB)) {
            M3D_LOG("Deflating chunks");
            z = stbi_zlib_compress((unsigned char *)h, len, (int*)&l, 9);
            if(z && l > 0 && l < len) { len = l; M3D_FREE(h); h = (m3dhdr_t*)z; }
        }
        /* add file header at the begining */
        len += 8;
        out = (unsigned char*)M3D_MALLOC(len);
        if(!out) goto memerr;
        memcpy(out, "3DMO", 4);
        *((uint32_t*)(out + 4)) = len;
        /* preview image chunk, must be the first if exists */
        if(model->preview.data && model->preview.length) {
            chunklen = 8 + model->preview.length;
            out = (unsigned char*)M3D_REALLOC(out, len + chunklen);
            if(!out) goto memerr;
            memcpy((uint8_t*)out + 8, "PRVW", 4);
            *((uint32_t*)((uint8_t*)out + 8 + 4)) = chunklen;
            memcpy((uint8_t*)out + 8 + 8, model->preview.data, model->preview.length);
            *((uint32_t*)(out + 4)) += chunklen;
        } else
            chunklen = 0;
        memcpy(out + 8 + chunklen, h, len - 8);
    }
    if(size) *size = out ? len : 0;
    if(vrtxidx) M3D_FREE(vrtxidx);
    if(mtrlidx) M3D_FREE(mtrlidx);
    if(tmapidx) M3D_FREE(tmapidx);
    if(skinidx) M3D_FREE(skinidx);
    if(norm) M3D_FREE(norm);
    if(face) M3D_FREE(face);
    if(cmap) M3D_FREE(cmap);
    if(tmap) M3D_FREE(tmap);
    if(skin) M3D_FREE(skin);
    if(str) M3D_FREE(str);
    if(vrtx) M3D_FREE(vrtx);
    if(opa) M3D_FREE(opa);
    if(h) M3D_FREE(h);
    return out;
}
#endif

#endif

#ifdef  __cplusplus
}
#ifdef M3D_CPPWRAPPER
#include <vector>
#include <string>
#include <memory>

/*** C++ wrapper class ***/
namespace M3D {
#ifdef M3D_IMPLEMENTATION

    class Model {
        public:
            m3d_t *model;

        public:
            Model() {
                this->model = (m3d_t*)M3D_MALLOC(sizeof(m3d_t)); memset(this->model, 0, sizeof(m3d_t));
            }
            Model(_unused const std::string &data, _unused m3dread_t ReadFileCB,
                _unused m3dfree_t FreeCB, _unused M3D::Model mtllib) {
#ifndef M3D_NOIMPORTER
                this->model = m3d_load((unsigned char *)data.data(), ReadFileCB, FreeCB, mtllib.model);
#else
                Model();
#endif
            }
            Model(_unused const std::vector<unsigned char> data, _unused m3dread_t ReadFileCB,
                _unused m3dfree_t FreeCB, _unused M3D::Model mtllib) {
#ifndef M3D_NOIMPORTER
                this->model = m3d_load((unsigned char *)&data[0], ReadFileCB, FreeCB, mtllib.model);
#else
                Model();
#endif
            }
            Model(_unused const unsigned char *data, _unused m3dread_t ReadFileCB,
                _unused m3dfree_t FreeCB, _unused M3D::Model mtllib) {
#ifndef M3D_NOIMPORTER
                this->model = m3d_load((unsigned char*)data, ReadFileCB, FreeCB, mtllib.model);
#else
                Model();
#endif
            }
            ~Model() { m3d_free(this->model); }

        public:
            m3d_t *getCStruct() { return this->model; }
            std::string getName() { return std::string(this->model->name); }
            void setName(std::string name) { this->model->name = (char*)name.c_str(); }
            std::string getLicense() { return std::string(this->model->license); }
            void setLicense(std::string license) { this->model->license = (char*)license.c_str(); }
            std::string getAuthor() { return std::string(this->model->author); }
            void setAuthor(std::string author) { this->model->author = (char*)author.c_str(); }
            std::string getDescription() { return std::string(this->model->desc); }
            void setDescription(std::string desc) { this->model->desc = (char*)desc.c_str(); }
            float getScale() { return this->model->scale; }
            void setScale(float scale) { this->model->scale = scale; }
            std::vector<unsigned char> getPreview() { return this->model->preview.data ?
                std::vector<unsigned char>(this->model->preview.data, this->model->preview.data + this->model->preview.length) :
                std::vector<unsigned char>(); }
            std::vector<uint32_t> getColorMap() { return this->model->cmap ? std::vector<uint32_t>(this->model->cmap,
                this->model->cmap + this->model->numcmap) : std::vector<uint32_t>(); }
            std::vector<m3dti_t> getTextureMap() { return this->model->tmap ? std::vector<m3dti_t>(this->model->tmap,
                this->model->tmap + this->model->numtmap) : std::vector<m3dti_t>(); }
            std::vector<m3dtx_t> getTextures() { return this->model->texture ? std::vector<m3dtx_t>(this->model->texture,
                this->model->texture + this->model->numtexture) : std::vector<m3dtx_t>(); }
            std::string getTextureName(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numtexture ?
                std::string(this->model->texture[idx].name) : nullptr; }
            std::vector<m3db_t> getBones() { return this->model->bone ? std::vector<m3db_t>(this->model->bone, this->model->bone +
                this->model->numbone) : std::vector<m3db_t>(); }
            std::string getBoneName(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numbone ?
                std::string(this->model->bone[idx].name) : nullptr; }
            std::vector<m3dm_t> getMaterials() { return this->model->material ? std::vector<m3dm_t>(this->model->material,
                this->model->material + this->model->nummaterial) : std::vector<m3dm_t>(); }
            std::string getMaterialName(int idx) { return idx >= 0 && (unsigned int)idx < this->model->nummaterial ?
                std::string(this->model->material[idx].name) : nullptr; }
            int getMaterialPropertyInt(int idx, int type) {
                    if (idx < 0 || (unsigned int)idx >= this->model->nummaterial || type < 0 || type >= 127 ||
                        !this->model->material[idx].prop) return -1;
                    for (int i = 0; i < this->model->material[idx].numprop; i++) {
                        if (this->model->material[idx].prop[i].type == type)
                            return this->model->material[idx].prop[i].value.num;
                    }
                    return -1;
                }
            uint32_t getMaterialPropertyColor(int idx, int type) { return this->getMaterialPropertyInt(idx, type); }
            float getMaterialPropertyFloat(int idx, int type) {
                    if (idx < 0 || (unsigned int)idx >= this->model->nummaterial || type < 0 || type >= 127 ||
                        !this->model->material[idx].prop) return -1.0f;
                    for (int i = 0; i < this->model->material[idx].numprop; i++) {
                        if (this->model->material[idx].prop[i].type == type)
                            return this->model->material[idx].prop[i].value.fnum;
                    }
                    return -1.0f;
                }
            m3dtx_t* getMaterialPropertyMap(int idx, int type) {
                    if (idx < 0 || (unsigned int)idx >= this->model->nummaterial || type < 128 || type > 255 ||
                        !this->model->material[idx].prop) return nullptr;
                    for (int i = 0; i < this->model->material[idx].numprop; i++) {
                        if (this->model->material[idx].prop[i].type == type)
                            return this->model->material[idx].prop[i].value.textureid < this->model->numtexture ?
                                &this->model->texture[this->model->material[idx].prop[i].value.textureid] : nullptr;
                    }
                    return nullptr;
                }
            std::vector<m3dv_t> getVertices() { return this->model->vertex ? std::vector<m3dv_t>(this->model->vertex,
                this->model->vertex + this->model->numvertex) : std::vector<m3dv_t>(); }
            std::vector<m3df_t> getFace() { return this->model->face ? std::vector<m3df_t>(this->model->face, this->model->face +
                this->model->numface) : std::vector<m3df_t>(); }
            std::vector<m3dvt_t> getVoxelTypes() { return this->model->voxtype ? std::vector<m3dvt_t>(this->model->voxtype,
                this->model->voxtype + this->model->numvoxtype) : std::vector<m3dvt_t>(); }
            std::string getVoxelTypeName(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numvoxtype &&
                this->model->voxtype[idx].name && this->model->voxtype[idx].name[0] ?
                std::string(this->model->voxtype[idx].name) : nullptr; }
            std::vector<m3dvi_t> getVoxelTypeItems(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numvoxtype &&
                this->model->voxtype[idx].item ? std::vector<m3dvi_t>(this->model->voxtype[idx].item,
                this->model->voxtype[idx].item + this->model->voxtype[idx].numitem) : std::vector<m3dvi_t>(); }
            std::vector<m3dvx_t> getVoxelBlocks() { return this->model->voxel ? std::vector<m3dvx_t>(this->model->voxel,
                this->model->voxel + this->model->numvoxel) : std::vector<m3dvx_t>(); }
            std::string getVoxelBlockName(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numvoxel &&
                this->model->voxel[idx].name && this->model->voxel[idx].name[0] ?
                std::string(this->model->voxel[idx].name) : nullptr; }
            std::vector<M3D_VOXEL> getVoxelBlockData(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numvoxel &&
                this->model->voxel[idx].data ? std::vector<M3D_VOXEL>(this->model->voxel[idx].data,
                this->model->voxel[idx].data + this->model->voxel[idx].w*this->model->voxel[idx].h*this->model->voxel[idx].d) :
                std::vector<M3D_VOXEL>(); }
            std::vector<m3dh_t> getShape() { return this->model->shape ? std::vector<m3dh_t>(this->model->shape,
                this->model->shape + this->model->numshape) : std::vector<m3dh_t>(); }
            std::string getShapeName(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numshape &&
                this->model->shape[idx].name && this->model->shape[idx].name[0] ?
                std::string(this->model->shape[idx].name) : nullptr; }
            unsigned int getShapeGroup(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numshape ?
                this->model->shape[idx].group : 0xFFFFFFFF; }
            std::vector<m3dc_t> getShapeCommands(int idx) { return idx >= 0 && (unsigned int)idx < this->model->numshape &&
                this->model->shape[idx].cmd ? std::vector<m3dc_t>(this->model->shape[idx].cmd, this->model->shape[idx].cmd +
                this->model->shape[idx].numcmd) : std::vector<m3dc_t>(); }
            std::vector<m3dl_t> getAnnotationLabels() { return this->model->label ? std::vector<m3dl_t>(this->model->label,
                this->model->label + this->model->numlabel) : std::vector<m3dl_t>(); }
            std::vector<m3ds_t> getSkin() { return this->model->skin ? std::vector<m3ds_t>(this->model->skin, this->model->skin +
                this->model->numskin) : std::vector<m3ds_t>(); }
            std::vector<m3da_t> getActions() { return this->model->action ? std::vector<m3da_t>(this->model->action,
                this->model->action + this->model->numaction) : std::vector<m3da_t>(); }
            std::string getActionName(int aidx) { return aidx >= 0 && (unsigned int)aidx < this->model->numaction ?
                std::string(this->model->action[aidx].name) : nullptr; }
            unsigned int getActionDuration(int aidx) { return aidx >= 0 && (unsigned int)aidx < this->model->numaction ?
                this->model->action[aidx].durationmsec : 0; }
            std::vector<m3dfr_t> getActionFrames(int aidx) { return aidx >= 0 && (unsigned int)aidx < this->model->numaction ?
                std::vector<m3dfr_t>(this->model->action[aidx].frame, this->model->action[aidx].frame +
                this->model->action[aidx].numframe) : std::vector<m3dfr_t>(); }
            unsigned int getActionFrameTimestamp(int aidx, int fidx) { return aidx >= 0 && (unsigned int)aidx < this->model->numaction?
                    (fidx >= 0 && (unsigned int)fidx < this->model->action[aidx].numframe ?
                    this->model->action[aidx].frame[fidx].msec : 0) : 0; }
            std::vector<m3dtr_t> getActionFrameTransforms(int aidx, int fidx) {
                return aidx >= 0 && (unsigned int)aidx < this->model->numaction ? (
                    fidx >= 0 && (unsigned int)fidx < this->model->action[aidx].numframe ?
                    std::vector<m3dtr_t>(this->model->action[aidx].frame[fidx].transform,
                    this->model->action[aidx].frame[fidx].transform + this->model->action[aidx].frame[fidx].numtransform) :
                    std::vector<m3dtr_t>()) : std::vector<m3dtr_t>(); }
            std::vector<m3dtr_t> getActionFrame(int aidx, int fidx, std::vector<m3dtr_t> skeleton) {
                m3dtr_t *pose = m3d_frame(this->model, (unsigned int)aidx, (unsigned int)fidx,
                    skeleton.size() ? &skeleton[0] : nullptr);
                return std::vector<m3dtr_t>(pose, pose + this->model->numbone); }
            std::vector<m3db_t> getActionPose(int aidx, unsigned int msec) {
                m3db_t *pose = m3d_pose(this->model, (unsigned int)aidx, (unsigned int)msec);
                return std::vector<m3db_t>(pose, pose + this->model->numbone); }
            std::vector<m3di_t> getInlinedAssets() { return this->model->inlined ? std::vector<m3di_t>(this->model->inlined,
                this->model->inlined + this->model->numinlined) : std::vector<m3di_t>(); }
            std::vector<std::unique_ptr<m3dchunk_t>> getExtras() { return this->model->extra ?
                std::vector<std::unique_ptr<m3dchunk_t>>(this->model->extra,
                this->model->extra + this->model->numextra) : std::vector<std::unique_ptr<m3dchunk_t>>(); }
            std::vector<unsigned char> Save(_unused int quality, _unused int flags) {
#ifdef M3D_EXPORTER
                unsigned int size;
                unsigned char *ptr = m3d_save(this->model, quality, flags, &size);
                return ptr && size ? std::vector<unsigned char>(ptr, ptr + size) : std::vector<unsigned char>();
#else
                return std::vector<unsigned char>();
#endif
            }
    };

#else
    class Model {
        private:
            m3d_t *model;

        public:
            Model(const std::string &data, m3dread_t ReadFileCB, m3dfree_t FreeCB);
            Model(const std::vector<unsigned char> data, m3dread_t ReadFileCB, m3dfree_t FreeCB);
            Model(const unsigned char *data, m3dread_t ReadFileCB, m3dfree_t FreeCB);
            Model();
            ~Model();

        public:
            m3d_t *getCStruct();
            std::string getName();
            void setName(std::string name);
            std::string getLicense();
            void setLicense(std::string license);
            std::string getAuthor();
            void setAuthor(std::string author);
            std::string getDescription();
            void setDescription(std::string desc);
            float getScale();
            void setScale(float scale);
            std::vector<unsigned char> getPreview();
            std::vector<uint32_t> getColorMap();
            std::vector<m3dti_t> getTextureMap();
            std::vector<m3dtx_t> getTextures();
            std::string getTextureName(int idx);
            std::vector<m3db_t> getBones();
            std::string getBoneName(int idx);
            std::vector<m3dm_t> getMaterials();
            std::string getMaterialName(int idx);
            int getMaterialPropertyInt(int idx, int type);
            uint32_t getMaterialPropertyColor(int idx, int type);
            float getMaterialPropertyFloat(int idx, int type);
            m3dtx_t* getMaterialPropertyMap(int idx, int type);
            std::vector<m3dv_t> getVertices();
            std::vector<m3df_t> getFace();
            std::vector<m3dvt_t> getVoxelTypes();
            std::string getVoxelTypeName(int idx);
            std::vector<m3dvi_t> getVoxelTypeItems(int idx);
            std::vector<m3dvx_t> getVoxelBlocks();
            std::string getVoxelBlockName(int idx);
            std::vector<M3D_VOXEL> getVoxelBlockData(int idx);
            std::vector<m3dh_t> getShape();
            std::string getShapeName(int idx);
            unsigned int getShapeGroup(int idx);
            std::vector<m3dc_t> getShapeCommands(int idx);
            std::vector<m3dl_t> getAnnotationLabels();
            std::vector<m3ds_t> getSkin();
            std::vector<m3da_t> getActions();
            std::string getActionName(int aidx);
            unsigned int getActionDuration(int aidx);
            std::vector<m3dfr_t> getActionFrames(int aidx);
            unsigned int getActionFrameTimestamp(int aidx, int fidx);
            std::vector<m3dtr_t> getActionFrameTransforms(int aidx, int fidx);
            std::vector<m3dtr_t> getActionFrame(int aidx, int fidx, std::vector<m3dtr_t> skeleton);
            std::vector<m3db_t> getActionPose(int aidx, unsigned int msec);
            std::vector<m3di_t> getInlinedAssets();
            std::vector<std::unique_ptr<m3dchunk_t>> getExtras();
            std::vector<unsigned char> Save(int quality, int flags);
    };

#endif /* impl */
}
#endif

#endif /* __cplusplus */

#endif
//FILE_END
//FILE_START:deps/cgltf.h
/**
 * cgltf - a single-file glTF 2.0 parser written in C99.
 *
 * Version: 1.15
 *
 * Website: https://github.com/jkuhlmann/cgltf
 *
 * Distributed under the MIT License, see notice at the end of this file.
 *
 * Building:
 * Include this file where you need the struct and function
 * declarations. Have exactly one source file where you define
 * `CGLTF_IMPLEMENTATION` before including this file to get the
 * function definitions.
 *
 * Reference:
 * `cgltf_result cgltf_parse(const cgltf_options*, const void*,
 * cgltf_size, cgltf_data**)` parses both glTF and GLB data. If
 * this function returns `cgltf_result_success`, you have to call
 * `cgltf_free()` on the created `cgltf_data*` variable.
 * Note that contents of external files for buffers and images are not
 * automatically loaded. You'll need to read these files yourself using
 * URIs in the `cgltf_data` structure.
 *
 * `cgltf_options` is the struct passed to `cgltf_parse()` to control
 * parts of the parsing process. You can use it to force the file type
 * and provide memory allocation as well as file operation callbacks.
 * Should be zero-initialized to trigger default behavior.
 *
 * `cgltf_data` is the struct allocated and filled by `cgltf_parse()`.
 * It generally mirrors the glTF format as described by the spec (see
 * https://github.com/KhronosGroup/glTF/tree/master/specification/2.0).
 *
 * `void cgltf_free(cgltf_data*)` frees the allocated `cgltf_data`
 * variable.
 *
 * `cgltf_result cgltf_load_buffers(const cgltf_options*, cgltf_data*,
 * const char* gltf_path)` can be optionally called to open and read buffer
 * files using the `FILE*` APIs. The `gltf_path` argument is the path to
 * the original glTF file, which allows the parser to resolve the path to
 * buffer files.
 *
 * `cgltf_result cgltf_load_buffer_base64(const cgltf_options* options,
 * cgltf_size size, const char* base64, void** out_data)` decodes
 * base64-encoded data content. Used internally by `cgltf_load_buffers()`.
 * This is useful when decoding data URIs in images.
 *
 * `cgltf_result cgltf_parse_file(const cgltf_options* options, const
 * char* path, cgltf_data** out_data)` can be used to open the given
 * file using `FILE*` APIs and parse the data using `cgltf_parse()`.
 *
 * `cgltf_result cgltf_validate(cgltf_data*)` can be used to do additional
 * checks to make sure the parsed glTF data is valid.
 *
 * `cgltf_node_transform_local` converts the translation / rotation / scale properties of a node
 * into a mat4.
 *
 * `cgltf_node_transform_world` calls `cgltf_node_transform_local` on every ancestor in order
 * to compute the root-to-node transformation.
 *
 * `cgltf_accessor_unpack_floats` reads in the data from an accessor, applies sparse data (if any),
 * and converts them to floating point. Assumes that `cgltf_load_buffers` has already been called.
 * By passing null for the output pointer, users can find out how many floats are required in the
 * output buffer.
 *
 * `cgltf_accessor_unpack_indices` reads in the index data from an accessor. Assumes that
 * `cgltf_load_buffers` has already been called. By passing null for the output pointer, users can
 * find out how many indices are required in the output buffer. Returns 0 if the accessor is
 * sparse or if the output component size is less than the accessor's component size.
 *
 * `cgltf_num_components` is a tiny utility that tells you the dimensionality of
 * a certain accessor type. This can be used before `cgltf_accessor_unpack_floats` to help allocate
 * the necessary amount of memory. `cgltf_component_size` and `cgltf_calc_size` exist for
 * similar purposes.
 *
 * `cgltf_accessor_read_float` reads a certain element from a non-sparse accessor and converts it to
 * floating point, assuming that `cgltf_load_buffers` has already been called. The passed-in element
 * size is the number of floats in the output buffer, which should be in the range [1, 16]. Returns
 * false if the passed-in element_size is too small, or if the accessor is sparse.
 *
 * `cgltf_accessor_read_uint` is similar to its floating-point counterpart, but limited to reading
 * vector types and does not support matrix types. The passed-in element size is the number of uints
 * in the output buffer, which should be in the range [1, 4]. Returns false if the passed-in
 * element_size is too small, or if the accessor is sparse.
 *
 * `cgltf_accessor_read_index` is similar to its floating-point counterpart, but it returns size_t
 * and only works with single-component data types.
 *
 * `cgltf_copy_extras_json` allows users to retrieve the "extras" data that can be attached to many
 * glTF objects (which can be arbitrary JSON data). This is a legacy function, consider using
 * cgltf_extras::data directly instead. You can parse this data using your own JSON parser
 * or, if you've included the cgltf implementation using the integrated JSMN JSON parser.
 */
#ifndef CGLTF_H_INCLUDED__
#define CGLTF_H_INCLUDED__

#include <stddef.h>
#include <stdint.h> /* For uint8_t, uint32_t */

#ifdef __cplusplus
extern "C" {
#endif

typedef size_t cgltf_size;
typedef long long int cgltf_ssize;
typedef float cgltf_float;
typedef int cgltf_int;
typedef unsigned int cgltf_uint;
typedef int cgltf_bool;

typedef enum cgltf_file_type
{
	cgltf_file_type_invalid,
	cgltf_file_type_gltf,
	cgltf_file_type_glb,
	cgltf_file_type_max_enum
} cgltf_file_type;

typedef enum cgltf_result
{
	cgltf_result_success,
	cgltf_result_data_too_short,
	cgltf_result_unknown_format,
	cgltf_result_invalid_json,
	cgltf_result_invalid_gltf,
	cgltf_result_invalid_options,
	cgltf_result_file_not_found,
	cgltf_result_io_error,
	cgltf_result_out_of_memory,
	cgltf_result_legacy_gltf,
    cgltf_result_max_enum
} cgltf_result;

typedef struct cgltf_memory_options
{
	void* (*alloc_func)(void* user, cgltf_size size);
	void (*free_func) (void* user, void* ptr);
	void* user_data;
} cgltf_memory_options;

typedef struct cgltf_file_options
{
	cgltf_result(*read)(const struct cgltf_memory_options* memory_options, const struct cgltf_file_options* file_options, const char* path, cgltf_size* size, void** data);
	void (*release)(const struct cgltf_memory_options* memory_options, const struct cgltf_file_options* file_options, void* data);
	void* user_data;
} cgltf_file_options;

typedef struct cgltf_options
{
	cgltf_file_type type; /* invalid == auto detect */
	cgltf_size json_token_count; /* 0 == auto */
	cgltf_memory_options memory;
	cgltf_file_options file;
} cgltf_options;

typedef enum cgltf_buffer_view_type
{
	cgltf_buffer_view_type_invalid,
	cgltf_buffer_view_type_indices,
	cgltf_buffer_view_type_vertices,
	cgltf_buffer_view_type_max_enum
} cgltf_buffer_view_type;

typedef enum cgltf_attribute_type
{
	cgltf_attribute_type_invalid,
	cgltf_attribute_type_position,
	cgltf_attribute_type_normal,
	cgltf_attribute_type_tangent,
	cgltf_attribute_type_texcoord,
	cgltf_attribute_type_color,
	cgltf_attribute_type_joints,
	cgltf_attribute_type_weights,
	cgltf_attribute_type_custom,
	cgltf_attribute_type_max_enum
} cgltf_attribute_type;

typedef enum cgltf_component_type
{
	cgltf_component_type_invalid,
	cgltf_component_type_r_8, /* BYTE */
	cgltf_component_type_r_8u, /* UNSIGNED_BYTE */
	cgltf_component_type_r_16, /* SHORT */
	cgltf_component_type_r_16u, /* UNSIGNED_SHORT */
	cgltf_component_type_r_32u, /* UNSIGNED_INT */
	cgltf_component_type_r_32f, /* FLOAT */
    cgltf_component_type_max_enum
} cgltf_component_type;

typedef enum cgltf_type
{
	cgltf_type_invalid,
	cgltf_type_scalar,
	cgltf_type_vec2,
	cgltf_type_vec3,
	cgltf_type_vec4,
	cgltf_type_mat2,
	cgltf_type_mat3,
	cgltf_type_mat4,
	cgltf_type_max_enum
} cgltf_type;

typedef enum cgltf_primitive_type
{
	cgltf_primitive_type_invalid,
	cgltf_primitive_type_points,
	cgltf_primitive_type_lines,
	cgltf_primitive_type_line_loop,
	cgltf_primitive_type_line_strip,
	cgltf_primitive_type_triangles,
	cgltf_primitive_type_triangle_strip,
	cgltf_primitive_type_triangle_fan,
	cgltf_primitive_type_max_enum
} cgltf_primitive_type;

typedef enum cgltf_alpha_mode
{
	cgltf_alpha_mode_opaque,
	cgltf_alpha_mode_mask,
	cgltf_alpha_mode_blend,
	cgltf_alpha_mode_max_enum
} cgltf_alpha_mode;

typedef enum cgltf_animation_path_type {
	cgltf_animation_path_type_invalid,
	cgltf_animation_path_type_translation,
	cgltf_animation_path_type_rotation,
	cgltf_animation_path_type_scale,
	cgltf_animation_path_type_weights,
	cgltf_animation_path_type_max_enum
} cgltf_animation_path_type;

typedef enum cgltf_interpolation_type {
	cgltf_interpolation_type_linear,
	cgltf_interpolation_type_step,
	cgltf_interpolation_type_cubic_spline,
	cgltf_interpolation_type_max_enum
} cgltf_interpolation_type;

typedef enum cgltf_camera_type {
	cgltf_camera_type_invalid,
	cgltf_camera_type_perspective,
	cgltf_camera_type_orthographic,
	cgltf_camera_type_max_enum
} cgltf_camera_type;

typedef enum cgltf_light_type {
	cgltf_light_type_invalid,
	cgltf_light_type_directional,
	cgltf_light_type_point,
	cgltf_light_type_spot,
	cgltf_light_type_max_enum
} cgltf_light_type;

typedef enum cgltf_data_free_method {
	cgltf_data_free_method_none,
	cgltf_data_free_method_file_release,
	cgltf_data_free_method_memory_free,
	cgltf_data_free_method_max_enum
} cgltf_data_free_method;

typedef struct cgltf_extras {
	cgltf_size start_offset; /* this field is deprecated and will be removed in the future; use data instead */
	cgltf_size end_offset; /* this field is deprecated and will be removed in the future; use data instead */

	char* data;
} cgltf_extras;

typedef struct cgltf_extension {
	char* name;
	char* data;
} cgltf_extension;

typedef struct cgltf_buffer
{
	char* name;
	cgltf_size size;
	char* uri;
	void* data; /* loaded by cgltf_load_buffers */
	cgltf_data_free_method data_free_method;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_buffer;

typedef enum cgltf_meshopt_compression_mode {
	cgltf_meshopt_compression_mode_invalid,
	cgltf_meshopt_compression_mode_attributes,
	cgltf_meshopt_compression_mode_triangles,
	cgltf_meshopt_compression_mode_indices,
	cgltf_meshopt_compression_mode_max_enum
} cgltf_meshopt_compression_mode;

typedef enum cgltf_meshopt_compression_filter {
	cgltf_meshopt_compression_filter_none,
	cgltf_meshopt_compression_filter_octahedral,
	cgltf_meshopt_compression_filter_quaternion,
	cgltf_meshopt_compression_filter_exponential,
	cgltf_meshopt_compression_filter_max_enum
} cgltf_meshopt_compression_filter;

typedef struct cgltf_meshopt_compression
{
	cgltf_buffer* buffer;
	cgltf_size offset;
	cgltf_size size;
	cgltf_size stride;
	cgltf_size count;
	cgltf_meshopt_compression_mode mode;
	cgltf_meshopt_compression_filter filter;
} cgltf_meshopt_compression;

typedef struct cgltf_buffer_view
{
	char *name;
	cgltf_buffer* buffer;
	cgltf_size offset;
	cgltf_size size;
	cgltf_size stride; /* 0 == automatically determined by accessor */
	cgltf_buffer_view_type type;
	void* data; /* overrides buffer->data if present, filled by extensions */
	cgltf_bool has_meshopt_compression;
	cgltf_meshopt_compression meshopt_compression;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_buffer_view;

typedef struct cgltf_accessor_sparse
{
	cgltf_size count;
	cgltf_buffer_view* indices_buffer_view;
	cgltf_size indices_byte_offset;
	cgltf_component_type indices_component_type;
	cgltf_buffer_view* values_buffer_view;
	cgltf_size values_byte_offset;
} cgltf_accessor_sparse;

typedef struct cgltf_accessor
{
	char* name;
	cgltf_component_type component_type;
	cgltf_bool normalized;
	cgltf_type type;
	cgltf_size offset;
	cgltf_size count;
	cgltf_size stride;
	cgltf_buffer_view* buffer_view;
	cgltf_bool has_min;
	cgltf_float min[16];
	cgltf_bool has_max;
	cgltf_float max[16];
	cgltf_bool is_sparse;
	cgltf_accessor_sparse sparse;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_accessor;

typedef struct cgltf_attribute
{
	char* name;
	cgltf_attribute_type type;
	cgltf_int index;
	cgltf_accessor* data;
} cgltf_attribute;

typedef struct cgltf_image
{
	char* name;
	char* uri;
	cgltf_buffer_view* buffer_view;
	char* mime_type;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_image;

typedef enum cgltf_filter_type {
    cgltf_filter_type_undefined = 0,
    cgltf_filter_type_nearest = 9728,
    cgltf_filter_type_linear = 9729,
    cgltf_filter_type_nearest_mipmap_nearest = 9984,
    cgltf_filter_type_linear_mipmap_nearest = 9985,
    cgltf_filter_type_nearest_mipmap_linear = 9986,
    cgltf_filter_type_linear_mipmap_linear = 9987
} cgltf_filter_type;

typedef enum cgltf_wrap_mode {
    cgltf_wrap_mode_clamp_to_edge = 33071,
    cgltf_wrap_mode_mirrored_repeat = 33648,
    cgltf_wrap_mode_repeat = 10497
} cgltf_wrap_mode;

typedef struct cgltf_sampler
{
	char* name;
	cgltf_filter_type mag_filter;
	cgltf_filter_type min_filter;
	cgltf_wrap_mode wrap_s;
	cgltf_wrap_mode wrap_t;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_sampler;

typedef struct cgltf_texture
{
	char* name;
	cgltf_image* image;
	cgltf_sampler* sampler;
	cgltf_bool has_basisu;
	cgltf_image* basisu_image;
	cgltf_bool has_webp;
	cgltf_image* webp_image;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_texture;

typedef struct cgltf_texture_transform
{
	cgltf_float offset[2];
	cgltf_float rotation;
	cgltf_float scale[2];
	cgltf_bool has_texcoord;
	cgltf_int texcoord;
} cgltf_texture_transform;

typedef struct cgltf_texture_view
{
	cgltf_texture* texture;
	cgltf_int texcoord;
	cgltf_float scale; /* equivalent to strength for occlusion_texture */
	cgltf_bool has_transform;
	cgltf_texture_transform transform;
} cgltf_texture_view;

typedef struct cgltf_pbr_metallic_roughness
{
	cgltf_texture_view base_color_texture;
	cgltf_texture_view metallic_roughness_texture;

	cgltf_float base_color_factor[4];
	cgltf_float metallic_factor;
	cgltf_float roughness_factor;
} cgltf_pbr_metallic_roughness;

typedef struct cgltf_pbr_specular_glossiness
{
	cgltf_texture_view diffuse_texture;
	cgltf_texture_view specular_glossiness_texture;

	cgltf_float diffuse_factor[4];
	cgltf_float specular_factor[3];
	cgltf_float glossiness_factor;
} cgltf_pbr_specular_glossiness;

typedef struct cgltf_clearcoat
{
	cgltf_texture_view clearcoat_texture;
	cgltf_texture_view clearcoat_roughness_texture;
	cgltf_texture_view clearcoat_normal_texture;

	cgltf_float clearcoat_factor;
	cgltf_float clearcoat_roughness_factor;
} cgltf_clearcoat;

typedef struct cgltf_transmission
{
	cgltf_texture_view transmission_texture;
	cgltf_float transmission_factor;
} cgltf_transmission;

typedef struct cgltf_ior
{
	cgltf_float ior;
} cgltf_ior;

typedef struct cgltf_specular
{
	cgltf_texture_view specular_texture;
	cgltf_texture_view specular_color_texture;
	cgltf_float specular_color_factor[3];
	cgltf_float specular_factor;
} cgltf_specular;

typedef struct cgltf_volume
{
	cgltf_texture_view thickness_texture;
	cgltf_float thickness_factor;
	cgltf_float attenuation_color[3];
	cgltf_float attenuation_distance;
} cgltf_volume;

typedef struct cgltf_sheen
{
	cgltf_texture_view sheen_color_texture;
	cgltf_float sheen_color_factor[3];
	cgltf_texture_view sheen_roughness_texture;
	cgltf_float sheen_roughness_factor;
} cgltf_sheen;

typedef struct cgltf_emissive_strength
{
	cgltf_float emissive_strength;
} cgltf_emissive_strength;

typedef struct cgltf_iridescence
{
	cgltf_float iridescence_factor;
	cgltf_texture_view iridescence_texture;
	cgltf_float iridescence_ior;
	cgltf_float iridescence_thickness_min;
	cgltf_float iridescence_thickness_max;
	cgltf_texture_view iridescence_thickness_texture;
} cgltf_iridescence;

typedef struct cgltf_diffuse_transmission
{
	cgltf_texture_view diffuse_transmission_texture;
	cgltf_float diffuse_transmission_factor;
	cgltf_float diffuse_transmission_color_factor[3];
	cgltf_texture_view diffuse_transmission_color_texture;
} cgltf_diffuse_transmission;

typedef struct cgltf_anisotropy
{
	cgltf_float anisotropy_strength;
	cgltf_float anisotropy_rotation;
	cgltf_texture_view anisotropy_texture;
} cgltf_anisotropy;

typedef struct cgltf_dispersion
{
	cgltf_float dispersion;
} cgltf_dispersion;

typedef struct cgltf_material
{
	char* name;
	cgltf_bool has_pbr_metallic_roughness;
	cgltf_bool has_pbr_specular_glossiness;
	cgltf_bool has_clearcoat;
	cgltf_bool has_transmission;
	cgltf_bool has_volume;
	cgltf_bool has_ior;
	cgltf_bool has_specular;
	cgltf_bool has_sheen;
	cgltf_bool has_emissive_strength;
	cgltf_bool has_iridescence;
	cgltf_bool has_diffuse_transmission;
	cgltf_bool has_anisotropy;
	cgltf_bool has_dispersion;
	cgltf_pbr_metallic_roughness pbr_metallic_roughness;
	cgltf_pbr_specular_glossiness pbr_specular_glossiness;
	cgltf_clearcoat clearcoat;
	cgltf_ior ior;
	cgltf_specular specular;
	cgltf_sheen sheen;
	cgltf_transmission transmission;
	cgltf_volume volume;
	cgltf_emissive_strength emissive_strength;
	cgltf_iridescence iridescence;
	cgltf_diffuse_transmission diffuse_transmission;
	cgltf_anisotropy anisotropy;
	cgltf_dispersion dispersion;
	cgltf_texture_view normal_texture;
	cgltf_texture_view occlusion_texture;
	cgltf_texture_view emissive_texture;
	cgltf_float emissive_factor[3];
	cgltf_alpha_mode alpha_mode;
	cgltf_float alpha_cutoff;
	cgltf_bool double_sided;
	cgltf_bool unlit;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_material;

typedef struct cgltf_material_mapping
{
	cgltf_size variant;
	cgltf_material* material;
	cgltf_extras extras;
} cgltf_material_mapping;

typedef struct cgltf_morph_target {
	cgltf_attribute* attributes;
	cgltf_size attributes_count;
} cgltf_morph_target;

typedef struct cgltf_draco_mesh_compression {
	cgltf_buffer_view* buffer_view;
	cgltf_attribute* attributes;
	cgltf_size attributes_count;
} cgltf_draco_mesh_compression;

typedef struct cgltf_mesh_gpu_instancing {
	cgltf_attribute* attributes;
	cgltf_size attributes_count;
} cgltf_mesh_gpu_instancing;

typedef struct cgltf_primitive {
	cgltf_primitive_type type;
	cgltf_accessor* indices;
	cgltf_material* material;
	cgltf_attribute* attributes;
	cgltf_size attributes_count;
	cgltf_morph_target* targets;
	cgltf_size targets_count;
	cgltf_extras extras;
	cgltf_bool has_draco_mesh_compression;
	cgltf_draco_mesh_compression draco_mesh_compression;
	cgltf_material_mapping* mappings;
	cgltf_size mappings_count;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_primitive;

typedef struct cgltf_mesh {
	char* name;
	cgltf_primitive* primitives;
	cgltf_size primitives_count;
	cgltf_float* weights;
	cgltf_size weights_count;
	char** target_names;
	cgltf_size target_names_count;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_mesh;

typedef struct cgltf_node cgltf_node;

typedef struct cgltf_skin {
	char* name;
	cgltf_node** joints;
	cgltf_size joints_count;
	cgltf_node* skeleton;
	cgltf_accessor* inverse_bind_matrices;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_skin;

typedef struct cgltf_camera_perspective {
	cgltf_bool has_aspect_ratio;
	cgltf_float aspect_ratio;
	cgltf_float yfov;
	cgltf_bool has_zfar;
	cgltf_float zfar;
	cgltf_float znear;
	cgltf_extras extras;
} cgltf_camera_perspective;

typedef struct cgltf_camera_orthographic {
	cgltf_float xmag;
	cgltf_float ymag;
	cgltf_float zfar;
	cgltf_float znear;
	cgltf_extras extras;
} cgltf_camera_orthographic;

typedef struct cgltf_camera {
	char* name;
	cgltf_camera_type type;
	union {
		cgltf_camera_perspective perspective;
		cgltf_camera_orthographic orthographic;
	} data;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_camera;

typedef struct cgltf_light {
	char* name;
	cgltf_float color[3];
	cgltf_float intensity;
	cgltf_light_type type;
	cgltf_float range;
	cgltf_float spot_inner_cone_angle;
	cgltf_float spot_outer_cone_angle;
	cgltf_extras extras;
} cgltf_light;

struct cgltf_node {
	char* name;
	cgltf_node* parent;
	cgltf_node** children;
	cgltf_size children_count;
	cgltf_skin* skin;
	cgltf_mesh* mesh;
	cgltf_camera* camera;
	cgltf_light* light;
	cgltf_float* weights;
	cgltf_size weights_count;
	cgltf_bool has_translation;
	cgltf_bool has_rotation;
	cgltf_bool has_scale;
	cgltf_bool has_matrix;
	cgltf_float translation[3];
	cgltf_float rotation[4];
	cgltf_float scale[3];
	cgltf_float matrix[16];
	cgltf_extras extras;
	cgltf_bool has_mesh_gpu_instancing;
	cgltf_mesh_gpu_instancing mesh_gpu_instancing;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
};

typedef struct cgltf_scene {
	char* name;
	cgltf_node** nodes;
	cgltf_size nodes_count;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_scene;

typedef struct cgltf_animation_sampler {
	cgltf_accessor* input;
	cgltf_accessor* output;
	cgltf_interpolation_type interpolation;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_animation_sampler;

typedef struct cgltf_animation_channel {
	cgltf_animation_sampler* sampler;
	cgltf_node* target_node;
	cgltf_animation_path_type target_path;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_animation_channel;

typedef struct cgltf_animation {
	char* name;
	cgltf_animation_sampler* samplers;
	cgltf_size samplers_count;
	cgltf_animation_channel* channels;
	cgltf_size channels_count;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_animation;

typedef struct cgltf_material_variant
{
	char* name;
	cgltf_extras extras;
} cgltf_material_variant;

typedef struct cgltf_asset {
	char* copyright;
	char* generator;
	char* version;
	char* min_version;
	cgltf_extras extras;
	cgltf_size extensions_count;
	cgltf_extension* extensions;
} cgltf_asset;

typedef struct cgltf_data
{
	cgltf_file_type file_type;
	void* file_data;

	cgltf_asset asset;

	cgltf_mesh* meshes;
	cgltf_size meshes_count;

	cgltf_material* materials;
	cgltf_size materials_count;

	cgltf_accessor* accessors;
	cgltf_size accessors_count;

	cgltf_buffer_view* buffer_views;
	cgltf_size buffer_views_count;

	cgltf_buffer* buffers;
	cgltf_size buffers_count;

	cgltf_image* images;
	cgltf_size images_count;

	cgltf_texture* textures;
	cgltf_size textures_count;

	cgltf_sampler* samplers;
	cgltf_size samplers_count;

	cgltf_skin* skins;
	cgltf_size skins_count;

	cgltf_camera* cameras;
	cgltf_size cameras_count;

	cgltf_light* lights;
	cgltf_size lights_count;

	cgltf_node* nodes;
	cgltf_size nodes_count;

	cgltf_scene* scenes;
	cgltf_size scenes_count;

	cgltf_scene* scene;

	cgltf_animation* animations;
	cgltf_size animations_count;

	cgltf_material_variant* variants;
	cgltf_size variants_count;

	cgltf_extras extras;

	cgltf_size data_extensions_count;
	cgltf_extension* data_extensions;

	char** extensions_used;
	cgltf_size extensions_used_count;

	char** extensions_required;
	cgltf_size extensions_required_count;

	const char* json;
	cgltf_size json_size;

	const void* bin;
	cgltf_size bin_size;

	cgltf_memory_options memory;
	cgltf_file_options file;
} cgltf_data;

cgltf_result cgltf_parse(
		const cgltf_options* options,
		const void* data,
		cgltf_size size,
		cgltf_data** out_data);

cgltf_result cgltf_parse_file(
		const cgltf_options* options,
		const char* path,
		cgltf_data** out_data);

cgltf_result cgltf_load_buffers(
		const cgltf_options* options,
		cgltf_data* data,
		const char* gltf_path);

cgltf_result cgltf_load_buffer_base64(const cgltf_options* options, cgltf_size size, const char* base64, void** out_data);

cgltf_size cgltf_decode_string(char* string);
cgltf_size cgltf_decode_uri(char* uri);

cgltf_result cgltf_validate(cgltf_data* data);

void cgltf_free(cgltf_data* data);

void cgltf_node_transform_local(const cgltf_node* node, cgltf_float* out_matrix);
void cgltf_node_transform_world(const cgltf_node* node, cgltf_float* out_matrix);

const uint8_t* cgltf_buffer_view_data(const cgltf_buffer_view* view);

const cgltf_accessor* cgltf_find_accessor(const cgltf_primitive* prim, cgltf_attribute_type type, cgltf_int index);

cgltf_bool cgltf_accessor_read_float(const cgltf_accessor* accessor, cgltf_size index, cgltf_float* out, cgltf_size element_size);
cgltf_bool cgltf_accessor_read_uint(const cgltf_accessor* accessor, cgltf_size index, cgltf_uint* out, cgltf_size element_size);
cgltf_size cgltf_accessor_read_index(const cgltf_accessor* accessor, cgltf_size index);

cgltf_size cgltf_num_components(cgltf_type type);
cgltf_size cgltf_component_size(cgltf_component_type component_type);
cgltf_size cgltf_calc_size(cgltf_type type, cgltf_component_type component_type);

cgltf_size cgltf_accessor_unpack_floats(const cgltf_accessor* accessor, cgltf_float* out, cgltf_size float_count);
cgltf_size cgltf_accessor_unpack_indices(const cgltf_accessor* accessor, void* out, cgltf_size out_component_size, cgltf_size index_count);

/* this function is deprecated and will be removed in the future; use cgltf_extras::data instead */
cgltf_result cgltf_copy_extras_json(const cgltf_data* data, const cgltf_extras* extras, char* dest, cgltf_size* dest_size);

cgltf_size cgltf_mesh_index(const cgltf_data* data, const cgltf_mesh* object);
cgltf_size cgltf_material_index(const cgltf_data* data, const cgltf_material* object);
cgltf_size cgltf_accessor_index(const cgltf_data* data, const cgltf_accessor* object);
cgltf_size cgltf_buffer_view_index(const cgltf_data* data, const cgltf_buffer_view* object);
cgltf_size cgltf_buffer_index(const cgltf_data* data, const cgltf_buffer* object);
cgltf_size cgltf_image_index(const cgltf_data* data, const cgltf_image* object);
cgltf_size cgltf_texture_index(const cgltf_data* data, const cgltf_texture* object);
cgltf_size cgltf_sampler_index(const cgltf_data* data, const cgltf_sampler* object);
cgltf_size cgltf_skin_index(const cgltf_data* data, const cgltf_skin* object);
cgltf_size cgltf_camera_index(const cgltf_data* data, const cgltf_camera* object);
cgltf_size cgltf_light_index(const cgltf_data* data, const cgltf_light* object);
cgltf_size cgltf_node_index(const cgltf_data* data, const cgltf_node* object);
cgltf_size cgltf_scene_index(const cgltf_data* data, const cgltf_scene* object);
cgltf_size cgltf_animation_index(const cgltf_data* data, const cgltf_animation* object);
cgltf_size cgltf_animation_sampler_index(const cgltf_animation* animation, const cgltf_animation_sampler* object);
cgltf_size cgltf_animation_channel_index(const cgltf_animation* animation, const cgltf_animation_channel* object);

#ifdef __cplusplus
}
#endif

#endif /* #ifndef CGLTF_H_INCLUDED__ */

/*
 *
 * Stop now, if you are only interested in the API.
 * Below, you find the implementation.
 *
 */

#if defined(__INTELLISENSE__) || defined(__JETBRAINS_IDE__)
/* This makes MSVC/CLion intellisense work. */
#define CGLTF_IMPLEMENTATION
#endif

#ifdef CGLTF_IMPLEMENTATION

#include <assert.h> /* For assert */
#include <string.h> /* For strncpy */
#include <stdio.h>  /* For fopen */
#include <limits.h> /* For UINT_MAX etc */
#include <float.h>  /* For FLT_MAX */

#if !defined(CGLTF_MALLOC) || !defined(CGLTF_FREE) || !defined(CGLTF_ATOI) || !defined(CGLTF_ATOF) || !defined(CGLTF_ATOLL)
#include <stdlib.h> /* For malloc, free, atoi, atof */
#endif

/* JSMN_PARENT_LINKS is necessary to make parsing large structures linear in input size */
#define JSMN_PARENT_LINKS

/* JSMN_STRICT is necessary to reject invalid JSON documents */
#define JSMN_STRICT

/*
 * -- jsmn.h start --
 * Source: https://github.com/zserge/jsmn
 * License: MIT
 */
typedef enum {
	JSMN_UNDEFINED = 0,
	JSMN_OBJECT = 1,
	JSMN_ARRAY = 2,
	JSMN_STRING = 3,
	JSMN_PRIMITIVE = 4
} jsmntype_t;
enum jsmnerr {
	/* Not enough tokens were provided */
	JSMN_ERROR_NOMEM = -1,
	/* Invalid character inside JSON string */
	JSMN_ERROR_INVAL = -2,
	/* The string is not a full JSON packet, more bytes expected */
	JSMN_ERROR_PART = -3
};
typedef struct {
	jsmntype_t type;
	ptrdiff_t start;
	ptrdiff_t end;
	int size;
#ifdef JSMN_PARENT_LINKS
	int parent;
#endif
} jsmntok_t;
typedef struct {
	size_t pos; /* offset in the JSON string */
	unsigned int toknext; /* next token to allocate */
	int toksuper; /* superior token node, e.g parent object or array */
} jsmn_parser;
static void jsmn_init(jsmn_parser *parser);
static int jsmn_parse(jsmn_parser *parser, const char *js, size_t len, jsmntok_t *tokens, size_t num_tokens);
/*
 * -- jsmn.h end --
 */


#ifndef CGLTF_CONSTS
#define GlbHeaderSize 12
#define GlbChunkHeaderSize 8
static const uint32_t GlbVersion = 2;
static const uint32_t GlbMagic = 0x46546C67;
static const uint32_t GlbMagicJsonChunk = 0x4E4F534A;
static const uint32_t GlbMagicBinChunk = 0x004E4942;
#define CGLTF_CONSTS
#endif

#ifndef CGLTF_MALLOC
#define CGLTF_MALLOC(size) malloc(size)
#endif
#ifndef CGLTF_FREE
#define CGLTF_FREE(ptr) free(ptr)
#endif
#ifndef CGLTF_ATOI
#define CGLTF_ATOI(str) atoi(str)
#endif
#ifndef CGLTF_ATOF
#define CGLTF_ATOF(str) atof(str)
#endif
#ifndef CGLTF_ATOLL
#define CGLTF_ATOLL(str) atoll(str)
#endif
#ifndef CGLTF_VALIDATE_ENABLE_ASSERTS
#define CGLTF_VALIDATE_ENABLE_ASSERTS 0
#endif

static void* cgltf_default_alloc(void* user, cgltf_size size)
{
	(void)user;
	return CGLTF_MALLOC(size);
}

static void cgltf_default_free(void* user, void* ptr)
{
	(void)user;
	CGLTF_FREE(ptr);
}

static void* cgltf_calloc(cgltf_options* options, size_t element_size, cgltf_size count)
{
	if (SIZE_MAX / element_size < count)
	{
		return NULL;
	}
	void* result = options->memory.alloc_func(options->memory.user_data, element_size * count);
	if (!result)
	{
		return NULL;
	}
	memset(result, 0, element_size * count);
	return result;
}

static cgltf_result cgltf_default_file_read(const struct cgltf_memory_options* memory_options, const struct cgltf_file_options* file_options, const char* path, cgltf_size* size, void** data)
{
	(void)file_options;
	void* (*memory_alloc)(void*, cgltf_size) = memory_options->alloc_func ? memory_options->alloc_func : &cgltf_default_alloc;
	void (*memory_free)(void*, void*) = memory_options->free_func ? memory_options->free_func : &cgltf_default_free;

	FILE* file = fopen(path, "rb");
	if (!file)
	{
		return cgltf_result_file_not_found;
	}

	cgltf_size file_size = size ? *size : 0;

	if (file_size == 0)
	{
		fseek(file, 0, SEEK_END);

#ifdef _MSC_VER
		__int64 length = _ftelli64(file);
#else
		long length = ftell(file);
#endif

		if (length < 0)
		{
			fclose(file);
			return cgltf_result_io_error;
		}

		fseek(file, 0, SEEK_SET);
		file_size = (cgltf_size)length;
	}

	char* file_data = (char*)memory_alloc(memory_options->user_data, file_size);
	if (!file_data)
	{
		fclose(file);
		return cgltf_result_out_of_memory;
	}

	cgltf_size read_size = fread(file_data, 1, file_size, file);

	fclose(file);

	if (read_size != file_size)
	{
		memory_free(memory_options->user_data, file_data);
		return cgltf_result_io_error;
	}

	if (size)
	{
		*size = file_size;
	}
	if (data)
	{
		*data = file_data;
	}

	return cgltf_result_success;
}

static void cgltf_default_file_release(const struct cgltf_memory_options* memory_options, const struct cgltf_file_options* file_options, void* data)
{
	(void)file_options;
	void (*memfree)(void*, void*) = memory_options->free_func ? memory_options->free_func : &cgltf_default_free;
	memfree(memory_options->user_data, data);
}

static cgltf_result cgltf_parse_json(cgltf_options* options, const uint8_t* json_chunk, cgltf_size size, cgltf_data** out_data);

cgltf_result cgltf_parse(const cgltf_options* options, const void* data, cgltf_size size, cgltf_data** out_data)
{
	if (size < GlbHeaderSize)
	{
		return cgltf_result_data_too_short;
	}

	if (options == NULL)
	{
		return cgltf_result_invalid_options;
	}

	cgltf_options fixed_options = *options;
	if (fixed_options.memory.alloc_func == NULL)
	{
		fixed_options.memory.alloc_func = &cgltf_default_alloc;
	}
	if (fixed_options.memory.free_func == NULL)
	{
		fixed_options.memory.free_func = &cgltf_default_free;
	}

	uint32_t tmp;
	// Magic
	memcpy(&tmp, data, 4);
	if (tmp != GlbMagic)
	{
		if (fixed_options.type == cgltf_file_type_invalid)
		{
			fixed_options.type = cgltf_file_type_gltf;
		}
		else if (fixed_options.type == cgltf_file_type_glb)
		{
			return cgltf_result_unknown_format;
		}
	}

	if (fixed_options.type == cgltf_file_type_gltf)
	{
		cgltf_result json_result = cgltf_parse_json(&fixed_options, (const uint8_t*)data, size, out_data);
		if (json_result != cgltf_result_success)
		{
			return json_result;
		}

		(*out_data)->file_type = cgltf_file_type_gltf;

		return cgltf_result_success;
	}

	const uint8_t* ptr = (const uint8_t*)data;
	// Version
	memcpy(&tmp, ptr + 4, 4);
	uint32_t version = tmp;
	if (version != GlbVersion)
	{
		return version < GlbVersion ? cgltf_result_legacy_gltf : cgltf_result_unknown_format;
	}

	// Total length
	memcpy(&tmp, ptr + 8, 4);
	if (tmp > size)
	{
		return cgltf_result_data_too_short;
	}

	const uint8_t* json_chunk = ptr + GlbHeaderSize;

	if (GlbHeaderSize + GlbChunkHeaderSize > size)
	{
		return cgltf_result_data_too_short;
	}

	// JSON chunk: length
	uint32_t json_length;
	memcpy(&json_length, json_chunk, 4);
	if (json_length > size - GlbHeaderSize - GlbChunkHeaderSize)
	{
		return cgltf_result_data_too_short;
	}

	// JSON chunk: magic
	memcpy(&tmp, json_chunk + 4, 4);
	if (tmp != GlbMagicJsonChunk)
	{
		return cgltf_result_unknown_format;
	}

	json_chunk += GlbChunkHeaderSize;

	const void* bin = NULL;
	cgltf_size bin_size = 0;

	if (GlbChunkHeaderSize <= size - GlbHeaderSize - GlbChunkHeaderSize - json_length)
	{
		// We can read another chunk
		const uint8_t* bin_chunk = json_chunk + json_length;

		// Bin chunk: length
		uint32_t bin_length;
		memcpy(&bin_length, bin_chunk, 4);
		if (bin_length > size - GlbHeaderSize - GlbChunkHeaderSize - json_length - GlbChunkHeaderSize)
		{
			return cgltf_result_data_too_short;
		}

		// Bin chunk: magic
		memcpy(&tmp, bin_chunk + 4, 4);
		if (tmp != GlbMagicBinChunk)
		{
			return cgltf_result_unknown_format;
		}

		bin_chunk += GlbChunkHeaderSize;

		bin = bin_chunk;
		bin_size = bin_length;
	}

	cgltf_result json_result = cgltf_parse_json(&fixed_options, json_chunk, json_length, out_data);
	if (json_result != cgltf_result_success)
	{
		return json_result;
	}

	(*out_data)->file_type = cgltf_file_type_glb;
	(*out_data)->bin = bin;
	(*out_data)->bin_size = bin_size;

	return cgltf_result_success;
}

cgltf_result cgltf_parse_file(const cgltf_options* options, const char* path, cgltf_data** out_data)
{
	if (options == NULL)
	{
		return cgltf_result_invalid_options;
	}

	cgltf_result (*file_read)(const struct cgltf_memory_options*, const struct cgltf_file_options*, const char*, cgltf_size*, void**) = options->file.read ? options->file.read : &cgltf_default_file_read;
	void (*file_release)(const struct cgltf_memory_options*, const struct cgltf_file_options*, void* data) = options->file.release ? options->file.release : cgltf_default_file_release;

	void* file_data = NULL;
	cgltf_size file_size = 0;
	cgltf_result result = file_read(&options->memory, &options->file, path, &file_size, &file_data);
	if (result != cgltf_result_success)
	{
		return result;
	}

	result = cgltf_parse(options, file_data, file_size, out_data);

	if (result != cgltf_result_success)
	{
		file_release(&options->memory, &options->file, file_data);
		return result;
	}

	(*out_data)->file_data = file_data;

	return cgltf_result_success;
}

static void cgltf_combine_paths(char* path, const char* base, const char* uri)
{
	const char* s0 = strrchr(base, '/');
	const char* s1 = strrchr(base, '\\');
	const char* slash = s0 ? (s1 && s1 > s0 ? s1 : s0) : s1;

	if (slash)
	{
		size_t prefix = slash - base + 1;

		strncpy(path, base, prefix);
		strcpy(path + prefix, uri);
	}
	else
	{
		strcpy(path, uri);
	}
}

static cgltf_result cgltf_load_buffer_file(const cgltf_options* options, cgltf_size size, const char* uri, const char* gltf_path, void** out_data)
{
	void* (*memory_alloc)(void*, cgltf_size) = options->memory.alloc_func ? options->memory.alloc_func : &cgltf_default_alloc;
	void (*memory_free)(void*, void*) = options->memory.free_func ? options->memory.free_func : &cgltf_default_free;
	cgltf_result (*file_read)(const struct cgltf_memory_options*, const struct cgltf_file_options*, const char*, cgltf_size*, void**) = options->file.read ? options->file.read : &cgltf_default_file_read;

	char* path = (char*)memory_alloc(options->memory.user_data, strlen(uri) + strlen(gltf_path) + 1);
	if (!path)
	{
		return cgltf_result_out_of_memory;
	}

	cgltf_combine_paths(path, gltf_path, uri);

	// after combining, the tail of the resulting path is a uri; decode_uri converts it into path
	cgltf_decode_uri(path + strlen(path) - strlen(uri));

	void* file_data = NULL;
	cgltf_result result = file_read(&options->memory, &options->file, path, &size, &file_data);

	memory_free(options->memory.user_data, path);

	*out_data = (result == cgltf_result_success) ? file_data : NULL;

	return result;
}

cgltf_result cgltf_load_buffer_base64(const cgltf_options* options, cgltf_size size, const char* base64, void** out_data)
{
	void* (*memory_alloc)(void*, cgltf_size) = options->memory.alloc_func ? options->memory.alloc_func : &cgltf_default_alloc;
	void (*memory_free)(void*, void*) = options->memory.free_func ? options->memory.free_func : &cgltf_default_free;

	unsigned char* data = (unsigned char*)memory_alloc(options->memory.user_data, size);
	if (!data)
	{
		return cgltf_result_out_of_memory;
	}

	unsigned int buffer = 0;
	unsigned int buffer_bits = 0;

	for (cgltf_size i = 0; i < size; ++i)
	{
		while (buffer_bits < 8)
		{
			char ch = *base64++;

			int index =
				(unsigned)(ch - 'A') < 26 ? (ch - 'A') :
				(unsigned)(ch - 'a') < 26 ? (ch - 'a') + 26 :
				(unsigned)(ch - '0') < 10 ? (ch - '0') + 52 :
				ch == '+' ? 62 :
				ch == '/' ? 63 :
				-1;

			if (index < 0)
			{
				memory_free(options->memory.user_data, data);
				return cgltf_result_io_error;
			}

			buffer = (buffer << 6) | index;
			buffer_bits += 6;
		}

		data[i] = (unsigned char)(buffer >> (buffer_bits - 8));
		buffer_bits -= 8;
	}

	*out_data = data;

	return cgltf_result_success;
}

static int cgltf_unhex(char ch)
{
	return
		(unsigned)(ch - '0') < 10 ? (ch - '0') :
		(unsigned)(ch - 'A') < 6 ? (ch - 'A') + 10 :
		(unsigned)(ch - 'a') < 6 ? (ch - 'a') + 10 :
		-1;
}

cgltf_size cgltf_decode_string(char* string)
{
	char* read = string + strcspn(string, "\\");
	if (*read == 0)
	{
		return read - string;
	}
	char* write = string;
	char* last = string;

	for (;;)
	{
		// Copy characters since last escaped sequence
		cgltf_size written = read - last;
		memmove(write, last, written);
		write += written;

		if (*read++ == 0)
		{
			break;
		}

		// jsmn already checked that all escape sequences are valid
		switch (*read++)
		{
		case '\"': *write++ = '\"'; break;
		case '/':  *write++ = '/';  break;
		case '\\': *write++ = '\\'; break;
		case 'b':  *write++ = '\b'; break;
		case 'f':  *write++ = '\f'; break;
		case 'r':  *write++ = '\r'; break;
		case 'n':  *write++ = '\n'; break;
		case 't':  *write++ = '\t'; break;
		case 'u':
		{
			// UCS-2 codepoint \uXXXX to UTF-8
			int character = 0;
			for (cgltf_size i = 0; i < 4; ++i)
			{
				character = (character << 4) + cgltf_unhex(*read++);
			}

			if (character <= 0x7F)
			{
				*write++ = character & 0xFF;
			}
			else if (character <= 0x7FF)
			{
				*write++ = 0xC0 | ((character >> 6) & 0xFF);
				*write++ = 0x80 | (character & 0x3F);
			}
			else
			{
				*write++ = 0xE0 | ((character >> 12) & 0xFF);
				*write++ = 0x80 | ((character >> 6) & 0x3F);
				*write++ = 0x80 | (character & 0x3F);
			}
			break;
		}
		default:
			break;
		}

		last = read;
		read += strcspn(read, "\\");
	}

	*write = 0;
	return write - string;
}

cgltf_size cgltf_decode_uri(char* uri)
{
	char* write = uri;
	char* i = uri;

	while (*i)
	{
		if (*i == '%')
		{
			int ch1 = cgltf_unhex(i[1]);

			if (ch1 >= 0)
			{
				int ch2 = cgltf_unhex(i[2]);

				if (ch2 >= 0)
				{
					*write++ = (char)(ch1 * 16 + ch2);
					i += 3;
					continue;
				}
			}
		}

		*write++ = *i++;
	}

	*write = 0;
	return write - uri;
}

cgltf_result cgltf_load_buffers(const cgltf_options* options, cgltf_data* data, const char* gltf_path)
{
	if (options == NULL)
	{
		return cgltf_result_invalid_options;
	}

	if (data->buffers_count && data->buffers[0].data == NULL && data->buffers[0].uri == NULL && data->bin)
	{
		if (data->bin_size < data->buffers[0].size)
		{
			return cgltf_result_data_too_short;
		}

		data->buffers[0].data = (void*)data->bin;
		data->buffers[0].data_free_method = cgltf_data_free_method_none;
	}

	for (cgltf_size i = 0; i < data->buffers_count; ++i)
	{
		if (data->buffers[i].data)
		{
			continue;
		}

		const char* uri = data->buffers[i].uri;

		if (uri == NULL)
		{
			continue;
		}

		if (strncmp(uri, "data:", 5) == 0)
		{
			const char* comma = strchr(uri, ',');

			if (comma && comma - uri >= 7 && strncmp(comma - 7, ";base64", 7) == 0)
			{
				cgltf_result res = cgltf_load_buffer_base64(options, data->buffers[i].size, comma + 1, &data->buffers[i].data);
				data->buffers[i].data_free_method = cgltf_data_free_method_memory_free;

				if (res != cgltf_result_success)
				{
					return res;
				}
			}
			else
			{
				return cgltf_result_unknown_format;
			}
		}
		else if (strstr(uri, "://") == NULL && gltf_path)
		{
			cgltf_result res = cgltf_load_buffer_file(options, data->buffers[i].size, uri, gltf_path, &data->buffers[i].data);
			data->buffers[i].data_free_method = cgltf_data_free_method_file_release;

			if (res != cgltf_result_success)
			{
				return res;
			}
		}
		else
		{
			return cgltf_result_unknown_format;
		}
	}

	return cgltf_result_success;
}

static cgltf_size cgltf_calc_index_bound(cgltf_buffer_view* buffer_view, cgltf_size offset, cgltf_component_type component_type, cgltf_size count)
{
	char* data = (char*)buffer_view->buffer->data + offset + buffer_view->offset;
	cgltf_size bound = 0;

	switch (component_type)
	{
	case cgltf_component_type_r_8u:
		for (size_t i = 0; i < count; ++i)
		{
			cgltf_size v = ((unsigned char*)data)[i];
			bound = bound > v ? bound : v;
		}
		break;

	case cgltf_component_type_r_16u:
		for (size_t i = 0; i < count; ++i)
		{
			cgltf_size v = ((unsigned short*)data)[i];
			bound = bound > v ? bound : v;
		}
		break;

	case cgltf_component_type_r_32u:
		for (size_t i = 0; i < count; ++i)
		{
			cgltf_size v = ((unsigned int*)data)[i];
			bound = bound > v ? bound : v;
		}
		break;

	default:
		;
	}

	return bound;
}

#if CGLTF_VALIDATE_ENABLE_ASSERTS
#define CGLTF_ASSERT_IF(cond, result) assert(!(cond)); if (cond) return result;
#else
#define CGLTF_ASSERT_IF(cond, result) if (cond) return result;
#endif

cgltf_result cgltf_validate(cgltf_data* data)
{
	for (cgltf_size i = 0; i < data->accessors_count; ++i)
	{
		cgltf_accessor* accessor = &data->accessors[i];

		CGLTF_ASSERT_IF(data->accessors[i].component_type == cgltf_component_type_invalid, cgltf_result_invalid_gltf);
		CGLTF_ASSERT_IF(data->accessors[i].type == cgltf_type_invalid, cgltf_result_invalid_gltf);

		cgltf_size element_size = cgltf_calc_size(accessor->type, accessor->component_type);

		if (accessor->buffer_view)
		{
			cgltf_size req_size = accessor->offset + accessor->stride * (accessor->count - 1) + element_size;

			CGLTF_ASSERT_IF(accessor->buffer_view->size < req_size, cgltf_result_data_too_short);
		}

		if (accessor->is_sparse)
		{
			cgltf_accessor_sparse* sparse = &accessor->sparse;

			cgltf_size indices_component_size = cgltf_component_size(sparse->indices_component_type);
			cgltf_size indices_req_size = sparse->indices_byte_offset + indices_component_size * sparse->count;
			cgltf_size values_req_size = sparse->values_byte_offset + element_size * sparse->count;

			CGLTF_ASSERT_IF(sparse->indices_buffer_view->size < indices_req_size ||
							sparse->values_buffer_view->size < values_req_size, cgltf_result_data_too_short);

			CGLTF_ASSERT_IF(sparse->indices_component_type != cgltf_component_type_r_8u &&
							sparse->indices_component_type != cgltf_component_type_r_16u &&
							sparse->indices_component_type != cgltf_component_type_r_32u, cgltf_result_invalid_gltf);

			if (sparse->indices_buffer_view->buffer->data)
			{
				cgltf_size index_bound = cgltf_calc_index_bound(sparse->indices_buffer_view, sparse->indices_byte_offset, sparse->indices_component_type, sparse->count);

				CGLTF_ASSERT_IF(index_bound >= accessor->count, cgltf_result_data_too_short);
			}
		}
	}

	for (cgltf_size i = 0; i < data->buffer_views_count; ++i)
	{
		cgltf_size req_size = data->buffer_views[i].offset + data->buffer_views[i].size;

		CGLTF_ASSERT_IF(data->buffer_views[i].buffer && data->buffer_views[i].buffer->size < req_size, cgltf_result_data_too_short);

		if (data->buffer_views[i].has_meshopt_compression)
		{
			cgltf_meshopt_compression* mc = &data->buffer_views[i].meshopt_compression;

			CGLTF_ASSERT_IF(mc->buffer == NULL || mc->buffer->size < mc->offset + mc->size, cgltf_result_data_too_short);

			CGLTF_ASSERT_IF(data->buffer_views[i].stride && mc->stride != data->buffer_views[i].stride, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(data->buffer_views[i].size != mc->stride * mc->count, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(mc->mode == cgltf_meshopt_compression_mode_invalid, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(mc->mode == cgltf_meshopt_compression_mode_attributes && !(mc->stride % 4 == 0 && mc->stride <= 256), cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(mc->mode == cgltf_meshopt_compression_mode_triangles && mc->count % 3 != 0, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF((mc->mode == cgltf_meshopt_compression_mode_triangles || mc->mode == cgltf_meshopt_compression_mode_indices) && mc->stride != 2 && mc->stride != 4, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF((mc->mode == cgltf_meshopt_compression_mode_triangles || mc->mode == cgltf_meshopt_compression_mode_indices) && mc->filter != cgltf_meshopt_compression_filter_none, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(mc->filter == cgltf_meshopt_compression_filter_octahedral && mc->stride != 4 && mc->stride != 8, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(mc->filter == cgltf_meshopt_compression_filter_quaternion && mc->stride != 8, cgltf_result_invalid_gltf);
		}
	}

	for (cgltf_size i = 0; i < data->meshes_count; ++i)
	{
		if (data->meshes[i].weights)
		{
			CGLTF_ASSERT_IF(data->meshes[i].primitives_count && data->meshes[i].primitives[0].targets_count != data->meshes[i].weights_count, cgltf_result_invalid_gltf);
		}

		if (data->meshes[i].target_names)
		{
			CGLTF_ASSERT_IF(data->meshes[i].primitives_count && data->meshes[i].primitives[0].targets_count != data->meshes[i].target_names_count, cgltf_result_invalid_gltf);
		}

		for (cgltf_size j = 0; j < data->meshes[i].primitives_count; ++j)
		{
			CGLTF_ASSERT_IF(data->meshes[i].primitives[j].type == cgltf_primitive_type_invalid, cgltf_result_invalid_gltf);
			CGLTF_ASSERT_IF(data->meshes[i].primitives[j].targets_count != data->meshes[i].primitives[0].targets_count, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(data->meshes[i].primitives[j].attributes_count == 0, cgltf_result_invalid_gltf);

			cgltf_accessor* first = data->meshes[i].primitives[j].attributes[0].data;

			CGLTF_ASSERT_IF(first->count == 0, cgltf_result_invalid_gltf);

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].attributes_count; ++k)
			{
				CGLTF_ASSERT_IF(data->meshes[i].primitives[j].attributes[k].data->count != first->count, cgltf_result_invalid_gltf);
			}

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].targets_count; ++k)
			{
				for (cgltf_size m = 0; m < data->meshes[i].primitives[j].targets[k].attributes_count; ++m)
				{
					CGLTF_ASSERT_IF(data->meshes[i].primitives[j].targets[k].attributes[m].data->count != first->count, cgltf_result_invalid_gltf);
				}
			}

			cgltf_accessor* indices = data->meshes[i].primitives[j].indices;

			CGLTF_ASSERT_IF(indices &&
				indices->component_type != cgltf_component_type_r_8u &&
				indices->component_type != cgltf_component_type_r_16u &&
				indices->component_type != cgltf_component_type_r_32u, cgltf_result_invalid_gltf);

			CGLTF_ASSERT_IF(indices && indices->type != cgltf_type_scalar, cgltf_result_invalid_gltf);
			CGLTF_ASSERT_IF(indices && indices->stride != cgltf_component_size(indices->component_type), cgltf_result_invalid_gltf);

			if (indices && indices->buffer_view && indices->buffer_view->buffer->data)
			{
				cgltf_size index_bound = cgltf_calc_index_bound(indices->buffer_view, indices->offset, indices->component_type, indices->count);

				CGLTF_ASSERT_IF(index_bound >= first->count, cgltf_result_data_too_short);
			}

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].mappings_count; ++k)
			{
				CGLTF_ASSERT_IF(data->meshes[i].primitives[j].mappings[k].variant >= data->variants_count, cgltf_result_invalid_gltf);
			}
		}
	}

	for (cgltf_size i = 0; i < data->nodes_count; ++i)
	{
		if (data->nodes[i].weights && data->nodes[i].mesh)
		{
			CGLTF_ASSERT_IF(data->nodes[i].mesh->primitives_count && data->nodes[i].mesh->primitives[0].targets_count != data->nodes[i].weights_count, cgltf_result_invalid_gltf);
		}

		if (data->nodes[i].has_mesh_gpu_instancing)
		{
			CGLTF_ASSERT_IF(data->nodes[i].mesh == NULL, cgltf_result_invalid_gltf);
			CGLTF_ASSERT_IF(data->nodes[i].mesh_gpu_instancing.attributes_count == 0, cgltf_result_invalid_gltf);

			cgltf_accessor* first = data->nodes[i].mesh_gpu_instancing.attributes[0].data;

			for (cgltf_size k = 0; k < data->nodes[i].mesh_gpu_instancing.attributes_count; ++k)
			{
				CGLTF_ASSERT_IF(data->nodes[i].mesh_gpu_instancing.attributes[k].data->count != first->count, cgltf_result_invalid_gltf);
			}
		}
	}

	for (cgltf_size i = 0; i < data->nodes_count; ++i)
	{
		cgltf_node* p1 = data->nodes[i].parent;
		cgltf_node* p2 = p1 ? p1->parent : NULL;

		while (p1 && p2)
		{
			CGLTF_ASSERT_IF(p1 == p2, cgltf_result_invalid_gltf);

			p1 = p1->parent;
			p2 = p2->parent ? p2->parent->parent : NULL;
		}
	}

	for (cgltf_size i = 0; i < data->scenes_count; ++i)
	{
		for (cgltf_size j = 0; j < data->scenes[i].nodes_count; ++j)
		{
			CGLTF_ASSERT_IF(data->scenes[i].nodes[j]->parent, cgltf_result_invalid_gltf);
		}
	}

	for (cgltf_size i = 0; i < data->animations_count; ++i)
	{
		for (cgltf_size j = 0; j < data->animations[i].channels_count; ++j)
		{
			cgltf_animation_channel* channel = &data->animations[i].channels[j];

			if (!channel->target_node)
			{
				continue;
			}

			cgltf_size components = 1;

			if (channel->target_path == cgltf_animation_path_type_weights)
			{
				CGLTF_ASSERT_IF(!channel->target_node->mesh || !channel->target_node->mesh->primitives_count, cgltf_result_invalid_gltf);

				components = channel->target_node->mesh->primitives[0].targets_count;
			}

			cgltf_size values = channel->sampler->interpolation == cgltf_interpolation_type_cubic_spline ? 3 : 1;

			CGLTF_ASSERT_IF(channel->sampler->input->count * components * values != channel->sampler->output->count, cgltf_result_invalid_gltf);
		}
	}

	for (cgltf_size i = 0; i < data->variants_count; ++i)
	{
		CGLTF_ASSERT_IF(!data->variants[i].name, cgltf_result_invalid_gltf);
	}

	return cgltf_result_success;
}

cgltf_result cgltf_copy_extras_json(const cgltf_data* data, const cgltf_extras* extras, char* dest, cgltf_size* dest_size)
{
	cgltf_size json_size = extras->end_offset - extras->start_offset;

	if (!dest)
	{
		if (dest_size)
		{
			*dest_size = json_size + 1;
			return cgltf_result_success;
		}
		return cgltf_result_invalid_options;
	}

	if (*dest_size + 1 < json_size)
	{
		strncpy(dest, data->json + extras->start_offset, *dest_size - 1);
		dest[*dest_size - 1] = 0;
	}
	else
	{
		strncpy(dest, data->json + extras->start_offset, json_size);
		dest[json_size] = 0;
	}

	return cgltf_result_success;
}

static void cgltf_free_extras(cgltf_data* data, cgltf_extras* extras)
{
	data->memory.free_func(data->memory.user_data, extras->data);
}

static void cgltf_free_extensions(cgltf_data* data, cgltf_extension* extensions, cgltf_size extensions_count)
{
	for (cgltf_size i = 0; i < extensions_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, extensions[i].name);
		data->memory.free_func(data->memory.user_data, extensions[i].data);
	}
	data->memory.free_func(data->memory.user_data, extensions);
}

void cgltf_free(cgltf_data* data)
{
	if (!data)
	{
		return;
	}

	void (*file_release)(const struct cgltf_memory_options*, const struct cgltf_file_options*, void* data) = data->file.release ? data->file.release : cgltf_default_file_release;

	data->memory.free_func(data->memory.user_data, data->asset.copyright);
	data->memory.free_func(data->memory.user_data, data->asset.generator);
	data->memory.free_func(data->memory.user_data, data->asset.version);
	data->memory.free_func(data->memory.user_data, data->asset.min_version);

	cgltf_free_extensions(data, data->asset.extensions, data->asset.extensions_count);
	cgltf_free_extras(data, &data->asset.extras);

	for (cgltf_size i = 0; i < data->accessors_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->accessors[i].name);

		cgltf_free_extensions(data, data->accessors[i].extensions, data->accessors[i].extensions_count);
		cgltf_free_extras(data, &data->accessors[i].extras);
	}
	data->memory.free_func(data->memory.user_data, data->accessors);

	for (cgltf_size i = 0; i < data->buffer_views_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->buffer_views[i].name);
		data->memory.free_func(data->memory.user_data, data->buffer_views[i].data);

		cgltf_free_extensions(data, data->buffer_views[i].extensions, data->buffer_views[i].extensions_count);
		cgltf_free_extras(data, &data->buffer_views[i].extras);
	}
	data->memory.free_func(data->memory.user_data, data->buffer_views);

	for (cgltf_size i = 0; i < data->buffers_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->buffers[i].name);

		if (data->buffers[i].data_free_method == cgltf_data_free_method_file_release)
		{
			file_release(&data->memory, &data->file, data->buffers[i].data);
		}
		else if (data->buffers[i].data_free_method == cgltf_data_free_method_memory_free)
		{
			data->memory.free_func(data->memory.user_data, data->buffers[i].data);
		}

		data->memory.free_func(data->memory.user_data, data->buffers[i].uri);

		cgltf_free_extensions(data, data->buffers[i].extensions, data->buffers[i].extensions_count);
		cgltf_free_extras(data, &data->buffers[i].extras);
	}
	data->memory.free_func(data->memory.user_data, data->buffers);

	for (cgltf_size i = 0; i < data->meshes_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->meshes[i].name);

		for (cgltf_size j = 0; j < data->meshes[i].primitives_count; ++j)
		{
			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].attributes_count; ++k)
			{
				data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].attributes[k].name);
			}

			data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].attributes);

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].targets_count; ++k)
			{
				for (cgltf_size m = 0; m < data->meshes[i].primitives[j].targets[k].attributes_count; ++m)
				{
					data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].targets[k].attributes[m].name);
				}

				data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].targets[k].attributes);
			}

			data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].targets);

			if (data->meshes[i].primitives[j].has_draco_mesh_compression)
			{
				for (cgltf_size k = 0; k < data->meshes[i].primitives[j].draco_mesh_compression.attributes_count; ++k)
				{
					data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].draco_mesh_compression.attributes[k].name);
				}

				data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].draco_mesh_compression.attributes);
			}

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].mappings_count; ++k)
			{
				cgltf_free_extras(data, &data->meshes[i].primitives[j].mappings[k].extras);
			}

			data->memory.free_func(data->memory.user_data, data->meshes[i].primitives[j].mappings);

			cgltf_free_extensions(data, data->meshes[i].primitives[j].extensions, data->meshes[i].primitives[j].extensions_count);
			cgltf_free_extras(data, &data->meshes[i].primitives[j].extras);
		}

		data->memory.free_func(data->memory.user_data, data->meshes[i].primitives);
		data->memory.free_func(data->memory.user_data, data->meshes[i].weights);

		for (cgltf_size j = 0; j < data->meshes[i].target_names_count; ++j)
		{
			data->memory.free_func(data->memory.user_data, data->meshes[i].target_names[j]);
		}

		cgltf_free_extensions(data, data->meshes[i].extensions, data->meshes[i].extensions_count);
		cgltf_free_extras(data, &data->meshes[i].extras);

		data->memory.free_func(data->memory.user_data, data->meshes[i].target_names);
	}

	data->memory.free_func(data->memory.user_data, data->meshes);

	for (cgltf_size i = 0; i < data->materials_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->materials[i].name);

		cgltf_free_extensions(data, data->materials[i].extensions, data->materials[i].extensions_count);
		cgltf_free_extras(data, &data->materials[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->materials);

	for (cgltf_size i = 0; i < data->images_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->images[i].name);
		data->memory.free_func(data->memory.user_data, data->images[i].uri);
		data->memory.free_func(data->memory.user_data, data->images[i].mime_type);

		cgltf_free_extensions(data, data->images[i].extensions, data->images[i].extensions_count);
		cgltf_free_extras(data, &data->images[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->images);

	for (cgltf_size i = 0; i < data->textures_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->textures[i].name);

		cgltf_free_extensions(data, data->textures[i].extensions, data->textures[i].extensions_count);
		cgltf_free_extras(data, &data->textures[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->textures);

	for (cgltf_size i = 0; i < data->samplers_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->samplers[i].name);

		cgltf_free_extensions(data, data->samplers[i].extensions, data->samplers[i].extensions_count);
		cgltf_free_extras(data, &data->samplers[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->samplers);

	for (cgltf_size i = 0; i < data->skins_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->skins[i].name);
		data->memory.free_func(data->memory.user_data, data->skins[i].joints);

		cgltf_free_extensions(data, data->skins[i].extensions, data->skins[i].extensions_count);
		cgltf_free_extras(data, &data->skins[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->skins);

	for (cgltf_size i = 0; i < data->cameras_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->cameras[i].name);

		if (data->cameras[i].type == cgltf_camera_type_perspective)
		{
			cgltf_free_extras(data, &data->cameras[i].data.perspective.extras);
		}
		else if (data->cameras[i].type == cgltf_camera_type_orthographic)
		{
			cgltf_free_extras(data, &data->cameras[i].data.orthographic.extras);
		}

		cgltf_free_extensions(data, data->cameras[i].extensions, data->cameras[i].extensions_count);
		cgltf_free_extras(data, &data->cameras[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->cameras);

	for (cgltf_size i = 0; i < data->lights_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->lights[i].name);

		cgltf_free_extras(data, &data->lights[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->lights);

	for (cgltf_size i = 0; i < data->nodes_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->nodes[i].name);
		data->memory.free_func(data->memory.user_data, data->nodes[i].children);
		data->memory.free_func(data->memory.user_data, data->nodes[i].weights);

		if (data->nodes[i].has_mesh_gpu_instancing)
		{
			for (cgltf_size j = 0; j < data->nodes[i].mesh_gpu_instancing.attributes_count; ++j)
			{
				data->memory.free_func(data->memory.user_data, data->nodes[i].mesh_gpu_instancing.attributes[j].name);
			}

			data->memory.free_func(data->memory.user_data, data->nodes[i].mesh_gpu_instancing.attributes);
		}

		cgltf_free_extensions(data, data->nodes[i].extensions, data->nodes[i].extensions_count);
		cgltf_free_extras(data, &data->nodes[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->nodes);

	for (cgltf_size i = 0; i < data->scenes_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->scenes[i].name);
		data->memory.free_func(data->memory.user_data, data->scenes[i].nodes);

		cgltf_free_extensions(data, data->scenes[i].extensions, data->scenes[i].extensions_count);
		cgltf_free_extras(data, &data->scenes[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->scenes);

	for (cgltf_size i = 0; i < data->animations_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->animations[i].name);
		for (cgltf_size j = 0; j <  data->animations[i].samplers_count; ++j)
		{
			cgltf_free_extensions(data, data->animations[i].samplers[j].extensions, data->animations[i].samplers[j].extensions_count);
			cgltf_free_extras(data, &data->animations[i].samplers[j].extras);
		}
		data->memory.free_func(data->memory.user_data, data->animations[i].samplers);

		for (cgltf_size j = 0; j <  data->animations[i].channels_count; ++j)
		{
			cgltf_free_extensions(data, data->animations[i].channels[j].extensions, data->animations[i].channels[j].extensions_count);
			cgltf_free_extras(data, &data->animations[i].channels[j].extras);
		}
		data->memory.free_func(data->memory.user_data, data->animations[i].channels);

		cgltf_free_extensions(data, data->animations[i].extensions, data->animations[i].extensions_count);
		cgltf_free_extras(data, &data->animations[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->animations);

	for (cgltf_size i = 0; i < data->variants_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->variants[i].name);

		cgltf_free_extras(data, &data->variants[i].extras);
	}

	data->memory.free_func(data->memory.user_data, data->variants);

	cgltf_free_extensions(data, data->data_extensions, data->data_extensions_count);
	cgltf_free_extras(data, &data->extras);

	for (cgltf_size i = 0; i < data->extensions_used_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->extensions_used[i]);
	}

	data->memory.free_func(data->memory.user_data, data->extensions_used);

	for (cgltf_size i = 0; i < data->extensions_required_count; ++i)
	{
		data->memory.free_func(data->memory.user_data, data->extensions_required[i]);
	}

	data->memory.free_func(data->memory.user_data, data->extensions_required);

	file_release(&data->memory, &data->file, data->file_data);

	data->memory.free_func(data->memory.user_data, data);
}

void cgltf_node_transform_local(const cgltf_node* node, cgltf_float* out_matrix)
{
	cgltf_float* lm = out_matrix;

	if (node->has_matrix)
	{
		memcpy(lm, node->matrix, sizeof(float) * 16);
	}
	else
	{
		float tx = node->translation[0];
		float ty = node->translation[1];
		float tz = node->translation[2];

		float qx = node->rotation[0];
		float qy = node->rotation[1];
		float qz = node->rotation[2];
		float qw = node->rotation[3];

		float sx = node->scale[0];
		float sy = node->scale[1];
		float sz = node->scale[2];

		lm[0] = (1 - 2 * qy*qy - 2 * qz*qz) * sx;
		lm[1] = (2 * qx*qy + 2 * qz*qw) * sx;
		lm[2] = (2 * qx*qz - 2 * qy*qw) * sx;
		lm[3] = 0.f;

		lm[4] = (2 * qx*qy - 2 * qz*qw) * sy;
		lm[5] = (1 - 2 * qx*qx - 2 * qz*qz) * sy;
		lm[6] = (2 * qy*qz + 2 * qx*qw) * sy;
		lm[7] = 0.f;

		lm[8] = (2 * qx*qz + 2 * qy*qw) * sz;
		lm[9] = (2 * qy*qz - 2 * qx*qw) * sz;
		lm[10] = (1 - 2 * qx*qx - 2 * qy*qy) * sz;
		lm[11] = 0.f;

		lm[12] = tx;
		lm[13] = ty;
		lm[14] = tz;
		lm[15] = 1.f;
	}
}

void cgltf_node_transform_world(const cgltf_node* node, cgltf_float* out_matrix)
{
	cgltf_float* lm = out_matrix;
	cgltf_node_transform_local(node, lm);

	const cgltf_node* parent = node->parent;

	while (parent)
	{
		float pm[16];
		cgltf_node_transform_local(parent, pm);

		for (int i = 0; i < 4; ++i)
		{
			float l0 = lm[i * 4 + 0];
			float l1 = lm[i * 4 + 1];
			float l2 = lm[i * 4 + 2];

			float r0 = l0 * pm[0] + l1 * pm[4] + l2 * pm[8];
			float r1 = l0 * pm[1] + l1 * pm[5] + l2 * pm[9];
			float r2 = l0 * pm[2] + l1 * pm[6] + l2 * pm[10];

			lm[i * 4 + 0] = r0;
			lm[i * 4 + 1] = r1;
			lm[i * 4 + 2] = r2;
		}

		lm[12] += pm[12];
		lm[13] += pm[13];
		lm[14] += pm[14];

		parent = parent->parent;
	}
}

static cgltf_ssize cgltf_component_read_integer(const void* in, cgltf_component_type component_type)
{
	switch (component_type)
	{
		case cgltf_component_type_r_16:
			return *((const int16_t*) in);
		case cgltf_component_type_r_16u:
			return *((const uint16_t*) in);
		case cgltf_component_type_r_32u:
			return *((const uint32_t*) in);
		case cgltf_component_type_r_8:
			return *((const int8_t*) in);
		case cgltf_component_type_r_8u:
			return *((const uint8_t*) in);
		default:
			return 0;
	}
}

static cgltf_size cgltf_component_read_index(const void* in, cgltf_component_type component_type)
{
	switch (component_type)
	{
		case cgltf_component_type_r_16u:
			return *((const uint16_t*) in);
		case cgltf_component_type_r_32u:
			return *((const uint32_t*) in);
		case cgltf_component_type_r_8u:
			return *((const uint8_t*) in);
		default:
			return 0;
	}
}

static cgltf_float cgltf_component_read_float(const void* in, cgltf_component_type component_type, cgltf_bool normalized)
{
	if (component_type == cgltf_component_type_r_32f)
	{
		return *((const float*) in);
	}

	if (normalized)
	{
		switch (component_type)
		{
			// note: glTF spec doesn't currently define normalized conversions for 32-bit integers
			case cgltf_component_type_r_16:
				return *((const int16_t*) in) / (cgltf_float)32767;
			case cgltf_component_type_r_16u:
				return *((const uint16_t*) in) / (cgltf_float)65535;
			case cgltf_component_type_r_8:
				return *((const int8_t*) in) / (cgltf_float)127;
			case cgltf_component_type_r_8u:
				return *((const uint8_t*) in) / (cgltf_float)255;
			default:
				return 0;
		}
	}

	return (cgltf_float)cgltf_component_read_integer(in, component_type);
}

static cgltf_bool cgltf_element_read_float(const uint8_t* element, cgltf_type type, cgltf_component_type component_type, cgltf_bool normalized, cgltf_float* out, cgltf_size element_size)
{
	cgltf_size num_components = cgltf_num_components(type);

	if (element_size < num_components) {
		return 0;
	}

	// There are three special cases for component extraction, see #data-alignment in the 2.0 spec.

	cgltf_size component_size = cgltf_component_size(component_type);

	if (type == cgltf_type_mat2 && component_size == 1)
	{
		out[0] = cgltf_component_read_float(element, component_type, normalized);
		out[1] = cgltf_component_read_float(element + 1, component_type, normalized);
		out[2] = cgltf_component_read_float(element + 4, component_type, normalized);
		out[3] = cgltf_component_read_float(element + 5, component_type, normalized);
		return 1;
	}

	if (type == cgltf_type_mat3 && component_size == 1)
	{
		out[0] = cgltf_component_read_float(element, component_type, normalized);
		out[1] = cgltf_component_read_float(element + 1, component_type, normalized);
		out[2] = cgltf_component_read_float(element + 2, component_type, normalized);
		out[3] = cgltf_component_read_float(element + 4, component_type, normalized);
		out[4] = cgltf_component_read_float(element + 5, component_type, normalized);
		out[5] = cgltf_component_read_float(element + 6, component_type, normalized);
		out[6] = cgltf_component_read_float(element + 8, component_type, normalized);
		out[7] = cgltf_component_read_float(element + 9, component_type, normalized);
		out[8] = cgltf_component_read_float(element + 10, component_type, normalized);
		return 1;
	}

	if (type == cgltf_type_mat3 && component_size == 2)
	{
		out[0] = cgltf_component_read_float(element, component_type, normalized);
		out[1] = cgltf_component_read_float(element + 2, component_type, normalized);
		out[2] = cgltf_component_read_float(element + 4, component_type, normalized);
		out[3] = cgltf_component_read_float(element + 8, component_type, normalized);
		out[4] = cgltf_component_read_float(element + 10, component_type, normalized);
		out[5] = cgltf_component_read_float(element + 12, component_type, normalized);
		out[6] = cgltf_component_read_float(element + 16, component_type, normalized);
		out[7] = cgltf_component_read_float(element + 18, component_type, normalized);
		out[8] = cgltf_component_read_float(element + 20, component_type, normalized);
		return 1;
	}

	for (cgltf_size i = 0; i < num_components; ++i)
	{
		out[i] = cgltf_component_read_float(element + component_size * i, component_type, normalized);
	}
	return 1;
}

const uint8_t* cgltf_buffer_view_data(const cgltf_buffer_view* view)
{
	if (view->data)
		return (const uint8_t*)view->data;

	if (!view->buffer->data)
		return NULL;

	const uint8_t* result = (const uint8_t*)view->buffer->data;
	result += view->offset;
	return result;
}

const cgltf_accessor* cgltf_find_accessor(const cgltf_primitive* prim, cgltf_attribute_type type, cgltf_int index)
{
	for (cgltf_size i = 0; i < prim->attributes_count; ++i)
	{
		const cgltf_attribute* attr = &prim->attributes[i];
		if (attr->type == type && attr->index == index)
			return attr->data;
	}

	return NULL;
}

static const uint8_t* cgltf_find_sparse_index(const cgltf_accessor* accessor, cgltf_size needle)
{
	const cgltf_accessor_sparse* sparse = &accessor->sparse;
	const uint8_t* index_data = cgltf_buffer_view_data(sparse->indices_buffer_view);
	const uint8_t* value_data = cgltf_buffer_view_data(sparse->values_buffer_view);

	if (index_data == NULL || value_data == NULL)
		return NULL;

	index_data += sparse->indices_byte_offset;
	value_data += sparse->values_byte_offset;

	cgltf_size index_stride = cgltf_component_size(sparse->indices_component_type);

	cgltf_size offset = 0;
	cgltf_size length = sparse->count;

	while (length)
	{
		cgltf_size rem = length % 2;
		length /= 2;

		cgltf_size index = cgltf_component_read_index(index_data + (offset + length) * index_stride, sparse->indices_component_type);
		offset += index < needle ? length + rem : 0;
	}

	if (offset == sparse->count)
		return NULL;

	cgltf_size index = cgltf_component_read_index(index_data + offset * index_stride, sparse->indices_component_type);
	return index == needle ? value_data + offset * accessor->stride : NULL;
}

cgltf_bool cgltf_accessor_read_float(const cgltf_accessor* accessor, cgltf_size index, cgltf_float* out, cgltf_size element_size)
{
	if (accessor->is_sparse)
	{
		const uint8_t* element = cgltf_find_sparse_index(accessor, index);
		if (element)
			return cgltf_element_read_float(element, accessor->type, accessor->component_type, accessor->normalized, out, element_size);
	}
	if (accessor->buffer_view == NULL)
	{
		memset(out, 0, element_size * sizeof(cgltf_float));
		return 1;
	}
	const uint8_t* element = cgltf_buffer_view_data(accessor->buffer_view);
	if (element == NULL)
	{
		return 0;
	}
	element += accessor->offset + accessor->stride * index;
	return cgltf_element_read_float(element, accessor->type, accessor->component_type, accessor->normalized, out, element_size);
}

cgltf_size cgltf_accessor_unpack_floats(const cgltf_accessor* accessor, cgltf_float* out, cgltf_size float_count)
{
	cgltf_size floats_per_element = cgltf_num_components(accessor->type);
	cgltf_size available_floats = accessor->count * floats_per_element;
	if (out == NULL)
	{
		return available_floats;
	}

	float_count = available_floats < float_count ? available_floats : float_count;
	cgltf_size element_count = float_count / floats_per_element;

	// First pass: convert each element in the base accessor.
	if (accessor->buffer_view == NULL)
	{
		memset(out, 0, element_count * floats_per_element * sizeof(cgltf_float));
	}
	else
	{
		const uint8_t* element = cgltf_buffer_view_data(accessor->buffer_view);
		if (element == NULL)
		{
			return 0;
		}
		element += accessor->offset;

		if (accessor->component_type == cgltf_component_type_r_32f && accessor->stride == floats_per_element * sizeof(cgltf_float))
		{
			memcpy(out, element, element_count * floats_per_element * sizeof(cgltf_float));
		}
		else
		{
			cgltf_float* dest = out;

			for (cgltf_size index = 0; index < element_count; index++, dest += floats_per_element, element += accessor->stride)
			{
				if (!cgltf_element_read_float(element, accessor->type, accessor->component_type, accessor->normalized, dest, floats_per_element))
				{
					return 0;
				}
			}
		}
	}

	// Second pass: write out each element in the sparse accessor.
	if (accessor->is_sparse)
	{
		const cgltf_accessor_sparse* sparse = &accessor->sparse;

		const uint8_t* index_data = cgltf_buffer_view_data(sparse->indices_buffer_view);
		const uint8_t* reader_head = cgltf_buffer_view_data(sparse->values_buffer_view);

		if (index_data == NULL || reader_head == NULL)
		{
			return 0;
		}

		index_data += sparse->indices_byte_offset;
		reader_head += sparse->values_byte_offset;

		cgltf_size index_stride = cgltf_component_size(sparse->indices_component_type);
		for (cgltf_size reader_index = 0; reader_index < sparse->count; reader_index++, index_data += index_stride, reader_head += accessor->stride)
		{
			size_t writer_index = cgltf_component_read_index(index_data, sparse->indices_component_type);
			float* writer_head = out + writer_index * floats_per_element;

			if (!cgltf_element_read_float(reader_head, accessor->type, accessor->component_type, accessor->normalized, writer_head, floats_per_element))
			{
				return 0;
			}
		}
	}

	return element_count * floats_per_element;
}

static cgltf_uint cgltf_component_read_uint(const void* in, cgltf_component_type component_type)
{
	switch (component_type)
	{
		case cgltf_component_type_r_8:
			return *((const int8_t*) in);

		case cgltf_component_type_r_8u:
			return *((const uint8_t*) in);

		case cgltf_component_type_r_16:
			return *((const int16_t*) in);

		case cgltf_component_type_r_16u:
			return *((const uint16_t*) in);

		case cgltf_component_type_r_32u:
			return *((const uint32_t*) in);

		default:
			return 0;
	}
}

static cgltf_bool cgltf_element_read_uint(const uint8_t* element, cgltf_type type, cgltf_component_type component_type, cgltf_uint* out, cgltf_size element_size)
{
	cgltf_size num_components = cgltf_num_components(type);

	if (element_size < num_components)
	{
		return 0;
	}

	// Reading integer matrices is not a valid use case
	if (type == cgltf_type_mat2 || type == cgltf_type_mat3 || type == cgltf_type_mat4)
	{
		return 0;
	}

	cgltf_size component_size = cgltf_component_size(component_type);

	for (cgltf_size i = 0; i < num_components; ++i)
	{
		out[i] = cgltf_component_read_uint(element + component_size * i, component_type);
	}
	return 1;
}

cgltf_bool cgltf_accessor_read_uint(const cgltf_accessor* accessor, cgltf_size index, cgltf_uint* out, cgltf_size element_size)
{
	if (accessor->is_sparse)
	{
		const uint8_t* element = cgltf_find_sparse_index(accessor, index);
		if (element)
			return cgltf_element_read_uint(element, accessor->type, accessor->component_type, out, element_size);
	}
	if (accessor->buffer_view == NULL)
	{
		memset(out, 0, element_size * sizeof(cgltf_uint));
		return 1;
	}
	const uint8_t* element = cgltf_buffer_view_data(accessor->buffer_view);
	if (element == NULL)
	{
		return 0;
	}
	element += accessor->offset + accessor->stride * index;
	return cgltf_element_read_uint(element, accessor->type, accessor->component_type, out, element_size);
}

cgltf_size cgltf_accessor_read_index(const cgltf_accessor* accessor, cgltf_size index)
{
	if (accessor->is_sparse)
	{
		const uint8_t* element = cgltf_find_sparse_index(accessor, index);
		if (element)
			return cgltf_component_read_index(element, accessor->component_type);
	}
	if (accessor->buffer_view == NULL)
	{
		return 0;
	}
	const uint8_t* element = cgltf_buffer_view_data(accessor->buffer_view);
	if (element == NULL)
	{
		return 0; // This is an error case, but we can't communicate the error with existing interface.
	}
	element += accessor->offset + accessor->stride * index;
	return cgltf_component_read_index(element, accessor->component_type);
}

cgltf_size cgltf_mesh_index(const cgltf_data* data, const cgltf_mesh* object)
{
	assert(object && (cgltf_size)(object - data->meshes) < data->meshes_count);
	return (cgltf_size)(object - data->meshes);
}

cgltf_size cgltf_material_index(const cgltf_data* data, const cgltf_material* object)
{
	assert(object && (cgltf_size)(object - data->materials) < data->materials_count);
	return (cgltf_size)(object - data->materials);
}

cgltf_size cgltf_accessor_index(const cgltf_data* data, const cgltf_accessor* object)
{
	assert(object && (cgltf_size)(object - data->accessors) < data->accessors_count);
	return (cgltf_size)(object - data->accessors);
}

cgltf_size cgltf_buffer_view_index(const cgltf_data* data, const cgltf_buffer_view* object)
{
	assert(object && (cgltf_size)(object - data->buffer_views) < data->buffer_views_count);
	return (cgltf_size)(object - data->buffer_views);
}

cgltf_size cgltf_buffer_index(const cgltf_data* data, const cgltf_buffer* object)
{
	assert(object && (cgltf_size)(object - data->buffers) < data->buffers_count);
	return (cgltf_size)(object - data->buffers);
}

cgltf_size cgltf_image_index(const cgltf_data* data, const cgltf_image* object)
{
	assert(object && (cgltf_size)(object - data->images) < data->images_count);
	return (cgltf_size)(object - data->images);
}

cgltf_size cgltf_texture_index(const cgltf_data* data, const cgltf_texture* object)
{
	assert(object && (cgltf_size)(object - data->textures) < data->textures_count);
	return (cgltf_size)(object - data->textures);
}

cgltf_size cgltf_sampler_index(const cgltf_data* data, const cgltf_sampler* object)
{
	assert(object && (cgltf_size)(object - data->samplers) < data->samplers_count);
	return (cgltf_size)(object - data->samplers);
}

cgltf_size cgltf_skin_index(const cgltf_data* data, const cgltf_skin* object)
{
	assert(object && (cgltf_size)(object - data->skins) < data->skins_count);
	return (cgltf_size)(object - data->skins);
}

cgltf_size cgltf_camera_index(const cgltf_data* data, const cgltf_camera* object)
{
	assert(object && (cgltf_size)(object - data->cameras) < data->cameras_count);
	return (cgltf_size)(object - data->cameras);
}

cgltf_size cgltf_light_index(const cgltf_data* data, const cgltf_light* object)
{
	assert(object && (cgltf_size)(object - data->lights) < data->lights_count);
	return (cgltf_size)(object - data->lights);
}

cgltf_size cgltf_node_index(const cgltf_data* data, const cgltf_node* object)
{
	assert(object && (cgltf_size)(object - data->nodes) < data->nodes_count);
	return (cgltf_size)(object - data->nodes);
}

cgltf_size cgltf_scene_index(const cgltf_data* data, const cgltf_scene* object)
{
	assert(object && (cgltf_size)(object - data->scenes) < data->scenes_count);
	return (cgltf_size)(object - data->scenes);
}

cgltf_size cgltf_animation_index(const cgltf_data* data, const cgltf_animation* object)
{
	assert(object && (cgltf_size)(object - data->animations) < data->animations_count);
	return (cgltf_size)(object - data->animations);
}

cgltf_size cgltf_animation_sampler_index(const cgltf_animation* animation, const cgltf_animation_sampler* object)
{
	assert(object && (cgltf_size)(object - animation->samplers) < animation->samplers_count);
	return (cgltf_size)(object - animation->samplers);
}

cgltf_size cgltf_animation_channel_index(const cgltf_animation* animation, const cgltf_animation_channel* object)
{
	assert(object && (cgltf_size)(object - animation->channels) < animation->channels_count);
	return (cgltf_size)(object - animation->channels);
}

cgltf_size cgltf_accessor_unpack_indices(const cgltf_accessor* accessor, void* out, cgltf_size out_component_size, cgltf_size index_count)
{
	if (out == NULL)
	{
		return accessor->count;
	}

	cgltf_size numbers_per_element = cgltf_num_components(accessor->type);
	cgltf_size available_numbers = accessor->count * numbers_per_element;

	index_count = available_numbers < index_count ? available_numbers : index_count;
	cgltf_size index_component_size = cgltf_component_size(accessor->component_type);

	if (accessor->is_sparse)
	{
		return 0;
	}
	if (accessor->buffer_view == NULL)
	{
		return 0;
	}
	if (index_component_size > out_component_size)
	{
		return 0;
	}
	const uint8_t* element = cgltf_buffer_view_data(accessor->buffer_view);
	if (element == NULL)
	{
		return 0;
	}
	element += accessor->offset;

	if (index_component_size == out_component_size && accessor->stride == out_component_size * numbers_per_element)
	{
		memcpy(out, element, index_count * index_component_size);
		return index_count;
	}

	// Data couldn't be copied with memcpy due to stride being larger than the component size.
	// OR
	// The component size of the output array is larger than the component size of the index data, so index data will be padded.
	switch (out_component_size)
	{
	case 1:
		for (cgltf_size index = 0; index < index_count; index++, element += accessor->stride)
		{
			((uint8_t*)out)[index] = (uint8_t)cgltf_component_read_index(element, accessor->component_type);
		}
		break;
	case 2:
		for (cgltf_size index = 0; index < index_count; index++, element += accessor->stride)
		{
			((uint16_t*)out)[index] = (uint16_t)cgltf_component_read_index(element, accessor->component_type);
		}
		break;
	case 4:
		for (cgltf_size index = 0; index < index_count; index++, element += accessor->stride)
		{
			((uint32_t*)out)[index] = (uint32_t)cgltf_component_read_index(element, accessor->component_type);
		}
		break;
	default:
		return 0;
	}

	return index_count;
}

#define CGLTF_ERROR_JSON -1
#define CGLTF_ERROR_NOMEM -2
#define CGLTF_ERROR_LEGACY -3

#define CGLTF_CHECK_TOKTYPE(tok_, type_) if ((tok_).type != (type_)) { return CGLTF_ERROR_JSON; }
#define CGLTF_CHECK_TOKTYPE_RET(tok_, type_, ret_) if ((tok_).type != (type_)) { return ret_; }
#define CGLTF_CHECK_KEY(tok_) if ((tok_).type != JSMN_STRING || (tok_).size == 0) { return CGLTF_ERROR_JSON; } /* checking size for 0 verifies that a value follows the key */

#define CGLTF_PTRINDEX(type, idx) (type*)((cgltf_size)idx + 1)
#define CGLTF_PTRFIXUP(var, data, size) if (var) { if ((cgltf_size)var > size) { return CGLTF_ERROR_JSON; } var = &data[(cgltf_size)var-1]; }
#define CGLTF_PTRFIXUP_REQ(var, data, size) if (!var || (cgltf_size)var > size) { return CGLTF_ERROR_JSON; } var = &data[(cgltf_size)var-1];

static int cgltf_json_strcmp(jsmntok_t const* tok, const uint8_t* json_chunk, const char* str)
{
	CGLTF_CHECK_TOKTYPE(*tok, JSMN_STRING);
	size_t const str_len = strlen(str);
	size_t const name_length = (size_t)(tok->end - tok->start);
	return (str_len == name_length) ? strncmp((const char*)json_chunk + tok->start, str, str_len) : 128;
}

static int cgltf_json_to_int(jsmntok_t const* tok, const uint8_t* json_chunk)
{
	CGLTF_CHECK_TOKTYPE(*tok, JSMN_PRIMITIVE);
	char tmp[128];
	int size = (size_t)(tok->end - tok->start) < sizeof(tmp) ? (int)(tok->end - tok->start) : (int)(sizeof(tmp) - 1);
	strncpy(tmp, (const char*)json_chunk + tok->start, size);
	tmp[size] = 0;
	return CGLTF_ATOI(tmp);
}

static cgltf_size cgltf_json_to_size(jsmntok_t const* tok, const uint8_t* json_chunk)
{
	CGLTF_CHECK_TOKTYPE_RET(*tok, JSMN_PRIMITIVE, 0);
	char tmp[128];
	int size = (size_t)(tok->end - tok->start) < sizeof(tmp) ? (int)(tok->end - tok->start) : (int)(sizeof(tmp) - 1);
	strncpy(tmp, (const char*)json_chunk + tok->start, size);
	tmp[size] = 0;
	long long res = CGLTF_ATOLL(tmp);
	return res < 0 ? 0 : (cgltf_size)res;
}

static cgltf_float cgltf_json_to_float(jsmntok_t const* tok, const uint8_t* json_chunk)
{
	CGLTF_CHECK_TOKTYPE(*tok, JSMN_PRIMITIVE);
	char tmp[128];
	int size = (size_t)(tok->end - tok->start) < sizeof(tmp) ? (int)(tok->end - tok->start) : (int)(sizeof(tmp) - 1);
	strncpy(tmp, (const char*)json_chunk + tok->start, size);
	tmp[size] = 0;
	return (cgltf_float)CGLTF_ATOF(tmp);
}

static cgltf_bool cgltf_json_to_bool(jsmntok_t const* tok, const uint8_t* json_chunk)
{
	int size = (int)(tok->end - tok->start);
	return size == 4 && memcmp(json_chunk + tok->start, "true", 4) == 0;
}

static int cgltf_skip_json(jsmntok_t const* tokens, int i)
{
	int end = i + 1;

	while (i < end)
	{
		switch (tokens[i].type)
		{
		case JSMN_OBJECT:
			end += tokens[i].size * 2;
			break;

		case JSMN_ARRAY:
			end += tokens[i].size;
			break;

		case JSMN_PRIMITIVE:
		case JSMN_STRING:
			break;

		default:
			return -1;
		}

		i++;
	}

	return i;
}

static void cgltf_fill_float_array(float* out_array, int size, float value)
{
	for (int j = 0; j < size; ++j)
	{
		out_array[j] = value;
	}
}

static int cgltf_parse_json_float_array(jsmntok_t const* tokens, int i, const uint8_t* json_chunk, float* out_array, int size)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_ARRAY);
	if (tokens[i].size != size)
	{
		return CGLTF_ERROR_JSON;
	}
	++i;
	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
		out_array[j] = cgltf_json_to_float(tokens + i, json_chunk);
		++i;
	}
	return i;
}

static int cgltf_parse_json_string(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, char** out_string)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_STRING);
	if (*out_string)
	{
		return CGLTF_ERROR_JSON;
	}
	int size = (int)(tokens[i].end - tokens[i].start);
	char* result = (char*)options->memory.alloc_func(options->memory.user_data, size + 1);
	if (!result)
	{
		return CGLTF_ERROR_NOMEM;
	}
	strncpy(result, (const char*)json_chunk + tokens[i].start, size);
	result[size] = 0;
	*out_string = result;
	return i + 1;
}

static int cgltf_parse_json_array(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, size_t element_size, void** out_array, cgltf_size* out_size)
{
	(void)json_chunk;
	if (tokens[i].type != JSMN_ARRAY)
	{
		return tokens[i].type == JSMN_OBJECT ? CGLTF_ERROR_LEGACY : CGLTF_ERROR_JSON;
	}
	if (*out_array)
	{
		return CGLTF_ERROR_JSON;
	}
	int size = tokens[i].size;
	void* result = cgltf_calloc(options, element_size, size);
	if (!result)
	{
		return CGLTF_ERROR_NOMEM;
	}
	*out_array = result;
	*out_size = size;
	return i + 1;
}

static int cgltf_parse_json_string_array(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, char*** out_array, cgltf_size* out_size)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_ARRAY);
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(char*), (void**)out_array, out_size);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < *out_size; ++j)
	{
		i = cgltf_parse_json_string(options, tokens, i, json_chunk, j + (*out_array));
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static void cgltf_parse_attribute_type(const char* name, cgltf_attribute_type* out_type, int* out_index)
{
	if (*name == '_')
	{
		*out_type = cgltf_attribute_type_custom;
		return;
	}

	const char* us = strchr(name, '_');
	size_t len = us ? (size_t)(us - name) : strlen(name);

	if (len == 8 && strncmp(name, "POSITION", 8) == 0)
	{
		*out_type = cgltf_attribute_type_position;
	}
	else if (len == 6 && strncmp(name, "NORMAL", 6) == 0)
	{
		*out_type = cgltf_attribute_type_normal;
	}
	else if (len == 7 && strncmp(name, "TANGENT", 7) == 0)
	{
		*out_type = cgltf_attribute_type_tangent;
	}
	else if (len == 8 && strncmp(name, "TEXCOORD", 8) == 0)
	{
		*out_type = cgltf_attribute_type_texcoord;
	}
	else if (len == 5 && strncmp(name, "COLOR", 5) == 0)
	{
		*out_type = cgltf_attribute_type_color;
	}
	else if (len == 6 && strncmp(name, "JOINTS", 6) == 0)
	{
		*out_type = cgltf_attribute_type_joints;
	}
	else if (len == 7 && strncmp(name, "WEIGHTS", 7) == 0)
	{
		*out_type = cgltf_attribute_type_weights;
	}
	else
	{
		*out_type = cgltf_attribute_type_invalid;
	}

	if (us && *out_type != cgltf_attribute_type_invalid)
	{
		*out_index = CGLTF_ATOI(us + 1);
		if (*out_index < 0)
		{
			*out_type = cgltf_attribute_type_invalid;
			*out_index = 0;
		}
	}
}

static int cgltf_parse_json_attribute_list(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_attribute** out_attributes, cgltf_size* out_attributes_count)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	if (*out_attributes)
	{
		return CGLTF_ERROR_JSON;
	}

	*out_attributes_count = tokens[i].size;
	*out_attributes = (cgltf_attribute*)cgltf_calloc(options, sizeof(cgltf_attribute), *out_attributes_count);
	++i;

	if (!*out_attributes)
	{
		return CGLTF_ERROR_NOMEM;
	}

	for (cgltf_size j = 0; j < *out_attributes_count; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		i = cgltf_parse_json_string(options, tokens, i, json_chunk, &(*out_attributes)[j].name);
		if (i < 0)
		{
			return CGLTF_ERROR_JSON;
		}

		cgltf_parse_attribute_type((*out_attributes)[j].name, &(*out_attributes)[j].type, &(*out_attributes)[j].index);

		(*out_attributes)[j].data = CGLTF_PTRINDEX(cgltf_accessor, cgltf_json_to_int(tokens + i, json_chunk));
		++i;
	}

	return i;
}

static int cgltf_parse_json_extras(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_extras* out_extras)
{
	if (out_extras->data)
	{
		return CGLTF_ERROR_JSON;
	}

	/* fill deprecated fields for now, this will be removed in the future */
	out_extras->start_offset = tokens[i].start;
	out_extras->end_offset = tokens[i].end;

	size_t start = tokens[i].start;
	size_t size = tokens[i].end - start;
	out_extras->data = (char*)options->memory.alloc_func(options->memory.user_data, size + 1);
	if (!out_extras->data)
	{
		return CGLTF_ERROR_NOMEM;
	}
	strncpy(out_extras->data, (const char*)json_chunk + start, size);
	out_extras->data[size] = '\0';

	i = cgltf_skip_json(tokens, i);
	return i;
}

static int cgltf_parse_json_unprocessed_extension(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_extension* out_extension)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_STRING);
	CGLTF_CHECK_TOKTYPE(tokens[i+1], JSMN_OBJECT);
	if (out_extension->name)
	{
		return CGLTF_ERROR_JSON;
	}

	cgltf_size name_length = tokens[i].end - tokens[i].start;
	out_extension->name = (char*)options->memory.alloc_func(options->memory.user_data, name_length + 1);
	if (!out_extension->name)
	{
		return CGLTF_ERROR_NOMEM;
	}
	strncpy(out_extension->name, (const char*)json_chunk + tokens[i].start, name_length);
	out_extension->name[name_length] = 0;
	i++;

	size_t start = tokens[i].start;
	size_t size = tokens[i].end - start;
	out_extension->data = (char*)options->memory.alloc_func(options->memory.user_data, size + 1);
	if (!out_extension->data)
	{
		return CGLTF_ERROR_NOMEM;
	}
	strncpy(out_extension->data, (const char*)json_chunk + start, size);
	out_extension->data[size] = '\0';

	i = cgltf_skip_json(tokens, i);

	return i;
}

static int cgltf_parse_json_unprocessed_extensions(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_size* out_extensions_count, cgltf_extension** out_extensions)
{
	++i;

	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	if(*out_extensions)
	{
		return CGLTF_ERROR_JSON;
	}

	int extensions_size = tokens[i].size;
	*out_extensions_count = 0;
	*out_extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);

	if (!*out_extensions)
	{
		return CGLTF_ERROR_NOMEM;
	}

	++i;

	for (int j = 0; j < extensions_size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		cgltf_size extension_index = (*out_extensions_count)++;
		cgltf_extension* extension = &((*out_extensions)[extension_index]);
		i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, extension);

		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_draco_mesh_compression(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_draco_mesh_compression* out_draco_mesh_compression)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "attributes") == 0)
		{
			i = cgltf_parse_json_attribute_list(options, tokens, i + 1, json_chunk, &out_draco_mesh_compression->attributes, &out_draco_mesh_compression->attributes_count);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "bufferView") == 0)
		{
			++i;
			out_draco_mesh_compression->buffer_view = CGLTF_PTRINDEX(cgltf_buffer_view, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_mesh_gpu_instancing(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_mesh_gpu_instancing* out_mesh_gpu_instancing)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "attributes") == 0)
		{
			i = cgltf_parse_json_attribute_list(options, tokens, i + 1, json_chunk, &out_mesh_gpu_instancing->attributes, &out_mesh_gpu_instancing->attributes_count);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_material_mapping_data(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_material_mapping* out_mappings, cgltf_size* offset)
{
	(void)options;
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_ARRAY);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

		int obj_size = tokens[i].size;
		++i;

		int material = -1;
		int variants_tok = -1;
		int extras_tok = -1;

		for (int k = 0; k < obj_size; ++k)
		{
			CGLTF_CHECK_KEY(tokens[i]);

			if (cgltf_json_strcmp(tokens + i, json_chunk, "material") == 0)
			{
				++i;
				material = cgltf_json_to_int(tokens + i, json_chunk);
				++i;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "variants") == 0)
			{
				variants_tok = i+1;
				CGLTF_CHECK_TOKTYPE(tokens[variants_tok], JSMN_ARRAY);

				i = cgltf_skip_json(tokens, i+1);
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
			{
				extras_tok = i + 1;
				i = cgltf_skip_json(tokens, extras_tok);
			}
			else
			{
				i = cgltf_skip_json(tokens, i+1);
			}

			if (i < 0)
			{
				return i;
			}
		}

		if (material < 0 || variants_tok < 0)
		{
			return CGLTF_ERROR_JSON;
		}

		if (out_mappings)
		{
			for (int k = 0; k < tokens[variants_tok].size; ++k)
			{
				int variant = cgltf_json_to_int(&tokens[variants_tok + 1 + k], json_chunk);
				if (variant < 0)
					return variant;

				out_mappings[*offset].material = CGLTF_PTRINDEX(cgltf_material, material);
				out_mappings[*offset].variant = variant;

				if (extras_tok >= 0)
				{
					int e = cgltf_parse_json_extras(options, tokens, extras_tok, json_chunk, &out_mappings[*offset].extras);
					if (e < 0)
						return e;
				}

				(*offset)++;
			}
		}
		else
		{
			(*offset) += tokens[variants_tok].size;
		}
	}

	return i;
}

static int cgltf_parse_json_material_mappings(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_primitive* out_prim)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "mappings") == 0)
		{
			if (out_prim->mappings)
			{
				return CGLTF_ERROR_JSON;
			}

			cgltf_size mappings_offset = 0;
			int k = cgltf_parse_json_material_mapping_data(options, tokens, i + 1, json_chunk, NULL, &mappings_offset);
			if (k < 0)
			{
				return k;
			}

			out_prim->mappings_count = mappings_offset;
			out_prim->mappings = (cgltf_material_mapping*)cgltf_calloc(options, sizeof(cgltf_material_mapping), out_prim->mappings_count);

			mappings_offset = 0;
			i = cgltf_parse_json_material_mapping_data(options, tokens, i + 1, json_chunk, out_prim->mappings, &mappings_offset);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static cgltf_primitive_type cgltf_json_to_primitive_type(jsmntok_t const* tok, const uint8_t* json_chunk)
{
	int type = cgltf_json_to_int(tok, json_chunk);

	switch (type)
	{
	case 0:
		return cgltf_primitive_type_points;
	case 1:
		return cgltf_primitive_type_lines;
	case 2:
		return cgltf_primitive_type_line_loop;
	case 3:
		return cgltf_primitive_type_line_strip;
	case 4:
		return cgltf_primitive_type_triangles;
	case 5:
		return cgltf_primitive_type_triangle_strip;
	case 6:
		return cgltf_primitive_type_triangle_fan;
	default:
		return cgltf_primitive_type_invalid;
	}
}

static int cgltf_parse_json_primitive(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_primitive* out_prim)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	out_prim->type = cgltf_primitive_type_triangles;

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "mode") == 0)
		{
			++i;
			out_prim->type = cgltf_json_to_primitive_type(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "indices") == 0)
		{
			++i;
			out_prim->indices = CGLTF_PTRINDEX(cgltf_accessor, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "material") == 0)
		{
			++i;
			out_prim->material = CGLTF_PTRINDEX(cgltf_material, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "attributes") == 0)
		{
			i = cgltf_parse_json_attribute_list(options, tokens, i + 1, json_chunk, &out_prim->attributes, &out_prim->attributes_count);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "targets") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_morph_target), (void**)&out_prim->targets, &out_prim->targets_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size k = 0; k < out_prim->targets_count; ++k)
			{
				i = cgltf_parse_json_attribute_list(options, tokens, i, json_chunk, &out_prim->targets[k].attributes, &out_prim->targets[k].attributes_count);
				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_prim->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			if(out_prim->extensions)
			{
				return CGLTF_ERROR_JSON;
			}

			int extensions_size = tokens[i].size;
			out_prim->extensions_count = 0;
			out_prim->extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);

			if (!out_prim->extensions)
			{
				return CGLTF_ERROR_NOMEM;
			}

			++i;
			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_draco_mesh_compression") == 0)
				{
					out_prim->has_draco_mesh_compression = 1;
					i = cgltf_parse_json_draco_mesh_compression(options, tokens, i + 1, json_chunk, &out_prim->draco_mesh_compression);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_variants") == 0)
				{
					i = cgltf_parse_json_material_mappings(options, tokens, i + 1, json_chunk, out_prim);
				}
				else
				{
					i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, &(out_prim->extensions[out_prim->extensions_count++]));
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_mesh(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_mesh* out_mesh)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_mesh->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "primitives") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_primitive), (void**)&out_mesh->primitives, &out_mesh->primitives_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size prim_index = 0; prim_index < out_mesh->primitives_count; ++prim_index)
			{
				i = cgltf_parse_json_primitive(options, tokens, i, json_chunk, &out_mesh->primitives[prim_index]);
				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "weights") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_float), (void**)&out_mesh->weights, &out_mesh->weights_count);
			if (i < 0)
			{
				return i;
			}

			i = cgltf_parse_json_float_array(tokens, i - 1, json_chunk, out_mesh->weights, (int)out_mesh->weights_count);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			++i;

			out_mesh->extras.start_offset = tokens[i].start;
			out_mesh->extras.end_offset = tokens[i].end;

			if (tokens[i].type == JSMN_OBJECT)
			{
				int extras_size = tokens[i].size;
				++i;

				for (int k = 0; k < extras_size; ++k)
				{
					CGLTF_CHECK_KEY(tokens[i]);

					if (cgltf_json_strcmp(tokens+i, json_chunk, "targetNames") == 0 && tokens[i+1].type == JSMN_ARRAY)
					{
						i = cgltf_parse_json_string_array(options, tokens, i + 1, json_chunk, &out_mesh->target_names, &out_mesh->target_names_count);
					}
					else
					{
						i = cgltf_skip_json(tokens, i+1);
					}

					if (i < 0)
					{
						return i;
					}
				}
			}
			else
			{
				i = cgltf_skip_json(tokens, i);
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_mesh->extensions_count, &out_mesh->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_meshes(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_mesh), (void**)&out_data->meshes, &out_data->meshes_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->meshes_count; ++j)
	{
		i = cgltf_parse_json_mesh(options, tokens, i, json_chunk, &out_data->meshes[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static cgltf_component_type cgltf_json_to_component_type(jsmntok_t const* tok, const uint8_t* json_chunk)
{
	int type = cgltf_json_to_int(tok, json_chunk);

	switch (type)
	{
	case 5120:
		return cgltf_component_type_r_8;
	case 5121:
		return cgltf_component_type_r_8u;
	case 5122:
		return cgltf_component_type_r_16;
	case 5123:
		return cgltf_component_type_r_16u;
	case 5125:
		return cgltf_component_type_r_32u;
	case 5126:
		return cgltf_component_type_r_32f;
	default:
		return cgltf_component_type_invalid;
	}
}

static int cgltf_parse_json_accessor_sparse(jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_accessor_sparse* out_sparse)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "count") == 0)
		{
			++i;
			out_sparse->count = cgltf_json_to_size(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "indices") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

			int indices_size = tokens[i].size;
			++i;

			for (int k = 0; k < indices_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "bufferView") == 0)
				{
					++i;
					out_sparse->indices_buffer_view = CGLTF_PTRINDEX(cgltf_buffer_view, cgltf_json_to_int(tokens + i, json_chunk));
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteOffset") == 0)
				{
					++i;
					out_sparse->indices_byte_offset = cgltf_json_to_size(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "componentType") == 0)
				{
					++i;
					out_sparse->indices_component_type = cgltf_json_to_component_type(tokens + i, json_chunk);
					++i;
				}
				else
				{
					i = cgltf_skip_json(tokens, i+1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "values") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

			int values_size = tokens[i].size;
			++i;

			for (int k = 0; k < values_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "bufferView") == 0)
				{
					++i;
					out_sparse->values_buffer_view = CGLTF_PTRINDEX(cgltf_buffer_view, cgltf_json_to_int(tokens + i, json_chunk));
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteOffset") == 0)
				{
					++i;
					out_sparse->values_byte_offset = cgltf_json_to_size(tokens + i, json_chunk);
					++i;
				}
				else
				{
					i = cgltf_skip_json(tokens, i+1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_accessor(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_accessor* out_accessor)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_accessor->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "bufferView") == 0)
		{
			++i;
			out_accessor->buffer_view = CGLTF_PTRINDEX(cgltf_buffer_view, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteOffset") == 0)
		{
			++i;
			out_accessor->offset =
					cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "componentType") == 0)
		{
			++i;
			out_accessor->component_type = cgltf_json_to_component_type(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "normalized") == 0)
		{
			++i;
			out_accessor->normalized = cgltf_json_to_bool(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "count") == 0)
		{
			++i;
			out_accessor->count = cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "type") == 0)
		{
			++i;
			if (cgltf_json_strcmp(tokens+i, json_chunk, "SCALAR") == 0)
			{
				out_accessor->type = cgltf_type_scalar;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "VEC2") == 0)
			{
				out_accessor->type = cgltf_type_vec2;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "VEC3") == 0)
			{
				out_accessor->type = cgltf_type_vec3;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "VEC4") == 0)
			{
				out_accessor->type = cgltf_type_vec4;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "MAT2") == 0)
			{
				out_accessor->type = cgltf_type_mat2;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "MAT3") == 0)
			{
				out_accessor->type = cgltf_type_mat3;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "MAT4") == 0)
			{
				out_accessor->type = cgltf_type_mat4;
			}
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "min") == 0)
		{
			++i;
			out_accessor->has_min = 1;
			// note: we can't parse the precise number of elements since type may not have been computed yet
			int min_size = tokens[i].size > 16 ? 16 : tokens[i].size;
			i = cgltf_parse_json_float_array(tokens, i, json_chunk, out_accessor->min, min_size);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "max") == 0)
		{
			++i;
			out_accessor->has_max = 1;
			// note: we can't parse the precise number of elements since type may not have been computed yet
			int max_size = tokens[i].size > 16 ? 16 : tokens[i].size;
			i = cgltf_parse_json_float_array(tokens, i, json_chunk, out_accessor->max, max_size);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "sparse") == 0)
		{
			out_accessor->is_sparse = 1;
			i = cgltf_parse_json_accessor_sparse(tokens, i + 1, json_chunk, &out_accessor->sparse);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_accessor->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_accessor->extensions_count, &out_accessor->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_texture_transform(jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_texture_transform* out_texture_transform)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "offset") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_texture_transform->offset, 2);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "rotation") == 0)
		{
			++i;
			out_texture_transform->rotation = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "scale") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_texture_transform->scale, 2);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "texCoord") == 0)
		{
			++i;
			out_texture_transform->has_texcoord = 1;
			out_texture_transform->texcoord = cgltf_json_to_int(tokens + i, json_chunk);
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_texture_view(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_texture_view* out_texture_view)
{
	(void)options;

	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	out_texture_view->scale = 1.0f;
	cgltf_fill_float_array(out_texture_view->transform.scale, 2, 1.0f);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "index") == 0)
		{
			++i;
			out_texture_view->texture = CGLTF_PTRINDEX(cgltf_texture, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "texCoord") == 0)
		{
			++i;
			out_texture_view->texcoord = cgltf_json_to_int(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "scale") == 0)
		{
			++i;
			out_texture_view->scale = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "strength") == 0)
		{
			++i;
			out_texture_view->scale = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			int extensions_size = tokens[i].size;

			++i;

			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_texture_transform") == 0)
				{
					out_texture_view->has_transform = 1;
					i = cgltf_parse_json_texture_transform(tokens, i + 1, json_chunk, &out_texture_view->transform);
				}
				else
				{
					i = cgltf_skip_json(tokens, i + 1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_pbr_metallic_roughness(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_pbr_metallic_roughness* out_pbr)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "metallicFactor") == 0)
		{
			++i;
			out_pbr->metallic_factor =
				cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "roughnessFactor") == 0)
		{
			++i;
			out_pbr->roughness_factor =
				cgltf_json_to_float(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "baseColorFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_pbr->base_color_factor, 4);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "baseColorTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_pbr->base_color_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "metallicRoughnessTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_pbr->metallic_roughness_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_pbr_specular_glossiness(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_pbr_specular_glossiness* out_pbr)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "diffuseFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_pbr->diffuse_factor, 4);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "specularFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_pbr->specular_factor, 3);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "glossinessFactor") == 0)
		{
			++i;
			out_pbr->glossiness_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "diffuseTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_pbr->diffuse_texture);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "specularGlossinessTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_pbr->specular_glossiness_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_clearcoat(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_clearcoat* out_clearcoat)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "clearcoatFactor") == 0)
		{
			++i;
			out_clearcoat->clearcoat_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "clearcoatRoughnessFactor") == 0)
		{
			++i;
			out_clearcoat->clearcoat_roughness_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "clearcoatTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_clearcoat->clearcoat_texture);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "clearcoatRoughnessTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_clearcoat->clearcoat_roughness_texture);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "clearcoatNormalTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_clearcoat->clearcoat_normal_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_ior(jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_ior* out_ior)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	// Default values
	out_ior->ior = 1.5f;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "ior") == 0)
		{
			++i;
			out_ior->ior = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_specular(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_specular* out_specular)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	// Default values
	out_specular->specular_factor = 1.0f;
	cgltf_fill_float_array(out_specular->specular_color_factor, 3, 1.0f);

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "specularFactor") == 0)
		{
			++i;
			out_specular->specular_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "specularColorFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_specular->specular_color_factor, 3);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "specularTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_specular->specular_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "specularColorTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_specular->specular_color_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_transmission(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_transmission* out_transmission)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "transmissionFactor") == 0)
		{
			++i;
			out_transmission->transmission_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "transmissionTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_transmission->transmission_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_volume(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_volume* out_volume)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "thicknessFactor") == 0)
		{
			++i;
			out_volume->thickness_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "thicknessTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_volume->thickness_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "attenuationColor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_volume->attenuation_color, 3);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "attenuationDistance") == 0)
		{
			++i;
			out_volume->attenuation_distance = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_sheen(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_sheen* out_sheen)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "sheenColorFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_sheen->sheen_color_factor, 3);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "sheenColorTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_sheen->sheen_color_texture);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "sheenRoughnessFactor") == 0)
		{
			++i;
			out_sheen->sheen_roughness_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "sheenRoughnessTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_sheen->sheen_roughness_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_emissive_strength(jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_emissive_strength* out_emissive_strength)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	// Default
	out_emissive_strength->emissive_strength = 1.f;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "emissiveStrength") == 0)
		{
			++i;
			out_emissive_strength->emissive_strength = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_iridescence(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_iridescence* out_iridescence)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	// Default
	out_iridescence->iridescence_ior = 1.3f;
	out_iridescence->iridescence_thickness_min = 100.f;
	out_iridescence->iridescence_thickness_max = 400.f;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "iridescenceFactor") == 0)
		{
			++i;
			out_iridescence->iridescence_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "iridescenceTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_iridescence->iridescence_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "iridescenceIor") == 0)
		{
			++i;
			out_iridescence->iridescence_ior = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "iridescenceThicknessMinimum") == 0)
		{
			++i;
			out_iridescence->iridescence_thickness_min = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "iridescenceThicknessMaximum") == 0)
		{
			++i;
			out_iridescence->iridescence_thickness_max = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "iridescenceThicknessTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_iridescence->iridescence_thickness_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_diffuse_transmission(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_diffuse_transmission* out_diff_transmission)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;

	// Defaults
	cgltf_fill_float_array(out_diff_transmission->diffuse_transmission_color_factor, 3, 1.0f);
	out_diff_transmission->diffuse_transmission_factor = 0.f;
	
	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "diffuseTransmissionFactor") == 0)
		{
			++i;
			out_diff_transmission->diffuse_transmission_factor = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "diffuseTransmissionTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_diff_transmission->diffuse_transmission_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "diffuseTransmissionColorFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_diff_transmission->diffuse_transmission_color_factor, 3);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "diffuseTransmissionColorTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_diff_transmission->diffuse_transmission_color_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_anisotropy(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_anisotropy* out_anisotropy)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;


	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "anisotropyStrength") == 0)
		{
			++i;
			out_anisotropy->anisotropy_strength = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "anisotropyRotation") == 0)
		{
			++i;
			out_anisotropy->anisotropy_rotation = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "anisotropyTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk, &out_anisotropy->anisotropy_texture);
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_dispersion(jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_dispersion* out_dispersion)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
	int size = tokens[i].size;
	++i;


	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "dispersion") == 0)
		{
			++i;
			out_dispersion->dispersion = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_image(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_image* out_image)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "uri") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_image->uri);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "bufferView") == 0)
		{
			++i;
			out_image->buffer_view = CGLTF_PTRINDEX(cgltf_buffer_view, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "mimeType") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_image->mime_type);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_image->name);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_image->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_image->extensions_count, &out_image->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_sampler(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_sampler* out_sampler)
{
	(void)options;
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	out_sampler->wrap_s = cgltf_wrap_mode_repeat;
	out_sampler->wrap_t = cgltf_wrap_mode_repeat;

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_sampler->name);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "magFilter") == 0)
		{
			++i;
			out_sampler->mag_filter
				= (cgltf_filter_type)cgltf_json_to_int(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "minFilter") == 0)
		{
			++i;
			out_sampler->min_filter
				= (cgltf_filter_type)cgltf_json_to_int(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "wrapS") == 0)
		{
			++i;
			out_sampler->wrap_s
				= (cgltf_wrap_mode)cgltf_json_to_int(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "wrapT") == 0)
		{
			++i;
			out_sampler->wrap_t
				= (cgltf_wrap_mode)cgltf_json_to_int(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_sampler->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_sampler->extensions_count, &out_sampler->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_texture(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_texture* out_texture)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_texture->name);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "sampler") == 0)
		{
			++i;
			out_texture->sampler = CGLTF_PTRINDEX(cgltf_sampler, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "source") == 0)
		{
			++i;
			out_texture->image = CGLTF_PTRINDEX(cgltf_image, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_texture->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			if (out_texture->extensions)
			{
				return CGLTF_ERROR_JSON;
			}

			int extensions_size = tokens[i].size;
			++i;
			out_texture->extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);
			out_texture->extensions_count = 0;

			if (!out_texture->extensions)
			{
				return CGLTF_ERROR_NOMEM;
			}

			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_texture_basisu") == 0)
				{
					out_texture->has_basisu = 1;
					++i;
					CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
					int num_properties = tokens[i].size;
					++i;

					for (int t = 0; t < num_properties; ++t)
					{
						CGLTF_CHECK_KEY(tokens[i]);

						if (cgltf_json_strcmp(tokens + i, json_chunk, "source") == 0)
						{
							++i;
							out_texture->basisu_image = CGLTF_PTRINDEX(cgltf_image, cgltf_json_to_int(tokens + i, json_chunk));
							++i;
						}
						else
						{
							i = cgltf_skip_json(tokens, i + 1);
						}
						if (i < 0)
						{
							return i;
						}
					}
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "EXT_texture_webp") == 0)
				{
					out_texture->has_webp = 1;
					++i;
					CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
					int num_properties = tokens[i].size;
					++i;

					for (int t = 0; t < num_properties; ++t)
					{
						CGLTF_CHECK_KEY(tokens[i]);

						if (cgltf_json_strcmp(tokens + i, json_chunk, "source") == 0)
						{
							++i;
							out_texture->webp_image = CGLTF_PTRINDEX(cgltf_image, cgltf_json_to_int(tokens + i, json_chunk));
							++i;
						}
						else
						{
							i = cgltf_skip_json(tokens, i + 1);
						}
						if (i < 0)
						{
							return i;
						}
					}
				}
				else
				{
					i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, &(out_texture->extensions[out_texture->extensions_count++]));
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_material(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_material* out_material)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	cgltf_fill_float_array(out_material->pbr_metallic_roughness.base_color_factor, 4, 1.0f);
	out_material->pbr_metallic_roughness.metallic_factor = 1.0f;
	out_material->pbr_metallic_roughness.roughness_factor = 1.0f;

	cgltf_fill_float_array(out_material->pbr_specular_glossiness.diffuse_factor, 4, 1.0f);
	cgltf_fill_float_array(out_material->pbr_specular_glossiness.specular_factor, 3, 1.0f);
	out_material->pbr_specular_glossiness.glossiness_factor = 1.0f;

	cgltf_fill_float_array(out_material->volume.attenuation_color, 3, 1.0f);
	out_material->volume.attenuation_distance = FLT_MAX;

	out_material->alpha_cutoff = 0.5f;

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_material->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "pbrMetallicRoughness") == 0)
		{
			out_material->has_pbr_metallic_roughness = 1;
			i = cgltf_parse_json_pbr_metallic_roughness(options, tokens, i + 1, json_chunk, &out_material->pbr_metallic_roughness);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "emissiveFactor") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_material->emissive_factor, 3);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "normalTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk,
				&out_material->normal_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "occlusionTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk,
				&out_material->occlusion_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "emissiveTexture") == 0)
		{
			i = cgltf_parse_json_texture_view(options, tokens, i + 1, json_chunk,
				&out_material->emissive_texture);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "alphaMode") == 0)
		{
			++i;
			if (cgltf_json_strcmp(tokens + i, json_chunk, "OPAQUE") == 0)
			{
				out_material->alpha_mode = cgltf_alpha_mode_opaque;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "MASK") == 0)
			{
				out_material->alpha_mode = cgltf_alpha_mode_mask;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "BLEND") == 0)
			{
				out_material->alpha_mode = cgltf_alpha_mode_blend;
			}
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "alphaCutoff") == 0)
		{
			++i;
			out_material->alpha_cutoff = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "doubleSided") == 0)
		{
			++i;
			out_material->double_sided =
				cgltf_json_to_bool(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_material->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			if(out_material->extensions)
			{
				return CGLTF_ERROR_JSON;
			}

			int extensions_size = tokens[i].size;
			++i;
			out_material->extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);
			out_material->extensions_count= 0;

			if (!out_material->extensions)
			{
				return CGLTF_ERROR_NOMEM;
			}

			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_pbrSpecularGlossiness") == 0)
				{
					out_material->has_pbr_specular_glossiness = 1;
					i = cgltf_parse_json_pbr_specular_glossiness(options, tokens, i + 1, json_chunk, &out_material->pbr_specular_glossiness);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_unlit") == 0)
				{
					out_material->unlit = 1;
					i = cgltf_skip_json(tokens, i+1);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_clearcoat") == 0)
				{
					out_material->has_clearcoat = 1;
					i = cgltf_parse_json_clearcoat(options, tokens, i + 1, json_chunk, &out_material->clearcoat);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_ior") == 0)
				{
					out_material->has_ior = 1;
					i = cgltf_parse_json_ior(tokens, i + 1, json_chunk, &out_material->ior);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_specular") == 0)
				{
					out_material->has_specular = 1;
					i = cgltf_parse_json_specular(options, tokens, i + 1, json_chunk, &out_material->specular);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_transmission") == 0)
				{
					out_material->has_transmission = 1;
					i = cgltf_parse_json_transmission(options, tokens, i + 1, json_chunk, &out_material->transmission);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_materials_volume") == 0)
				{
					out_material->has_volume = 1;
					i = cgltf_parse_json_volume(options, tokens, i + 1, json_chunk, &out_material->volume);
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_sheen") == 0)
				{
					out_material->has_sheen = 1;
					i = cgltf_parse_json_sheen(options, tokens, i + 1, json_chunk, &out_material->sheen);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_materials_emissive_strength") == 0)
				{
					out_material->has_emissive_strength = 1;
					i = cgltf_parse_json_emissive_strength(tokens, i + 1, json_chunk, &out_material->emissive_strength);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_materials_iridescence") == 0)
				{
					out_material->has_iridescence = 1;
					i = cgltf_parse_json_iridescence(options, tokens, i + 1, json_chunk, &out_material->iridescence);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_materials_diffuse_transmission") == 0)
				{
					out_material->has_diffuse_transmission = 1;
					i = cgltf_parse_json_diffuse_transmission(options, tokens, i + 1, json_chunk, &out_material->diffuse_transmission);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_materials_anisotropy") == 0)
				{
					out_material->has_anisotropy = 1;
					i = cgltf_parse_json_anisotropy(options, tokens, i + 1, json_chunk, &out_material->anisotropy);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "KHR_materials_dispersion") == 0)
				{
					out_material->has_dispersion = 1;
					i = cgltf_parse_json_dispersion(tokens, i + 1, json_chunk, &out_material->dispersion);
				}
				else
				{
					i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, &(out_material->extensions[out_material->extensions_count++]));
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_accessors(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_accessor), (void**)&out_data->accessors, &out_data->accessors_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->accessors_count; ++j)
	{
		i = cgltf_parse_json_accessor(options, tokens, i, json_chunk, &out_data->accessors[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_materials(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_material), (void**)&out_data->materials, &out_data->materials_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->materials_count; ++j)
	{
		i = cgltf_parse_json_material(options, tokens, i, json_chunk, &out_data->materials[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_images(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_image), (void**)&out_data->images, &out_data->images_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->images_count; ++j)
	{
		i = cgltf_parse_json_image(options, tokens, i, json_chunk, &out_data->images[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_textures(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_texture), (void**)&out_data->textures, &out_data->textures_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->textures_count; ++j)
	{
		i = cgltf_parse_json_texture(options, tokens, i, json_chunk, &out_data->textures[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_samplers(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_sampler), (void**)&out_data->samplers, &out_data->samplers_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->samplers_count; ++j)
	{
		i = cgltf_parse_json_sampler(options, tokens, i, json_chunk, &out_data->samplers[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_meshopt_compression(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_meshopt_compression* out_meshopt_compression)
{
	(void)options;
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "buffer") == 0)
		{
			++i;
			out_meshopt_compression->buffer = CGLTF_PTRINDEX(cgltf_buffer, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteOffset") == 0)
		{
			++i;
			out_meshopt_compression->offset = cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteLength") == 0)
		{
			++i;
			out_meshopt_compression->size = cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteStride") == 0)
		{
			++i;
			out_meshopt_compression->stride = cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "count") == 0)
		{
			++i;
			out_meshopt_compression->count = cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "mode") == 0)
		{
			++i;
			if (cgltf_json_strcmp(tokens+i, json_chunk, "ATTRIBUTES") == 0)
			{
				out_meshopt_compression->mode = cgltf_meshopt_compression_mode_attributes;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "TRIANGLES") == 0)
			{
				out_meshopt_compression->mode = cgltf_meshopt_compression_mode_triangles;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "INDICES") == 0)
			{
				out_meshopt_compression->mode = cgltf_meshopt_compression_mode_indices;
			}
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "filter") == 0)
		{
			++i;
			if (cgltf_json_strcmp(tokens+i, json_chunk, "NONE") == 0)
			{
				out_meshopt_compression->filter = cgltf_meshopt_compression_filter_none;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "OCTAHEDRAL") == 0)
			{
				out_meshopt_compression->filter = cgltf_meshopt_compression_filter_octahedral;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "QUATERNION") == 0)
			{
				out_meshopt_compression->filter = cgltf_meshopt_compression_filter_quaternion;
			}
			else if (cgltf_json_strcmp(tokens+i, json_chunk, "EXPONENTIAL") == 0)
			{
				out_meshopt_compression->filter = cgltf_meshopt_compression_filter_exponential;
			}
			++i;
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_buffer_view(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_buffer_view* out_buffer_view)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_buffer_view->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "buffer") == 0)
		{
			++i;
			out_buffer_view->buffer = CGLTF_PTRINDEX(cgltf_buffer, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteOffset") == 0)
		{
			++i;
			out_buffer_view->offset =
					cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteLength") == 0)
		{
			++i;
			out_buffer_view->size =
					cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteStride") == 0)
		{
			++i;
			out_buffer_view->stride =
					cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "target") == 0)
		{
			++i;
			int type = cgltf_json_to_int(tokens+i, json_chunk);
			switch (type)
			{
			case 34962:
				type = cgltf_buffer_view_type_vertices;
				break;
			case 34963:
				type = cgltf_buffer_view_type_indices;
				break;
			default:
				type = cgltf_buffer_view_type_invalid;
				break;
			}
			out_buffer_view->type = (cgltf_buffer_view_type)type;
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_buffer_view->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			if(out_buffer_view->extensions)
			{
				return CGLTF_ERROR_JSON;
			}

			int extensions_size = tokens[i].size;
			out_buffer_view->extensions_count = 0;
			out_buffer_view->extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);

			if (!out_buffer_view->extensions)
			{
				return CGLTF_ERROR_NOMEM;
			}

			++i;
			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "EXT_meshopt_compression") == 0)
				{
					out_buffer_view->has_meshopt_compression = 1;
					i = cgltf_parse_json_meshopt_compression(options, tokens, i + 1, json_chunk, &out_buffer_view->meshopt_compression);
				}
				else
				{
					i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, &(out_buffer_view->extensions[out_buffer_view->extensions_count++]));
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_buffer_views(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_buffer_view), (void**)&out_data->buffer_views, &out_data->buffer_views_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->buffer_views_count; ++j)
	{
		i = cgltf_parse_json_buffer_view(options, tokens, i, json_chunk, &out_data->buffer_views[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_buffer(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_buffer* out_buffer)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_buffer->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "byteLength") == 0)
		{
			++i;
			out_buffer->size =
					cgltf_json_to_size(tokens+i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "uri") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_buffer->uri);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_buffer->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_buffer->extensions_count, &out_buffer->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_buffers(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_buffer), (void**)&out_data->buffers, &out_data->buffers_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->buffers_count; ++j)
	{
		i = cgltf_parse_json_buffer(options, tokens, i, json_chunk, &out_data->buffers[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_skin(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_skin* out_skin)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_skin->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "joints") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_node*), (void**)&out_skin->joints, &out_skin->joints_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size k = 0; k < out_skin->joints_count; ++k)
			{
				out_skin->joints[k] = CGLTF_PTRINDEX(cgltf_node, cgltf_json_to_int(tokens + i, json_chunk));
				++i;
			}
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "skeleton") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
			out_skin->skeleton = CGLTF_PTRINDEX(cgltf_node, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "inverseBindMatrices") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
			out_skin->inverse_bind_matrices = CGLTF_PTRINDEX(cgltf_accessor, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_skin->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_skin->extensions_count, &out_skin->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_skins(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_skin), (void**)&out_data->skins, &out_data->skins_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->skins_count; ++j)
	{
		i = cgltf_parse_json_skin(options, tokens, i, json_chunk, &out_data->skins[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_camera(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_camera* out_camera)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_camera->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "perspective") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

			int data_size = tokens[i].size;
			++i;

			if (out_camera->type != cgltf_camera_type_invalid)
			{
				return CGLTF_ERROR_JSON;
			}

			out_camera->type = cgltf_camera_type_perspective;

			for (int k = 0; k < data_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "aspectRatio") == 0)
				{
					++i;
					out_camera->data.perspective.has_aspect_ratio = 1;
					out_camera->data.perspective.aspect_ratio = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "yfov") == 0)
				{
					++i;
					out_camera->data.perspective.yfov = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "zfar") == 0)
				{
					++i;
					out_camera->data.perspective.has_zfar = 1;
					out_camera->data.perspective.zfar = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "znear") == 0)
				{
					++i;
					out_camera->data.perspective.znear = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
				{
					i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_camera->data.perspective.extras);
				}
				else
				{
					i = cgltf_skip_json(tokens, i+1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "orthographic") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

			int data_size = tokens[i].size;
			++i;

			if (out_camera->type != cgltf_camera_type_invalid)
			{
				return CGLTF_ERROR_JSON;
			}

			out_camera->type = cgltf_camera_type_orthographic;

			for (int k = 0; k < data_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "xmag") == 0)
				{
					++i;
					out_camera->data.orthographic.xmag = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "ymag") == 0)
				{
					++i;
					out_camera->data.orthographic.ymag = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "zfar") == 0)
				{
					++i;
					out_camera->data.orthographic.zfar = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "znear") == 0)
				{
					++i;
					out_camera->data.orthographic.znear = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
				{
					i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_camera->data.orthographic.extras);
				}
				else
				{
					i = cgltf_skip_json(tokens, i+1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_camera->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_camera->extensions_count, &out_camera->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_cameras(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_camera), (void**)&out_data->cameras, &out_data->cameras_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->cameras_count; ++j)
	{
		i = cgltf_parse_json_camera(options, tokens, i, json_chunk, &out_data->cameras[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_light(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_light* out_light)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	out_light->color[0] = 1.f;
	out_light->color[1] = 1.f;
	out_light->color[2] = 1.f;
	out_light->intensity = 1.f;

	out_light->spot_inner_cone_angle = 0.f;
	out_light->spot_outer_cone_angle = 3.1415926535f / 4.0f;

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_light->name);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "color") == 0)
		{
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_light->color, 3);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "intensity") == 0)
		{
			++i;
			out_light->intensity = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "type") == 0)
		{
			++i;
			if (cgltf_json_strcmp(tokens + i, json_chunk, "directional") == 0)
			{
				out_light->type = cgltf_light_type_directional;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "point") == 0)
			{
				out_light->type = cgltf_light_type_point;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "spot") == 0)
			{
				out_light->type = cgltf_light_type_spot;
			}
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "range") == 0)
		{
			++i;
			out_light->range = cgltf_json_to_float(tokens + i, json_chunk);
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "spot") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

			int data_size = tokens[i].size;
			++i;

			for (int k = 0; k < data_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "innerConeAngle") == 0)
				{
					++i;
					out_light->spot_inner_cone_angle = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "outerConeAngle") == 0)
				{
					++i;
					out_light->spot_outer_cone_angle = cgltf_json_to_float(tokens + i, json_chunk);
					++i;
				}
				else
				{
					i = cgltf_skip_json(tokens, i+1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_light->extras);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_lights(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_light), (void**)&out_data->lights, &out_data->lights_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->lights_count; ++j)
	{
		i = cgltf_parse_json_light(options, tokens, i, json_chunk, &out_data->lights[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_node(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_node* out_node)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	out_node->rotation[3] = 1.0f;
	out_node->scale[0] = 1.0f;
	out_node->scale[1] = 1.0f;
	out_node->scale[2] = 1.0f;
	out_node->matrix[0] = 1.0f;
	out_node->matrix[5] = 1.0f;
	out_node->matrix[10] = 1.0f;
	out_node->matrix[15] = 1.0f;

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_node->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "children") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_node*), (void**)&out_node->children, &out_node->children_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size k = 0; k < out_node->children_count; ++k)
			{
				out_node->children[k] = CGLTF_PTRINDEX(cgltf_node, cgltf_json_to_int(tokens + i, json_chunk));
				++i;
			}
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "mesh") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
			out_node->mesh = CGLTF_PTRINDEX(cgltf_mesh, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "skin") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
			out_node->skin = CGLTF_PTRINDEX(cgltf_skin, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "camera") == 0)
		{
			++i;
			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
			out_node->camera = CGLTF_PTRINDEX(cgltf_camera, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "translation") == 0)
		{
			out_node->has_translation = 1;
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_node->translation, 3);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "rotation") == 0)
		{
			out_node->has_rotation = 1;
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_node->rotation, 4);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "scale") == 0)
		{
			out_node->has_scale = 1;
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_node->scale, 3);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "matrix") == 0)
		{
			out_node->has_matrix = 1;
			i = cgltf_parse_json_float_array(tokens, i + 1, json_chunk, out_node->matrix, 16);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "weights") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_float), (void**)&out_node->weights, &out_node->weights_count);
			if (i < 0)
			{
				return i;
			}

			i = cgltf_parse_json_float_array(tokens, i - 1, json_chunk, out_node->weights, (int)out_node->weights_count);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_node->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			if(out_node->extensions)
			{
				return CGLTF_ERROR_JSON;
			}

			int extensions_size = tokens[i].size;
			out_node->extensions_count= 0;
			out_node->extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);

			if (!out_node->extensions)
			{
				return CGLTF_ERROR_NOMEM;
			}

			++i;

			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_lights_punctual") == 0)
				{
					++i;

					CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

					int data_size = tokens[i].size;
					++i;

					for (int m = 0; m < data_size; ++m)
					{
						CGLTF_CHECK_KEY(tokens[i]);

						if (cgltf_json_strcmp(tokens + i, json_chunk, "light") == 0)
						{
							++i;
							CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_PRIMITIVE);
							out_node->light = CGLTF_PTRINDEX(cgltf_light, cgltf_json_to_int(tokens + i, json_chunk));
							++i;
						}
						else
						{
							i = cgltf_skip_json(tokens, i + 1);
						}

						if (i < 0)
						{
							return i;
						}
					}
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "EXT_mesh_gpu_instancing") == 0)
				{
					out_node->has_mesh_gpu_instancing = 1;
					i = cgltf_parse_json_mesh_gpu_instancing(options, tokens, i + 1, json_chunk, &out_node->mesh_gpu_instancing);
				}
				else
				{
					i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, &(out_node->extensions[out_node->extensions_count++]));
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_nodes(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_node), (void**)&out_data->nodes, &out_data->nodes_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->nodes_count; ++j)
	{
		i = cgltf_parse_json_node(options, tokens, i, json_chunk, &out_data->nodes[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_scene(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_scene* out_scene)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_scene->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "nodes") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_node*), (void**)&out_scene->nodes, &out_scene->nodes_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size k = 0; k < out_scene->nodes_count; ++k)
			{
				out_scene->nodes[k] = CGLTF_PTRINDEX(cgltf_node, cgltf_json_to_int(tokens + i, json_chunk));
				++i;
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_scene->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_scene->extensions_count, &out_scene->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_scenes(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_scene), (void**)&out_data->scenes, &out_data->scenes_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->scenes_count; ++j)
	{
		i = cgltf_parse_json_scene(options, tokens, i, json_chunk, &out_data->scenes[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_animation_sampler(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_animation_sampler* out_sampler)
{
	(void)options;
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "input") == 0)
		{
			++i;
			out_sampler->input = CGLTF_PTRINDEX(cgltf_accessor, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "output") == 0)
		{
			++i;
			out_sampler->output = CGLTF_PTRINDEX(cgltf_accessor, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "interpolation") == 0)
		{
			++i;
			if (cgltf_json_strcmp(tokens + i, json_chunk, "LINEAR") == 0)
			{
				out_sampler->interpolation = cgltf_interpolation_type_linear;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "STEP") == 0)
			{
				out_sampler->interpolation = cgltf_interpolation_type_step;
			}
			else if (cgltf_json_strcmp(tokens + i, json_chunk, "CUBICSPLINE") == 0)
			{
				out_sampler->interpolation = cgltf_interpolation_type_cubic_spline;
			}
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_sampler->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_sampler->extensions_count, &out_sampler->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_animation_channel(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_animation_channel* out_channel)
{
	(void)options;
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "sampler") == 0)
		{
			++i;
			out_channel->sampler = CGLTF_PTRINDEX(cgltf_animation_sampler, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "target") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

			int target_size = tokens[i].size;
			++i;

			for (int k = 0; k < target_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "node") == 0)
				{
					++i;
					out_channel->target_node = CGLTF_PTRINDEX(cgltf_node, cgltf_json_to_int(tokens + i, json_chunk));
					++i;
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "path") == 0)
				{
					++i;
					if (cgltf_json_strcmp(tokens+i, json_chunk, "translation") == 0)
					{
						out_channel->target_path = cgltf_animation_path_type_translation;
					}
					else if (cgltf_json_strcmp(tokens+i, json_chunk, "rotation") == 0)
					{
						out_channel->target_path = cgltf_animation_path_type_rotation;
					}
					else if (cgltf_json_strcmp(tokens+i, json_chunk, "scale") == 0)
					{
						out_channel->target_path = cgltf_animation_path_type_scale;
					}
					else if (cgltf_json_strcmp(tokens+i, json_chunk, "weights") == 0)
					{
						out_channel->target_path = cgltf_animation_path_type_weights;
					}
					++i;
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
				{
					i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_channel->extras);
				}
				else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
				{
					i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_channel->extensions_count, &out_channel->extensions);
				}
				else
				{
					i = cgltf_skip_json(tokens, i+1);
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_animation(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_animation* out_animation)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_animation->name);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "samplers") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_animation_sampler), (void**)&out_animation->samplers, &out_animation->samplers_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size k = 0; k < out_animation->samplers_count; ++k)
			{
				i = cgltf_parse_json_animation_sampler(options, tokens, i, json_chunk, &out_animation->samplers[k]);
				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "channels") == 0)
		{
			i = cgltf_parse_json_array(options, tokens, i + 1, json_chunk, sizeof(cgltf_animation_channel), (void**)&out_animation->channels, &out_animation->channels_count);
			if (i < 0)
			{
				return i;
			}

			for (cgltf_size k = 0; k < out_animation->channels_count; ++k)
			{
				i = cgltf_parse_json_animation_channel(options, tokens, i, json_chunk, &out_animation->channels[k]);
				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_animation->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_animation->extensions_count, &out_animation->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_animations(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_animation), (void**)&out_data->animations, &out_data->animations_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->animations_count; ++j)
	{
		i = cgltf_parse_json_animation(options, tokens, i, json_chunk, &out_data->animations[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_variant(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_material_variant* out_variant)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "name") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_variant->name);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_variant->extras);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

static int cgltf_parse_json_variants(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	i = cgltf_parse_json_array(options, tokens, i, json_chunk, sizeof(cgltf_material_variant), (void**)&out_data->variants, &out_data->variants_count);
	if (i < 0)
	{
		return i;
	}

	for (cgltf_size j = 0; j < out_data->variants_count; ++j)
	{
		i = cgltf_parse_json_variant(options, tokens, i, json_chunk, &out_data->variants[j]);
		if (i < 0)
		{
			return i;
		}
	}
	return i;
}

static int cgltf_parse_json_asset(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_asset* out_asset)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens+i, json_chunk, "copyright") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_asset->copyright);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "generator") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_asset->generator);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "version") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_asset->version);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "minVersion") == 0)
		{
			i = cgltf_parse_json_string(options, tokens, i + 1, json_chunk, &out_asset->min_version);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_asset->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			i = cgltf_parse_json_unprocessed_extensions(options, tokens, i, json_chunk, &out_asset->extensions_count, &out_asset->extensions);
		}
		else
		{
			i = cgltf_skip_json(tokens, i+1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	if (out_asset->version && CGLTF_ATOF(out_asset->version) < 2)
	{
		return CGLTF_ERROR_LEGACY;
	}

	return i;
}

cgltf_size cgltf_num_components(cgltf_type type) {
	switch (type)
	{
	case cgltf_type_vec2:
		return 2;
	case cgltf_type_vec3:
		return 3;
	case cgltf_type_vec4:
		return 4;
	case cgltf_type_mat2:
		return 4;
	case cgltf_type_mat3:
		return 9;
	case cgltf_type_mat4:
		return 16;
	case cgltf_type_invalid:
	case cgltf_type_scalar:
	default:
		return 1;
	}
}

cgltf_size cgltf_component_size(cgltf_component_type component_type) {
	switch (component_type)
	{
	case cgltf_component_type_r_8:
	case cgltf_component_type_r_8u:
		return 1;
	case cgltf_component_type_r_16:
	case cgltf_component_type_r_16u:
		return 2;
	case cgltf_component_type_r_32u:
	case cgltf_component_type_r_32f:
		return 4;
	case cgltf_component_type_invalid:
	default:
		return 0;
	}
}

cgltf_size cgltf_calc_size(cgltf_type type, cgltf_component_type component_type)
{
	cgltf_size component_size = cgltf_component_size(component_type);
	if (type == cgltf_type_mat2 && component_size == 1)
	{
		return 8 * component_size;
	}
	else if (type == cgltf_type_mat3 && (component_size == 1 || component_size == 2))
	{
		return 12 * component_size;
	}
	return component_size * cgltf_num_components(type);
}

static int cgltf_fixup_pointers(cgltf_data* out_data);

static int cgltf_parse_json_root(cgltf_options* options, jsmntok_t const* tokens, int i, const uint8_t* json_chunk, cgltf_data* out_data)
{
	CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

	int size = tokens[i].size;
	++i;

	for (int j = 0; j < size; ++j)
	{
		CGLTF_CHECK_KEY(tokens[i]);

		if (cgltf_json_strcmp(tokens + i, json_chunk, "asset") == 0)
		{
			i = cgltf_parse_json_asset(options, tokens, i + 1, json_chunk, &out_data->asset);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "meshes") == 0)
		{
			i = cgltf_parse_json_meshes(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "accessors") == 0)
		{
			i = cgltf_parse_json_accessors(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "bufferViews") == 0)
		{
			i = cgltf_parse_json_buffer_views(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "buffers") == 0)
		{
			i = cgltf_parse_json_buffers(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "materials") == 0)
		{
			i = cgltf_parse_json_materials(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "images") == 0)
		{
			i = cgltf_parse_json_images(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "textures") == 0)
		{
			i = cgltf_parse_json_textures(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "samplers") == 0)
		{
			i = cgltf_parse_json_samplers(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "skins") == 0)
		{
			i = cgltf_parse_json_skins(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "cameras") == 0)
		{
			i = cgltf_parse_json_cameras(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "nodes") == 0)
		{
			i = cgltf_parse_json_nodes(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "scenes") == 0)
		{
			i = cgltf_parse_json_scenes(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "scene") == 0)
		{
			++i;
			out_data->scene = CGLTF_PTRINDEX(cgltf_scene, cgltf_json_to_int(tokens + i, json_chunk));
			++i;
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "animations") == 0)
		{
			i = cgltf_parse_json_animations(options, tokens, i + 1, json_chunk, out_data);
		}
		else if (cgltf_json_strcmp(tokens+i, json_chunk, "extras") == 0)
		{
			i = cgltf_parse_json_extras(options, tokens, i + 1, json_chunk, &out_data->extras);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensions") == 0)
		{
			++i;

			CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);
			if(out_data->data_extensions)
			{
				return CGLTF_ERROR_JSON;
			}

			int extensions_size = tokens[i].size;
			out_data->data_extensions_count = 0;
			out_data->data_extensions = (cgltf_extension*)cgltf_calloc(options, sizeof(cgltf_extension), extensions_size);

			if (!out_data->data_extensions)
			{
				return CGLTF_ERROR_NOMEM;
			}

			++i;

			for (int k = 0; k < extensions_size; ++k)
			{
				CGLTF_CHECK_KEY(tokens[i]);

				if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_lights_punctual") == 0)
				{
					++i;

					CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

					int data_size = tokens[i].size;
					++i;

					for (int m = 0; m < data_size; ++m)
					{
						CGLTF_CHECK_KEY(tokens[i]);

						if (cgltf_json_strcmp(tokens + i, json_chunk, "lights") == 0)
						{
							i = cgltf_parse_json_lights(options, tokens, i + 1, json_chunk, out_data);
						}
						else
						{
							i = cgltf_skip_json(tokens, i + 1);
						}

						if (i < 0)
						{
							return i;
						}
					}
				}
				else if (cgltf_json_strcmp(tokens+i, json_chunk, "KHR_materials_variants") == 0)
				{
					++i;

					CGLTF_CHECK_TOKTYPE(tokens[i], JSMN_OBJECT);

					int data_size = tokens[i].size;
					++i;

					for (int m = 0; m < data_size; ++m)
					{
						CGLTF_CHECK_KEY(tokens[i]);

						if (cgltf_json_strcmp(tokens + i, json_chunk, "variants") == 0)
						{
							i = cgltf_parse_json_variants(options, tokens, i + 1, json_chunk, out_data);
						}
						else
						{
							i = cgltf_skip_json(tokens, i + 1);
						}

						if (i < 0)
						{
							return i;
						}
					}
				}
				else
				{
					i = cgltf_parse_json_unprocessed_extension(options, tokens, i, json_chunk, &(out_data->data_extensions[out_data->data_extensions_count++]));
				}

				if (i < 0)
				{
					return i;
				}
			}
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensionsUsed") == 0)
		{
			i = cgltf_parse_json_string_array(options, tokens, i + 1, json_chunk, &out_data->extensions_used, &out_data->extensions_used_count);
		}
		else if (cgltf_json_strcmp(tokens + i, json_chunk, "extensionsRequired") == 0)
		{
			i = cgltf_parse_json_string_array(options, tokens, i + 1, json_chunk, &out_data->extensions_required, &out_data->extensions_required_count);
		}
		else
		{
			i = cgltf_skip_json(tokens, i + 1);
		}

		if (i < 0)
		{
			return i;
		}
	}

	return i;
}

cgltf_result cgltf_parse_json(cgltf_options* options, const uint8_t* json_chunk, cgltf_size size, cgltf_data** out_data)
{
	jsmn_parser parser = { 0, 0, 0 };

	if (options->json_token_count == 0)
	{
		int token_count = jsmn_parse(&parser, (const char*)json_chunk, size, NULL, 0);

		if (token_count <= 0)
		{
			return cgltf_result_invalid_json;
		}

		options->json_token_count = token_count;
	}

	jsmntok_t* tokens = (jsmntok_t*)options->memory.alloc_func(options->memory.user_data, sizeof(jsmntok_t) * (options->json_token_count + 1));

	if (!tokens)
	{
		return cgltf_result_out_of_memory;
	}

	jsmn_init(&parser);

	int token_count = jsmn_parse(&parser, (const char*)json_chunk, size, tokens, options->json_token_count);

	if (token_count <= 0)
	{
		options->memory.free_func(options->memory.user_data, tokens);
		return cgltf_result_invalid_json;
	}

	// this makes sure that we always have an UNDEFINED token at the end of the stream
	// for invalid JSON inputs this makes sure we don't perform out of bound reads of token data
	tokens[token_count].type = JSMN_UNDEFINED;

	cgltf_data* data = (cgltf_data*)options->memory.alloc_func(options->memory.user_data, sizeof(cgltf_data));

	if (!data)
	{
		options->memory.free_func(options->memory.user_data, tokens);
		return cgltf_result_out_of_memory;
	}

	memset(data, 0, sizeof(cgltf_data));
	data->memory = options->memory;
	data->file = options->file;

	int i = cgltf_parse_json_root(options, tokens, 0, json_chunk, data);

	options->memory.free_func(options->memory.user_data, tokens);

	if (i < 0)
	{
		cgltf_free(data);

		switch (i)
		{
		case CGLTF_ERROR_NOMEM: return cgltf_result_out_of_memory;
		case CGLTF_ERROR_LEGACY: return cgltf_result_legacy_gltf;
		default: return cgltf_result_invalid_gltf;
		}
	}

	if (cgltf_fixup_pointers(data) < 0)
	{
		cgltf_free(data);
		return cgltf_result_invalid_gltf;
	}

	data->json = (const char*)json_chunk;
	data->json_size = size;

	*out_data = data;

	return cgltf_result_success;
}

static int cgltf_fixup_pointers(cgltf_data* data)
{
	for (cgltf_size i = 0; i < data->meshes_count; ++i)
	{
		for (cgltf_size j = 0; j < data->meshes[i].primitives_count; ++j)
		{
			CGLTF_PTRFIXUP(data->meshes[i].primitives[j].indices, data->accessors, data->accessors_count);
			CGLTF_PTRFIXUP(data->meshes[i].primitives[j].material, data->materials, data->materials_count);

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].attributes_count; ++k)
			{
				CGLTF_PTRFIXUP_REQ(data->meshes[i].primitives[j].attributes[k].data, data->accessors, data->accessors_count);
			}

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].targets_count; ++k)
			{
				for (cgltf_size m = 0; m < data->meshes[i].primitives[j].targets[k].attributes_count; ++m)
				{
					CGLTF_PTRFIXUP_REQ(data->meshes[i].primitives[j].targets[k].attributes[m].data, data->accessors, data->accessors_count);
				}
			}

			if (data->meshes[i].primitives[j].has_draco_mesh_compression)
			{
				CGLTF_PTRFIXUP_REQ(data->meshes[i].primitives[j].draco_mesh_compression.buffer_view, data->buffer_views, data->buffer_views_count);
				for (cgltf_size m = 0; m < data->meshes[i].primitives[j].draco_mesh_compression.attributes_count; ++m)
				{
					CGLTF_PTRFIXUP_REQ(data->meshes[i].primitives[j].draco_mesh_compression.attributes[m].data, data->accessors, data->accessors_count);
				}
			}

			for (cgltf_size k = 0; k < data->meshes[i].primitives[j].mappings_count; ++k)
			{
				CGLTF_PTRFIXUP_REQ(data->meshes[i].primitives[j].mappings[k].material, data->materials, data->materials_count);
			}
		}
	}

	for (cgltf_size i = 0; i < data->accessors_count; ++i)
	{
		CGLTF_PTRFIXUP(data->accessors[i].buffer_view, data->buffer_views, data->buffer_views_count);

		if (data->accessors[i].is_sparse)
		{
			CGLTF_PTRFIXUP_REQ(data->accessors[i].sparse.indices_buffer_view, data->buffer_views, data->buffer_views_count);
			CGLTF_PTRFIXUP_REQ(data->accessors[i].sparse.values_buffer_view, data->buffer_views, data->buffer_views_count);
		}

		if (data->accessors[i].buffer_view)
		{
			data->accessors[i].stride = data->accessors[i].buffer_view->stride;
		}

		if (data->accessors[i].stride == 0)
		{
			data->accessors[i].stride = cgltf_calc_size(data->accessors[i].type, data->accessors[i].component_type);
		}
	}

	for (cgltf_size i = 0; i < data->textures_count; ++i)
	{
		CGLTF_PTRFIXUP(data->textures[i].image, data->images, data->images_count);
		CGLTF_PTRFIXUP(data->textures[i].basisu_image, data->images, data->images_count);
		CGLTF_PTRFIXUP(data->textures[i].webp_image, data->images, data->images_count);
		CGLTF_PTRFIXUP(data->textures[i].sampler, data->samplers, data->samplers_count);
	}

	for (cgltf_size i = 0; i < data->images_count; ++i)
	{
		CGLTF_PTRFIXUP(data->images[i].buffer_view, data->buffer_views, data->buffer_views_count);
	}

	for (cgltf_size i = 0; i < data->materials_count; ++i)
	{
		CGLTF_PTRFIXUP(data->materials[i].normal_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].emissive_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].occlusion_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].pbr_metallic_roughness.base_color_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].pbr_metallic_roughness.metallic_roughness_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].pbr_specular_glossiness.diffuse_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].pbr_specular_glossiness.specular_glossiness_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].clearcoat.clearcoat_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].clearcoat.clearcoat_roughness_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].clearcoat.clearcoat_normal_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].specular.specular_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].specular.specular_color_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].transmission.transmission_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].volume.thickness_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].sheen.sheen_color_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].sheen.sheen_roughness_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].iridescence.iridescence_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].iridescence.iridescence_thickness_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].diffuse_transmission.diffuse_transmission_texture.texture, data->textures, data->textures_count);
		CGLTF_PTRFIXUP(data->materials[i].diffuse_transmission.diffuse_transmission_color_texture.texture, data->textures, data->textures_count);

		CGLTF_PTRFIXUP(data->materials[i].anisotropy.anisotropy_texture.texture, data->textures, data->textures_count);
	}

	for (cgltf_size i = 0; i < data->buffer_views_count; ++i)
	{
		CGLTF_PTRFIXUP_REQ(data->buffer_views[i].buffer, data->buffers, data->buffers_count);

		if (data->buffer_views[i].has_meshopt_compression)
		{
			CGLTF_PTRFIXUP_REQ(data->buffer_views[i].meshopt_compression.buffer, data->buffers, data->buffers_count);
		}
	}

	for (cgltf_size i = 0; i < data->skins_count; ++i)
	{
		for (cgltf_size j = 0; j < data->skins[i].joints_count; ++j)
		{
			CGLTF_PTRFIXUP_REQ(data->skins[i].joints[j], data->nodes, data->nodes_count);
		}

		CGLTF_PTRFIXUP(data->skins[i].skeleton, data->nodes, data->nodes_count);
		CGLTF_PTRFIXUP(data->skins[i].inverse_bind_matrices, data->accessors, data->accessors_count);
	}

	for (cgltf_size i = 0; i < data->nodes_count; ++i)
	{
		for (cgltf_size j = 0; j < data->nodes[i].children_count; ++j)
		{
			CGLTF_PTRFIXUP_REQ(data->nodes[i].children[j], data->nodes, data->nodes_count);

			if (data->nodes[i].children[j]->parent)
			{
				return CGLTF_ERROR_JSON;
			}

			data->nodes[i].children[j]->parent = &data->nodes[i];
		}

		CGLTF_PTRFIXUP(data->nodes[i].mesh, data->meshes, data->meshes_count);
		CGLTF_PTRFIXUP(data->nodes[i].skin, data->skins, data->skins_count);
		CGLTF_PTRFIXUP(data->nodes[i].camera, data->cameras, data->cameras_count);
		CGLTF_PTRFIXUP(data->nodes[i].light, data->lights, data->lights_count);

		if (data->nodes[i].has_mesh_gpu_instancing)
		{
			for (cgltf_size m = 0; m < data->nodes[i].mesh_gpu_instancing.attributes_count; ++m)
			{
				CGLTF_PTRFIXUP_REQ(data->nodes[i].mesh_gpu_instancing.attributes[m].data, data->accessors, data->accessors_count);
			}
		}
	}

	for (cgltf_size i = 0; i < data->scenes_count; ++i)
	{
		for (cgltf_size j = 0; j < data->scenes[i].nodes_count; ++j)
		{
			CGLTF_PTRFIXUP_REQ(data->scenes[i].nodes[j], data->nodes, data->nodes_count);

			if (data->scenes[i].nodes[j]->parent)
			{
				return CGLTF_ERROR_JSON;
			}
		}
	}

	CGLTF_PTRFIXUP(data->scene, data->scenes, data->scenes_count);

	for (cgltf_size i = 0; i < data->animations_count; ++i)
	{
		for (cgltf_size j = 0; j < data->animations[i].samplers_count; ++j)
		{
			CGLTF_PTRFIXUP_REQ(data->animations[i].samplers[j].input, data->accessors, data->accessors_count);
			CGLTF_PTRFIXUP_REQ(data->animations[i].samplers[j].output, data->accessors, data->accessors_count);
		}

		for (cgltf_size j = 0; j < data->animations[i].channels_count; ++j)
		{
			CGLTF_PTRFIXUP_REQ(data->animations[i].channels[j].sampler, data->animations[i].samplers, data->animations[i].samplers_count);
			CGLTF_PTRFIXUP(data->animations[i].channels[j].target_node, data->nodes, data->nodes_count);
		}
	}

	return 0;
}

/*
 * -- jsmn.c start --
 * Source: https://github.com/zserge/jsmn
 * License: MIT
 *
 * Copyright (c) 2010 Serge A. Zaitsev

 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:

 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 */

/**
 * Allocates a fresh unused token from the token pull.
 */
static jsmntok_t *jsmn_alloc_token(jsmn_parser *parser,
				   jsmntok_t *tokens, size_t num_tokens) {
	jsmntok_t *tok;
	if (parser->toknext >= num_tokens) {
		return NULL;
	}
	tok = &tokens[parser->toknext++];
	tok->start = tok->end = -1;
	tok->size = 0;
#ifdef JSMN_PARENT_LINKS
	tok->parent = -1;
#endif
	return tok;
}

/**
 * Fills token type and boundaries.
 */
static void jsmn_fill_token(jsmntok_t *token, jsmntype_t type,
				ptrdiff_t start, ptrdiff_t end) {
	token->type = type;
	token->start = start;
	token->end = end;
	token->size = 0;
}

/**
 * Fills next available token with JSON primitive.
 */
static int jsmn_parse_primitive(jsmn_parser *parser, const char *js,
				size_t len, jsmntok_t *tokens, size_t num_tokens) {
	jsmntok_t *token;
	ptrdiff_t start;

	start = parser->pos;

	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
		switch (js[parser->pos]) {
#ifndef JSMN_STRICT
		/* In strict mode primitive must be followed by "," or "}" or "]" */
		case ':':
#endif
		case '\t' : case '\r' : case '\n' : case ' ' :
		case ','  : case ']'  : case '}' :
			goto found;
		}
		if (js[parser->pos] < 32 || js[parser->pos] >= 127) {
			parser->pos = start;
			return JSMN_ERROR_INVAL;
		}
	}
#ifdef JSMN_STRICT
	/* In strict mode primitive must be followed by a comma/object/array */
	parser->pos = start;
	return JSMN_ERROR_PART;
#endif

found:
	if (tokens == NULL) {
		parser->pos--;
		return 0;
	}
	token = jsmn_alloc_token(parser, tokens, num_tokens);
	if (token == NULL) {
		parser->pos = start;
		return JSMN_ERROR_NOMEM;
	}
	jsmn_fill_token(token, JSMN_PRIMITIVE, start, parser->pos);
#ifdef JSMN_PARENT_LINKS
	token->parent = parser->toksuper;
#endif
	parser->pos--;
	return 0;
}

/**
 * Fills next token with JSON string.
 */
static int jsmn_parse_string(jsmn_parser *parser, const char *js,
				 size_t len, jsmntok_t *tokens, size_t num_tokens) {
	jsmntok_t *token;

	ptrdiff_t start = parser->pos;

	parser->pos++;

	/* Skip starting quote */
	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
		char c = js[parser->pos];

		/* Quote: end of string */
		if (c == '\"') {
			if (tokens == NULL) {
				return 0;
			}
			token = jsmn_alloc_token(parser, tokens, num_tokens);
			if (token == NULL) {
				parser->pos = start;
				return JSMN_ERROR_NOMEM;
			}
			jsmn_fill_token(token, JSMN_STRING, start+1, parser->pos);
#ifdef JSMN_PARENT_LINKS
			token->parent = parser->toksuper;
#endif
			return 0;
		}

		/* Backslash: Quoted symbol expected */
		if (c == '\\' && parser->pos + 1 < len) {
			int i;
			parser->pos++;
			switch (js[parser->pos]) {
			/* Allowed escaped symbols */
			case '\"': case '/' : case '\\' : case 'b' :
			case 'f' : case 'r' : case 'n'  : case 't' :
				break;
				/* Allows escaped symbol \uXXXX */
			case 'u':
				parser->pos++;
				for(i = 0; i < 4 && parser->pos < len && js[parser->pos] != '\0'; i++) {
					/* If it isn't a hex character we have an error */
					if(!((js[parser->pos] >= 48 && js[parser->pos] <= 57) || /* 0-9 */
						 (js[parser->pos] >= 65 && js[parser->pos] <= 70) || /* A-F */
						 (js[parser->pos] >= 97 && js[parser->pos] <= 102))) { /* a-f */
						parser->pos = start;
						return JSMN_ERROR_INVAL;
					}
					parser->pos++;
				}
				parser->pos--;
				break;
				/* Unexpected symbol */
			default:
				parser->pos = start;
				return JSMN_ERROR_INVAL;
			}
		}
	}
	parser->pos = start;
	return JSMN_ERROR_PART;
}

/**
 * Parse JSON string and fill tokens.
 */
static int jsmn_parse(jsmn_parser *parser, const char *js, size_t len,
		   jsmntok_t *tokens, size_t num_tokens) {
	int r;
	int i;
	jsmntok_t *token;
	int count = parser->toknext;

	for (; parser->pos < len && js[parser->pos] != '\0'; parser->pos++) {
		char c;
		jsmntype_t type;

		c = js[parser->pos];
		switch (c) {
		case '{': case '[':
			count++;
			if (tokens == NULL) {
				break;
			}
			token = jsmn_alloc_token(parser, tokens, num_tokens);
			if (token == NULL)
				return JSMN_ERROR_NOMEM;
			if (parser->toksuper != -1) {
				tokens[parser->toksuper].size++;
#ifdef JSMN_PARENT_LINKS
				token->parent = parser->toksuper;
#endif
			}
			token->type = (c == '{' ? JSMN_OBJECT : JSMN_ARRAY);
			token->start = parser->pos;
			parser->toksuper = parser->toknext - 1;
			break;
		case '}': case ']':
			if (tokens == NULL)
				break;
			type = (c == '}' ? JSMN_OBJECT : JSMN_ARRAY);
#ifdef JSMN_PARENT_LINKS
			if (parser->toknext < 1) {
				return JSMN_ERROR_INVAL;
			}
			token = &tokens[parser->toknext - 1];
			for (;;) {
				if (token->start != -1 && token->end == -1) {
					if (token->type != type) {
						return JSMN_ERROR_INVAL;
					}
					token->end = parser->pos + 1;
					parser->toksuper = token->parent;
					break;
				}
				if (token->parent == -1) {
					if(token->type != type || parser->toksuper == -1) {
						return JSMN_ERROR_INVAL;
					}
					break;
				}
				token = &tokens[token->parent];
			}
#else
			for (i = parser->toknext - 1; i >= 0; i--) {
				token = &tokens[i];
				if (token->start != -1 && token->end == -1) {
					if (token->type != type) {
						return JSMN_ERROR_INVAL;
					}
					parser->toksuper = -1;
					token->end = parser->pos + 1;
					break;
				}
			}
			/* Error if unmatched closing bracket */
			if (i == -1) return JSMN_ERROR_INVAL;
			for (; i >= 0; i--) {
				token = &tokens[i];
				if (token->start != -1 && token->end == -1) {
					parser->toksuper = i;
					break;
				}
			}
#endif
			break;
		case '\"':
			r = jsmn_parse_string(parser, js, len, tokens, num_tokens);
			if (r < 0) return r;
			count++;
			if (parser->toksuper != -1 && tokens != NULL)
				tokens[parser->toksuper].size++;
			break;
		case '\t' : case '\r' : case '\n' : case ' ':
			break;
		case ':':
			parser->toksuper = parser->toknext - 1;
			break;
		case ',':
			if (tokens != NULL && parser->toksuper != -1 &&
					tokens[parser->toksuper].type != JSMN_ARRAY &&
					tokens[parser->toksuper].type != JSMN_OBJECT) {
#ifdef JSMN_PARENT_LINKS
				parser->toksuper = tokens[parser->toksuper].parent;
#else
				for (i = parser->toknext - 1; i >= 0; i--) {
					if (tokens[i].type == JSMN_ARRAY || tokens[i].type == JSMN_OBJECT) {
						if (tokens[i].start != -1 && tokens[i].end == -1) {
							parser->toksuper = i;
							break;
						}
					}
				}
#endif
			}
			break;
#ifdef JSMN_STRICT
			/* In strict mode primitives are: numbers and booleans */
		case '-': case '0': case '1' : case '2': case '3' : case '4':
		case '5': case '6': case '7' : case '8': case '9':
		case 't': case 'f': case 'n' :
			/* And they must not be keys of the object */
			if (tokens != NULL && parser->toksuper != -1) {
				jsmntok_t *t = &tokens[parser->toksuper];
				if (t->type == JSMN_OBJECT ||
						(t->type == JSMN_STRING && t->size != 0)) {
					return JSMN_ERROR_INVAL;
				}
			}
#else
			/* In non-strict mode every unquoted value is a primitive */
		default:
#endif
			r = jsmn_parse_primitive(parser, js, len, tokens, num_tokens);
			if (r < 0) return r;
			count++;
			if (parser->toksuper != -1 && tokens != NULL)
				tokens[parser->toksuper].size++;
			break;

#ifdef JSMN_STRICT
			/* Unexpected char in strict mode */
		default:
			return JSMN_ERROR_INVAL;
#endif
		}
	}

	if (tokens != NULL) {
		for (i = parser->toknext - 1; i >= 0; i--) {
			/* Unmatched opened object or array */
			if (tokens[i].start != -1 && tokens[i].end == -1) {
				return JSMN_ERROR_PART;
			}
		}
	}

	return count;
}

/**
 * Creates a new parser based over a given  buffer with an array of tokens
 * available.
 */
static void jsmn_init(jsmn_parser *parser) {
	parser->pos = 0;
	parser->toknext = 0;
	parser->toksuper = -1;
}
/*
 * -- jsmn.c end --
 */

#endif /* #ifdef CGLTF_IMPLEMENTATION */

/* cgltf is distributed under MIT license:
 *
 * Copyright (c) 2018-2021 Johannes Kuhlmann

 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:

 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
//FILE_END

//FILE_START:poki.h
/*
Poki - minimal creative coding framework

Copyright (c) 2025, Arne Koenig
Redistribution and use in source and binary forms, with or without modification, are permitted.
THIS SOFTWARE IS PROVIDED 'AS-IS', WITHOUT ANY EXPRESS OR IMPLIED WARRANTY. IN NO EVENT WILL THE AUTHORS BE HELD LIABLE FOR ANY DAMAGES ARISING FROM THE USE OF THIS SOFTWARE.
*/

#ifndef POKI_H
#define POKI_H

#ifndef PK_SINGLE_HEADER
#include "deps/sokol_gfx.h"
#include "deps/sokol_fetch.h"
#include "deps/hmm.h"
#include "shaders/shaders.glsl.h"
#endif // PK_SINGLE_HEADER

#ifdef __cplusplus
extern "C" {
#endif

#ifndef pk_malloc
#define pk_malloc(x) malloc(x)
#endif
#ifndef pk_free
#define pk_free(x) free(x)
#endif
#ifndef pk_assert
#include <assert.h>
#define pk_assert(x) assert(x)
#endif
#ifndef pk_printf
#include <stdio.h>
#define pk_printf printf
#endif

#if defined(_WIN32) && !defined(SOKOL_GLES3)
#define PK_REQUEST_DEDICATED_DEVICE \
_declspec(dllexport) unsigned long NvOptimusEnablement = 1; \
_declspec(dllexport) int AmdPowerXpressRequestHighPerformance = 1;
#else
#define PK_REQUEST_DEDICATED_DEVICE
#endif

//TODO: Add useful render target helpers.

//--FORWARD--------------

typedef struct m3d_t m3d_t;
typedef struct cgltf_data cgltf_data;
typedef struct sapp_event sapp_event;


//--INIT&SHUTDOWN----------------------------------------

/*
TODO: Maybe allocate the memory needed for models, animations & Co upfront, to avoid fragmentation.
The buffer sizes should be configurable using pk_desc.
TODO: Add proper allocator interface and hook it to the dependencies.
*/

typedef struct pk_desc {
    sg_desc gfx;
    sfetch_desc_t fetch;
} pk_desc;

void pk_setup(const pk_desc* desc);
void pk_shutdown(void);


//--CAMERA------------------------------------------------------------
//modified from https://github.com/floooh/sokol-samples

typedef struct pk_cam_desc {
    float mindist;
    float maxdist;
    float minlat;
    float maxlat;
    float distance;
    float latitude;
    float longitude;
    float aspect;
    float nearz;
    float farz;
    float sensitivity;
    HMM_Vec3 center;
} pk_cam_desc;

typedef struct pk_cam {
    float mindist;
    float maxdist;
    float minlat;
    float maxlat;
    float distance;
    float latitude;
    float longitude;
    float aspect;
    float nearz;
    float farz;
    float sensitivity;
    HMM_Vec3 center;
    HMM_Vec3 eyepos;
    HMM_Mat4 view;
    HMM_Mat4 proj;
    HMM_Mat4 viewproj;
} pk_cam;

void pk_init_cam(pk_cam* cam, const pk_cam_desc* desc);
void pk_orbit_cam(pk_cam* cam, float dx, float dy);
void pk_zoom_cam(pk_cam* cam, float d);
void pk_update_cam(pk_cam* cam, int fb_width, int fb_height);
#ifndef PK_NO_SAPP
void pk_cam_input(pk_cam* cam, const sapp_event* ev);
#endif //PK_NO_SAPP


//--TEXTURES--------------------------------------------------------

typedef struct pk_texture_desc {
    int width, height;
    sg_image_usage usage;
    sg_range data;
    sg_pixel_format format;
    sg_filter min_filter;
    sg_filter mag_filter;
    sg_wrap wrap_u;
    sg_wrap wrap_v;
} pk_texture_desc;

typedef struct pk_texture {
    sg_image image;
    sg_sampler sampler;
} pk_texture;

void pk_init_texture(pk_texture* tex, const pk_texture_desc* desc);
void pk_checker_texture(pk_texture* tex);
void pk_update_texture(pk_texture* tex, sg_range data);
void pk_release_texture(pk_texture* tex);


//--NODE---------------------------------------------------------------------

#define PK_MAX_NAME_LEN 32

typedef struct pk_node {
    char name[PK_MAX_NAME_LEN];
    struct pk_node* parent;
    HMM_Vec3 position;
    HMM_Vec3 scale;
    HMM_Quat rotation;
} pk_node;

void pk_init_node(pk_node* node);
void pk_release_node(pk_node* node);
HMM_Mat4 pk_node_transform(const pk_node* node);


//--PRIMITIVE--------------------------------------------------------------

typedef struct pk_vertex_pnt {
    HMM_Vec3 pos;
    HMM_Vec3 nrm;
    HMM_Vec2 uv;
} pk_vertex_pnt;

sg_vertex_layout_state pk_pnt_layout(void);

typedef struct pk_vertex_skin {
    uint16_t indices[4];
    float weights[4];
} pk_vertex_skin;

sg_vertex_layout_state pk_skinned_layout(void);

typedef struct {
	sg_range vertices;
	sg_range indices;
	int num_elements;
    bool is_mutable;
} pk_primitive_desc;

typedef struct pk_primitive {
	sg_bindings bindings;
	int base_element;
	int num_elements;
} pk_primitive;

void pk_alloc_primitive(pk_primitive* primitive, uint16_t vubf_count, uint16_t sbuf_count);
void pk_init_primitive(pk_primitive* primitive, const pk_primitive_desc* desc);
bool pk_load_m3d(pk_primitive* mesh, pk_node* node, m3d_t* m3d);
void pk_release_primitive(pk_primitive* primitive);
void pk_texture_primitive(pk_primitive* primitive, const pk_texture* tex, int slot);
void pk_draw_primitive(const pk_primitive* primitive, int num_instances);


//--MESH-------------------------------------------------------------------

typedef struct pk_mesh {
    pk_primitive* primitives;
    uint16_t primitive_count;
    pk_node* node;
} pk_mesh;

void pk_draw_mesh(pk_mesh* mesh, pk_vs_params_t* vs_params);
void pk_release_mesh(pk_mesh* mesh);


//--MODEL-----------------------------------------------------------------

typedef struct pk_model {
    pk_mesh* meshes;
    uint16_t mesh_count;
    pk_node* nodes;
    uint16_t node_count;
} pk_model;

bool pk_load_gltf(pk_model* model, cgltf_data* data);
void pk_release_model(pk_model* model);
pk_node* pk_find_model_node(const pk_model*, const char* name);
void pk_set_model_texture(pk_model* model, const pk_texture* tex, int slot);
void pk_draw_model(pk_model* model, pk_vs_params_t* vs_params);


//--ANIMATION-------------------------------------------------------------

/*
TODO: Gltf and m3d animation handling works quite different right now.
This should change. Internally both use very different methods, to
evaluate the animations, in particular the bone animation thing needs an
overhaul, because it's not very memory efficient.
*/

//--GLTF---------------------------

typedef enum {
    PK_ANIM_PATH_UNDEFINED,
    PK_ANIM_PATH_TRANSLATION,
    PK_ANIM_PATH_ROTATION,
    PK_ANIM_PATH_SCALE,
} pk_gltf_anim_path_type;

typedef enum {
    PK_ANIM_INTERP_UNDEFINED,
    PK_ANIM_INTERP_LINEAR,
    PK_ANIM_INTERP_STEP,
    PK_ANIM_INTERP_CUBIC, //not used - atm we force cubic to linear
} pk_gltf_anim_interp_type;

typedef struct pk_gltf_keyframe {
    float time;
    float* value;
} pk_gltf_keyframe;

typedef struct pk_gltf_anim_channel {
    pk_node* target_node;
    pk_gltf_anim_path_type path;
    pk_gltf_keyframe* keyframes;
    int num_keyframes;
    pk_gltf_anim_interp_type interpolation;
} pk_gltf_anim_channel;

typedef struct pk_gltf_anim {
    pk_gltf_anim_channel* channels;
    int num_channels;
    float duration;
    float elapsed_time;
    bool loop;
    bool ready;
} pk_gltf_anim;

bool pk_load_gltf_anim(pk_gltf_anim* anim, pk_model* model, cgltf_data* data);
void pk_release_gltf_anim(pk_gltf_anim* anim);
void pk_play_gltf_anim(pk_gltf_anim* anim, float delta_time);

//--M3D------------------------------

typedef struct pk_bone {
    char name[PK_MAX_NAME_LEN];
    int parent;
} pk_bone;

typedef struct pk_transform {
    HMM_Vec3 pos;
    HMM_Quat rot;
    HMM_Vec3 scale;
} pk_transform;

typedef struct pk_skeleton {
    pk_bone* bones;
    int bone_count;
    pk_transform* bind_poses;
} pk_skeleton;

bool pk_load_skeleton(pk_skeleton* skeleton, m3d_t* m3d);
void pk_release_skeleton(pk_skeleton* skeleton);

typedef struct pk_bone_anim {
    int bone_count;
    int frame_count;
    pk_bone* bones;
    pk_transform** poses;
    float time;
    int frame;
} pk_bone_anim;

pk_bone_anim* pk_load_bone_anims(m3d_t* m3d, int* count);
void pk_play_bone_anim(HMM_Mat4* trs, pk_skeleton* skeleton, pk_bone_anim* anim, float dt);
void pk_release_bone_anim(pk_bone_anim* anim); //IMPLEMENT


//--IO---------------------------------------------------------------------------

//TODO: add void* udata field to the request structs, to enable avoiding globals
//Maybe add optional automatic texture loading for models.

typedef void(*pk_fail_callback)(const sfetch_response_t* response);

//--IMAGE-LOADING----------

typedef struct pk_image_data {
    void* pixels;
    int width, height;
} pk_image_data;

typedef void(*pk_image_loaded_callback)(pk_image_data* image);

typedef struct pk_image_request {
    const char* path;
    sfetch_range_t buffer;
    pk_image_loaded_callback loaded_cb;
    pk_fail_callback fail_cb;
} pk_image_request;

//Supports .qoi and .png, will generate a 4x4 checker texture on fail, if no fail callback is provided.
sfetch_handle_t pk_load_image_data(const pk_image_request* req);

//--M3D-LOADING----------------

typedef void(*pk_m3d_loaded_callback)(m3d_t* m3d);

typedef struct pk_m3d_request {
    const char* path;
    sfetch_range_t buffer;
    pk_m3d_loaded_callback loaded_cb;
    pk_fail_callback fail_cb;
} pk_m3d_request;

sfetch_handle_t pk_load_m3d_data(const pk_m3d_request* req);
void pk_release_m3d_data(m3d_t* m3d);


//--GLTF-LOADING---------------

typedef void(*pk_gltf_loaded_callback)(cgltf_data* gltf);

typedef struct pk_gltf_request {
    const char* path;
    sfetch_range_t buffer;
    pk_gltf_loaded_callback loaded_cb;
    pk_fail_callback fail_cb;
} pk_gltf_request;

sfetch_handle_t pk_load_gltf_data(const pk_gltf_request* req);
void pk_release_gltf_data(cgltf_data* data);


#ifdef __cplusplus
} //extern "C"
#endif

#endif // POKI_H
//FILE_END

#ifdef POKI_IMPL

//FILE_START:poki.c
#ifndef PK_SINGLE_HEADER
#include "poki.h"
#ifndef PK_NO_SAPP
#include "deps/sokol_app.h"
#endif //PK_NO_SAPP
#include "deps/qoi.h"
#include "deps/cute_png.h"
#include "deps/m3d.h"
#include "deps/cgltf.h"
#endif

#include <string.h>

#define PK_DEF(val, def) ((val == 0) ? def : val)

void pk_setup(const pk_desc* desc) {
    sg_setup(&desc->gfx);
    sfetch_setup(&desc->fetch);
}

void pk_shutdown(void) {
    sfetch_shutdown();
    sg_shutdown();
}


//---------------------------------------------------------------------------------
//--CAMERA-------------------------------------------------------------------------
//---------------------------------------------------------------------------------


#define CAM_DEF_MIN_DIST (2.0f)
#define CAM_DEF_MAX_DIST (50.0f)
#define CAM_DEF_MIN_LAT (-85.0f)
#define CAM_DEF_MAX_LAT (85.0f)
#define CAM_DEF_DIST (10.0f)
#define CAM_DEF_ASPECT (60.0f)
#define CAM_DEF_NEARZ (1.0f)
#define CAM_DEF_FARZ (1000.0f)
#define CAM_DEF_SENSITIVITY (30.0f)

static HMM_Vec3 _cam_euclidean(float latitude, float longitude) {
    const float lat = latitude * HMM_DegToRad;
    const float lng = longitude * HMM_DegToRad;
    return HMM_V3(cosf(lat) * sinf(lng), sinf(lat), cosf(lat) * cosf(lng));
}

void pk_init_cam(pk_cam* cam, const pk_cam_desc* desc) {
    pk_assert(desc && cam);
    cam->mindist = PK_DEF(desc->mindist, CAM_DEF_MIN_DIST);
    cam->maxdist = PK_DEF(desc->maxdist, CAM_DEF_MAX_DIST);
    cam->minlat = PK_DEF(desc->minlat, CAM_DEF_MIN_LAT);
    cam->maxlat = PK_DEF(desc->maxlat, CAM_DEF_MAX_LAT);
    cam->distance = PK_DEF(desc->distance, CAM_DEF_DIST);
    cam->center = desc->center;
    cam->latitude = desc->latitude;
    cam->longitude = desc->longitude;
    cam->aspect = PK_DEF(desc->aspect, CAM_DEF_ASPECT);
    cam->nearz = PK_DEF(desc->nearz, CAM_DEF_NEARZ);
    cam->farz = PK_DEF(desc->farz, CAM_DEF_FARZ);
    cam->sensitivity = PK_DEF(desc->sensitivity, CAM_DEF_SENSITIVITY);
}

void pk_orbit_cam(pk_cam* cam, float dx, float dy) {
    pk_assert(cam);
    cam->longitude -= dx;
    if (cam->longitude < 0.0f) {
        cam->longitude += 360.0f;
    }
    if (cam->longitude > 360.0f) {
        cam->longitude -= 360.0f;
    }
    cam->latitude = HMM_Clamp(cam->minlat, cam->latitude + dy, cam->maxlat);
}

void pk_zoom_cam(pk_cam* cam, float d) {
    pk_assert(cam);
    cam->distance = HMM_Clamp(cam->mindist, cam->distance + d, cam->maxdist);
}

void pk_update_cam(pk_cam* cam, int fb_width, int fb_height) {
    pk_assert(cam);
    const float w = (float)fb_width;
    const float h = (float)fb_height;

    cam->eyepos =  HMM_AddV3(cam->center, HMM_MulV3F(_cam_euclidean(cam->latitude, cam->longitude), cam->distance));
    cam->view = HMM_LookAt_RH(cam->eyepos, cam->center, HMM_V3(0.0f, 1.0f, 0.0f));
    cam->proj = HMM_Perspective_RH_ZO(cam->aspect * HMM_DegToRad, w / h, 0.1f, 1000.f);
    cam->viewproj = HMM_MulM4(cam->proj, cam->view);
}

#ifndef PK_NO_SAPP
void pk_cam_input(pk_cam* cam, const sapp_event* ev) {
    pk_assert(cam);
    switch (ev->type) {
    case SAPP_EVENTTYPE_MOUSE_DOWN:
        if (ev->mouse_button == SAPP_MOUSEBUTTON_RIGHT) {
            sapp_lock_mouse(true);
        }
        break;
    case SAPP_EVENTTYPE_MOUSE_UP:
        if (ev->mouse_button == SAPP_MOUSEBUTTON_RIGHT) {
            sapp_lock_mouse(false);
        }
        break;
    case SAPP_EVENTTYPE_MOUSE_SCROLL:
        pk_zoom_cam(cam, ev->scroll_y * (cam->sensitivity * 0.005f));
        break;
    case SAPP_EVENTTYPE_MOUSE_MOVE:
        if (sapp_mouse_locked()) {
            pk_orbit_cam(cam, ev->mouse_dx * 0.25f, ev->mouse_dy * 0.25f);
        }
        break;
    default:
        break;
    }
}
#endif //PK_NO_SAPP


//---------------------------------------------------------------------------------
//--TEXTURES-----------------------------------------------------------------------
//---------------------------------------------------------------------------------


#define PK_DEF_IMG_SIZE 256

static const uint32_t _checker_pixels[4 * 4] = {
    0xFFAAAAAA, 0xFF555555, 0xFFAAAAAA, 0xFF555555,
    0xFF555555, 0xFFAAAAAA, 0xFF555555, 0xFFAAAAAA,
    0xFFAAAAAA, 0xFF555555, 0xFFAAAAAA, 0xFF555555,
    0xFF555555, 0xFFAAAAAA, 0xFF555555, 0xFFAAAAAA,
};

static sg_image_desc _checker_image_desc(void) {
    sg_image_desc desc = { 0 };
    desc.width = 4;
    desc.height = 4;
    desc.data.subimage[0][0] = SG_RANGE(_checker_pixels);
    return desc;
}

void pk_init_texture(pk_texture* tex, const pk_texture_desc* desc) {
    pk_assert(tex);
    sg_image_desc img = { 0 };
    img.usage= desc->usage;
    img.data.subimage[0][0] = desc->data;
    img.width = PK_DEF(desc->width, PK_DEF_IMG_SIZE);
    img.height = PK_DEF(desc->height, PK_DEF_IMG_SIZE);
    img.pixel_format = desc->format;
    tex->image = sg_make_image(&img);

    sg_sampler_desc sd = { 0 };
    sd.min_filter = desc->min_filter;
    sd.mag_filter = desc->mag_filter;
    sd.wrap_u = desc->wrap_u;
    sd.wrap_v = desc->wrap_v;
    tex->sampler = sg_make_sampler(&sd);
}

void pk_checker_texture(pk_texture* tex) {
    pk_assert(tex);
    sg_image_desc img = _checker_image_desc();
    tex->image = sg_make_image(&img);
    tex->sampler = sg_make_sampler(&(sg_sampler_desc) { 0 });
}

void pk_update_texture(pk_texture* tex, sg_range data) {
    pk_assert(tex && data.ptr);
    sg_image_data img = { 0 };
    img.subimage[0][0] = data;
    sg_update_image(tex->image, &img);
}

void pk_release_texture(pk_texture* tex) {
    pk_assert(tex);
    sg_destroy_image(tex->image);
    sg_destroy_sampler(tex->sampler);
}


//---------------------------------------------------------------------------------
//--PRIMITIVE----------------------------------------------------------------------
//---------------------------------------------------------------------------------


sg_vertex_layout_state pk_pnt_layout() {
    return (sg_vertex_layout_state) {
        .buffers[0].stride = sizeof(pk_vertex_pnt),
        .attrs = {
            [0].format = SG_VERTEXFORMAT_FLOAT3,
            [1].format = SG_VERTEXFORMAT_FLOAT3,
            [2].format = SG_VERTEXFORMAT_FLOAT2,
        },
    };
}

sg_vertex_layout_state pk_skinned_layout() {
    return (sg_vertex_layout_state) {
        .buffers = {
            [0].stride = sizeof(pk_vertex_pnt),
            [1].stride = sizeof(pk_vertex_skin),
        },
        .attrs = {
            [0] = {.buffer_index = 0, .format = SG_VERTEXFORMAT_FLOAT3},
            [1] = {.buffer_index = 0, .format = SG_VERTEXFORMAT_FLOAT3},
            [2] = {.buffer_index = 0, .format = SG_VERTEXFORMAT_FLOAT2},
            [3] = {.buffer_index = 1, .format = SG_VERTEXFORMAT_USHORT4},
            [4] = {.buffer_index = 1, .format = SG_VERTEXFORMAT_FLOAT4},
        }
    };
}

void pk_alloc_primitive(pk_primitive* primitive, uint16_t vbuf_count, uint16_t sbuf_count) {
    pk_assert(primitive &&
        vbuf_count < SG_MAX_VERTEXBUFFER_BINDSLOTS &&
        sbuf_count < SG_MAX_STORAGEBUFFER_BINDSLOTS
    );

    primitive->bindings.index_buffer = sg_alloc_buffer();

    for (uint16_t i = 0; i < vbuf_count; ++i) {
        if (i > SG_MAX_VERTEXBUFFER_BINDSLOTS) break;
        primitive->bindings.vertex_buffers[i] = sg_alloc_buffer();
    }

    for (uint16_t i = 0; i < sbuf_count; ++i) {
        if (i > SG_MAX_STORAGEBUFFER_BINDSLOTS) break;
        primitive->bindings.storage_buffers[i] = sg_alloc_buffer();
    }
}

void pk_init_primitive(pk_primitive* primitive, const pk_primitive_desc* desc) {
    pk_assert(primitive && desc);
    pk_release_primitive(primitive);
    sg_buffer_desc bufdesc = { 0 };
    bufdesc.usage.vertex_buffer = true;
    bufdesc.usage.immutable = !desc->is_mutable;
    bufdesc.data = desc->vertices;
    primitive->bindings.vertex_buffers[0] = sg_make_buffer(&bufdesc);

    if (desc->indices.size != 0) {
        bufdesc.data = desc->indices;
        bufdesc.usage.immutable = !desc->is_mutable;
        bufdesc.usage.index_buffer = true;
        primitive->bindings.index_buffer = sg_make_buffer(&bufdesc);
    }

    primitive->base_element = 0;
    primitive->num_elements = desc->num_elements;
}

/*
TODO: The index buffer which is generated here is very silly (0, 1, 2, ...)
Do something clever about that.
*/
bool pk_load_m3d(pk_primitive* prim, pk_node* node, m3d_t* m3d) {
    pk_assert(m3d && prim);
    uint32_t total_vertices = m3d->numface * 3;

    pk_vertex_pnt* pnt = pk_malloc(total_vertices * sizeof(pk_vertex_pnt));
    pk_assert(pnt);

    bool has_skin = (m3d->numbone > 0 && m3d->numskin > 0);
    pk_vertex_skin* skin = NULL;
    if (has_skin) {
        skin = pk_malloc(total_vertices * sizeof(pk_vertex_skin));
        pk_assert(skin);
    }

    uint32_t* indices = pk_malloc(sizeof(uint32_t) * total_vertices);
    pk_assert(indices);

    unsigned int k = 0;
    for (unsigned int i = 0; i < m3d->numface; i++) {
        for (unsigned int j = 0; j < 3; j++, k++) {
            uint32_t outIndex = i * 3 + j;
            indices[outIndex] = outIndex;

            memcpy(&pnt[k].pos.X, &m3d->vertex[m3d->face[i].vertex[j]].x, 3 * sizeof(float));
            memcpy(&pnt[k].nrm.X, &m3d->vertex[m3d->face[i].normal[j]].x, 3 * sizeof(float));

            if (m3d->tmap && m3d->face[i].texcoord[j] < m3d->numtmap) {
                pnt[k].uv.U = m3d->tmap[m3d->face[i].texcoord[j]].u;
                pnt[k].uv.V = 1.0f - m3d->tmap[m3d->face[i].texcoord[j]].v;
            }
            else {
                pnt[k].uv = HMM_V2(0.f, 0.f);
            }

            if(has_skin) {
                unsigned int s = m3d->vertex[m3d->face[i].vertex[j]].skinid;
                if (s != M3D_UNDEF) {
                    for (int b = 0; b < 4; b++) {
                        //printf("boneindex: %i\n", app.model->skin[s].boneid[b]);
                        skin[k].indices[b] = (uint16_t)m3d->skin[s].boneid[b];
                        skin[k].weights[b] = m3d->skin[s].weight[b];
                    }
                }
                else {
                    // If no skinning, default to one full-weight bone (or identity)
                    skin[k].indices[0] = 0;
                    skin[k].weights[0] = 1.0f;
                    for (int b = 1; b < 4; b++) {
                        skin[k].indices[b] = 0;
                        skin[k].weights[b] = 0.0f;
                    }
                }
            }
        }
    }

    sg_buffer_desc bd = { 0 };
    bd.usage.vertex_buffer = true;
    bd.usage.immutable = true;
    bd.data = (sg_range){ pnt, total_vertices * sizeof(pk_vertex_pnt) };
    sg_init_buffer(prim->bindings.vertex_buffers[0], &bd);

    if (has_skin) {
        bd.usage.vertex_buffer = true;
        bd.usage.immutable = true;
        bd.data = (sg_range){ skin, total_vertices * sizeof(pk_vertex_skin) };
        sg_init_buffer(prim->bindings.vertex_buffers[1], &bd);
    }

    bd.usage.index_buffer = true;
    bd.data = (sg_range){ indices, total_vertices * sizeof(uint32_t) };
    sg_init_buffer(prim->bindings.index_buffer, &bd);

    /*
    We could bake the scale into the vertex data, but let's instead scale the node,
    if there is one.
    */
    if (node) {
        node->scale.X = m3d->scale;
        node->scale.Y = m3d->scale;
        node->scale.Z = m3d->scale;
    }

    prim->base_element = 0;
    prim->num_elements = total_vertices;

    pk_free(pnt);
    pk_free(indices);
    if(skin != NULL) { pk_free(skin); }
    pk_printf("Loaded pk_primitive %s\n", m3d->name);
    return true;
}

void pk_release_primitive(pk_primitive* primitive) {
    pk_assert(primitive);
    for (int i = 0; i < SG_MAX_VERTEXBUFFER_BINDSLOTS; ++i) {
        sg_destroy_buffer(primitive->bindings.vertex_buffers[i]);
    }
    for (int i = 0; i < SG_MAX_STORAGEBUFFER_BINDSLOTS; ++i) {
        sg_destroy_buffer(primitive->bindings.storage_buffers[i]);
    }
    sg_destroy_buffer(primitive->bindings.index_buffer);
}

void pk_texture_primitive(pk_primitive* primitive, const pk_texture* tex, int slot) {
    pk_assert(primitive && tex && slot < SG_MAX_IMAGE_SAMPLER_PAIRS);
    primitive->bindings.images[slot] = tex->image;
    primitive->bindings.samplers[slot] = tex->sampler;
}

void pk_draw_primitive(const pk_primitive* primitive, int num_instances) {
    pk_assert(primitive);
    sg_apply_bindings(&primitive->bindings);
    sg_draw(primitive->base_element, primitive->num_elements, num_instances);
}


//---------------------------------------------------------------------------------
//--NODE---------------------------------------------------------------------------
//---------------------------------------------------------------------------------


void pk_init_node(pk_node* node) {
    pk_assert(node);
    strncpy(node->name, "UNNAMED", PK_MAX_NAME_LEN - 1);
    node->name[PK_MAX_NAME_LEN - 1] = '\0';
    node->parent = NULL;
    node->position = HMM_V3(0, 0, 0);
    node->scale = HMM_V3(1, 1, 1);
    node->rotation = HMM_Q(0, 0, 0, 1);
}

void pk_release_node(pk_node* node) {
    pk_assert(node);
    pk_free(node->name);
}

HMM_Mat4 pk_node_transform(const pk_node* node) {
    pk_assert(node);

    HMM_Mat4 pos = HMM_Translate(node->position);
    HMM_Mat4 rot = HMM_QToM4(node->rotation);
    HMM_Mat4 scl = HMM_Scale(node->scale);

    HMM_Mat4 ret = HMM_MulM4(pos, HMM_MulM4(rot, scl));

    if (node->parent != NULL) {
        HMM_Mat4 parent_transform = pk_node_transform(node->parent);
        ret = HMM_MulM4(parent_transform, ret);
    }
    return ret;
}


//---------------------------------------------------------------------------------
//--MESH---------------------------------------------------------------------------
//---------------------------------------------------------------------------------


void pk_release_mesh(pk_mesh* mesh) {
    pk_assert(mesh);
    for (uint16_t i = 0; i < mesh->primitive_count; ++i) {
        pk_release_primitive(&mesh->primitives[i]);
    }
}

void pk_draw_mesh(pk_mesh* mesh, pk_vs_params_t* vs_params) {
    pk_assert(mesh && vs_params);
    vs_params->model = pk_node_transform(mesh->node);
    sg_apply_uniforms(UB_pk_vs_params, &(sg_range){vs_params, sizeof(pk_vs_params_t)});
    for (uint16_t i = 0; i < mesh->primitive_count; ++i) {
        pk_draw_primitive(&mesh->primitives[i], 1);
    }
}


//---------------------------------------------------------------------------------
//--MODEL/GLTF---------------------------------------------------------------------
//---------------------------------------------------------------------------------


static uint32_t* load_indices(const cgltf_primitive* prim, size_t* index_count) {
    if (!prim->indices) {
        pk_printf("No indices found in model!\n");
        return NULL;
    }

    const cgltf_accessor* index_accessor = prim->indices;
    size_t gltf_index_count = index_accessor->count;
    *index_count = gltf_index_count;
    uint32_t* indices = pk_malloc(gltf_index_count * sizeof(uint32_t));
    pk_assert(indices);

    for (size_t i = 0; i < gltf_index_count; ++i) {
        uint32_t index = 0;
        cgltf_accessor_read_uint(index_accessor, i, &index, 1);
        indices[i] = index;
    }

    return indices;
}

static pk_vertex_pnt* interleave_attributes(const cgltf_primitive* primitive, size_t* vertex_count) {
    cgltf_accessor* position_accessor = NULL;
    cgltf_accessor* normal_accessor = NULL;
    cgltf_accessor* uv_accessor = NULL;

    for (size_t i = 0; i < primitive->attributes_count; ++i) {
        const cgltf_attribute* attribute = &primitive->attributes[i];

        switch (attribute->type) {
        case cgltf_attribute_type_position:
            position_accessor = attribute->data;
            break;
        case cgltf_attribute_type_normal:
            normal_accessor = attribute->data;
            break;
        case cgltf_attribute_type_texcoord:
            uv_accessor = attribute->data;
            break;
        default:
            break;
        }
    }

    //This should fail, if there is not at least a position attribute...
    if (!position_accessor) {
        pk_printf("No position attribute found in gltf primitive!\n");
        return NULL;
    }

    size_t gltf_vertex_count = position_accessor->count;
    *vertex_count = gltf_vertex_count;

    pk_vertex_pnt* interleaved = pk_malloc(gltf_vertex_count * sizeof(pk_vertex_pnt));

    for (size_t i = 0; i < gltf_vertex_count; ++i) {
        pk_vertex_pnt vertex = {0};

        if (position_accessor) {
            cgltf_accessor_read_float(position_accessor, i, vertex.pos.Elements, 3);
        }
        if (normal_accessor) {
            cgltf_accessor_read_float(normal_accessor, i, vertex.nrm.Elements, 3);
        }
        if (uv_accessor) {
            cgltf_accessor_read_float(uv_accessor, i, vertex.uv.Elements, 2);
        }

        interleaved[i] = vertex;
    }

    return interleaved;
}

// keep as reminder for skinning
/*
static array_t<pk_vertex_skin> interleave_attributes_skin(const cgltf_primitive& primitive) {
    array_t<pk_vertex_skin> interleaved = {};

    const cgltf_accessor* jointsAccessor = nullptr;
    const cgltf_accessor* weightsAccessor = nullptr;

    // Find the accessors for joints and weights
    for (size_t i = 0; i < primitive.attributes_count; ++i) {
        const cgltf_attribute& attribute = primitive.attributes[i];
        switch (attribute.type) {
        case cgltf_attribute_type_joints:
            jointsAccessor = attribute.data;
            break;
        case cgltf_attribute_type_weights:
            weightsAccessor = attribute.data;
            break;
        default:
            break;
        }
    }

    if (weightsAccessor == nullptr || jointsAccessor == nullptr) {
        fprintf(stderr, "Missing skinning attributes (joints or weights) in primitive.\n");
        return interleaved;
    }

    size_t vertex_count = weightsAccessor->count;
    interleaved.resize(vertex_count);

    for (size_t i = 0; i < vertex_count; ++i) {
        pk_vertex_skin vertex = {};

        // Read joint indices (uint8_t)
        uint32_t joints[4] = { 0 };
        cgltf_accessor_read_uint(jointsAccessor, i, (uint32_t*)joints, 4);
        vertex.joints = pack_u32(joints[0], joints[1], joints[2], joints[3]);

        // Read weights (float), normalize to uint8_t range
        float weights[4] = { 0.0f };
        cgltf_accessor_read_float(weightsAccessor, i, weights, 4);
        vertex.weights = pack_f4_ubyte4n(weights[0], weights[1], weights[2], weights[3]);

        interleaved.insert(i, vertex);  // Assign the constructed vertex
    }

    return interleaved;
}
*/

static pk_node* load_scene_nodes(cgltf_data* data, size_t* node_count) {
    pk_node* nodes = (pk_node*)pk_malloc(sizeof(pk_node) * data->nodes_count);
    pk_assert(nodes);
    *node_count = data->nodes_count;

    for (size_t i = 0; i < data->nodes_count; i++) {
        const cgltf_node* gl_node = &data->nodes[i];

        // Set node properties
        const char* nodeName = gl_node->name ? gl_node->name : "UNNAMED";
        strncpy(nodes[i].name, nodeName, PK_MAX_NAME_LEN - 1);
        nodes[i].name[sizeof(nodes[i].name) - 1] = '\0';

        if (gl_node->has_translation) {
            nodes[i].position = HMM_V3(gl_node->translation[0], gl_node->translation[1], gl_node->translation[2]);
        }
        else {
            nodes[i].position = HMM_V3(0.f, 0.f, 0.f);
        }

        if (gl_node->has_scale) {
            nodes[i].scale = HMM_V3(gl_node->scale[0], gl_node->scale[1], gl_node->scale[2]);
        }
        else {
            nodes[i].scale = HMM_V3(1.0f, 1.0f, 1.0f);
        }

        if (gl_node->has_rotation) {
            nodes[i].rotation = HMM_Q(
                gl_node->rotation[0],
                gl_node->rotation[1],
                gl_node->rotation[2],
                gl_node->rotation[3]
            );
        }
        else {
            nodes[i].rotation = HMM_Q(0.f, 0.f, 0.f, 1.0f);
        }
    }
    return nodes;
}

static void organize_nodes(cgltf_data* data, pk_node* nodes) {
    for (size_t i = 0; i < data->nodes_count; ++i) {
        const cgltf_node* gl_node = &data->nodes[i];
        pk_node* current_node = &nodes[i];

        // Assign parent if it exists
        if (gl_node->parent) {
            for (size_t j = 0; j < data->nodes_count; ++j) {
                if (&data->nodes[j] == gl_node->parent) {
                    current_node->parent = &nodes[j];
                    break;
                }
            }
        }
        else {
            current_node->parent = NULL; //root node
        }
    }
}

static pk_primitive create_primitive(
    pk_vertex_pnt* vertices, size_t vertex_count,
    uint32_t* indices, size_t index_count) {

    pk_primitive prim = {0};
    pk_primitive_desc desc = {0};
    desc.is_mutable = false;
    desc.num_elements = (int)index_count;
    desc.vertices = (sg_range){ vertices, vertex_count * sizeof(pk_vertex_pnt) };
    desc.indices = (sg_range){ indices, index_count * sizeof(uint32_t) };
    pk_init_primitive(&prim, &desc);
    return prim;
}

//--PUBLIC----------------------

bool pk_load_gltf(pk_model* model, cgltf_data* data) {
    pk_assert(model && data);
    size_t node_count;
    pk_node* nodes = load_scene_nodes(data, &node_count);
    organize_nodes(data, nodes);

    model->nodes = nodes;
    model->node_count = (uint16_t)node_count;

    pk_printf("Scene node info:");
    for (uint16_t i = 0; i < model->node_count; ++i) {
        pk_printf("Node: %s\n", model->nodes[i].name);
        if (model->nodes[i].parent) {
            pk_printf("Parent: %s\n", model->nodes[i].parent->name);
        }
    }

    pk_mesh* meshes = pk_malloc(data->meshes_count * sizeof(pk_mesh));
    pk_assert(meshes);
    size_t mesh_idx = 0;

    //process nodes and assign meshes/models in one loop
    for (size_t i = 0; i < data->nodes_count; ++i) {
        const cgltf_node* gl_node = &data->nodes[i];
        pk_node* current_node = &model->nodes[i];

        //process meshes attached to this node
        if (gl_node->mesh) {

            const cgltf_mesh* gl_mesh = gl_node->mesh;
            pk_primitive* primitives = pk_malloc(gl_node->mesh->primitives_count * sizeof(pk_primitive));
            pk_assert(primitives);
            //bool is_skinned = (gl_node->skin != NULL);

            for (size_t j = 0; j < gl_mesh->primitives_count; ++j) {
                const cgltf_primitive* primitive = &gl_mesh->primitives[j];

                size_t vertex_count;
                pk_vertex_pnt* vertices = interleave_attributes(primitive, &vertex_count);
                size_t index_count;
                uint32_t* indices = load_indices(primitive, &index_count);

                if (vertex_count > 0 && index_count > 0) {
                    primitives[j] = create_primitive(vertices, vertex_count, indices, index_count);
                    pk_free(vertices);
                    pk_free(indices);
                    /*
                    if (is_skinned) {
                        array_t<pk_vertex_skin> skin_verts = interleave_attributes_skin(primitive);
                        sg_buffer_desc skin = {};
                        skin.type = SG_BUFFERTYPE_VERTEXBUFFER;
                        skin.usage = SG_USAGE_IMMUTABLE;
                        skin.data = sg_range{ skin_verts.data, skin_verts.count * sizeof(pk_vertex_skin) };
                        prim.bindings.vertex_buffers[1] = sg_make_buffer(skin);
                    }
                    */
                }
                else {
                    pk_printf("No vertices or indices found for mesh '%s'\n", gl_mesh->name ? gl_mesh->name : "Unnamed");
                }

            }

            meshes[mesh_idx].node = current_node;
            meshes[mesh_idx].primitives = primitives;
            meshes[mesh_idx].primitive_count = (uint16_t)gl_mesh->primitives_count;
            mesh_idx++;
        }
    }

    model->meshes = meshes;
    model->mesh_count = (uint16_t)data->meshes_count;
    return true;
}

pk_node* pk_find_model_node(const pk_model* model, const char* name) {
    pk_assert(model);
    for (int i = 0; i < model->node_count; ++i) {
        pk_node* node = &model->nodes[i];
        if (strcmp(node->name, name) == 0) {
            return node;
        }
    }
    return NULL;
}

void pk_set_model_texture(pk_model* model, const pk_texture* tex, int slot) {
    pk_assert(model && tex);
    for (uint16_t i = 0; i < model->mesh_count; ++i) {
        pk_mesh* mesh = &model->meshes[i];
        for (uint16_t j = 0; j < mesh->primitive_count; j++) {
            pk_texture_primitive(&mesh->primitives[j], tex, slot);
        }
    }
}

void pk_draw_model(pk_model* model, pk_vs_params_t* vs_params) {
    pk_assert(model && vs_params);
    for (uint16_t i = 0; i < model->mesh_count; ++i) {
        pk_mesh* mesh = &model->meshes[i];
        vs_params->model = pk_node_transform(mesh->node);
        pk_draw_mesh(mesh, vs_params);
    }
}

void pk_release_model(pk_model* model) {
    pk_assert(model);
    for (uint16_t i = 0; i < model->mesh_count; ++i) {
        pk_mesh* mesh = &model->meshes[i];
        pk_release_mesh(mesh);
    }
    pk_free(model->meshes);
    pk_free(model->nodes);
}


//---------------------------------------------------------------------------------
//--GLTF_ANIM----------------------------------------------------------------------
//---------------------------------------------------------------------------------


static pk_gltf_anim_interp_type get_interpolation_type(cgltf_interpolation_type interpolation) {
    switch (interpolation) {
    case cgltf_interpolation_type_linear:
        return PK_ANIM_INTERP_LINEAR;
    case cgltf_interpolation_type_step:
        return PK_ANIM_INTERP_STEP;
    case cgltf_interpolation_type_cubic_spline:
        //force cubic spline to linear
        return PK_ANIM_INTERP_LINEAR;
    default:
        return PK_ANIM_INTERP_LINEAR;
    }
}

static void extract_animation_channel(
    cgltf_animation_channel* gltf_channel,
    pk_gltf_anim_channel* pk_channel,
    pk_model* model, cgltf_data* data) {

    pk_channel->target_node = pk_find_model_node(model, gltf_channel->target_node->name);
    if (!pk_channel->target_node)
        return;

    //Determine which property is animated.
    switch (gltf_channel->target_path) {
    case cgltf_animation_path_type_translation:
        pk_channel->path = PK_ANIM_PATH_TRANSLATION;
        break;
    case cgltf_animation_path_type_rotation:
        pk_channel->path = PK_ANIM_PATH_ROTATION;
        break;
    case cgltf_animation_path_type_scale:
        pk_channel->path = PK_ANIM_PATH_SCALE;
        break;
    default:
        return;
    }

    int num_keyframes = (int)gltf_channel->sampler->input->count;
    pk_channel->num_keyframes = num_keyframes;

    pk_channel->keyframes = (pk_gltf_keyframe*)pk_malloc(sizeof(pk_gltf_keyframe) * num_keyframes);
    pk_assert(pk_channel->keyframes);

    //Determine the number of components expected.
    //Even if the sampler is cubic spline, we force linear so we expect
    //3 for translation/scale and 4 for rotation.
    cgltf_size components = (pk_channel->path == PK_ANIM_PATH_ROTATION) ? 4 : 3;

    for (int i = 0; i < num_keyframes; ++i) {
        pk_channel->keyframes[i].time = 0.0f;

        cgltf_accessor_read_float(gltf_channel->sampler->input, i,
            &pk_channel->keyframes[i].time, 1);

        pk_channel->keyframes[i].value = (float*)pk_malloc(sizeof(float) * components);
        pk_assert(pk_channel->keyframes[i].value);
        cgltf_accessor_read_float(gltf_channel->sampler->output, i,
            pk_channel->keyframes[i].value, components);

    }

    pk_channel->interpolation = get_interpolation_type(gltf_channel->sampler->interpolation);
}

static void load_gltf_animations(cgltf_data* data, pk_gltf_anim* target, pk_model* model) {
    target->num_channels = 0;
    target->duration = 0;

    //Count total animation channels.
    for (int i = 0; i < data->animations_count; ++i) {
        cgltf_animation* anim = &data->animations[i];
        target->num_channels += (int)anim->channels_count;
    }

    target->channels = (pk_gltf_anim_channel*)pk_malloc(target->num_channels * sizeof(pk_gltf_anim_channel));
    pk_assert(target->channels);

    int channel_index = 0;
    for (int i = 0; i < data->animations_count; ++i) {
        cgltf_animation* anim = &data->animations[i];
        for (int j = 0; j < anim->channels_count; ++j) {
            cgltf_animation_channel* gltf_channel = &anim->channels[j];
            pk_gltf_anim_channel* pk_channel = &target->channels[channel_index++];
            extract_animation_channel(gltf_channel, pk_channel, model, data);
            //Update the overall duration.
            for (int k = 0; k < pk_channel->num_keyframes; ++k) {
                if (pk_channel->keyframes[k].time > target->duration) {
                    target->duration = pk_channel->keyframes[k].time;
                }
            }
        }
    }

    target->elapsed_time = 0.0f;
    target->loop = true;
    target->ready = true;
}

bool pk_load_gltf_anim(pk_gltf_anim* anim, pk_model* model, cgltf_data* data) {
    if (data->animations_count > 0) {
        load_gltf_animations(data, anim, model);
        return true;
    }
    else {
        pk_printf("No animations found in gltf file.\n");
        return false;
    }
}

/*
TODO: These are just here, because the initial version used an older version
of handmademath... Remove on occasion.
*/

static float interpolate(float a, float b, float t) {
    return a + t * (b - a);
}

static float quat_dot(HMM_Quat q1, HMM_Quat q2) {
    return (q1.X * q2.X) + (q1.Y * q2.Y) + (q1.Z * q2.Z) + (q1.W * q2.W);
}

static HMM_Quat lerp_quat(HMM_Quat q1, float t, HMM_Quat q2) {
    float x = HMM_Lerp(q1.X, t, q2.X);
    float y = HMM_Lerp(q1.Y, t, q2.Y);
    float z = HMM_Lerp(q1.Z, t, q2.Z);
    float w = HMM_Lerp(q1.W, t, q2.W);
    return HMM_NormQ(HMM_Q(x, y, z, w));
}

static void find_keyframes(float time, pk_gltf_anim_channel* channel, int* key1, int* key2, float* t) {
    int num_keyframes = channel->num_keyframes;
    for (int i = 0; i < num_keyframes - 1; ++i) {
        if (time >= channel->keyframes[i].time && time <= channel->keyframes[i + 1].time) {
            *key1 = i;
            *key2 = i + 1;
            float time1 = channel->keyframes[i].time;
            float time2 = channel->keyframes[i + 1].time;
            *t = (time - time1) / (time2 - time1);
            return;
        }
    }
    //Clamp to the last keyframe if time is beyond the range.
    *key1 = num_keyframes - 1;
    *key2 = num_keyframes - 1;
    *t = 0.0f;
}

static void interpolate_animation(pk_gltf_anim_channel* channel, float current_time) {
    pk_assert(channel);
    int key1 = 0, key2 = 0;
    float t = 0.f;
    find_keyframes(current_time, channel, &key1, &key2, &t);

    //For STEP interpolation, use the first keyframe's value.
    if (channel->interpolation == PK_ANIM_INTERP_STEP) {
        t = 0.0f;
    }

    pk_gltf_keyframe* kf1 = &channel->keyframes[key1];
    pk_gltf_keyframe* kf2 = &channel->keyframes[key2];

    if (channel->path == PK_ANIM_PATH_TRANSLATION) {
        float result[3] = { 0 };
        for (int i = 0; i < 3; ++i) {
            result[i] = interpolate(kf1->value[i], kf2->value[i], t);
        }
        channel->target_node->position = HMM_V3(result[0], result[1], result[2]);
    }
    else if (channel->path == PK_ANIM_PATH_ROTATION) {
        HMM_Quat rot1 = HMM_Q(kf1->value[0], kf1->value[1], kf1->value[2], kf1->value[3]);
        HMM_Quat rot2 = HMM_Q(kf2->value[0], kf2->value[1], kf2->value[2], kf2->value[3]);

        //ensure shortest path by flipping if necessary
        if (quat_dot(rot1, rot2) < 0.0f) {
            rot2.X = -rot2.X;
            rot2.Y = -rot2.Y;
            rot2.Z = -rot2.Z;
            rot2.W = -rot2.W;
        }

        if (quat_dot(rot1, rot2) > 0.9995f) {
            //Use linear interpolation for nearly identical quaternions.
            channel->target_node->rotation = lerp_quat(rot1, t, rot2);
        }
        else {
            channel->target_node->rotation = HMM_NormQ(HMM_SLerp(rot1, t, rot2));
        }
    }
    else if (channel->path == PK_ANIM_PATH_SCALE) {
        float result[3] = { 0 };
        for (int i = 0; i < 3; ++i) {
            result[i] = interpolate(kf1->value[i], kf2->value[i], t);
        }
        channel->target_node->scale = HMM_V3(result[0], result[1], result[2]);
    }
}

//--PUBLIC--------------------------------------------------

void pk_play_gltf_anim(pk_gltf_anim* animation, float dt) {
    pk_assert(animation);
    if (!animation->ready) return;
    animation->elapsed_time += dt;
    if (animation->loop) {
        animation->elapsed_time = fmodf(animation->elapsed_time, animation->duration);
    }
    else if (animation->elapsed_time > animation->duration) {
        animation->elapsed_time = animation->duration;
    }

    for (int i = 0; i < animation->num_channels; ++i) {
        pk_gltf_anim_channel* channel = &animation->channels[i];
        if (channel->target_node) {
            interpolate_animation(channel, animation->elapsed_time);
        }
    }
}

void pk_release_gltf_anim(pk_gltf_anim* anim) {
    pk_assert(anim);
    for (int i = 0; i < anim->num_channels; ++i) {
        pk_gltf_anim_channel* channel = &anim->channels[i];
        pk_assert(channel);
        for (int j = 0; j < channel->num_keyframes; ++j) {
            if (channel->keyframes[j].value != NULL) {
                pk_free(channel->keyframes[j].value);
            }
        }
        if (channel->keyframes != NULL) {
            pk_free(channel->keyframes);
        }
    }
    pk_free(anim->channels);
}


//---------------------------------------------------------------------------------
//--BONE_ANIM----------------------------------------------------------------------
//---------------------------------------------------------------------------------

/*
This is based around the implementation in raylib.
TODO: Make more efficient by not storing every keyframe
and interpolating the poses instead.
*/

static HMM_Mat4 HMM_TRS(HMM_Vec3 pos, HMM_Quat rotation, HMM_Vec3 scale) {
    HMM_Mat4 T = HMM_Translate(pos);
    HMM_Mat4 R = HMM_QToM4(rotation);
    HMM_Mat4 S = HMM_Scale(scale);
    return HMM_MulM4(HMM_MulM4(T, R), S);
}

static HMM_Vec3 HMM_RotateVec3(HMM_Vec3 v, HMM_Quat q) {
    //extract vector part of the quaternion
    HMM_Vec3 qv = HMM_V3(q.X, q.Y, q.Z);
    //compute cross product of qv and v
    HMM_Vec3 uv = HMM_Cross(qv, v);
    //compute cross product of qv and uv
    HMM_Vec3 uuv = HMM_Cross(qv, uv);
    //scale the first cross product by 2*w
    uv = HMM_MulV3F(uv, 2.0f * q.W);
    //scale the second cross product by 2
    uuv = HMM_MulV3F(uuv, 2.0f);
    //add components to the original vector
    return HMM_AddV3(v, HMM_AddV3(uv, uuv));
}

#define M3D_ANIMDELAY 17

pk_bone_anim* pk_load_bone_anims(m3d_t* m3d, int* count) {
    pk_assert(m3d);
    int i = 0, j = 0;
    *count = 0;

    pk_bone_anim* anims = NULL;
    anims = pk_malloc(m3d->numaction*sizeof(pk_bone_anim));
    pk_assert(anims);
    memset(anims, 0, m3d->numaction * sizeof(pk_bone_anim));
    *count = m3d->numaction;

    for (unsigned int a = 0; a < m3d->numaction; a++) {
        anims[a].frame_count = m3d->action[a].durationmsec/M3D_ANIMDELAY;
        anims[a].bone_count = m3d->numbone + 1;
        anims[a].bones = pk_malloc((m3d->numbone + 1)*sizeof(pk_bone));
        anims[a].poses = pk_malloc(anims[a].frame_count*sizeof(pk_transform*));

        for (i = 0; i < (int)m3d->numbone; i++) {
            anims[a].bones[i].parent = m3d->bone[i].parent;
            strncpy(anims[a].bones[i].name, m3d->bone[i].name, PK_MAX_NAME_LEN - 1);
            anims[a].bones[i].name[PK_MAX_NAME_LEN - 1] = '\0';
        }

        //A special, never transformed "no bone" bone, used for boneless vertices.
        anims[a].bones[i].parent = -1;
        strncpy(anims[a].bones[i].name, "NO BONE", PK_MAX_NAME_LEN - 1);
        anims[a].bones[i].name[PK_MAX_NAME_LEN - 1] = '\0';

        /*
        M3D stores frames at arbitrary intervals with sparse skeletons. We need full skeletons at
        //regular intervals, so let the M3D SDK do the heavy lifting and calculate interpolated bones
        //TODO: maybe just store at arbitary intervals and interpolate at runtime during pk_play_bone_anim(...),
        which should be faster.
        */
        for (i = 0; i < anims[a].frame_count; i++) {
            anims[a].poses[i] = pk_malloc((m3d->numbone + 1)*sizeof(pk_transform));

            m3db_t *pose = m3d_pose(m3d, a, i*M3D_ANIMDELAY);

            if (pose != NULL) {
                for (j = 0; j < (int)m3d->numbone; j++) {
                    anims[a].poses[i][j].pos.X = m3d->vertex[pose[j].pos].x*m3d->scale;
                    anims[a].poses[i][j].pos.Y = m3d->vertex[pose[j].pos].y*m3d->scale;
                    anims[a].poses[i][j].pos.Z = m3d->vertex[pose[j].pos].z*m3d->scale;
                    anims[a].poses[i][j].rot.X = m3d->vertex[pose[j].ori].x;
                    anims[a].poses[i][j].rot.Y = m3d->vertex[pose[j].ori].y;
                    anims[a].poses[i][j].rot.Z = m3d->vertex[pose[j].ori].z;
                    anims[a].poses[i][j].rot.W = m3d->vertex[pose[j].ori].w;
                    anims[a].poses[i][j].rot = HMM_NormQ(anims[a].poses[i][j].rot);
                    anims[a].poses[i][j].scale.X = anims[a].poses[i][j].scale.Y = anims[a].poses[i][j].scale.Z = 1.0f;

                    //Child bones are stored in parent bone relative space, convert that into model space!
                    if (anims[a].bones[j].parent >= 0) {
                        anims[a].poses[i][j].rot = HMM_MulQ(anims[a].poses[i][anims[a].bones[j].parent].rot, anims[a].poses[i][j].rot);
                        anims[a].poses[i][j].pos = HMM_RotateVec3(anims[a].poses[i][j].pos, anims[a].poses[i][anims[a].bones[j].parent].rot);
                        anims[a].poses[i][j].pos = HMM_AddV3(anims[a].poses[i][j].pos, anims[a].poses[i][anims[a].bones[j].parent].pos);
                        anims[a].poses[i][j].scale = HMM_MulV3(anims[a].poses[i][j].scale, anims[a].poses[i][anims[a].bones[j].parent].scale);
                    }
                }

                //Default transform for the "no bone" bone
                anims[a].poses[i][j].pos.X = 0.0f;
                anims[a].poses[i][j].pos.Y = 0.0f;
                anims[a].poses[i][j].pos.Z = 0.0f;
                anims[a].poses[i][j].rot.X = 0.0f;
                anims[a].poses[i][j].rot.Y = 0.0f;
                anims[a].poses[i][j].rot.Z = 0.0f;
                anims[a].poses[i][j].rot.W = 1.0f;
                anims[a].poses[i][j].scale = HMM_V3(1.f, 1.f, 1.f);
                pk_free(pose);
            }
        }
    }
    return anims;
}

bool pk_load_skeleton(pk_skeleton* skel, m3d_t* m3d) {
    pk_assert(skel && m3d);

    if (m3d->numbone) {
        skel->bone_count = m3d->numbone + 1;

        skel->bones = pk_malloc(skel->bone_count * sizeof(pk_bone));
        pk_assert(skel->bones);
        memset(skel->bones, 0, sizeof(pk_bone) * skel->bone_count);

        skel->bind_poses = pk_malloc(skel->bone_count * sizeof(pk_transform));
        pk_assert(skel->bind_poses);
        memset(skel->bind_poses, 0, sizeof(pk_transform) * skel->bone_count);

        int i = 0;
        for (i = 0; i < (int)m3d->numbone; i++) {
            skel->bones[i].parent = m3d->bone[i].parent;
            strncpy(skel->bones[i].name, m3d->bone[i].name, PK_MAX_NAME_LEN - 1);
            skel->bones[i].name[PK_MAX_NAME_LEN - 1] = '\0';

            skel->bind_poses[i].pos.X = m3d->vertex[m3d->bone[i].pos].x*m3d->scale;
            skel->bind_poses[i].pos.Y = m3d->vertex[m3d->bone[i].pos].y*m3d->scale;
            skel->bind_poses[i].pos.Z = m3d->vertex[m3d->bone[i].pos].z*m3d->scale;
            skel->bind_poses[i].rot.X = m3d->vertex[m3d->bone[i].ori].x;
            skel->bind_poses[i].rot.Y = m3d->vertex[m3d->bone[i].ori].y;
            skel->bind_poses[i].rot.Z = m3d->vertex[m3d->bone[i].ori].z;
            skel->bind_poses[i].rot.W = m3d->vertex[m3d->bone[i].ori].w;

            skel->bind_poses[i].rot = HMM_NormQ(skel->bind_poses[i].rot);
            skel->bind_poses[i].scale.X = skel->bind_poses[i].scale.Y = skel->bind_poses[i].scale.Z = 1.0f;

            //Child bones are stored in parent bone relative space, convert that into model space..
            if (skel->bones[i].parent >= 0) {
                skel->bind_poses[i].rot = HMM_MulQ(skel->bind_poses[skel->bones[i].parent].rot, skel->bind_poses[i].rot);
                skel->bind_poses[i].pos = HMM_RotateVec3(skel->bind_poses[i].pos, skel->bind_poses[skel->bones[i].parent].rot);
                skel->bind_poses[i].pos = HMM_AddV3(skel->bind_poses[i].pos, skel->bind_poses[skel->bones[i].parent].pos);
                skel->bind_poses[i].scale = HMM_MulV3(skel->bind_poses[i].scale, skel->bind_poses[skel->bones[i].parent].scale);
            }
        }

        //Add a "no bone" bone.
        skel->bones[i].parent = -1;
        strncpy(skel->bones[i].name, "NO BONE", PK_MAX_NAME_LEN - 1);
        skel->bones[i].name[PK_MAX_NAME_LEN - 1] = '\0';
        skel->bind_poses[i].pos = HMM_V3(0.f, 0.f, 0.f);
        skel->bind_poses[i].rot = HMM_Q(0.f, 0.f, 0.f, 1.0f);
        skel->bind_poses[i].scale = HMM_V3(1.f, 1.f, 1.f);

        return true;
    }
    return false;
}

void pk_release_skeleton(pk_skeleton* skel) {
    pk_assert(skel);
    if(skel->bind_poses) {
        pk_free(skel->bind_poses);
    }
    if(skel->bones) {
        pk_free(skel->bones);
    }
}

void pk_play_bone_anim(HMM_Mat4* trs, pk_skeleton* skeleton, pk_bone_anim* anim, float dt){
    if ((anim->frame_count > 0) && (anim->bones != NULL) && (anim->poses != NULL)) {

        anim->time += dt * 1000.0f;  //to milliseconds

        while (anim->time >= M3D_ANIMDELAY) {
            anim->time -= M3D_ANIMDELAY;  //Subtract frame delay to keep timing "accurate".
            anim->frame = (anim->frame + 1) % anim->frame_count;
        }

        for (int id = 0; id < anim->bone_count; id++) {
            HMM_Vec3 in_pos = skeleton->bind_poses[id].pos;
            HMM_Quat in_rot = skeleton->bind_poses[id].rot;
            HMM_Vec3 in_scale = skeleton->bind_poses[id].scale;

            HMM_Vec3 out_pos = anim->poses[anim->frame][id].pos;
            HMM_Quat out_rot = anim->poses[anim->frame][id].rot;
            HMM_Vec3 out_scale = anim->poses[anim->frame][id].scale;

            HMM_Quat inv_rot = HMM_InvQ(in_rot);
            HMM_Vec3 inv_pos = HMM_RotateVec3(HMM_V3(-in_pos.X, -in_pos.Y, -in_pos.Z), inv_rot);
            HMM_Vec3 inv_scale = HMM_DivV3(HMM_V3(1,1,1), in_scale);

            HMM_Vec3 bone_pos = HMM_AddV3(HMM_RotateVec3(HMM_MulV3(out_scale, inv_pos), out_rot), out_pos);
            HMM_Quat bone_rot = HMM_MulQ(out_rot, inv_rot);
            HMM_Vec3 bone_scale = HMM_MulV3(out_scale, inv_scale);

            HMM_Mat4 bone_mat = HMM_MulM4(HMM_MulM4(
                HMM_Translate(bone_pos),
                HMM_QToM4(bone_rot)),
                HMM_Scale(bone_scale)
            );
            trs[id] = bone_mat;
        }
    }
}

void pk_release_bone_anim(pk_bone_anim* anim) {
    if (!anim) return;

    if (anim->poses) {
        for (int i = 0; i < anim->frame_count; ++i) {
            pk_free(anim->poses[i]);
        }
        pk_free(anim->poses);
    }

    if (anim->bones) {
        pk_free(anim->bones);
    }
}


//--IO-----------------------------------------------------------------------------------------------------


//--------------------------------------------------------------------------
//--IMAGE-LOADING-----------------------------------------------------------
//--------------------------------------------------------------------------

typedef struct {
    pk_image_loaded_callback loaded_cb;
    pk_fail_callback fail_cb;
} image_request_data;

// from https://github.com/phoboslab/qoi/blob/master/qoiconv.c
#define ENDS_WITH(str, end) (strcmp(str + strlen(str) - (sizeof(end)-1), end) == 0)

static void _img_fetch_callback(const sfetch_response_t* response) {
    image_request_data data = *(image_request_data*)response->user_data;

    pk_image_data img_data = { 0 };

    if (response->fetched) {
        if (ENDS_WITH(response->path, ".png")) {
            cp_image_t result = cp_load_png_mem(response->buffer.ptr, (int)response->buffer.size);
            img_data.pixels = (void*)result.pix;
            img_data.width = result.w;
            img_data.height = result.h;
            data.loaded_cb(&img_data);
        }
        else if (ENDS_WITH(response->path, ".qoi")) {
            qoi_desc qoi = { 0 };
            img_data.pixels = qoi_decode(response->buffer.ptr, (int)response->buffer.size, &qoi, 4);
            img_data.width = qoi.width;
            img_data.height = qoi.height;
            data.loaded_cb(&img_data);
        }
        else {
            pk_printf("Image format not supported: %s\n", response->path);
            if (data.fail_cb != NULL) {
                data.fail_cb(response);
            }
            else {
                img_data.pixels = (void*)_checker_pixels;
                img_data.width = img_data.height = 4;
                data.loaded_cb(&img_data);
            }
        }
    }
    else if (response->failed) {
        switch (response->error_code) {
        case SFETCH_ERROR_FILE_NOT_FOUND: pk_printf("Image file not found: %s\n", response->path); break;
        case SFETCH_ERROR_BUFFER_TOO_SMALL: pk_printf("Image buffer too small: %s\n", response->path); break;
        default: break;
        }

		if (data.fail_cb != NULL) {
			data.fail_cb(response);
		} else {
            //Note: We pk_malloc() the pixels here, because it is very likely, that the user
            //will attempt, to pk_free() them after use...not very elegant, I know.
            img_data.pixels = pk_malloc(16 * sizeof(uint32_t));
            pk_assert(img_data.pixels);
            memcpy(img_data.pixels, _checker_pixels, 16 * sizeof(uint32_t));
            img_data.width = img_data.height = 4;
            data.loaded_cb(&img_data);
        }
    }
}

sfetch_handle_t pk_load_image_data(const pk_image_request* req) {
	image_request_data data = {
        .loaded_cb = req->loaded_cb,
		.fail_cb = req->fail_cb,
	};

	return sfetch_send(&(sfetch_request_t) {
		.path = req->path,
		.callback = _img_fetch_callback,
		.buffer = req->buffer,
		.user_data = SFETCH_RANGE(data),
	});
}


//-----------------------------------------------------------------------
//--M3D-LOADING----------------------------------------------------------
//-----------------------------------------------------------------------


typedef struct {
    pk_m3d_loaded_callback loaded_cb;
    pk_fail_callback fail_cb;
} m3d_request_data;

void pk_release_m3d_data(m3d_t* data) {
    m3d_free(data);
}

static void _m3d_fetch_callback(const sfetch_response_t* response) {
    m3d_request_data data = *(m3d_request_data*)response->user_data;

    if (response->fetched) {
        m3d_t* m3d = m3d_load((unsigned char*)response->buffer.ptr, NULL, NULL, NULL);
        if (m3d != NULL && data.loaded_cb != NULL) {
			data.loaded_cb(m3d);
        }
        if (!m3d) {
            data.fail_cb(response);
        }
    }
    else if (response->failed) {
        switch (response->error_code) {
        case SFETCH_ERROR_FILE_NOT_FOUND: pk_printf("M3d file not found: %s", response->path); break;
        case SFETCH_ERROR_BUFFER_TOO_SMALL: pk_printf("M3d buffer too small: %s", response->path); break;
        default: break;
        }
        if (data.fail_cb != NULL) {
            data.fail_cb(response);
        }
    }
}

sfetch_handle_t pk_load_m3d_data(const pk_m3d_request* req) {
    m3d_request_data data = {
        .loaded_cb = req->loaded_cb,
        .fail_cb = req->fail_cb,
    };

    return sfetch_send(&(sfetch_request_t) {
        .path = req->path,
		.callback = _m3d_fetch_callback,
		.buffer = req->buffer,
		.user_data = SFETCH_RANGE(data),
    });
}


//-------------------------------------------------------------------------
//--GLTF_LOADING-----------------------------------------------------------
//-------------------------------------------------------------------------


typedef struct {
    pk_gltf_loaded_callback loaded_cb;
    pk_fail_callback fail_cb;
} gltf_request_data;

static void _gltf_fetch_callback(const sfetch_response_t* response) {
    gltf_request_data data = *(gltf_request_data*)response->user_data;

    if (response->fetched) {
		cgltf_options options = {0};
		cgltf_data* gltf = NULL;
        cgltf_result result = cgltf_parse(
            &options,
            response->buffer.ptr,
            response->buffer.size,
            &gltf
		);

		if (result != cgltf_result_success) {
			pk_printf("Failed to load glTF file: %s", response->path);
			return;
		}

		result = cgltf_load_buffers(&options, gltf, response->path);
		if (result != cgltf_result_success) {
			pk_printf("Failed to load glTF buffers: %s", response->path);
			cgltf_free(gltf);
			return;
		}

        if (gltf != NULL && data.loaded_cb != NULL) {
            data.loaded_cb(gltf);
        }

    }
    else if (response->failed) {
        switch (response->error_code) {
        case SFETCH_ERROR_FILE_NOT_FOUND: pk_printf("Gltf file not found: %s\n", response->path); break;
        case SFETCH_ERROR_BUFFER_TOO_SMALL: pk_printf("Gltf buffer too small: %s\n", response->path); break;
        default: break;
        }
        if (data.fail_cb != NULL) {
            data.fail_cb(response);
        }
    }
}

sfetch_handle_t pk_load_gltf_data(const pk_gltf_request* req) {
    gltf_request_data data = {0};
    data.loaded_cb = req->loaded_cb;
    data.fail_cb = req->fail_cb;

    sfetch_request_t r = {0};
    r.path = req->path;
    r.callback = _gltf_fetch_callback;
    r.buffer = req->buffer;
    r.user_data = SFETCH_RANGE(data);
    return sfetch_send(&r);
}

void pk_release_gltf_data(cgltf_data* data) {
    cgltf_free(data);
}
//FILE_END

#endif // POKI_IMPL
